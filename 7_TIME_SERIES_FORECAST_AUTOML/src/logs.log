2023-01-03 20:59:29,150:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-01-03 20:59:29,150:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-01-03 20:59:29,150:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-01-03 20:59:29,150:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-01-03 20:59:30,258:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-01-03 21:02:09,301:INFO:PyCaret RegressionExperiment
2023-01-03 21:02:09,301:INFO:Logging name: reg-default-name
2023-01-03 21:02:09,301:INFO:ML Usecase: MLUsecase.REGRESSION
2023-01-03 21:02:09,301:INFO:version 3.0.0.rc6
2023-01-03 21:02:09,301:INFO:Initializing setup()
2023-01-03 21:02:09,302:INFO:self.USI: 5fa7
2023-01-03 21:02:09,302:INFO:self._variable_keys: {'y_train', '_ml_usecase', 'fold_groups_param', 'fold_shuffle_param', 'logging_param', 'n_jobs_param', 'fold_generator', 'transform_target_param', 'data', 'USI', 'X_test', 'gpu_n_jobs_param', '_available_plots', 'target_param', 'idx', 'exp_id', 'y', 'seed', 'exp_name_log', 'log_plots_param', 'y_test', 'gpu_param', 'memory', 'pipeline', 'X_train', 'X', 'html_param'}
2023-01-03 21:02:09,302:INFO:Checking environment
2023-01-03 21:02:09,302:INFO:python_version: 3.9.13
2023-01-03 21:02:09,302:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-01-03 21:02:09,302:INFO:machine: AMD64
2023-01-03 21:02:09,302:INFO:platform: Windows-10-10.0.19044-SP0
2023-01-03 21:02:09,302:INFO:Memory: svmem(total=17114804224, available=10163564544, percent=40.6, used=6951239680, free=10163564544)
2023-01-03 21:02:09,302:INFO:Physical Core: 4
2023-01-03 21:02:09,302:INFO:Logical Core: 4
2023-01-03 21:02:09,302:INFO:Checking libraries
2023-01-03 21:02:09,302:INFO:System:
2023-01-03 21:02:09,302:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-01-03 21:02:09,302:INFO:executable: c:\Users\Kodotautas\anaconda3\python.exe
2023-01-03 21:02:09,302:INFO:   machine: Windows-10-10.0.19044-SP0
2023-01-03 21:02:09,302:INFO:PyCaret required dependencies:
2023-01-03 21:02:09,302:INFO:                 pip: 22.2.2
2023-01-03 21:02:09,302:INFO:          setuptools: 63.4.1
2023-01-03 21:02:09,303:INFO:             pycaret: 3.0.0rc6
2023-01-03 21:02:09,303:INFO:             IPython: 7.31.1
2023-01-03 21:02:09,303:INFO:          ipywidgets: 7.6.5
2023-01-03 21:02:09,303:INFO:                tqdm: 4.64.1
2023-01-03 21:02:09,303:INFO:               numpy: 1.21.5
2023-01-03 21:02:09,303:INFO:              pandas: 1.4.4
2023-01-03 21:02:09,303:INFO:              jinja2: 2.11.3
2023-01-03 21:02:09,303:INFO:               scipy: 1.9.1
2023-01-03 21:02:09,303:INFO:              joblib: 1.2.0
2023-01-03 21:02:09,303:INFO:             sklearn: 1.0.2
2023-01-03 21:02:09,303:INFO:                pyod: 1.0.7
2023-01-03 21:02:09,303:INFO:            imblearn: 0.10.1
2023-01-03 21:02:09,303:INFO:   category_encoders: 2.5.1.post0
2023-01-03 21:02:09,303:INFO:            lightgbm: 3.3.3
2023-01-03 21:02:09,303:INFO:               numba: 0.55.1
2023-01-03 21:02:09,303:INFO:            requests: 2.28.1
2023-01-03 21:02:09,303:INFO:          matplotlib: 3.5.2
2023-01-03 21:02:09,303:INFO:          scikitplot: 0.3.7
2023-01-03 21:02:09,303:INFO:         yellowbrick: 1.5
2023-01-03 21:02:09,303:INFO:              plotly: 5.9.0
2023-01-03 21:02:09,303:INFO:             kaleido: 0.2.1
2023-01-03 21:02:09,303:INFO:         statsmodels: 0.13.2
2023-01-03 21:02:09,303:INFO:              sktime: 0.14.1
2023-01-03 21:02:09,303:INFO:               tbats: 1.1.2
2023-01-03 21:02:09,304:INFO:            pmdarima: 2.0.2
2023-01-03 21:02:09,304:INFO:              psutil: 5.9.0
2023-01-03 21:02:09,304:INFO:PyCaret optional dependencies:
2023-01-03 21:02:09,743:INFO:                shap: 0.41.0
2023-01-03 21:02:09,743:INFO:           interpret: Not installed
2023-01-03 21:02:09,743:INFO:                umap: Not installed
2023-01-03 21:02:09,743:INFO:    pandas_profiling: Not installed
2023-01-03 21:02:09,743:INFO:  explainerdashboard: Not installed
2023-01-03 21:02:09,744:INFO:             autoviz: Not installed
2023-01-03 21:02:09,744:INFO:           fairlearn: Not installed
2023-01-03 21:02:09,744:INFO:             xgboost: Not installed
2023-01-03 21:02:09,744:INFO:            catboost: Not installed
2023-01-03 21:02:09,744:INFO:              kmodes: Not installed
2023-01-03 21:02:09,744:INFO:             mlxtend: Not installed
2023-01-03 21:02:09,744:INFO:       statsforecast: Not installed
2023-01-03 21:02:09,744:INFO:        tune_sklearn: 0.4.3
2023-01-03 21:02:09,744:INFO:                 ray: 2.0.0
2023-01-03 21:02:09,744:INFO:            hyperopt: 0.2.7
2023-01-03 21:02:09,744:INFO:              optuna: 3.0.1
2023-01-03 21:02:09,744:INFO:               skopt: 0.9.0
2023-01-03 21:02:09,744:INFO:              mlflow: Not installed
2023-01-03 21:02:09,744:INFO:              gradio: Not installed
2023-01-03 21:02:09,744:INFO:             fastapi: 0.88.0
2023-01-03 21:02:09,744:INFO:             uvicorn: 0.20.0
2023-01-03 21:02:09,744:INFO:              m2cgen: Not installed
2023-01-03 21:02:09,745:INFO:           evidently: Not installed
2023-01-03 21:02:09,745:INFO:                nltk: 3.7
2023-01-03 21:02:09,745:INFO:            pyLDAvis: Not installed
2023-01-03 21:02:09,745:INFO:              gensim: 4.1.2
2023-01-03 21:02:09,745:INFO:               spacy: 3.4.2
2023-01-03 21:02:09,745:INFO:           wordcloud: Not installed
2023-01-03 21:02:09,745:INFO:            textblob: Not installed
2023-01-03 21:02:09,745:INFO:               fugue: Not installed
2023-01-03 21:02:09,745:INFO:           streamlit: Not installed
2023-01-03 21:02:09,745:INFO:             prophet: Not installed
2023-01-03 21:02:09,745:INFO:None
2023-01-03 21:02:09,745:INFO:Set up data.
2023-01-03 21:03:52,595:INFO:PyCaret RegressionExperiment
2023-01-03 21:03:52,595:INFO:Logging name: reg-default-name
2023-01-03 21:03:52,596:INFO:ML Usecase: MLUsecase.REGRESSION
2023-01-03 21:03:52,596:INFO:version 3.0.0.rc6
2023-01-03 21:03:52,596:INFO:Initializing setup()
2023-01-03 21:03:52,596:INFO:self.USI: a620
2023-01-03 21:03:52,596:INFO:self._variable_keys: {'y_train', '_ml_usecase', 'fold_groups_param', 'fold_shuffle_param', 'logging_param', 'n_jobs_param', 'fold_generator', 'transform_target_param', 'data', 'USI', 'X_test', 'gpu_n_jobs_param', '_available_plots', 'target_param', 'idx', 'exp_id', 'y', 'seed', 'exp_name_log', 'log_plots_param', 'y_test', 'gpu_param', 'memory', 'pipeline', 'X_train', 'X', 'html_param'}
2023-01-03 21:03:52,596:INFO:Checking environment
2023-01-03 21:03:52,596:INFO:python_version: 3.9.13
2023-01-03 21:03:52,596:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-01-03 21:03:52,597:INFO:machine: AMD64
2023-01-03 21:03:52,597:INFO:platform: Windows-10-10.0.19044-SP0
2023-01-03 21:03:52,597:INFO:Memory: svmem(total=17114804224, available=10178965504, percent=40.5, used=6935838720, free=10178965504)
2023-01-03 21:03:52,597:INFO:Physical Core: 4
2023-01-03 21:03:52,597:INFO:Logical Core: 4
2023-01-03 21:03:52,597:INFO:Checking libraries
2023-01-03 21:03:52,597:INFO:System:
2023-01-03 21:03:52,597:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-01-03 21:03:52,597:INFO:executable: c:\Users\Kodotautas\anaconda3\python.exe
2023-01-03 21:03:52,597:INFO:   machine: Windows-10-10.0.19044-SP0
2023-01-03 21:03:52,597:INFO:PyCaret required dependencies:
2023-01-03 21:03:52,597:INFO:                 pip: 22.2.2
2023-01-03 21:03:52,597:INFO:          setuptools: 63.4.1
2023-01-03 21:03:52,597:INFO:             pycaret: 3.0.0rc6
2023-01-03 21:03:52,597:INFO:             IPython: 7.31.1
2023-01-03 21:03:52,597:INFO:          ipywidgets: 7.6.5
2023-01-03 21:03:52,598:INFO:                tqdm: 4.64.1
2023-01-03 21:03:52,598:INFO:               numpy: 1.21.5
2023-01-03 21:03:52,598:INFO:              pandas: 1.4.4
2023-01-03 21:03:52,598:INFO:              jinja2: 2.11.3
2023-01-03 21:03:52,598:INFO:               scipy: 1.9.1
2023-01-03 21:03:52,598:INFO:              joblib: 1.2.0
2023-01-03 21:03:52,598:INFO:             sklearn: 1.0.2
2023-01-03 21:03:52,598:INFO:                pyod: 1.0.7
2023-01-03 21:03:52,598:INFO:            imblearn: 0.10.1
2023-01-03 21:03:52,598:INFO:   category_encoders: 2.5.1.post0
2023-01-03 21:03:52,598:INFO:            lightgbm: 3.3.3
2023-01-03 21:03:52,598:INFO:               numba: 0.55.1
2023-01-03 21:03:52,599:INFO:            requests: 2.28.1
2023-01-03 21:03:52,599:INFO:          matplotlib: 3.5.2
2023-01-03 21:03:52,599:INFO:          scikitplot: 0.3.7
2023-01-03 21:03:52,599:INFO:         yellowbrick: 1.5
2023-01-03 21:03:52,599:INFO:              plotly: 5.9.0
2023-01-03 21:03:52,599:INFO:             kaleido: 0.2.1
2023-01-03 21:03:52,599:INFO:         statsmodels: 0.13.2
2023-01-03 21:03:52,599:INFO:              sktime: 0.14.1
2023-01-03 21:03:52,599:INFO:               tbats: 1.1.2
2023-01-03 21:03:52,599:INFO:            pmdarima: 2.0.2
2023-01-03 21:03:52,599:INFO:              psutil: 5.9.0
2023-01-03 21:03:52,599:INFO:PyCaret optional dependencies:
2023-01-03 21:03:52,599:INFO:                shap: 0.41.0
2023-01-03 21:03:52,599:INFO:           interpret: Not installed
2023-01-03 21:03:52,599:INFO:                umap: Not installed
2023-01-03 21:03:52,599:INFO:    pandas_profiling: Not installed
2023-01-03 21:03:52,599:INFO:  explainerdashboard: Not installed
2023-01-03 21:03:52,599:INFO:             autoviz: Not installed
2023-01-03 21:03:52,599:INFO:           fairlearn: Not installed
2023-01-03 21:03:52,600:INFO:             xgboost: Not installed
2023-01-03 21:03:52,600:INFO:            catboost: Not installed
2023-01-03 21:03:52,600:INFO:              kmodes: Not installed
2023-01-03 21:03:52,600:INFO:             mlxtend: Not installed
2023-01-03 21:03:52,600:INFO:       statsforecast: Not installed
2023-01-03 21:03:52,600:INFO:        tune_sklearn: 0.4.3
2023-01-03 21:03:52,600:INFO:                 ray: 2.0.0
2023-01-03 21:03:52,600:INFO:            hyperopt: 0.2.7
2023-01-03 21:03:52,600:INFO:              optuna: 3.0.1
2023-01-03 21:03:52,600:INFO:               skopt: 0.9.0
2023-01-03 21:03:52,600:INFO:              mlflow: Not installed
2023-01-03 21:03:52,600:INFO:              gradio: Not installed
2023-01-03 21:03:52,600:INFO:             fastapi: 0.88.0
2023-01-03 21:03:52,600:INFO:             uvicorn: 0.20.0
2023-01-03 21:03:52,600:INFO:              m2cgen: Not installed
2023-01-03 21:03:52,600:INFO:           evidently: Not installed
2023-01-03 21:03:52,600:INFO:                nltk: 3.7
2023-01-03 21:03:52,600:INFO:            pyLDAvis: Not installed
2023-01-03 21:03:52,600:INFO:              gensim: 4.1.2
2023-01-03 21:03:52,600:INFO:               spacy: 3.4.2
2023-01-03 21:03:52,600:INFO:           wordcloud: Not installed
2023-01-03 21:03:52,600:INFO:            textblob: Not installed
2023-01-03 21:03:52,600:INFO:               fugue: Not installed
2023-01-03 21:03:52,600:INFO:           streamlit: Not installed
2023-01-03 21:03:52,601:INFO:             prophet: Not installed
2023-01-03 21:03:52,601:INFO:None
2023-01-03 21:03:52,601:INFO:Set up data.
2023-01-03 21:03:52,617:INFO:Set up train/test split.
2023-01-03 21:03:52,628:INFO:Set up index.
2023-01-03 21:03:52,630:INFO:Set up folding strategy.
2023-01-03 21:03:52,631:INFO:Assigning column types.
2023-01-03 21:03:52,639:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-01-03 21:03:52,640:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-01-03 21:03:52,644:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-03 21:03:52,650:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 21:03:52,720:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 21:03:52,768:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 21:03:52,768:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:03:52,918:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:03:52,918:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-01-03 21:03:52,923:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-03 21:03:52,928:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 21:03:52,995:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 21:03:53,041:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 21:03:53,042:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:03:53,042:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:03:53,042:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-01-03 21:03:53,048:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-03 21:03:53,052:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 21:03:53,119:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 21:03:53,166:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 21:03:53,166:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:03:53,167:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:03:53,171:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-03 21:03:53,176:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 21:03:53,241:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 21:03:53,289:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 21:03:53,289:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:03:53,289:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:03:53,290:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-01-03 21:03:53,301:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 21:03:53,370:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 21:03:53,418:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 21:03:53,419:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:03:53,419:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:03:53,429:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 21:03:53,496:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 21:03:53,543:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 21:03:53,543:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:03:53,544:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:03:53,544:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-01-03 21:03:53,621:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 21:03:53,668:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 21:03:53,669:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:03:53,669:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:03:53,746:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 21:03:53,794:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 21:03:53,795:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:03:53,795:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:03:53,796:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-01-03 21:03:53,874:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 21:03:53,922:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:03:53,922:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:03:54,000:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 21:03:54,045:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:03:54,046:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:03:54,046:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-01-03 21:03:54,171:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:03:54,171:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:03:54,292:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:03:54,292:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:03:54,293:INFO:Preparing preprocessing pipeline...
2023-01-03 21:03:54,295:INFO:Set up simple imputation.
2023-01-03 21:03:54,295:INFO:Set up removing multicollinearity.
2023-01-03 21:03:54,295:INFO:Set up removing outliers.
2023-01-03 21:03:54,295:INFO:Set up column transformation.
2023-01-03 21:03:54,295:INFO:Set up feature normalization.
2023-01-03 21:03:54,295:INFO:Set up feature selection.
2023-01-03 21:03:54,420:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:03:54,420:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:05:11,748:INFO:PyCaret RegressionExperiment
2023-01-03 21:05:11,749:INFO:Logging name: reg-default-name
2023-01-03 21:05:11,749:INFO:ML Usecase: MLUsecase.REGRESSION
2023-01-03 21:05:11,749:INFO:version 3.0.0.rc6
2023-01-03 21:05:11,749:INFO:Initializing setup()
2023-01-03 21:05:11,749:INFO:self.USI: 6588
2023-01-03 21:05:11,749:INFO:self._variable_keys: {'y_train', '_ml_usecase', 'fold_groups_param', 'fold_shuffle_param', 'logging_param', 'n_jobs_param', 'fold_generator', 'transform_target_param', 'data', 'USI', 'X_test', 'gpu_n_jobs_param', '_available_plots', 'target_param', 'idx', 'exp_id', 'y', 'seed', 'exp_name_log', 'log_plots_param', 'y_test', 'gpu_param', 'memory', 'pipeline', 'X_train', 'X', 'html_param'}
2023-01-03 21:05:11,749:INFO:Checking environment
2023-01-03 21:05:11,749:INFO:python_version: 3.9.13
2023-01-03 21:05:11,749:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-01-03 21:05:11,749:INFO:machine: AMD64
2023-01-03 21:05:11,749:INFO:platform: Windows-10-10.0.19044-SP0
2023-01-03 21:05:11,749:INFO:Memory: svmem(total=17114804224, available=10324582400, percent=39.7, used=6790221824, free=10324582400)
2023-01-03 21:05:11,749:INFO:Physical Core: 4
2023-01-03 21:05:11,749:INFO:Logical Core: 4
2023-01-03 21:05:11,749:INFO:Checking libraries
2023-01-03 21:05:11,749:INFO:System:
2023-01-03 21:05:11,749:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-01-03 21:05:11,749:INFO:executable: c:\Users\Kodotautas\anaconda3\python.exe
2023-01-03 21:05:11,749:INFO:   machine: Windows-10-10.0.19044-SP0
2023-01-03 21:05:11,750:INFO:PyCaret required dependencies:
2023-01-03 21:05:11,750:INFO:                 pip: 22.2.2
2023-01-03 21:05:11,750:INFO:          setuptools: 63.4.1
2023-01-03 21:05:11,750:INFO:             pycaret: 3.0.0rc6
2023-01-03 21:05:11,750:INFO:             IPython: 7.31.1
2023-01-03 21:05:11,750:INFO:          ipywidgets: 7.6.5
2023-01-03 21:05:11,750:INFO:                tqdm: 4.64.1
2023-01-03 21:05:11,750:INFO:               numpy: 1.21.5
2023-01-03 21:05:11,750:INFO:              pandas: 1.4.4
2023-01-03 21:05:11,750:INFO:              jinja2: 2.11.3
2023-01-03 21:05:11,750:INFO:               scipy: 1.9.1
2023-01-03 21:05:11,750:INFO:              joblib: 1.2.0
2023-01-03 21:05:11,750:INFO:             sklearn: 1.0.2
2023-01-03 21:05:11,750:INFO:                pyod: 1.0.7
2023-01-03 21:05:11,750:INFO:            imblearn: 0.10.1
2023-01-03 21:05:11,750:INFO:   category_encoders: 2.5.1.post0
2023-01-03 21:05:11,751:INFO:            lightgbm: 3.3.3
2023-01-03 21:05:11,751:INFO:               numba: 0.55.1
2023-01-03 21:05:11,751:INFO:            requests: 2.28.1
2023-01-03 21:05:11,751:INFO:          matplotlib: 3.5.2
2023-01-03 21:05:11,751:INFO:          scikitplot: 0.3.7
2023-01-03 21:05:11,751:INFO:         yellowbrick: 1.5
2023-01-03 21:05:11,751:INFO:              plotly: 5.9.0
2023-01-03 21:05:11,751:INFO:             kaleido: 0.2.1
2023-01-03 21:05:11,751:INFO:         statsmodels: 0.13.2
2023-01-03 21:05:11,751:INFO:              sktime: 0.14.1
2023-01-03 21:05:11,751:INFO:               tbats: 1.1.2
2023-01-03 21:05:11,751:INFO:            pmdarima: 2.0.2
2023-01-03 21:05:11,751:INFO:              psutil: 5.9.0
2023-01-03 21:05:11,751:INFO:PyCaret optional dependencies:
2023-01-03 21:05:11,751:INFO:                shap: 0.41.0
2023-01-03 21:05:11,751:INFO:           interpret: Not installed
2023-01-03 21:05:11,751:INFO:                umap: Not installed
2023-01-03 21:05:11,751:INFO:    pandas_profiling: Not installed
2023-01-03 21:05:11,751:INFO:  explainerdashboard: Not installed
2023-01-03 21:05:11,751:INFO:             autoviz: Not installed
2023-01-03 21:05:11,751:INFO:           fairlearn: Not installed
2023-01-03 21:05:11,751:INFO:             xgboost: Not installed
2023-01-03 21:05:11,752:INFO:            catboost: Not installed
2023-01-03 21:05:11,752:INFO:              kmodes: Not installed
2023-01-03 21:05:11,752:INFO:             mlxtend: Not installed
2023-01-03 21:05:11,752:INFO:       statsforecast: Not installed
2023-01-03 21:05:11,752:INFO:        tune_sklearn: 0.4.3
2023-01-03 21:05:11,752:INFO:                 ray: 2.0.0
2023-01-03 21:05:11,752:INFO:            hyperopt: 0.2.7
2023-01-03 21:05:11,752:INFO:              optuna: 3.0.1
2023-01-03 21:05:11,752:INFO:               skopt: 0.9.0
2023-01-03 21:05:11,752:INFO:              mlflow: Not installed
2023-01-03 21:05:11,752:INFO:              gradio: Not installed
2023-01-03 21:05:11,752:INFO:             fastapi: 0.88.0
2023-01-03 21:05:11,752:INFO:             uvicorn: 0.20.0
2023-01-03 21:05:11,752:INFO:              m2cgen: Not installed
2023-01-03 21:05:11,752:INFO:           evidently: Not installed
2023-01-03 21:05:11,752:INFO:                nltk: 3.7
2023-01-03 21:05:11,752:INFO:            pyLDAvis: Not installed
2023-01-03 21:05:11,752:INFO:              gensim: 4.1.2
2023-01-03 21:05:11,752:INFO:               spacy: 3.4.2
2023-01-03 21:05:11,752:INFO:           wordcloud: Not installed
2023-01-03 21:05:11,752:INFO:            textblob: Not installed
2023-01-03 21:05:11,752:INFO:               fugue: Not installed
2023-01-03 21:05:11,752:INFO:           streamlit: Not installed
2023-01-03 21:05:11,753:INFO:             prophet: Not installed
2023-01-03 21:05:11,753:INFO:None
2023-01-03 21:05:11,753:INFO:Set up data.
2023-01-03 21:05:11,770:INFO:Set up train/test split.
2023-01-03 21:05:11,780:INFO:Set up index.
2023-01-03 21:05:11,782:INFO:Set up folding strategy.
2023-01-03 21:05:11,782:INFO:Assigning column types.
2023-01-03 21:05:11,791:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-01-03 21:05:11,791:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-01-03 21:05:11,796:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-03 21:05:11,801:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 21:05:11,866:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 21:05:11,917:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 21:05:11,917:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:05:11,918:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:05:11,918:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-01-03 21:05:11,923:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-03 21:05:11,928:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 21:05:11,996:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 21:05:12,044:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 21:05:12,044:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:05:12,045:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:05:12,045:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-01-03 21:05:12,050:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-03 21:05:12,055:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 21:05:12,122:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 21:05:12,170:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 21:05:12,171:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:05:12,171:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:05:12,176:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-03 21:05:12,181:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 21:05:12,249:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 21:05:12,295:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 21:05:12,296:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:05:12,296:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:05:12,297:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-01-03 21:05:12,307:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 21:05:12,372:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 21:05:12,418:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 21:05:12,419:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:05:12,419:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:05:12,429:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 21:05:12,496:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 21:05:12,542:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 21:05:12,543:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:05:12,543:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:05:12,544:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-01-03 21:05:12,619:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 21:05:12,665:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 21:05:12,665:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:05:12,666:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:05:12,745:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 21:05:12,792:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 21:05:12,793:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:05:12,793:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:05:12,793:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-01-03 21:05:12,868:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 21:05:12,914:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:05:12,915:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:05:12,991:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 21:05:13,039:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:05:13,039:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:05:13,039:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-01-03 21:05:13,161:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:05:13,161:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:05:13,283:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:05:13,283:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:05:13,285:INFO:Preparing preprocessing pipeline...
2023-01-03 21:05:13,287:INFO:Set up simple imputation.
2023-01-03 21:05:13,287:INFO:Set up column transformation.
2023-01-03 21:05:13,287:INFO:Set up feature normalization.
2023-01-03 21:05:13,732:INFO:Finished creating preprocessing pipeline.
2023-01-03 21:05:13,738:INFO:Pipeline: Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2023-01-03 21:05:13,739:INFO:Creating final display dataframe.
2023-01-03 21:05:14,277:INFO:Setup _display_container:                Description             Value
0               Session id               123
1                   Target        b2b+b2c+vt
2              Target type        Regression
3               Data shape       (11081, 38)
4         Train data shape        (7756, 38)
5          Test data shape        (3325, 38)
6         Numeric features                 8
7               Preprocess              True
8          Imputation type            simple
9       Numeric imputation              mean
10  Categorical imputation              mode
11          Transformation              True
12   Transformation method       yeo-johnson
13               Normalize              True
14        Normalize method            zscore
15          Fold Generator   TimeSeriesSplit
16             Fold Number                 5
17                CPU Jobs                -1
18                 Use GPU             False
19          Log Experiment             False
20         Experiment Name  reg-default-name
21                     USI              6588
2023-01-03 21:05:14,416:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:05:14,416:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:05:14,599:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:05:14,600:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:05:14,602:INFO:setup() successfully completed in 2.85s...............
2023-01-03 21:05:14,603:INFO:Initializing compare_models()
2023-01-03 21:05:14,603:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024E553620D0>, include=None, fold=None, round=4, cross_validation=True, sort=MAE, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x0000024E553620D0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'MAE', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-01-03 21:05:14,603:INFO:Checking exceptions
2023-01-03 21:05:14,608:INFO:Preparing display monitor
2023-01-03 21:05:14,670:INFO:Initializing Linear Regression
2023-01-03 21:05:14,670:INFO:Total runtime is 0.0 minutes
2023-01-03 21:05:14,676:INFO:SubProcess create_model() called ==================================
2023-01-03 21:05:14,677:INFO:Initializing create_model()
2023-01-03 21:05:14,677:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024E553620D0>, estimator=lr, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024E55416220>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:05:14,677:INFO:Checking exceptions
2023-01-03 21:05:14,677:INFO:Importing libraries
2023-01-03 21:05:14,677:INFO:Copying training dataset
2023-01-03 21:05:14,686:INFO:Defining folds
2023-01-03 21:05:14,686:INFO:Declaring metric variables
2023-01-03 21:05:14,691:INFO:Importing untrained model
2023-01-03 21:05:14,695:INFO:Linear Regression Imported successfully
2023-01-03 21:05:14,719:INFO:Starting cross validation
2023-01-03 21:05:14,729:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:05:21,436:INFO:Calculating mean and std
2023-01-03 21:05:21,438:INFO:Creating metrics dataframe
2023-01-03 21:05:21,441:INFO:Uploading results into container
2023-01-03 21:05:21,441:INFO:Uploading model into container now
2023-01-03 21:05:21,441:INFO:_master_model_container: 1
2023-01-03 21:05:21,442:INFO:_display_container: 2
2023-01-03 21:05:21,442:INFO:LinearRegression(n_jobs=-1)
2023-01-03 21:05:21,442:INFO:create_model() successfully completed......................................
2023-01-03 21:05:21,546:INFO:SubProcess create_model() end ==================================
2023-01-03 21:05:21,546:INFO:Creating metrics dataframe
2023-01-03 21:05:21,554:INFO:Initializing Lasso Regression
2023-01-03 21:05:21,555:INFO:Total runtime is 0.11475303967793783 minutes
2023-01-03 21:05:21,559:INFO:SubProcess create_model() called ==================================
2023-01-03 21:05:21,560:INFO:Initializing create_model()
2023-01-03 21:05:21,560:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024E553620D0>, estimator=lasso, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024E55416220>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:05:21,560:INFO:Checking exceptions
2023-01-03 21:05:21,560:INFO:Importing libraries
2023-01-03 21:05:21,560:INFO:Copying training dataset
2023-01-03 21:05:21,569:INFO:Defining folds
2023-01-03 21:05:21,570:INFO:Declaring metric variables
2023-01-03 21:05:21,574:INFO:Importing untrained model
2023-01-03 21:05:21,578:INFO:Lasso Regression Imported successfully
2023-01-03 21:05:21,588:INFO:Starting cross validation
2023-01-03 21:05:21,589:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:05:22,009:INFO:Calculating mean and std
2023-01-03 21:05:22,011:INFO:Creating metrics dataframe
2023-01-03 21:05:22,014:INFO:Uploading results into container
2023-01-03 21:05:22,014:INFO:Uploading model into container now
2023-01-03 21:05:22,015:INFO:_master_model_container: 2
2023-01-03 21:05:22,015:INFO:_display_container: 2
2023-01-03 21:05:22,016:INFO:Lasso(random_state=123)
2023-01-03 21:05:22,016:INFO:create_model() successfully completed......................................
2023-01-03 21:05:22,117:INFO:SubProcess create_model() end ==================================
2023-01-03 21:05:22,117:INFO:Creating metrics dataframe
2023-01-03 21:05:22,127:INFO:Initializing Ridge Regression
2023-01-03 21:05:22,128:INFO:Total runtime is 0.12430305480957032 minutes
2023-01-03 21:05:22,132:INFO:SubProcess create_model() called ==================================
2023-01-03 21:05:22,132:INFO:Initializing create_model()
2023-01-03 21:05:22,132:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024E553620D0>, estimator=ridge, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024E55416220>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:05:22,132:INFO:Checking exceptions
2023-01-03 21:05:22,132:INFO:Importing libraries
2023-01-03 21:05:22,132:INFO:Copying training dataset
2023-01-03 21:05:22,141:INFO:Defining folds
2023-01-03 21:05:22,141:INFO:Declaring metric variables
2023-01-03 21:05:22,146:INFO:Importing untrained model
2023-01-03 21:05:22,151:INFO:Ridge Regression Imported successfully
2023-01-03 21:05:22,160:INFO:Starting cross validation
2023-01-03 21:05:22,162:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:05:22,404:INFO:Calculating mean and std
2023-01-03 21:05:22,406:INFO:Creating metrics dataframe
2023-01-03 21:05:22,409:INFO:Uploading results into container
2023-01-03 21:05:22,409:INFO:Uploading model into container now
2023-01-03 21:05:22,409:INFO:_master_model_container: 3
2023-01-03 21:05:22,410:INFO:_display_container: 2
2023-01-03 21:05:22,410:INFO:Ridge(random_state=123)
2023-01-03 21:05:22,410:INFO:create_model() successfully completed......................................
2023-01-03 21:05:22,513:INFO:SubProcess create_model() end ==================================
2023-01-03 21:05:22,513:INFO:Creating metrics dataframe
2023-01-03 21:05:22,526:INFO:Initializing Elastic Net
2023-01-03 21:05:22,526:INFO:Total runtime is 0.13093318939208987 minutes
2023-01-03 21:05:22,530:INFO:SubProcess create_model() called ==================================
2023-01-03 21:05:22,531:INFO:Initializing create_model()
2023-01-03 21:05:22,531:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024E553620D0>, estimator=en, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024E55416220>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:05:22,531:INFO:Checking exceptions
2023-01-03 21:05:22,531:INFO:Importing libraries
2023-01-03 21:05:22,531:INFO:Copying training dataset
2023-01-03 21:05:22,541:INFO:Defining folds
2023-01-03 21:05:22,541:INFO:Declaring metric variables
2023-01-03 21:05:22,545:INFO:Importing untrained model
2023-01-03 21:05:22,549:INFO:Elastic Net Imported successfully
2023-01-03 21:05:22,559:INFO:Starting cross validation
2023-01-03 21:05:22,560:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:05:22,796:INFO:Calculating mean and std
2023-01-03 21:05:22,798:INFO:Creating metrics dataframe
2023-01-03 21:05:22,801:INFO:Uploading results into container
2023-01-03 21:05:22,801:INFO:Uploading model into container now
2023-01-03 21:05:22,802:INFO:_master_model_container: 4
2023-01-03 21:05:22,802:INFO:_display_container: 2
2023-01-03 21:05:22,802:INFO:ElasticNet(random_state=123)
2023-01-03 21:05:22,802:INFO:create_model() successfully completed......................................
2023-01-03 21:05:22,902:INFO:SubProcess create_model() end ==================================
2023-01-03 21:05:22,903:INFO:Creating metrics dataframe
2023-01-03 21:05:22,914:INFO:Initializing Least Angle Regression
2023-01-03 21:05:22,915:INFO:Total runtime is 0.13742141326268517 minutes
2023-01-03 21:05:22,920:INFO:SubProcess create_model() called ==================================
2023-01-03 21:05:22,921:INFO:Initializing create_model()
2023-01-03 21:05:22,921:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024E553620D0>, estimator=lar, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024E55416220>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:05:22,921:INFO:Checking exceptions
2023-01-03 21:05:22,921:INFO:Importing libraries
2023-01-03 21:05:22,921:INFO:Copying training dataset
2023-01-03 21:05:22,930:INFO:Defining folds
2023-01-03 21:05:22,930:INFO:Declaring metric variables
2023-01-03 21:05:22,935:INFO:Importing untrained model
2023-01-03 21:05:22,939:INFO:Least Angle Regression Imported successfully
2023-01-03 21:05:22,948:INFO:Starting cross validation
2023-01-03 21:05:22,950:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:05:22,998:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 21:05:23,005:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 21:05:23,014:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 21:05:23,037:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 21:05:23,063:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 21:05:23,192:INFO:Calculating mean and std
2023-01-03 21:05:23,194:INFO:Creating metrics dataframe
2023-01-03 21:05:23,197:INFO:Uploading results into container
2023-01-03 21:05:23,197:INFO:Uploading model into container now
2023-01-03 21:05:23,197:INFO:_master_model_container: 5
2023-01-03 21:05:23,198:INFO:_display_container: 2
2023-01-03 21:05:23,198:INFO:Lars(random_state=123)
2023-01-03 21:05:23,198:INFO:create_model() successfully completed......................................
2023-01-03 21:05:23,304:INFO:SubProcess create_model() end ==================================
2023-01-03 21:05:23,304:INFO:Creating metrics dataframe
2023-01-03 21:05:23,317:INFO:Initializing Lasso Least Angle Regression
2023-01-03 21:05:23,317:INFO:Total runtime is 0.1441238363583883 minutes
2023-01-03 21:05:23,322:INFO:SubProcess create_model() called ==================================
2023-01-03 21:05:23,323:INFO:Initializing create_model()
2023-01-03 21:05:23,323:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024E553620D0>, estimator=llar, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024E55416220>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:05:23,323:INFO:Checking exceptions
2023-01-03 21:05:23,323:INFO:Importing libraries
2023-01-03 21:05:23,323:INFO:Copying training dataset
2023-01-03 21:05:23,342:INFO:Defining folds
2023-01-03 21:05:23,342:INFO:Declaring metric variables
2023-01-03 21:05:23,346:INFO:Importing untrained model
2023-01-03 21:05:23,352:INFO:Lasso Least Angle Regression Imported successfully
2023-01-03 21:05:23,362:INFO:Starting cross validation
2023-01-03 21:05:23,363:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:05:23,413:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-03 21:05:23,417:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-03 21:05:23,427:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-03 21:05:23,439:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-03 21:05:23,475:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-03 21:05:23,603:INFO:Calculating mean and std
2023-01-03 21:05:23,605:INFO:Creating metrics dataframe
2023-01-03 21:05:23,608:INFO:Uploading results into container
2023-01-03 21:05:23,609:INFO:Uploading model into container now
2023-01-03 21:05:23,609:INFO:_master_model_container: 6
2023-01-03 21:05:23,609:INFO:_display_container: 2
2023-01-03 21:05:23,610:INFO:LassoLars(random_state=123)
2023-01-03 21:05:23,610:INFO:create_model() successfully completed......................................
2023-01-03 21:05:23,713:INFO:SubProcess create_model() end ==================================
2023-01-03 21:05:23,713:INFO:Creating metrics dataframe
2023-01-03 21:05:23,724:INFO:Initializing Orthogonal Matching Pursuit
2023-01-03 21:05:23,724:INFO:Total runtime is 0.15090714693069462 minutes
2023-01-03 21:05:23,728:INFO:SubProcess create_model() called ==================================
2023-01-03 21:05:23,728:INFO:Initializing create_model()
2023-01-03 21:05:23,728:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024E553620D0>, estimator=omp, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024E55416220>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:05:23,728:INFO:Checking exceptions
2023-01-03 21:05:23,728:INFO:Importing libraries
2023-01-03 21:05:23,728:INFO:Copying training dataset
2023-01-03 21:05:23,737:INFO:Defining folds
2023-01-03 21:05:23,738:INFO:Declaring metric variables
2023-01-03 21:05:23,742:INFO:Importing untrained model
2023-01-03 21:05:23,746:INFO:Orthogonal Matching Pursuit Imported successfully
2023-01-03 21:05:23,756:INFO:Starting cross validation
2023-01-03 21:05:23,757:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:05:23,805:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 21:05:23,810:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 21:05:23,819:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 21:05:23,832:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 21:05:23,862:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 21:05:23,998:INFO:Calculating mean and std
2023-01-03 21:05:24,000:INFO:Creating metrics dataframe
2023-01-03 21:05:24,003:INFO:Uploading results into container
2023-01-03 21:05:24,006:INFO:Uploading model into container now
2023-01-03 21:05:24,006:INFO:_master_model_container: 7
2023-01-03 21:05:24,006:INFO:_display_container: 2
2023-01-03 21:05:24,006:INFO:OrthogonalMatchingPursuit()
2023-01-03 21:05:24,007:INFO:create_model() successfully completed......................................
2023-01-03 21:05:24,107:INFO:SubProcess create_model() end ==================================
2023-01-03 21:05:24,108:INFO:Creating metrics dataframe
2023-01-03 21:05:24,118:INFO:Initializing Bayesian Ridge
2023-01-03 21:05:24,119:INFO:Total runtime is 0.15749195814132694 minutes
2023-01-03 21:05:24,123:INFO:SubProcess create_model() called ==================================
2023-01-03 21:05:24,123:INFO:Initializing create_model()
2023-01-03 21:05:24,124:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024E553620D0>, estimator=br, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024E55416220>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:05:24,124:INFO:Checking exceptions
2023-01-03 21:05:24,124:INFO:Importing libraries
2023-01-03 21:05:24,124:INFO:Copying training dataset
2023-01-03 21:05:24,132:INFO:Defining folds
2023-01-03 21:05:24,132:INFO:Declaring metric variables
2023-01-03 21:05:24,138:INFO:Importing untrained model
2023-01-03 21:05:24,142:INFO:Bayesian Ridge Imported successfully
2023-01-03 21:05:24,152:INFO:Starting cross validation
2023-01-03 21:05:24,153:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:05:24,413:INFO:Calculating mean and std
2023-01-03 21:05:24,415:INFO:Creating metrics dataframe
2023-01-03 21:05:24,420:INFO:Uploading results into container
2023-01-03 21:05:24,421:INFO:Uploading model into container now
2023-01-03 21:05:24,421:INFO:_master_model_container: 8
2023-01-03 21:05:24,421:INFO:_display_container: 2
2023-01-03 21:05:24,422:INFO:BayesianRidge()
2023-01-03 21:05:24,422:INFO:create_model() successfully completed......................................
2023-01-03 21:05:24,556:INFO:SubProcess create_model() end ==================================
2023-01-03 21:05:24,556:INFO:Creating metrics dataframe
2023-01-03 21:05:24,579:INFO:Initializing Passive Aggressive Regressor
2023-01-03 21:05:24,579:INFO:Total runtime is 0.16516103744506838 minutes
2023-01-03 21:05:24,583:INFO:SubProcess create_model() called ==================================
2023-01-03 21:05:24,584:INFO:Initializing create_model()
2023-01-03 21:05:24,584:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024E553620D0>, estimator=par, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024E55416220>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:05:24,584:INFO:Checking exceptions
2023-01-03 21:05:24,584:INFO:Importing libraries
2023-01-03 21:05:24,584:INFO:Copying training dataset
2023-01-03 21:05:24,593:INFO:Defining folds
2023-01-03 21:05:24,594:INFO:Declaring metric variables
2023-01-03 21:05:24,598:INFO:Importing untrained model
2023-01-03 21:05:24,602:INFO:Passive Aggressive Regressor Imported successfully
2023-01-03 21:05:24,629:INFO:Starting cross validation
2023-01-03 21:05:24,630:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:05:24,879:INFO:Calculating mean and std
2023-01-03 21:05:24,881:INFO:Creating metrics dataframe
2023-01-03 21:05:24,885:INFO:Uploading results into container
2023-01-03 21:05:24,886:INFO:Uploading model into container now
2023-01-03 21:05:24,886:INFO:_master_model_container: 9
2023-01-03 21:05:24,886:INFO:_display_container: 2
2023-01-03 21:05:24,887:INFO:PassiveAggressiveRegressor(random_state=123)
2023-01-03 21:05:24,887:INFO:create_model() successfully completed......................................
2023-01-03 21:05:24,994:INFO:SubProcess create_model() end ==================================
2023-01-03 21:05:24,994:INFO:Creating metrics dataframe
2023-01-03 21:05:25,008:INFO:Initializing Huber Regressor
2023-01-03 21:05:25,008:INFO:Total runtime is 0.17231099208196007 minutes
2023-01-03 21:05:25,011:INFO:SubProcess create_model() called ==================================
2023-01-03 21:05:25,012:INFO:Initializing create_model()
2023-01-03 21:05:25,012:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024E553620D0>, estimator=huber, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024E55416220>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:05:25,012:INFO:Checking exceptions
2023-01-03 21:05:25,012:INFO:Importing libraries
2023-01-03 21:05:25,012:INFO:Copying training dataset
2023-01-03 21:05:25,021:INFO:Defining folds
2023-01-03 21:05:25,022:INFO:Declaring metric variables
2023-01-03 21:05:25,025:INFO:Importing untrained model
2023-01-03 21:05:25,030:INFO:Huber Regressor Imported successfully
2023-01-03 21:05:25,040:INFO:Starting cross validation
2023-01-03 21:05:25,041:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:05:25,152:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-03 21:05:25,213:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-03 21:05:25,345:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-03 21:05:25,403:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-03 21:05:25,549:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-03 21:05:25,672:INFO:Calculating mean and std
2023-01-03 21:05:25,674:INFO:Creating metrics dataframe
2023-01-03 21:05:25,677:INFO:Uploading results into container
2023-01-03 21:05:25,677:INFO:Uploading model into container now
2023-01-03 21:05:25,678:INFO:_master_model_container: 10
2023-01-03 21:05:25,678:INFO:_display_container: 2
2023-01-03 21:05:25,678:INFO:HuberRegressor()
2023-01-03 21:05:25,678:INFO:create_model() successfully completed......................................
2023-01-03 21:05:25,776:INFO:SubProcess create_model() end ==================================
2023-01-03 21:05:25,776:INFO:Creating metrics dataframe
2023-01-03 21:05:25,792:INFO:Initializing K Neighbors Regressor
2023-01-03 21:05:25,793:INFO:Total runtime is 0.1853847185770671 minutes
2023-01-03 21:05:25,797:INFO:SubProcess create_model() called ==================================
2023-01-03 21:05:25,797:INFO:Initializing create_model()
2023-01-03 21:05:25,797:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024E553620D0>, estimator=knn, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024E55416220>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:05:25,798:INFO:Checking exceptions
2023-01-03 21:05:25,798:INFO:Importing libraries
2023-01-03 21:05:25,798:INFO:Copying training dataset
2023-01-03 21:05:25,807:INFO:Defining folds
2023-01-03 21:05:25,807:INFO:Declaring metric variables
2023-01-03 21:05:25,811:INFO:Importing untrained model
2023-01-03 21:05:25,815:INFO:K Neighbors Regressor Imported successfully
2023-01-03 21:05:25,829:INFO:Starting cross validation
2023-01-03 21:05:25,830:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:05:26,638:INFO:Calculating mean and std
2023-01-03 21:05:26,640:INFO:Creating metrics dataframe
2023-01-03 21:05:26,643:INFO:Uploading results into container
2023-01-03 21:05:26,643:INFO:Uploading model into container now
2023-01-03 21:05:26,644:INFO:_master_model_container: 11
2023-01-03 21:05:26,644:INFO:_display_container: 2
2023-01-03 21:05:26,644:INFO:KNeighborsRegressor(n_jobs=-1)
2023-01-03 21:05:26,644:INFO:create_model() successfully completed......................................
2023-01-03 21:05:26,755:INFO:SubProcess create_model() end ==================================
2023-01-03 21:05:26,755:INFO:Creating metrics dataframe
2023-01-03 21:05:26,771:INFO:Initializing Decision Tree Regressor
2023-01-03 21:05:26,771:INFO:Total runtime is 0.20168573856353764 minutes
2023-01-03 21:05:26,776:INFO:SubProcess create_model() called ==================================
2023-01-03 21:05:26,777:INFO:Initializing create_model()
2023-01-03 21:05:26,777:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024E553620D0>, estimator=dt, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024E55416220>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:05:26,777:INFO:Checking exceptions
2023-01-03 21:05:26,777:INFO:Importing libraries
2023-01-03 21:05:26,778:INFO:Copying training dataset
2023-01-03 21:05:26,788:INFO:Defining folds
2023-01-03 21:05:26,788:INFO:Declaring metric variables
2023-01-03 21:05:26,794:INFO:Importing untrained model
2023-01-03 21:05:26,798:INFO:Decision Tree Regressor Imported successfully
2023-01-03 21:05:26,809:INFO:Starting cross validation
2023-01-03 21:05:26,811:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:05:27,241:INFO:Calculating mean and std
2023-01-03 21:05:27,243:INFO:Creating metrics dataframe
2023-01-03 21:05:27,246:INFO:Uploading results into container
2023-01-03 21:05:27,246:INFO:Uploading model into container now
2023-01-03 21:05:27,247:INFO:_master_model_container: 12
2023-01-03 21:05:27,247:INFO:_display_container: 2
2023-01-03 21:05:27,247:INFO:DecisionTreeRegressor(random_state=123)
2023-01-03 21:05:27,247:INFO:create_model() successfully completed......................................
2023-01-03 21:05:27,359:INFO:SubProcess create_model() end ==================================
2023-01-03 21:05:27,359:INFO:Creating metrics dataframe
2023-01-03 21:05:27,374:INFO:Initializing Random Forest Regressor
2023-01-03 21:05:27,374:INFO:Total runtime is 0.21174393494923913 minutes
2023-01-03 21:05:27,380:INFO:SubProcess create_model() called ==================================
2023-01-03 21:05:27,380:INFO:Initializing create_model()
2023-01-03 21:05:27,380:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024E553620D0>, estimator=rf, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024E55416220>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:05:27,380:INFO:Checking exceptions
2023-01-03 21:05:27,380:INFO:Importing libraries
2023-01-03 21:05:27,380:INFO:Copying training dataset
2023-01-03 21:05:27,391:INFO:Defining folds
2023-01-03 21:05:27,391:INFO:Declaring metric variables
2023-01-03 21:05:27,395:INFO:Importing untrained model
2023-01-03 21:05:27,399:INFO:Random Forest Regressor Imported successfully
2023-01-03 21:05:27,409:INFO:Starting cross validation
2023-01-03 21:05:27,410:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:05:35,756:INFO:Calculating mean and std
2023-01-03 21:05:35,758:INFO:Creating metrics dataframe
2023-01-03 21:05:35,761:INFO:Uploading results into container
2023-01-03 21:05:35,761:INFO:Uploading model into container now
2023-01-03 21:05:35,762:INFO:_master_model_container: 13
2023-01-03 21:05:35,762:INFO:_display_container: 2
2023-01-03 21:05:35,762:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-01-03 21:05:35,763:INFO:create_model() successfully completed......................................
2023-01-03 21:05:35,866:INFO:SubProcess create_model() end ==================================
2023-01-03 21:05:35,866:INFO:Creating metrics dataframe
2023-01-03 21:05:35,879:INFO:Initializing Extra Trees Regressor
2023-01-03 21:05:35,879:INFO:Total runtime is 0.3534882545471192 minutes
2023-01-03 21:05:35,883:INFO:SubProcess create_model() called ==================================
2023-01-03 21:05:35,883:INFO:Initializing create_model()
2023-01-03 21:05:35,883:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024E553620D0>, estimator=et, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024E55416220>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:05:35,883:INFO:Checking exceptions
2023-01-03 21:05:35,884:INFO:Importing libraries
2023-01-03 21:05:35,884:INFO:Copying training dataset
2023-01-03 21:05:35,892:INFO:Defining folds
2023-01-03 21:05:35,893:INFO:Declaring metric variables
2023-01-03 21:05:35,897:INFO:Importing untrained model
2023-01-03 21:05:35,901:INFO:Extra Trees Regressor Imported successfully
2023-01-03 21:05:35,910:INFO:Starting cross validation
2023-01-03 21:05:35,912:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:05:40,119:INFO:Calculating mean and std
2023-01-03 21:05:40,123:INFO:Creating metrics dataframe
2023-01-03 21:05:40,132:INFO:Uploading results into container
2023-01-03 21:05:40,132:INFO:Uploading model into container now
2023-01-03 21:05:40,133:INFO:_master_model_container: 14
2023-01-03 21:05:40,133:INFO:_display_container: 2
2023-01-03 21:05:40,133:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-01-03 21:05:40,133:INFO:create_model() successfully completed......................................
2023-01-03 21:05:40,242:INFO:SubProcess create_model() end ==================================
2023-01-03 21:05:40,243:INFO:Creating metrics dataframe
2023-01-03 21:05:40,254:INFO:Initializing AdaBoost Regressor
2023-01-03 21:05:40,255:INFO:Total runtime is 0.4264232238133749 minutes
2023-01-03 21:05:40,258:INFO:SubProcess create_model() called ==================================
2023-01-03 21:05:40,258:INFO:Initializing create_model()
2023-01-03 21:05:40,259:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024E553620D0>, estimator=ada, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024E55416220>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:05:40,259:INFO:Checking exceptions
2023-01-03 21:05:40,259:INFO:Importing libraries
2023-01-03 21:05:40,259:INFO:Copying training dataset
2023-01-03 21:05:40,267:INFO:Defining folds
2023-01-03 21:05:40,267:INFO:Declaring metric variables
2023-01-03 21:05:40,271:INFO:Importing untrained model
2023-01-03 21:05:40,275:INFO:AdaBoost Regressor Imported successfully
2023-01-03 21:05:40,283:INFO:Starting cross validation
2023-01-03 21:05:40,285:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:05:41,020:INFO:Calculating mean and std
2023-01-03 21:05:41,022:INFO:Creating metrics dataframe
2023-01-03 21:05:41,025:INFO:Uploading results into container
2023-01-03 21:05:41,025:INFO:Uploading model into container now
2023-01-03 21:05:41,025:INFO:_master_model_container: 15
2023-01-03 21:05:41,025:INFO:_display_container: 2
2023-01-03 21:05:41,026:INFO:AdaBoostRegressor(random_state=123)
2023-01-03 21:05:41,026:INFO:create_model() successfully completed......................................
2023-01-03 21:05:41,128:INFO:SubProcess create_model() end ==================================
2023-01-03 21:05:41,128:INFO:Creating metrics dataframe
2023-01-03 21:05:41,144:INFO:Initializing Gradient Boosting Regressor
2023-01-03 21:05:41,144:INFO:Total runtime is 0.441240946451823 minutes
2023-01-03 21:05:41,148:INFO:SubProcess create_model() called ==================================
2023-01-03 21:05:41,148:INFO:Initializing create_model()
2023-01-03 21:05:41,149:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024E553620D0>, estimator=gbr, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024E55416220>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:05:41,149:INFO:Checking exceptions
2023-01-03 21:05:41,149:INFO:Importing libraries
2023-01-03 21:05:41,149:INFO:Copying training dataset
2023-01-03 21:05:41,158:INFO:Defining folds
2023-01-03 21:05:41,158:INFO:Declaring metric variables
2023-01-03 21:05:41,162:INFO:Importing untrained model
2023-01-03 21:05:41,167:INFO:Gradient Boosting Regressor Imported successfully
2023-01-03 21:05:41,181:INFO:Starting cross validation
2023-01-03 21:05:41,185:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:05:45,210:INFO:Calculating mean and std
2023-01-03 21:05:45,212:INFO:Creating metrics dataframe
2023-01-03 21:05:45,215:INFO:Uploading results into container
2023-01-03 21:05:45,215:INFO:Uploading model into container now
2023-01-03 21:05:45,216:INFO:_master_model_container: 16
2023-01-03 21:05:45,216:INFO:_display_container: 2
2023-01-03 21:05:45,216:INFO:GradientBoostingRegressor(random_state=123)
2023-01-03 21:05:45,216:INFO:create_model() successfully completed......................................
2023-01-03 21:05:45,313:INFO:SubProcess create_model() end ==================================
2023-01-03 21:05:45,313:INFO:Creating metrics dataframe
2023-01-03 21:05:45,329:INFO:Initializing Light Gradient Boosting Machine
2023-01-03 21:05:45,329:INFO:Total runtime is 0.510993234316508 minutes
2023-01-03 21:05:45,333:INFO:SubProcess create_model() called ==================================
2023-01-03 21:05:45,334:INFO:Initializing create_model()
2023-01-03 21:05:45,334:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024E553620D0>, estimator=lightgbm, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024E55416220>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:05:45,334:INFO:Checking exceptions
2023-01-03 21:05:45,334:INFO:Importing libraries
2023-01-03 21:05:45,334:INFO:Copying training dataset
2023-01-03 21:05:45,343:INFO:Defining folds
2023-01-03 21:05:45,344:INFO:Declaring metric variables
2023-01-03 21:05:45,347:INFO:Importing untrained model
2023-01-03 21:05:45,352:INFO:Light Gradient Boosting Machine Imported successfully
2023-01-03 21:05:45,360:INFO:Starting cross validation
2023-01-03 21:05:45,362:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:05:47,419:INFO:Calculating mean and std
2023-01-03 21:05:47,421:INFO:Creating metrics dataframe
2023-01-03 21:05:47,424:INFO:Uploading results into container
2023-01-03 21:05:47,424:INFO:Uploading model into container now
2023-01-03 21:05:47,424:INFO:_master_model_container: 17
2023-01-03 21:05:47,424:INFO:_display_container: 2
2023-01-03 21:05:47,425:INFO:LGBMRegressor(random_state=123)
2023-01-03 21:05:47,425:INFO:create_model() successfully completed......................................
2023-01-03 21:05:47,524:INFO:SubProcess create_model() end ==================================
2023-01-03 21:05:47,524:INFO:Creating metrics dataframe
2023-01-03 21:05:47,540:INFO:Initializing Dummy Regressor
2023-01-03 21:05:47,541:INFO:Total runtime is 0.5478511174519857 minutes
2023-01-03 21:05:47,545:INFO:SubProcess create_model() called ==================================
2023-01-03 21:05:47,545:INFO:Initializing create_model()
2023-01-03 21:05:47,545:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024E553620D0>, estimator=dummy, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024E55416220>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:05:47,545:INFO:Checking exceptions
2023-01-03 21:05:47,545:INFO:Importing libraries
2023-01-03 21:05:47,545:INFO:Copying training dataset
2023-01-03 21:05:47,555:INFO:Defining folds
2023-01-03 21:05:47,555:INFO:Declaring metric variables
2023-01-03 21:05:47,559:INFO:Importing untrained model
2023-01-03 21:05:47,563:INFO:Dummy Regressor Imported successfully
2023-01-03 21:05:47,571:INFO:Starting cross validation
2023-01-03 21:05:47,572:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:05:47,802:INFO:Calculating mean and std
2023-01-03 21:05:47,804:INFO:Creating metrics dataframe
2023-01-03 21:05:47,807:INFO:Uploading results into container
2023-01-03 21:05:47,807:INFO:Uploading model into container now
2023-01-03 21:05:47,808:INFO:_master_model_container: 18
2023-01-03 21:05:47,808:INFO:_display_container: 2
2023-01-03 21:05:47,808:INFO:DummyRegressor()
2023-01-03 21:05:47,808:INFO:create_model() successfully completed......................................
2023-01-03 21:05:47,910:INFO:SubProcess create_model() end ==================================
2023-01-03 21:05:47,910:INFO:Creating metrics dataframe
2023-01-03 21:05:47,936:INFO:Initializing create_model()
2023-01-03 21:05:47,937:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024E553620D0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:05:47,937:INFO:Checking exceptions
2023-01-03 21:05:47,939:INFO:Importing libraries
2023-01-03 21:05:47,939:INFO:Copying training dataset
2023-01-03 21:05:47,947:INFO:Defining folds
2023-01-03 21:05:47,947:INFO:Declaring metric variables
2023-01-03 21:05:47,947:INFO:Importing untrained model
2023-01-03 21:05:47,947:INFO:Declaring custom model
2023-01-03 21:05:47,948:INFO:Extra Trees Regressor Imported successfully
2023-01-03 21:05:47,948:INFO:Cross validation set to False
2023-01-03 21:05:47,948:INFO:Fitting Model
2023-01-03 21:05:49,425:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-01-03 21:05:49,425:INFO:create_model() successfully completed......................................
2023-01-03 21:05:49,575:INFO:_master_model_container: 18
2023-01-03 21:05:49,575:INFO:_display_container: 2
2023-01-03 21:05:49,576:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-01-03 21:05:49,576:INFO:compare_models() successfully completed......................................
2023-01-03 21:09:30,189:INFO:PyCaret RegressionExperiment
2023-01-03 21:09:30,190:INFO:Logging name: reg-default-name
2023-01-03 21:09:30,190:INFO:ML Usecase: MLUsecase.REGRESSION
2023-01-03 21:09:30,190:INFO:version 3.0.0.rc6
2023-01-03 21:09:30,190:INFO:Initializing setup()
2023-01-03 21:09:30,190:INFO:self.USI: dc43
2023-01-03 21:09:30,190:INFO:self._variable_keys: {'y_train', '_ml_usecase', 'fold_groups_param', 'fold_shuffle_param', 'logging_param', 'n_jobs_param', 'fold_generator', 'transform_target_param', 'data', 'USI', 'X_test', 'gpu_n_jobs_param', '_available_plots', 'target_param', 'idx', 'exp_id', 'y', 'seed', 'exp_name_log', 'log_plots_param', 'y_test', 'gpu_param', 'memory', 'pipeline', 'X_train', 'X', 'html_param'}
2023-01-03 21:09:30,190:INFO:Checking environment
2023-01-03 21:09:30,190:INFO:python_version: 3.9.13
2023-01-03 21:09:30,190:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-01-03 21:09:30,190:INFO:machine: AMD64
2023-01-03 21:09:30,190:INFO:platform: Windows-10-10.0.19044-SP0
2023-01-03 21:09:30,190:INFO:Memory: svmem(total=17114804224, available=9636831232, percent=43.7, used=7477972992, free=9636831232)
2023-01-03 21:09:30,190:INFO:Physical Core: 4
2023-01-03 21:09:30,190:INFO:Logical Core: 4
2023-01-03 21:09:30,190:INFO:Checking libraries
2023-01-03 21:09:30,190:INFO:System:
2023-01-03 21:09:30,191:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-01-03 21:09:30,191:INFO:executable: c:\Users\Kodotautas\anaconda3\python.exe
2023-01-03 21:09:30,191:INFO:   machine: Windows-10-10.0.19044-SP0
2023-01-03 21:09:30,191:INFO:PyCaret required dependencies:
2023-01-03 21:09:30,191:INFO:                 pip: 22.2.2
2023-01-03 21:09:30,191:INFO:          setuptools: 63.4.1
2023-01-03 21:09:30,191:INFO:             pycaret: 3.0.0rc6
2023-01-03 21:09:30,191:INFO:             IPython: 7.31.1
2023-01-03 21:09:30,191:INFO:          ipywidgets: 7.6.5
2023-01-03 21:09:30,191:INFO:                tqdm: 4.64.1
2023-01-03 21:09:30,191:INFO:               numpy: 1.21.5
2023-01-03 21:09:30,191:INFO:              pandas: 1.4.4
2023-01-03 21:09:30,191:INFO:              jinja2: 2.11.3
2023-01-03 21:09:30,191:INFO:               scipy: 1.9.1
2023-01-03 21:09:30,191:INFO:              joblib: 1.2.0
2023-01-03 21:09:30,191:INFO:             sklearn: 1.0.2
2023-01-03 21:09:30,191:INFO:                pyod: 1.0.7
2023-01-03 21:09:30,191:INFO:            imblearn: 0.10.1
2023-01-03 21:09:30,191:INFO:   category_encoders: 2.5.1.post0
2023-01-03 21:09:30,191:INFO:            lightgbm: 3.3.3
2023-01-03 21:09:30,191:INFO:               numba: 0.55.1
2023-01-03 21:09:30,192:INFO:            requests: 2.28.1
2023-01-03 21:09:30,192:INFO:          matplotlib: 3.5.2
2023-01-03 21:09:30,192:INFO:          scikitplot: 0.3.7
2023-01-03 21:09:30,192:INFO:         yellowbrick: 1.5
2023-01-03 21:09:30,192:INFO:              plotly: 5.9.0
2023-01-03 21:09:30,192:INFO:             kaleido: 0.2.1
2023-01-03 21:09:30,192:INFO:         statsmodels: 0.13.2
2023-01-03 21:09:30,192:INFO:              sktime: 0.14.1
2023-01-03 21:09:30,192:INFO:               tbats: 1.1.2
2023-01-03 21:09:30,192:INFO:            pmdarima: 2.0.2
2023-01-03 21:09:30,192:INFO:              psutil: 5.9.0
2023-01-03 21:09:30,192:INFO:PyCaret optional dependencies:
2023-01-03 21:09:30,192:INFO:                shap: 0.41.0
2023-01-03 21:09:30,192:INFO:           interpret: Not installed
2023-01-03 21:09:30,192:INFO:                umap: Not installed
2023-01-03 21:09:30,192:INFO:    pandas_profiling: Not installed
2023-01-03 21:09:30,192:INFO:  explainerdashboard: Not installed
2023-01-03 21:09:30,192:INFO:             autoviz: Not installed
2023-01-03 21:09:30,192:INFO:           fairlearn: Not installed
2023-01-03 21:09:30,192:INFO:             xgboost: Not installed
2023-01-03 21:09:30,193:INFO:            catboost: Not installed
2023-01-03 21:09:30,193:INFO:              kmodes: Not installed
2023-01-03 21:09:30,193:INFO:             mlxtend: Not installed
2023-01-03 21:09:30,193:INFO:       statsforecast: Not installed
2023-01-03 21:09:30,193:INFO:        tune_sklearn: 0.4.3
2023-01-03 21:09:30,193:INFO:                 ray: 2.0.0
2023-01-03 21:09:30,193:INFO:            hyperopt: 0.2.7
2023-01-03 21:09:30,193:INFO:              optuna: 3.0.1
2023-01-03 21:09:30,193:INFO:               skopt: 0.9.0
2023-01-03 21:09:30,193:INFO:              mlflow: Not installed
2023-01-03 21:09:30,193:INFO:              gradio: Not installed
2023-01-03 21:09:30,193:INFO:             fastapi: 0.88.0
2023-01-03 21:09:30,193:INFO:             uvicorn: 0.20.0
2023-01-03 21:09:30,193:INFO:              m2cgen: Not installed
2023-01-03 21:09:30,193:INFO:           evidently: Not installed
2023-01-03 21:09:30,193:INFO:                nltk: 3.7
2023-01-03 21:09:30,193:INFO:            pyLDAvis: Not installed
2023-01-03 21:09:30,193:INFO:              gensim: 4.1.2
2023-01-03 21:09:30,193:INFO:               spacy: 3.4.2
2023-01-03 21:09:30,193:INFO:           wordcloud: Not installed
2023-01-03 21:09:30,193:INFO:            textblob: Not installed
2023-01-03 21:09:30,193:INFO:               fugue: Not installed
2023-01-03 21:09:30,193:INFO:           streamlit: Not installed
2023-01-03 21:09:30,193:INFO:             prophet: Not installed
2023-01-03 21:09:30,194:INFO:None
2023-01-03 21:09:30,194:INFO:Set up data.
2023-01-03 21:09:30,212:INFO:Set up train/test split.
2023-01-03 21:09:30,223:INFO:Set up index.
2023-01-03 21:09:30,225:INFO:Set up folding strategy.
2023-01-03 21:09:30,225:INFO:Assigning column types.
2023-01-03 21:09:30,236:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-01-03 21:09:30,237:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-01-03 21:09:30,241:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-03 21:09:30,247:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 21:09:30,314:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 21:09:30,363:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 21:09:30,364:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:09:30,364:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:09:30,364:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-01-03 21:09:30,369:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-03 21:09:30,374:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 21:09:30,438:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 21:09:30,484:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 21:09:30,484:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:09:30,484:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:09:30,485:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-01-03 21:09:30,489:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-03 21:09:30,494:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 21:09:30,560:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 21:09:30,610:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 21:09:30,611:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:09:30,611:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:09:30,617:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-03 21:09:30,621:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 21:09:30,686:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 21:09:30,732:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 21:09:30,733:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:09:30,733:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:09:30,733:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-01-03 21:09:30,743:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 21:09:30,807:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 21:09:30,856:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 21:09:30,857:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:09:30,858:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:09:30,868:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 21:09:30,934:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 21:09:30,981:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 21:09:30,982:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:09:30,982:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:09:30,982:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-01-03 21:09:31,060:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 21:09:31,112:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 21:09:31,113:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:09:31,114:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:09:31,191:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 21:09:31,240:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 21:09:31,244:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:09:31,244:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:09:31,245:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-01-03 21:09:31,324:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 21:09:31,373:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:09:31,373:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:09:31,449:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 21:09:31,497:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:09:31,497:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:09:31,497:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-01-03 21:09:31,626:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:09:31,626:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:09:31,749:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:09:31,749:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:09:31,750:INFO:Preparing preprocessing pipeline...
2023-01-03 21:09:31,751:INFO:Set up simple imputation.
2023-01-03 21:09:31,752:INFO:Set up column transformation.
2023-01-03 21:09:31,752:INFO:Set up feature normalization.
2023-01-03 21:09:31,785:INFO:Finished creating preprocessing pipeline.
2023-01-03 21:09:31,791:INFO:Pipeline: Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2023-01-03 21:09:31,791:INFO:Creating final display dataframe.
2023-01-03 21:09:32,021:INFO:Setup _display_container:                Description             Value
0               Session id               123
1                   Target        b2b+b2c+vt
2              Target type        Regression
3               Data shape       (11081, 38)
4         Train data shape        (7756, 38)
5          Test data shape        (3325, 38)
6         Numeric features                 8
7               Preprocess              True
8          Imputation type            simple
9       Numeric imputation              mean
10  Categorical imputation              mode
11          Transformation              True
12   Transformation method       yeo-johnson
13               Normalize              True
14        Normalize method            zscore
15          Fold Generator   TimeSeriesSplit
16             Fold Number                 5
17                CPU Jobs                -1
18                 Use GPU             False
19          Log Experiment             False
20         Experiment Name  reg-default-name
21                     USI              dc43
2023-01-03 21:09:32,205:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:09:32,205:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:09:32,330:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:09:32,330:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:09:32,331:INFO:setup() successfully completed in 2.14s...............
2023-01-03 21:09:32,331:INFO:Initializing compare_models()
2023-01-03 21:09:32,331:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024E5750B460>, include=None, fold=None, round=4, cross_validation=True, sort=MAE, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x0000024E5750B460>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'MAE', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-01-03 21:09:32,331:INFO:Checking exceptions
2023-01-03 21:09:32,336:INFO:Preparing display monitor
2023-01-03 21:09:32,376:INFO:Initializing Linear Regression
2023-01-03 21:09:32,376:INFO:Total runtime is 0.0 minutes
2023-01-03 21:09:32,381:INFO:SubProcess create_model() called ==================================
2023-01-03 21:09:32,381:INFO:Initializing create_model()
2023-01-03 21:09:32,382:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024E5750B460>, estimator=lr, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024E560E29A0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:09:32,382:INFO:Checking exceptions
2023-01-03 21:09:32,382:INFO:Importing libraries
2023-01-03 21:09:32,382:INFO:Copying training dataset
2023-01-03 21:09:32,390:INFO:Defining folds
2023-01-03 21:09:32,390:INFO:Declaring metric variables
2023-01-03 21:09:32,395:INFO:Importing untrained model
2023-01-03 21:09:32,400:INFO:Linear Regression Imported successfully
2023-01-03 21:09:32,410:INFO:Starting cross validation
2023-01-03 21:09:32,413:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:09:32,671:INFO:Calculating mean and std
2023-01-03 21:09:32,672:INFO:Creating metrics dataframe
2023-01-03 21:09:32,675:INFO:Uploading results into container
2023-01-03 21:09:32,675:INFO:Uploading model into container now
2023-01-03 21:09:32,675:INFO:_master_model_container: 1
2023-01-03 21:09:32,675:INFO:_display_container: 2
2023-01-03 21:09:32,676:INFO:LinearRegression(n_jobs=-1)
2023-01-03 21:09:32,676:INFO:create_model() successfully completed......................................
2023-01-03 21:09:32,783:INFO:SubProcess create_model() end ==================================
2023-01-03 21:09:32,783:INFO:Creating metrics dataframe
2023-01-03 21:09:32,790:INFO:Initializing Lasso Regression
2023-01-03 21:09:32,791:INFO:Total runtime is 0.006904125213623047 minutes
2023-01-03 21:09:32,794:INFO:SubProcess create_model() called ==================================
2023-01-03 21:09:32,795:INFO:Initializing create_model()
2023-01-03 21:09:32,795:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024E5750B460>, estimator=lasso, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024E560E29A0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:09:32,795:INFO:Checking exceptions
2023-01-03 21:09:32,795:INFO:Importing libraries
2023-01-03 21:09:32,795:INFO:Copying training dataset
2023-01-03 21:09:32,803:INFO:Defining folds
2023-01-03 21:09:32,803:INFO:Declaring metric variables
2023-01-03 21:09:32,807:INFO:Importing untrained model
2023-01-03 21:09:32,810:INFO:Lasso Regression Imported successfully
2023-01-03 21:09:32,821:INFO:Starting cross validation
2023-01-03 21:09:32,822:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:09:33,070:INFO:Calculating mean and std
2023-01-03 21:09:33,071:INFO:Creating metrics dataframe
2023-01-03 21:09:33,074:INFO:Uploading results into container
2023-01-03 21:09:33,074:INFO:Uploading model into container now
2023-01-03 21:09:33,075:INFO:_master_model_container: 2
2023-01-03 21:09:33,075:INFO:_display_container: 2
2023-01-03 21:09:33,075:INFO:Lasso(random_state=123)
2023-01-03 21:09:33,075:INFO:create_model() successfully completed......................................
2023-01-03 21:09:33,184:INFO:SubProcess create_model() end ==================================
2023-01-03 21:09:33,184:INFO:Creating metrics dataframe
2023-01-03 21:09:33,193:INFO:Initializing Ridge Regression
2023-01-03 21:09:33,193:INFO:Total runtime is 0.013608972231547039 minutes
2023-01-03 21:09:33,197:INFO:SubProcess create_model() called ==================================
2023-01-03 21:09:33,198:INFO:Initializing create_model()
2023-01-03 21:09:33,198:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024E5750B460>, estimator=ridge, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024E560E29A0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:09:33,198:INFO:Checking exceptions
2023-01-03 21:09:33,198:INFO:Importing libraries
2023-01-03 21:09:33,198:INFO:Copying training dataset
2023-01-03 21:09:33,206:INFO:Defining folds
2023-01-03 21:09:33,206:INFO:Declaring metric variables
2023-01-03 21:09:33,209:INFO:Importing untrained model
2023-01-03 21:09:33,213:INFO:Ridge Regression Imported successfully
2023-01-03 21:09:33,221:INFO:Starting cross validation
2023-01-03 21:09:33,222:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:09:33,452:INFO:Calculating mean and std
2023-01-03 21:09:33,454:INFO:Creating metrics dataframe
2023-01-03 21:09:33,457:INFO:Uploading results into container
2023-01-03 21:09:33,457:INFO:Uploading model into container now
2023-01-03 21:09:33,458:INFO:_master_model_container: 3
2023-01-03 21:09:33,458:INFO:_display_container: 2
2023-01-03 21:09:33,458:INFO:Ridge(random_state=123)
2023-01-03 21:09:33,458:INFO:create_model() successfully completed......................................
2023-01-03 21:09:33,560:INFO:SubProcess create_model() end ==================================
2023-01-03 21:09:33,560:INFO:Creating metrics dataframe
2023-01-03 21:09:33,572:INFO:Initializing Elastic Net
2023-01-03 21:09:33,572:INFO:Total runtime is 0.019919522603352866 minutes
2023-01-03 21:09:33,576:INFO:SubProcess create_model() called ==================================
2023-01-03 21:09:33,577:INFO:Initializing create_model()
2023-01-03 21:09:33,577:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024E5750B460>, estimator=en, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024E560E29A0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:09:33,577:INFO:Checking exceptions
2023-01-03 21:09:33,577:INFO:Importing libraries
2023-01-03 21:09:33,577:INFO:Copying training dataset
2023-01-03 21:09:33,587:INFO:Defining folds
2023-01-03 21:09:33,587:INFO:Declaring metric variables
2023-01-03 21:09:33,591:INFO:Importing untrained model
2023-01-03 21:09:33,595:INFO:Elastic Net Imported successfully
2023-01-03 21:09:33,605:INFO:Starting cross validation
2023-01-03 21:09:33,606:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:09:33,843:INFO:Calculating mean and std
2023-01-03 21:09:33,845:INFO:Creating metrics dataframe
2023-01-03 21:09:33,848:INFO:Uploading results into container
2023-01-03 21:09:33,848:INFO:Uploading model into container now
2023-01-03 21:09:33,849:INFO:_master_model_container: 4
2023-01-03 21:09:33,849:INFO:_display_container: 2
2023-01-03 21:09:33,849:INFO:ElasticNet(random_state=123)
2023-01-03 21:09:33,849:INFO:create_model() successfully completed......................................
2023-01-03 21:09:33,952:INFO:SubProcess create_model() end ==================================
2023-01-03 21:09:33,952:INFO:Creating metrics dataframe
2023-01-03 21:09:33,965:INFO:Initializing Least Angle Regression
2023-01-03 21:09:33,965:INFO:Total runtime is 0.026478167374928793 minutes
2023-01-03 21:09:33,970:INFO:SubProcess create_model() called ==================================
2023-01-03 21:09:33,970:INFO:Initializing create_model()
2023-01-03 21:09:33,970:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024E5750B460>, estimator=lar, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024E560E29A0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:09:33,970:INFO:Checking exceptions
2023-01-03 21:09:33,970:INFO:Importing libraries
2023-01-03 21:09:33,971:INFO:Copying training dataset
2023-01-03 21:09:33,988:INFO:Defining folds
2023-01-03 21:09:33,988:INFO:Declaring metric variables
2023-01-03 21:09:33,993:INFO:Importing untrained model
2023-01-03 21:09:34,003:INFO:Least Angle Regression Imported successfully
2023-01-03 21:09:34,019:INFO:Starting cross validation
2023-01-03 21:09:34,020:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:09:34,070:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 21:09:34,073:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 21:09:34,084:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 21:09:34,098:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 21:09:34,129:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 21:09:34,265:INFO:Calculating mean and std
2023-01-03 21:09:34,267:INFO:Creating metrics dataframe
2023-01-03 21:09:34,271:INFO:Uploading results into container
2023-01-03 21:09:34,272:INFO:Uploading model into container now
2023-01-03 21:09:34,272:INFO:_master_model_container: 5
2023-01-03 21:09:34,272:INFO:_display_container: 2
2023-01-03 21:09:34,273:INFO:Lars(random_state=123)
2023-01-03 21:09:34,273:INFO:create_model() successfully completed......................................
2023-01-03 21:09:34,372:INFO:SubProcess create_model() end ==================================
2023-01-03 21:09:34,372:INFO:Creating metrics dataframe
2023-01-03 21:09:34,382:INFO:Initializing Lasso Least Angle Regression
2023-01-03 21:09:34,383:INFO:Total runtime is 0.03344960212707519 minutes
2023-01-03 21:09:34,387:INFO:SubProcess create_model() called ==================================
2023-01-03 21:09:34,387:INFO:Initializing create_model()
2023-01-03 21:09:34,387:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024E5750B460>, estimator=llar, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024E560E29A0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:09:34,387:INFO:Checking exceptions
2023-01-03 21:09:34,387:INFO:Importing libraries
2023-01-03 21:09:34,387:INFO:Copying training dataset
2023-01-03 21:09:34,399:INFO:Defining folds
2023-01-03 21:09:34,399:INFO:Declaring metric variables
2023-01-03 21:09:34,404:INFO:Importing untrained model
2023-01-03 21:09:34,409:INFO:Lasso Least Angle Regression Imported successfully
2023-01-03 21:09:34,419:INFO:Starting cross validation
2023-01-03 21:09:34,420:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:09:34,517:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-03 21:09:34,524:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-03 21:09:34,542:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-03 21:09:34,544:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-03 21:09:34,574:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-03 21:09:34,701:INFO:Calculating mean and std
2023-01-03 21:09:34,703:INFO:Creating metrics dataframe
2023-01-03 21:09:34,706:INFO:Uploading results into container
2023-01-03 21:09:34,706:INFO:Uploading model into container now
2023-01-03 21:09:34,706:INFO:_master_model_container: 6
2023-01-03 21:09:34,706:INFO:_display_container: 2
2023-01-03 21:09:34,707:INFO:LassoLars(random_state=123)
2023-01-03 21:09:34,707:INFO:create_model() successfully completed......................................
2023-01-03 21:09:34,807:INFO:SubProcess create_model() end ==================================
2023-01-03 21:09:34,807:INFO:Creating metrics dataframe
2023-01-03 21:09:34,820:INFO:Initializing Orthogonal Matching Pursuit
2023-01-03 21:09:34,821:INFO:Total runtime is 0.040737903118133544 minutes
2023-01-03 21:09:34,824:INFO:SubProcess create_model() called ==================================
2023-01-03 21:09:34,825:INFO:Initializing create_model()
2023-01-03 21:09:34,825:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024E5750B460>, estimator=omp, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024E560E29A0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:09:34,825:INFO:Checking exceptions
2023-01-03 21:09:34,825:INFO:Importing libraries
2023-01-03 21:09:34,825:INFO:Copying training dataset
2023-01-03 21:09:34,834:INFO:Defining folds
2023-01-03 21:09:34,834:INFO:Declaring metric variables
2023-01-03 21:09:34,838:INFO:Importing untrained model
2023-01-03 21:09:34,842:INFO:Orthogonal Matching Pursuit Imported successfully
2023-01-03 21:09:34,851:INFO:Starting cross validation
2023-01-03 21:09:34,853:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:09:34,899:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 21:09:34,908:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 21:09:34,916:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 21:09:34,932:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 21:09:34,960:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 21:09:35,094:INFO:Calculating mean and std
2023-01-03 21:09:35,096:INFO:Creating metrics dataframe
2023-01-03 21:09:35,099:INFO:Uploading results into container
2023-01-03 21:09:35,099:INFO:Uploading model into container now
2023-01-03 21:09:35,100:INFO:_master_model_container: 7
2023-01-03 21:09:35,100:INFO:_display_container: 2
2023-01-03 21:09:35,100:INFO:OrthogonalMatchingPursuit()
2023-01-03 21:09:35,100:INFO:create_model() successfully completed......................................
2023-01-03 21:09:35,206:INFO:SubProcess create_model() end ==================================
2023-01-03 21:09:35,206:INFO:Creating metrics dataframe
2023-01-03 21:09:35,220:INFO:Initializing Bayesian Ridge
2023-01-03 21:09:35,220:INFO:Total runtime is 0.047392253081003824 minutes
2023-01-03 21:09:35,223:INFO:SubProcess create_model() called ==================================
2023-01-03 21:09:35,224:INFO:Initializing create_model()
2023-01-03 21:09:35,224:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024E5750B460>, estimator=br, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024E560E29A0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:09:35,224:INFO:Checking exceptions
2023-01-03 21:09:35,224:INFO:Importing libraries
2023-01-03 21:09:35,224:INFO:Copying training dataset
2023-01-03 21:09:35,234:INFO:Defining folds
2023-01-03 21:09:35,234:INFO:Declaring metric variables
2023-01-03 21:09:35,238:INFO:Importing untrained model
2023-01-03 21:09:35,243:INFO:Bayesian Ridge Imported successfully
2023-01-03 21:09:35,253:INFO:Starting cross validation
2023-01-03 21:09:35,255:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:09:35,395:INFO:Calculating mean and std
2023-01-03 21:09:35,397:INFO:Creating metrics dataframe
2023-01-03 21:09:35,401:INFO:Uploading results into container
2023-01-03 21:09:35,402:INFO:Uploading model into container now
2023-01-03 21:09:35,402:INFO:_master_model_container: 8
2023-01-03 21:09:35,403:INFO:_display_container: 2
2023-01-03 21:09:35,403:INFO:BayesianRidge()
2023-01-03 21:09:35,403:INFO:create_model() successfully completed......................................
2023-01-03 21:09:35,510:INFO:SubProcess create_model() end ==================================
2023-01-03 21:09:35,510:INFO:Creating metrics dataframe
2023-01-03 21:09:35,520:INFO:Initializing Passive Aggressive Regressor
2023-01-03 21:09:35,521:INFO:Total runtime is 0.052408921718597415 minutes
2023-01-03 21:09:35,524:INFO:SubProcess create_model() called ==================================
2023-01-03 21:09:35,524:INFO:Initializing create_model()
2023-01-03 21:09:35,525:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024E5750B460>, estimator=par, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024E560E29A0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:09:35,525:INFO:Checking exceptions
2023-01-03 21:09:35,525:INFO:Importing libraries
2023-01-03 21:09:35,525:INFO:Copying training dataset
2023-01-03 21:09:35,534:INFO:Defining folds
2023-01-03 21:09:35,534:INFO:Declaring metric variables
2023-01-03 21:09:35,538:INFO:Importing untrained model
2023-01-03 21:09:35,542:INFO:Passive Aggressive Regressor Imported successfully
2023-01-03 21:09:35,551:INFO:Starting cross validation
2023-01-03 21:09:35,552:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:09:35,799:INFO:Calculating mean and std
2023-01-03 21:09:35,801:INFO:Creating metrics dataframe
2023-01-03 21:09:35,804:INFO:Uploading results into container
2023-01-03 21:09:35,805:INFO:Uploading model into container now
2023-01-03 21:09:35,805:INFO:_master_model_container: 9
2023-01-03 21:09:35,806:INFO:_display_container: 2
2023-01-03 21:09:35,806:INFO:PassiveAggressiveRegressor(random_state=123)
2023-01-03 21:09:35,806:INFO:create_model() successfully completed......................................
2023-01-03 21:09:35,909:INFO:SubProcess create_model() end ==================================
2023-01-03 21:09:35,910:INFO:Creating metrics dataframe
2023-01-03 21:09:35,920:INFO:Initializing Huber Regressor
2023-01-03 21:09:35,921:INFO:Total runtime is 0.059072975317637125 minutes
2023-01-03 21:09:35,924:INFO:SubProcess create_model() called ==================================
2023-01-03 21:09:35,925:INFO:Initializing create_model()
2023-01-03 21:09:35,925:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024E5750B460>, estimator=huber, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024E560E29A0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:09:35,925:INFO:Checking exceptions
2023-01-03 21:09:35,925:INFO:Importing libraries
2023-01-03 21:09:35,925:INFO:Copying training dataset
2023-01-03 21:09:35,935:INFO:Defining folds
2023-01-03 21:09:35,936:INFO:Declaring metric variables
2023-01-03 21:09:35,940:INFO:Importing untrained model
2023-01-03 21:09:35,944:INFO:Huber Regressor Imported successfully
2023-01-03 21:09:35,954:INFO:Starting cross validation
2023-01-03 21:09:35,957:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:09:36,072:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-03 21:09:36,138:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-03 21:09:36,216:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-03 21:09:36,276:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-03 21:09:36,416:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-03 21:09:36,546:INFO:Calculating mean and std
2023-01-03 21:09:36,548:INFO:Creating metrics dataframe
2023-01-03 21:09:36,551:INFO:Uploading results into container
2023-01-03 21:09:36,551:INFO:Uploading model into container now
2023-01-03 21:09:36,551:INFO:_master_model_container: 10
2023-01-03 21:09:36,551:INFO:_display_container: 2
2023-01-03 21:09:36,552:INFO:HuberRegressor()
2023-01-03 21:09:36,552:INFO:create_model() successfully completed......................................
2023-01-03 21:09:36,654:INFO:SubProcess create_model() end ==================================
2023-01-03 21:09:36,654:INFO:Creating metrics dataframe
2023-01-03 21:09:36,667:INFO:Initializing K Neighbors Regressor
2023-01-03 21:09:36,667:INFO:Total runtime is 0.07151779731114705 minutes
2023-01-03 21:09:36,672:INFO:SubProcess create_model() called ==================================
2023-01-03 21:09:36,673:INFO:Initializing create_model()
2023-01-03 21:09:36,673:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024E5750B460>, estimator=knn, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024E560E29A0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:09:36,673:INFO:Checking exceptions
2023-01-03 21:09:36,673:INFO:Importing libraries
2023-01-03 21:09:36,673:INFO:Copying training dataset
2023-01-03 21:09:36,684:INFO:Defining folds
2023-01-03 21:09:36,685:INFO:Declaring metric variables
2023-01-03 21:09:36,689:INFO:Importing untrained model
2023-01-03 21:09:36,693:INFO:K Neighbors Regressor Imported successfully
2023-01-03 21:09:36,703:INFO:Starting cross validation
2023-01-03 21:09:36,704:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:09:37,405:INFO:Calculating mean and std
2023-01-03 21:09:37,407:INFO:Creating metrics dataframe
2023-01-03 21:09:37,409:INFO:Uploading results into container
2023-01-03 21:09:37,410:INFO:Uploading model into container now
2023-01-03 21:09:37,410:INFO:_master_model_container: 11
2023-01-03 21:09:37,410:INFO:_display_container: 2
2023-01-03 21:09:37,411:INFO:KNeighborsRegressor(n_jobs=-1)
2023-01-03 21:09:37,411:INFO:create_model() successfully completed......................................
2023-01-03 21:09:37,514:INFO:SubProcess create_model() end ==================================
2023-01-03 21:09:37,514:INFO:Creating metrics dataframe
2023-01-03 21:09:37,526:INFO:Initializing Decision Tree Regressor
2023-01-03 21:09:37,527:INFO:Total runtime is 0.08584300676981607 minutes
2023-01-03 21:09:37,531:INFO:SubProcess create_model() called ==================================
2023-01-03 21:09:37,532:INFO:Initializing create_model()
2023-01-03 21:09:37,532:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024E5750B460>, estimator=dt, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024E560E29A0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:09:37,532:INFO:Checking exceptions
2023-01-03 21:09:37,532:INFO:Importing libraries
2023-01-03 21:09:37,532:INFO:Copying training dataset
2023-01-03 21:09:37,540:INFO:Defining folds
2023-01-03 21:09:37,541:INFO:Declaring metric variables
2023-01-03 21:09:37,545:INFO:Importing untrained model
2023-01-03 21:09:37,550:INFO:Decision Tree Regressor Imported successfully
2023-01-03 21:09:37,557:INFO:Starting cross validation
2023-01-03 21:09:37,558:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:09:37,988:INFO:Calculating mean and std
2023-01-03 21:09:37,990:INFO:Creating metrics dataframe
2023-01-03 21:09:37,993:INFO:Uploading results into container
2023-01-03 21:09:37,993:INFO:Uploading model into container now
2023-01-03 21:09:37,993:INFO:_master_model_container: 12
2023-01-03 21:09:37,993:INFO:_display_container: 2
2023-01-03 21:09:37,994:INFO:DecisionTreeRegressor(random_state=123)
2023-01-03 21:09:37,994:INFO:create_model() successfully completed......................................
2023-01-03 21:09:38,093:INFO:SubProcess create_model() end ==================================
2023-01-03 21:09:38,093:INFO:Creating metrics dataframe
2023-01-03 21:09:38,106:INFO:Initializing Random Forest Regressor
2023-01-03 21:09:38,107:INFO:Total runtime is 0.09550213416417438 minutes
2023-01-03 21:09:38,110:INFO:SubProcess create_model() called ==================================
2023-01-03 21:09:38,110:INFO:Initializing create_model()
2023-01-03 21:09:38,111:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024E5750B460>, estimator=rf, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024E560E29A0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:09:38,111:INFO:Checking exceptions
2023-01-03 21:09:38,111:INFO:Importing libraries
2023-01-03 21:09:38,111:INFO:Copying training dataset
2023-01-03 21:09:38,120:INFO:Defining folds
2023-01-03 21:09:38,120:INFO:Declaring metric variables
2023-01-03 21:09:38,125:INFO:Importing untrained model
2023-01-03 21:09:38,129:INFO:Random Forest Regressor Imported successfully
2023-01-03 21:09:38,140:INFO:Starting cross validation
2023-01-03 21:09:38,141:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:09:46,064:INFO:Calculating mean and std
2023-01-03 21:09:46,066:INFO:Creating metrics dataframe
2023-01-03 21:09:46,069:INFO:Uploading results into container
2023-01-03 21:09:46,069:INFO:Uploading model into container now
2023-01-03 21:09:46,069:INFO:_master_model_container: 13
2023-01-03 21:09:46,069:INFO:_display_container: 2
2023-01-03 21:09:46,070:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-01-03 21:09:46,070:INFO:create_model() successfully completed......................................
2023-01-03 21:09:46,271:INFO:SubProcess create_model() end ==================================
2023-01-03 21:09:46,271:INFO:Creating metrics dataframe
2023-01-03 21:09:46,295:INFO:Initializing Extra Trees Regressor
2023-01-03 21:09:46,297:INFO:Total runtime is 0.23200440804163613 minutes
2023-01-03 21:09:46,301:INFO:SubProcess create_model() called ==================================
2023-01-03 21:09:46,302:INFO:Initializing create_model()
2023-01-03 21:09:46,302:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024E5750B460>, estimator=et, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024E560E29A0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:09:46,302:INFO:Checking exceptions
2023-01-03 21:09:46,302:INFO:Importing libraries
2023-01-03 21:09:46,302:INFO:Copying training dataset
2023-01-03 21:09:46,311:INFO:Defining folds
2023-01-03 21:09:46,311:INFO:Declaring metric variables
2023-01-03 21:09:46,316:INFO:Importing untrained model
2023-01-03 21:09:46,320:INFO:Extra Trees Regressor Imported successfully
2023-01-03 21:09:46,328:INFO:Starting cross validation
2023-01-03 21:09:46,330:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:09:50,188:INFO:Calculating mean and std
2023-01-03 21:09:50,190:INFO:Creating metrics dataframe
2023-01-03 21:09:50,193:INFO:Uploading results into container
2023-01-03 21:09:50,193:INFO:Uploading model into container now
2023-01-03 21:09:50,193:INFO:_master_model_container: 14
2023-01-03 21:09:50,193:INFO:_display_container: 2
2023-01-03 21:09:50,194:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-01-03 21:09:50,194:INFO:create_model() successfully completed......................................
2023-01-03 21:09:50,292:INFO:SubProcess create_model() end ==================================
2023-01-03 21:09:50,292:INFO:Creating metrics dataframe
2023-01-03 21:09:50,305:INFO:Initializing AdaBoost Regressor
2023-01-03 21:09:50,305:INFO:Total runtime is 0.29880737463633217 minutes
2023-01-03 21:09:50,310:INFO:SubProcess create_model() called ==================================
2023-01-03 21:09:50,311:INFO:Initializing create_model()
2023-01-03 21:09:50,311:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024E5750B460>, estimator=ada, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024E560E29A0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:09:50,311:INFO:Checking exceptions
2023-01-03 21:09:50,311:INFO:Importing libraries
2023-01-03 21:09:50,311:INFO:Copying training dataset
2023-01-03 21:09:50,320:INFO:Defining folds
2023-01-03 21:09:50,321:INFO:Declaring metric variables
2023-01-03 21:09:50,325:INFO:Importing untrained model
2023-01-03 21:09:50,330:INFO:AdaBoost Regressor Imported successfully
2023-01-03 21:09:50,340:INFO:Starting cross validation
2023-01-03 21:09:50,342:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:09:51,077:INFO:Calculating mean and std
2023-01-03 21:09:51,079:INFO:Creating metrics dataframe
2023-01-03 21:09:51,083:INFO:Uploading results into container
2023-01-03 21:09:51,083:INFO:Uploading model into container now
2023-01-03 21:09:51,084:INFO:_master_model_container: 15
2023-01-03 21:09:51,084:INFO:_display_container: 2
2023-01-03 21:09:51,084:INFO:AdaBoostRegressor(random_state=123)
2023-01-03 21:09:51,084:INFO:create_model() successfully completed......................................
2023-01-03 21:09:51,189:INFO:SubProcess create_model() end ==================================
2023-01-03 21:09:51,189:INFO:Creating metrics dataframe
2023-01-03 21:09:51,202:INFO:Initializing Gradient Boosting Regressor
2023-01-03 21:09:51,202:INFO:Total runtime is 0.31375865538914993 minutes
2023-01-03 21:09:51,207:INFO:SubProcess create_model() called ==================================
2023-01-03 21:09:51,207:INFO:Initializing create_model()
2023-01-03 21:09:51,207:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024E5750B460>, estimator=gbr, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024E560E29A0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:09:51,207:INFO:Checking exceptions
2023-01-03 21:09:51,207:INFO:Importing libraries
2023-01-03 21:09:51,207:INFO:Copying training dataset
2023-01-03 21:09:51,218:INFO:Defining folds
2023-01-03 21:09:51,218:INFO:Declaring metric variables
2023-01-03 21:09:51,222:INFO:Importing untrained model
2023-01-03 21:09:51,226:INFO:Gradient Boosting Regressor Imported successfully
2023-01-03 21:09:51,236:INFO:Starting cross validation
2023-01-03 21:09:51,237:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:09:55,203:INFO:Calculating mean and std
2023-01-03 21:09:55,205:INFO:Creating metrics dataframe
2023-01-03 21:09:55,208:INFO:Uploading results into container
2023-01-03 21:09:55,208:INFO:Uploading model into container now
2023-01-03 21:09:55,208:INFO:_master_model_container: 16
2023-01-03 21:09:55,209:INFO:_display_container: 2
2023-01-03 21:09:55,209:INFO:GradientBoostingRegressor(random_state=123)
2023-01-03 21:09:55,209:INFO:create_model() successfully completed......................................
2023-01-03 21:09:55,309:INFO:SubProcess create_model() end ==================================
2023-01-03 21:09:55,309:INFO:Creating metrics dataframe
2023-01-03 21:09:55,325:INFO:Initializing Light Gradient Boosting Machine
2023-01-03 21:09:55,325:INFO:Total runtime is 0.3824830412864685 minutes
2023-01-03 21:09:55,329:INFO:SubProcess create_model() called ==================================
2023-01-03 21:09:55,330:INFO:Initializing create_model()
2023-01-03 21:09:55,330:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024E5750B460>, estimator=lightgbm, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024E560E29A0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:09:55,330:INFO:Checking exceptions
2023-01-03 21:09:55,330:INFO:Importing libraries
2023-01-03 21:09:55,330:INFO:Copying training dataset
2023-01-03 21:09:55,339:INFO:Defining folds
2023-01-03 21:09:55,340:INFO:Declaring metric variables
2023-01-03 21:09:55,344:INFO:Importing untrained model
2023-01-03 21:09:55,349:INFO:Light Gradient Boosting Machine Imported successfully
2023-01-03 21:09:55,357:INFO:Starting cross validation
2023-01-03 21:09:55,359:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:09:56,327:INFO:Calculating mean and std
2023-01-03 21:09:56,329:INFO:Creating metrics dataframe
2023-01-03 21:09:56,333:INFO:Uploading results into container
2023-01-03 21:09:56,333:INFO:Uploading model into container now
2023-01-03 21:09:56,334:INFO:_master_model_container: 17
2023-01-03 21:09:56,334:INFO:_display_container: 2
2023-01-03 21:09:56,334:INFO:LGBMRegressor(random_state=123)
2023-01-03 21:09:56,334:INFO:create_model() successfully completed......................................
2023-01-03 21:09:56,438:INFO:SubProcess create_model() end ==================================
2023-01-03 21:09:56,438:INFO:Creating metrics dataframe
2023-01-03 21:09:56,454:INFO:Initializing Dummy Regressor
2023-01-03 21:09:56,454:INFO:Total runtime is 0.4012894550959269 minutes
2023-01-03 21:09:56,458:INFO:SubProcess create_model() called ==================================
2023-01-03 21:09:56,459:INFO:Initializing create_model()
2023-01-03 21:09:56,459:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024E5750B460>, estimator=dummy, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024E560E29A0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:09:56,459:INFO:Checking exceptions
2023-01-03 21:09:56,459:INFO:Importing libraries
2023-01-03 21:09:56,459:INFO:Copying training dataset
2023-01-03 21:09:56,469:INFO:Defining folds
2023-01-03 21:09:56,469:INFO:Declaring metric variables
2023-01-03 21:09:56,474:INFO:Importing untrained model
2023-01-03 21:09:56,478:INFO:Dummy Regressor Imported successfully
2023-01-03 21:09:56,485:INFO:Starting cross validation
2023-01-03 21:09:56,487:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:09:56,720:INFO:Calculating mean and std
2023-01-03 21:09:56,722:INFO:Creating metrics dataframe
2023-01-03 21:09:56,725:INFO:Uploading results into container
2023-01-03 21:09:56,725:INFO:Uploading model into container now
2023-01-03 21:09:56,725:INFO:_master_model_container: 18
2023-01-03 21:09:56,725:INFO:_display_container: 2
2023-01-03 21:09:56,726:INFO:DummyRegressor()
2023-01-03 21:09:56,726:INFO:create_model() successfully completed......................................
2023-01-03 21:09:56,828:INFO:SubProcess create_model() end ==================================
2023-01-03 21:09:56,829:INFO:Creating metrics dataframe
2023-01-03 21:09:56,857:INFO:Initializing create_model()
2023-01-03 21:09:56,857:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024E5750B460>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:09:56,857:INFO:Checking exceptions
2023-01-03 21:09:56,860:INFO:Importing libraries
2023-01-03 21:09:56,860:INFO:Copying training dataset
2023-01-03 21:09:56,868:INFO:Defining folds
2023-01-03 21:09:56,868:INFO:Declaring metric variables
2023-01-03 21:09:56,868:INFO:Importing untrained model
2023-01-03 21:09:56,868:INFO:Declaring custom model
2023-01-03 21:09:56,869:INFO:Extra Trees Regressor Imported successfully
2023-01-03 21:09:56,870:INFO:Cross validation set to False
2023-01-03 21:09:56,870:INFO:Fitting Model
2023-01-03 21:09:58,327:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-01-03 21:09:58,328:INFO:create_model() successfully completed......................................
2023-01-03 21:09:58,477:INFO:_master_model_container: 18
2023-01-03 21:09:58,477:INFO:_display_container: 2
2023-01-03 21:09:58,478:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-01-03 21:09:58,478:INFO:compare_models() successfully completed......................................
2023-01-03 21:09:58,489:INFO:Initializing tune_model()
2023-01-03 21:09:58,489:INFO:tune_model(estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=50, custom_grid=None, optimize=MAE, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024E5750B460>)
2023-01-03 21:09:58,489:INFO:Checking exceptions
2023-01-03 21:09:58,525:INFO:Copying training dataset
2023-01-03 21:09:58,535:INFO:Checking base model
2023-01-03 21:09:58,536:INFO:Base model : Extra Trees Regressor
2023-01-03 21:09:58,543:INFO:Declaring metric variables
2023-01-03 21:09:58,548:INFO:Defining Hyperparameters
2023-01-03 21:09:58,682:INFO:Tuning with n_jobs=-1
2023-01-03 21:09:58,682:INFO:Initializing RandomizedSearchCV
2023-01-03 21:09:58,750:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:09:58,752:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:09:58,758:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:09:58,770:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:10:08,853:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:10:27,114:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:10:31,066:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:10:35,702:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:10:41,102:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:10:47,228:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:10:54,255:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:10:56,274:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:10:57,593:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:11:01,964:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:11:07,089:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:11:17,356:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:11:22,400:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:11:28,160:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:11:29,497:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:11:38,833:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:11:39,252:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:11:42,096:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:11:45,253:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:11:46,309:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:11:47,215:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:11:48,165:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:11:49,093:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:11:54,850:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:12:02,219:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:12:06,972:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:12:34,209:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:12:39,769:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:12:46,757:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:12:47,572:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:13:00,849:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:13:07,151:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:13:09,421:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:13:12,789:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:13:22,597:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:13:32,127:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:13:36,985:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:13:42,390:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:13:43,318:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:13:51,077:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:13:59,598:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:14:02,094:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:14:08,045:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:14:15,384:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:14:19,448:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:14:33,966:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:14:34,437:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:14:35,900:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:14:36,644:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:14:40,982:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:14:45,559:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:14:53,347:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:14:54,372:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:14:55,562:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:14:56,570:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:14:57,730:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:14:58,327:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:14:59,315:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:14:59,802:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:15:00,347:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:15:00,471:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:15:00,663:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:15:01,319:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:15:01,459:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:15:01,590:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:15:04,112:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:15:05,063:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:15:07,068:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:15:07,550:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:15:09,379:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:15:09,831:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:15:10,178:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:15:10,549:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:15:10,980:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:15:13,006:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:15:26,616:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:16:06,881:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:16:10,822:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:16:14,328:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:16:18,061:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:16:22,152:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:16:26,306:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:16:30,112:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:16:34,130:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:16:38,761:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:16:44,369:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:16:51,368:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:16:55,377:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:16:59,406:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:17:02,339:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:17:02,389:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:17:04,947:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:17:04,959:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:17:17,925:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:17:38,462:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:18:27,076:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:18:35,917:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:18:39,538:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:18:43,311:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:18:47,046:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:18:50,846:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:18:54,558:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:18:57,760:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:19:01,314:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:19:05,226:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:19:09,602:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:19:14,213:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:19:18,067:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:19:22,801:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:19:28,244:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:19:28,488:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:19:35,469:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:19:37,657:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:19:38,450:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:19:40,314:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:19:41,285:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:19:43,161:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:19:44,204:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:19:52,225:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:20:08,055:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:20:37,120:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:20:40,836:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:20:44,158:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:20:47,588:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:20:51,244:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:20:54,809:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:20:58,387:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:21:02,948:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:21:08,987:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:21:09,455:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:21:21,534:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:21:25,486:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:21:28,238:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:21:28,936:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:21:33,448:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:21:37,350:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:21:47,310:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:21:48,180:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:21:51,302:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:21:55,404:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:21:55,689:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:22:06,760:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:22:17,152:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:22:20,869:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:22:33,679:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:22:34,224:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:22:42,159:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:22:46,683:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:22:54,610:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:23:08,543:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:23:14,958:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:23:31,177:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:23:37,638:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:23:47,748:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:23:53,334:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:24:15,096:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:24:45,760:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-01-03 21:24:45,760:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-01-03 21:24:45,760:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-01-03 21:24:45,760:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-01-03 21:24:46,372:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-01-03 21:24:46,722:INFO:PyCaret RegressionExperiment
2023-01-03 21:24:46,722:INFO:Logging name: reg-default-name
2023-01-03 21:24:46,722:INFO:ML Usecase: MLUsecase.REGRESSION
2023-01-03 21:24:46,722:INFO:version 3.0.0.rc6
2023-01-03 21:24:46,722:INFO:Initializing setup()
2023-01-03 21:24:46,723:INFO:self.USI: befc
2023-01-03 21:24:46,723:INFO:self._variable_keys: {'y_train', 'pipeline', 'exp_id', 'idx', 'data', '_ml_usecase', 'fold_shuffle_param', 'n_jobs_param', 'seed', 'logging_param', 'y_test', 'fold_groups_param', 'target_param', 'transform_target_param', 'y', 'gpu_param', 'X', 'fold_generator', 'html_param', 'log_plots_param', 'exp_name_log', 'memory', 'USI', 'gpu_n_jobs_param', '_available_plots', 'X_test', 'X_train'}
2023-01-03 21:24:46,723:INFO:Checking environment
2023-01-03 21:24:46,723:INFO:python_version: 3.9.13
2023-01-03 21:24:46,723:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-01-03 21:24:46,723:INFO:machine: AMD64
2023-01-03 21:24:46,723:INFO:platform: Windows-10-10.0.19044-SP0
2023-01-03 21:24:46,723:INFO:Memory: svmem(total=17114804224, available=10332995584, percent=39.6, used=6781808640, free=10332995584)
2023-01-03 21:24:46,723:INFO:Physical Core: 4
2023-01-03 21:24:46,723:INFO:Logical Core: 4
2023-01-03 21:24:46,723:INFO:Checking libraries
2023-01-03 21:24:46,723:INFO:System:
2023-01-03 21:24:46,723:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-01-03 21:24:46,724:INFO:executable: c:\Users\Kodotautas\anaconda3\python.exe
2023-01-03 21:24:46,724:INFO:   machine: Windows-10-10.0.19044-SP0
2023-01-03 21:24:46,724:INFO:PyCaret required dependencies:
2023-01-03 21:24:46,724:INFO:                 pip: 22.2.2
2023-01-03 21:24:46,724:INFO:          setuptools: 63.4.1
2023-01-03 21:24:46,724:INFO:             pycaret: 3.0.0rc6
2023-01-03 21:24:46,724:INFO:             IPython: 7.31.1
2023-01-03 21:24:46,724:INFO:          ipywidgets: 7.6.5
2023-01-03 21:24:46,724:INFO:                tqdm: 4.64.1
2023-01-03 21:24:46,724:INFO:               numpy: 1.21.5
2023-01-03 21:24:46,724:INFO:              pandas: 1.4.4
2023-01-03 21:24:46,724:INFO:              jinja2: 2.11.3
2023-01-03 21:24:46,724:INFO:               scipy: 1.9.1
2023-01-03 21:24:46,724:INFO:              joblib: 1.2.0
2023-01-03 21:24:46,724:INFO:             sklearn: 1.0.2
2023-01-03 21:24:46,724:INFO:                pyod: 1.0.7
2023-01-03 21:24:46,724:INFO:            imblearn: 0.10.1
2023-01-03 21:24:46,725:INFO:   category_encoders: 2.5.1.post0
2023-01-03 21:24:46,725:INFO:            lightgbm: 3.3.3
2023-01-03 21:24:46,725:INFO:               numba: 0.55.1
2023-01-03 21:24:46,725:INFO:            requests: 2.28.1
2023-01-03 21:24:46,725:INFO:          matplotlib: 3.5.2
2023-01-03 21:24:46,725:INFO:          scikitplot: 0.3.7
2023-01-03 21:24:46,725:INFO:         yellowbrick: 1.5
2023-01-03 21:24:46,725:INFO:              plotly: 5.9.0
2023-01-03 21:24:46,725:INFO:             kaleido: 0.2.1
2023-01-03 21:24:46,725:INFO:         statsmodels: 0.13.2
2023-01-03 21:24:46,725:INFO:              sktime: 0.14.1
2023-01-03 21:24:46,725:INFO:               tbats: 1.1.2
2023-01-03 21:24:46,725:INFO:            pmdarima: 2.0.2
2023-01-03 21:24:46,725:INFO:              psutil: 5.9.0
2023-01-03 21:24:46,725:INFO:PyCaret optional dependencies:
2023-01-03 21:24:47,075:INFO:                shap: 0.41.0
2023-01-03 21:24:47,075:INFO:           interpret: Not installed
2023-01-03 21:24:47,075:INFO:                umap: Not installed
2023-01-03 21:24:47,075:INFO:    pandas_profiling: Not installed
2023-01-03 21:24:47,075:INFO:  explainerdashboard: Not installed
2023-01-03 21:24:47,075:INFO:             autoviz: Not installed
2023-01-03 21:24:47,075:INFO:           fairlearn: Not installed
2023-01-03 21:24:47,076:INFO:             xgboost: Not installed
2023-01-03 21:24:47,076:INFO:            catboost: Not installed
2023-01-03 21:24:47,076:INFO:              kmodes: Not installed
2023-01-03 21:24:47,076:INFO:             mlxtend: Not installed
2023-01-03 21:24:47,076:INFO:       statsforecast: Not installed
2023-01-03 21:24:47,076:INFO:        tune_sklearn: 0.4.3
2023-01-03 21:24:47,076:INFO:                 ray: 2.0.0
2023-01-03 21:24:47,076:INFO:            hyperopt: 0.2.7
2023-01-03 21:24:47,076:INFO:              optuna: 3.0.1
2023-01-03 21:24:47,076:INFO:               skopt: 0.9.0
2023-01-03 21:24:47,076:INFO:              mlflow: Not installed
2023-01-03 21:24:47,076:INFO:              gradio: Not installed
2023-01-03 21:24:47,076:INFO:             fastapi: 0.88.0
2023-01-03 21:24:47,076:INFO:             uvicorn: 0.20.0
2023-01-03 21:24:47,076:INFO:              m2cgen: Not installed
2023-01-03 21:24:47,076:INFO:           evidently: Not installed
2023-01-03 21:24:47,076:INFO:                nltk: 3.7
2023-01-03 21:24:47,076:INFO:            pyLDAvis: Not installed
2023-01-03 21:24:47,076:INFO:              gensim: 4.1.2
2023-01-03 21:24:47,076:INFO:               spacy: 3.4.2
2023-01-03 21:24:47,076:INFO:           wordcloud: Not installed
2023-01-03 21:24:47,076:INFO:            textblob: Not installed
2023-01-03 21:24:47,076:INFO:               fugue: Not installed
2023-01-03 21:24:47,077:INFO:           streamlit: Not installed
2023-01-03 21:24:47,077:INFO:             prophet: Not installed
2023-01-03 21:24:47,077:INFO:None
2023-01-03 21:24:47,077:INFO:Set up data.
2023-01-03 21:24:47,095:INFO:Set up train/test split.
2023-01-03 21:24:47,106:INFO:Set up index.
2023-01-03 21:24:47,108:INFO:Set up folding strategy.
2023-01-03 21:24:47,108:INFO:Assigning column types.
2023-01-03 21:24:47,116:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-01-03 21:24:47,117:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-01-03 21:24:47,122:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-03 21:24:47,127:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 21:24:47,192:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 21:24:47,238:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 21:24:47,239:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:24:47,372:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:24:47,372:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-01-03 21:24:47,377:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-03 21:24:47,381:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 21:24:47,446:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 21:24:47,491:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 21:24:47,492:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:24:47,492:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:24:47,492:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-01-03 21:24:47,497:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-03 21:24:47,501:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 21:24:47,571:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 21:24:47,616:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 21:24:47,616:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:24:47,617:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:24:47,622:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-03 21:24:47,627:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 21:24:47,691:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 21:24:47,737:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 21:24:47,738:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:24:47,739:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:24:47,739:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-01-03 21:24:47,748:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 21:24:47,814:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 21:24:47,859:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 21:24:47,860:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:24:47,860:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:24:47,869:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 21:24:47,933:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 21:24:47,979:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 21:24:47,979:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:24:47,980:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:24:47,980:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-01-03 21:24:48,058:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 21:24:48,104:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 21:24:48,105:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:24:48,105:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:24:48,181:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 21:24:48,228:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 21:24:48,228:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:24:48,229:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:24:48,229:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-01-03 21:24:48,306:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 21:24:48,351:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:24:48,352:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:24:48,427:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 21:24:48,475:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:24:48,475:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:24:48,476:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-01-03 21:24:48,601:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:24:48,601:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:24:48,766:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:24:48,767:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:24:48,768:INFO:Preparing preprocessing pipeline...
2023-01-03 21:24:48,770:INFO:Set up simple imputation.
2023-01-03 21:24:48,770:INFO:Set up column transformation.
2023-01-03 21:24:48,770:INFO:Set up feature normalization.
2023-01-03 21:24:48,806:INFO:Finished creating preprocessing pipeline.
2023-01-03 21:24:48,813:INFO:Pipeline: Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2023-01-03 21:24:48,813:INFO:Creating final display dataframe.
2023-01-03 21:24:49,034:INFO:Setup _display_container:                Description             Value
0               Session id               123
1                   Target        b2b+b2c+vt
2              Target type        Regression
3               Data shape       (11081, 38)
4         Train data shape        (7756, 38)
5          Test data shape        (3325, 38)
6         Numeric features                 8
7               Preprocess              True
8          Imputation type            simple
9       Numeric imputation              mean
10  Categorical imputation              mode
11          Transformation              True
12   Transformation method       yeo-johnson
13               Normalize              True
14        Normalize method            zscore
15          Fold Generator   TimeSeriesSplit
16             Fold Number                 5
17                CPU Jobs                -1
18                 Use GPU             False
19          Log Experiment             False
20         Experiment Name  reg-default-name
21                     USI              befc
2023-01-03 21:24:49,171:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:24:49,172:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:24:49,297:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:24:49,298:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:24:49,298:INFO:setup() successfully completed in 2.58s...............
2023-01-03 21:24:49,299:INFO:Initializing compare_models()
2023-01-03 21:24:49,299:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002073D3E9490>, include=None, fold=None, round=4, cross_validation=True, sort=MAE, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000002073D3E9490>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'MAE', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-01-03 21:24:49,299:INFO:Checking exceptions
2023-01-03 21:24:49,304:INFO:Preparing display monitor
2023-01-03 21:24:49,343:INFO:Initializing Linear Regression
2023-01-03 21:24:49,343:INFO:Total runtime is 0.0 minutes
2023-01-03 21:24:49,347:INFO:SubProcess create_model() called ==================================
2023-01-03 21:24:49,348:INFO:Initializing create_model()
2023-01-03 21:24:49,348:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002073D3E9490>, estimator=lr, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020749117D90>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:24:49,348:INFO:Checking exceptions
2023-01-03 21:24:49,348:INFO:Importing libraries
2023-01-03 21:24:49,348:INFO:Copying training dataset
2023-01-03 21:24:49,358:INFO:Defining folds
2023-01-03 21:24:49,358:INFO:Declaring metric variables
2023-01-03 21:24:49,365:INFO:Importing untrained model
2023-01-03 21:24:49,371:INFO:Linear Regression Imported successfully
2023-01-03 21:24:49,380:INFO:Starting cross validation
2023-01-03 21:24:49,411:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:24:55,085:INFO:Calculating mean and std
2023-01-03 21:24:55,087:INFO:Creating metrics dataframe
2023-01-03 21:24:55,090:INFO:Uploading results into container
2023-01-03 21:24:55,090:INFO:Uploading model into container now
2023-01-03 21:24:55,091:INFO:_master_model_container: 1
2023-01-03 21:24:55,091:INFO:_display_container: 2
2023-01-03 21:24:55,091:INFO:LinearRegression(n_jobs=-1)
2023-01-03 21:24:55,091:INFO:create_model() successfully completed......................................
2023-01-03 21:24:55,183:INFO:SubProcess create_model() end ==================================
2023-01-03 21:24:55,183:INFO:Creating metrics dataframe
2023-01-03 21:24:55,195:INFO:Initializing Lasso Regression
2023-01-03 21:24:55,195:INFO:Total runtime is 0.09753888845443726 minutes
2023-01-03 21:24:55,199:INFO:SubProcess create_model() called ==================================
2023-01-03 21:24:55,199:INFO:Initializing create_model()
2023-01-03 21:24:55,199:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002073D3E9490>, estimator=lasso, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020749117D90>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:24:55,199:INFO:Checking exceptions
2023-01-03 21:24:55,199:INFO:Importing libraries
2023-01-03 21:24:55,199:INFO:Copying training dataset
2023-01-03 21:24:55,210:INFO:Defining folds
2023-01-03 21:24:55,210:INFO:Declaring metric variables
2023-01-03 21:24:55,214:INFO:Importing untrained model
2023-01-03 21:24:55,218:INFO:Lasso Regression Imported successfully
2023-01-03 21:24:55,228:INFO:Starting cross validation
2023-01-03 21:24:55,230:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:24:55,529:INFO:Calculating mean and std
2023-01-03 21:24:55,531:INFO:Creating metrics dataframe
2023-01-03 21:24:55,535:INFO:Uploading results into container
2023-01-03 21:24:55,536:INFO:Uploading model into container now
2023-01-03 21:24:55,537:INFO:_master_model_container: 2
2023-01-03 21:24:55,537:INFO:_display_container: 2
2023-01-03 21:24:55,538:INFO:Lasso(random_state=123)
2023-01-03 21:24:55,538:INFO:create_model() successfully completed......................................
2023-01-03 21:24:55,632:INFO:SubProcess create_model() end ==================================
2023-01-03 21:24:55,632:INFO:Creating metrics dataframe
2023-01-03 21:24:55,641:INFO:Initializing Ridge Regression
2023-01-03 21:24:55,641:INFO:Total runtime is 0.10497538248697917 minutes
2023-01-03 21:24:55,645:INFO:SubProcess create_model() called ==================================
2023-01-03 21:24:55,645:INFO:Initializing create_model()
2023-01-03 21:24:55,645:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002073D3E9490>, estimator=ridge, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020749117D90>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:24:55,645:INFO:Checking exceptions
2023-01-03 21:24:55,645:INFO:Importing libraries
2023-01-03 21:24:55,646:INFO:Copying training dataset
2023-01-03 21:24:55,654:INFO:Defining folds
2023-01-03 21:24:55,654:INFO:Declaring metric variables
2023-01-03 21:24:55,659:INFO:Importing untrained model
2023-01-03 21:24:55,664:INFO:Ridge Regression Imported successfully
2023-01-03 21:24:55,673:INFO:Starting cross validation
2023-01-03 21:24:55,676:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:24:55,911:INFO:Calculating mean and std
2023-01-03 21:24:55,913:INFO:Creating metrics dataframe
2023-01-03 21:24:55,916:INFO:Uploading results into container
2023-01-03 21:24:55,916:INFO:Uploading model into container now
2023-01-03 21:24:55,916:INFO:_master_model_container: 3
2023-01-03 21:24:55,916:INFO:_display_container: 2
2023-01-03 21:24:55,917:INFO:Ridge(random_state=123)
2023-01-03 21:24:55,917:INFO:create_model() successfully completed......................................
2023-01-03 21:24:56,011:INFO:SubProcess create_model() end ==================================
2023-01-03 21:24:56,011:INFO:Creating metrics dataframe
2023-01-03 21:24:56,020:INFO:Initializing Elastic Net
2023-01-03 21:24:56,021:INFO:Total runtime is 0.11129301389058431 minutes
2023-01-03 21:24:56,026:INFO:SubProcess create_model() called ==================================
2023-01-03 21:24:56,026:INFO:Initializing create_model()
2023-01-03 21:24:56,027:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002073D3E9490>, estimator=en, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020749117D90>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:24:56,027:INFO:Checking exceptions
2023-01-03 21:24:56,027:INFO:Importing libraries
2023-01-03 21:24:56,027:INFO:Copying training dataset
2023-01-03 21:24:56,034:INFO:Defining folds
2023-01-03 21:24:56,034:INFO:Declaring metric variables
2023-01-03 21:24:56,040:INFO:Importing untrained model
2023-01-03 21:24:56,046:INFO:Elastic Net Imported successfully
2023-01-03 21:24:56,055:INFO:Starting cross validation
2023-01-03 21:24:56,056:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:24:56,291:INFO:Calculating mean and std
2023-01-03 21:24:56,293:INFO:Creating metrics dataframe
2023-01-03 21:24:56,296:INFO:Uploading results into container
2023-01-03 21:24:56,296:INFO:Uploading model into container now
2023-01-03 21:24:56,296:INFO:_master_model_container: 4
2023-01-03 21:24:56,296:INFO:_display_container: 2
2023-01-03 21:24:56,297:INFO:ElasticNet(random_state=123)
2023-01-03 21:24:56,297:INFO:create_model() successfully completed......................................
2023-01-03 21:24:56,391:INFO:SubProcess create_model() end ==================================
2023-01-03 21:24:56,392:INFO:Creating metrics dataframe
2023-01-03 21:24:56,403:INFO:Initializing Least Angle Regression
2023-01-03 21:24:56,403:INFO:Total runtime is 0.1176597515741984 minutes
2023-01-03 21:24:56,408:INFO:SubProcess create_model() called ==================================
2023-01-03 21:24:56,409:INFO:Initializing create_model()
2023-01-03 21:24:56,409:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002073D3E9490>, estimator=lar, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020749117D90>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:24:56,409:INFO:Checking exceptions
2023-01-03 21:24:56,409:INFO:Importing libraries
2023-01-03 21:24:56,409:INFO:Copying training dataset
2023-01-03 21:24:56,417:INFO:Defining folds
2023-01-03 21:24:56,418:INFO:Declaring metric variables
2023-01-03 21:24:56,423:INFO:Importing untrained model
2023-01-03 21:24:56,427:INFO:Least Angle Regression Imported successfully
2023-01-03 21:24:56,436:INFO:Starting cross validation
2023-01-03 21:24:56,437:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:24:56,492:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 21:24:56,495:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 21:24:56,499:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 21:24:56,513:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 21:24:56,554:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 21:24:56,687:INFO:Calculating mean and std
2023-01-03 21:24:56,689:INFO:Creating metrics dataframe
2023-01-03 21:24:56,692:INFO:Uploading results into container
2023-01-03 21:24:56,692:INFO:Uploading model into container now
2023-01-03 21:24:56,692:INFO:_master_model_container: 5
2023-01-03 21:24:56,692:INFO:_display_container: 2
2023-01-03 21:24:56,693:INFO:Lars(random_state=123)
2023-01-03 21:24:56,693:INFO:create_model() successfully completed......................................
2023-01-03 21:24:56,787:INFO:SubProcess create_model() end ==================================
2023-01-03 21:24:56,787:INFO:Creating metrics dataframe
2023-01-03 21:24:56,797:INFO:Initializing Lasso Least Angle Regression
2023-01-03 21:24:56,797:INFO:Total runtime is 0.12423036098480225 minutes
2023-01-03 21:24:56,802:INFO:SubProcess create_model() called ==================================
2023-01-03 21:24:56,802:INFO:Initializing create_model()
2023-01-03 21:24:56,802:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002073D3E9490>, estimator=llar, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020749117D90>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:24:56,803:INFO:Checking exceptions
2023-01-03 21:24:56,803:INFO:Importing libraries
2023-01-03 21:24:56,803:INFO:Copying training dataset
2023-01-03 21:24:56,812:INFO:Defining folds
2023-01-03 21:24:56,812:INFO:Declaring metric variables
2023-01-03 21:24:56,816:INFO:Importing untrained model
2023-01-03 21:24:56,821:INFO:Lasso Least Angle Regression Imported successfully
2023-01-03 21:24:56,829:INFO:Starting cross validation
2023-01-03 21:24:56,831:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:24:56,881:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-03 21:24:56,885:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-03 21:24:56,895:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-03 21:24:56,912:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-03 21:24:56,936:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-03 21:24:57,071:INFO:Calculating mean and std
2023-01-03 21:24:57,073:INFO:Creating metrics dataframe
2023-01-03 21:24:57,076:INFO:Uploading results into container
2023-01-03 21:24:57,076:INFO:Uploading model into container now
2023-01-03 21:24:57,077:INFO:_master_model_container: 6
2023-01-03 21:24:57,077:INFO:_display_container: 2
2023-01-03 21:24:57,077:INFO:LassoLars(random_state=123)
2023-01-03 21:24:57,077:INFO:create_model() successfully completed......................................
2023-01-03 21:24:57,174:INFO:SubProcess create_model() end ==================================
2023-01-03 21:24:57,174:INFO:Creating metrics dataframe
2023-01-03 21:24:57,186:INFO:Initializing Orthogonal Matching Pursuit
2023-01-03 21:24:57,186:INFO:Total runtime is 0.1307167450586955 minutes
2023-01-03 21:24:57,191:INFO:SubProcess create_model() called ==================================
2023-01-03 21:24:57,191:INFO:Initializing create_model()
2023-01-03 21:24:57,191:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002073D3E9490>, estimator=omp, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020749117D90>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:24:57,192:INFO:Checking exceptions
2023-01-03 21:24:57,192:INFO:Importing libraries
2023-01-03 21:24:57,192:INFO:Copying training dataset
2023-01-03 21:24:57,200:INFO:Defining folds
2023-01-03 21:24:57,200:INFO:Declaring metric variables
2023-01-03 21:24:57,205:INFO:Importing untrained model
2023-01-03 21:24:57,209:INFO:Orthogonal Matching Pursuit Imported successfully
2023-01-03 21:24:57,218:INFO:Starting cross validation
2023-01-03 21:24:57,220:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:24:57,267:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 21:24:57,270:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 21:24:57,280:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 21:24:57,296:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 21:24:57,320:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 21:24:57,454:INFO:Calculating mean and std
2023-01-03 21:24:57,456:INFO:Creating metrics dataframe
2023-01-03 21:24:57,459:INFO:Uploading results into container
2023-01-03 21:24:57,459:INFO:Uploading model into container now
2023-01-03 21:24:57,459:INFO:_master_model_container: 7
2023-01-03 21:24:57,459:INFO:_display_container: 2
2023-01-03 21:24:57,460:INFO:OrthogonalMatchingPursuit()
2023-01-03 21:24:57,460:INFO:create_model() successfully completed......................................
2023-01-03 21:24:57,552:INFO:SubProcess create_model() end ==================================
2023-01-03 21:24:57,553:INFO:Creating metrics dataframe
2023-01-03 21:24:57,565:INFO:Initializing Bayesian Ridge
2023-01-03 21:24:57,565:INFO:Total runtime is 0.13703006903330486 minutes
2023-01-03 21:24:57,569:INFO:SubProcess create_model() called ==================================
2023-01-03 21:24:57,569:INFO:Initializing create_model()
2023-01-03 21:24:57,570:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002073D3E9490>, estimator=br, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020749117D90>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:24:57,570:INFO:Checking exceptions
2023-01-03 21:24:57,570:INFO:Importing libraries
2023-01-03 21:24:57,570:INFO:Copying training dataset
2023-01-03 21:24:57,579:INFO:Defining folds
2023-01-03 21:24:57,579:INFO:Declaring metric variables
2023-01-03 21:24:57,584:INFO:Importing untrained model
2023-01-03 21:24:57,589:INFO:Bayesian Ridge Imported successfully
2023-01-03 21:24:57,599:INFO:Starting cross validation
2023-01-03 21:24:57,600:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:24:57,851:INFO:Calculating mean and std
2023-01-03 21:24:57,853:INFO:Creating metrics dataframe
2023-01-03 21:24:57,856:INFO:Uploading results into container
2023-01-03 21:24:57,856:INFO:Uploading model into container now
2023-01-03 21:24:57,857:INFO:_master_model_container: 8
2023-01-03 21:24:57,857:INFO:_display_container: 2
2023-01-03 21:24:57,857:INFO:BayesianRidge()
2023-01-03 21:24:57,857:INFO:create_model() successfully completed......................................
2023-01-03 21:24:57,947:INFO:SubProcess create_model() end ==================================
2023-01-03 21:24:57,947:INFO:Creating metrics dataframe
2023-01-03 21:24:57,958:INFO:Initializing Passive Aggressive Regressor
2023-01-03 21:24:57,959:INFO:Total runtime is 0.14359596967697144 minutes
2023-01-03 21:24:57,964:INFO:SubProcess create_model() called ==================================
2023-01-03 21:24:57,964:INFO:Initializing create_model()
2023-01-03 21:24:57,964:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002073D3E9490>, estimator=par, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020749117D90>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:24:57,964:INFO:Checking exceptions
2023-01-03 21:24:57,964:INFO:Importing libraries
2023-01-03 21:24:57,964:INFO:Copying training dataset
2023-01-03 21:24:57,974:INFO:Defining folds
2023-01-03 21:24:57,974:INFO:Declaring metric variables
2023-01-03 21:24:57,978:INFO:Importing untrained model
2023-01-03 21:24:57,982:INFO:Passive Aggressive Regressor Imported successfully
2023-01-03 21:24:57,990:INFO:Starting cross validation
2023-01-03 21:24:57,992:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:24:58,233:INFO:Calculating mean and std
2023-01-03 21:24:58,235:INFO:Creating metrics dataframe
2023-01-03 21:24:58,238:INFO:Uploading results into container
2023-01-03 21:24:58,239:INFO:Uploading model into container now
2023-01-03 21:24:58,240:INFO:_master_model_container: 9
2023-01-03 21:24:58,240:INFO:_display_container: 2
2023-01-03 21:24:58,241:INFO:PassiveAggressiveRegressor(random_state=123)
2023-01-03 21:24:58,241:INFO:create_model() successfully completed......................................
2023-01-03 21:24:58,335:INFO:SubProcess create_model() end ==================================
2023-01-03 21:24:58,335:INFO:Creating metrics dataframe
2023-01-03 21:24:58,347:INFO:Initializing Huber Regressor
2023-01-03 21:24:58,347:INFO:Total runtime is 0.15007315079371136 minutes
2023-01-03 21:24:58,352:INFO:SubProcess create_model() called ==================================
2023-01-03 21:24:58,352:INFO:Initializing create_model()
2023-01-03 21:24:58,352:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002073D3E9490>, estimator=huber, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020749117D90>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:24:58,353:INFO:Checking exceptions
2023-01-03 21:24:58,353:INFO:Importing libraries
2023-01-03 21:24:58,353:INFO:Copying training dataset
2023-01-03 21:24:58,361:INFO:Defining folds
2023-01-03 21:24:58,362:INFO:Declaring metric variables
2023-01-03 21:24:58,366:INFO:Importing untrained model
2023-01-03 21:24:58,370:INFO:Huber Regressor Imported successfully
2023-01-03 21:24:58,379:INFO:Starting cross validation
2023-01-03 21:24:58,380:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:24:58,564:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-03 21:24:58,639:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-03 21:24:58,655:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-03 21:24:58,711:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-03 21:24:58,880:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-03 21:24:58,997:INFO:Calculating mean and std
2023-01-03 21:24:58,999:INFO:Creating metrics dataframe
2023-01-03 21:24:59,001:INFO:Uploading results into container
2023-01-03 21:24:59,002:INFO:Uploading model into container now
2023-01-03 21:24:59,002:INFO:_master_model_container: 10
2023-01-03 21:24:59,002:INFO:_display_container: 2
2023-01-03 21:24:59,003:INFO:HuberRegressor()
2023-01-03 21:24:59,003:INFO:create_model() successfully completed......................................
2023-01-03 21:24:59,091:INFO:SubProcess create_model() end ==================================
2023-01-03 21:24:59,092:INFO:Creating metrics dataframe
2023-01-03 21:24:59,108:INFO:Initializing K Neighbors Regressor
2023-01-03 21:24:59,109:INFO:Total runtime is 0.16274955272674563 minutes
2023-01-03 21:24:59,112:INFO:SubProcess create_model() called ==================================
2023-01-03 21:24:59,113:INFO:Initializing create_model()
2023-01-03 21:24:59,113:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002073D3E9490>, estimator=knn, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020749117D90>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:24:59,113:INFO:Checking exceptions
2023-01-03 21:24:59,113:INFO:Importing libraries
2023-01-03 21:24:59,113:INFO:Copying training dataset
2023-01-03 21:24:59,122:INFO:Defining folds
2023-01-03 21:24:59,122:INFO:Declaring metric variables
2023-01-03 21:24:59,127:INFO:Importing untrained model
2023-01-03 21:24:59,131:INFO:K Neighbors Regressor Imported successfully
2023-01-03 21:24:59,142:INFO:Starting cross validation
2023-01-03 21:24:59,143:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:24:59,866:INFO:Calculating mean and std
2023-01-03 21:24:59,868:INFO:Creating metrics dataframe
2023-01-03 21:24:59,871:INFO:Uploading results into container
2023-01-03 21:24:59,871:INFO:Uploading model into container now
2023-01-03 21:24:59,872:INFO:_master_model_container: 11
2023-01-03 21:24:59,872:INFO:_display_container: 2
2023-01-03 21:24:59,872:INFO:KNeighborsRegressor(n_jobs=-1)
2023-01-03 21:24:59,872:INFO:create_model() successfully completed......................................
2023-01-03 21:24:59,967:INFO:SubProcess create_model() end ==================================
2023-01-03 21:24:59,967:INFO:Creating metrics dataframe
2023-01-03 21:24:59,981:INFO:Initializing Decision Tree Regressor
2023-01-03 21:24:59,981:INFO:Total runtime is 0.17730882565180464 minutes
2023-01-03 21:24:59,985:INFO:SubProcess create_model() called ==================================
2023-01-03 21:24:59,985:INFO:Initializing create_model()
2023-01-03 21:24:59,985:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002073D3E9490>, estimator=dt, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020749117D90>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:24:59,985:INFO:Checking exceptions
2023-01-03 21:24:59,985:INFO:Importing libraries
2023-01-03 21:24:59,985:INFO:Copying training dataset
2023-01-03 21:24:59,995:INFO:Defining folds
2023-01-03 21:24:59,996:INFO:Declaring metric variables
2023-01-03 21:24:59,999:INFO:Importing untrained model
2023-01-03 21:25:00,004:INFO:Decision Tree Regressor Imported successfully
2023-01-03 21:25:00,013:INFO:Starting cross validation
2023-01-03 21:25:00,014:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:25:00,423:INFO:Calculating mean and std
2023-01-03 21:25:00,425:INFO:Creating metrics dataframe
2023-01-03 21:25:00,428:INFO:Uploading results into container
2023-01-03 21:25:00,428:INFO:Uploading model into container now
2023-01-03 21:25:00,429:INFO:_master_model_container: 12
2023-01-03 21:25:00,429:INFO:_display_container: 2
2023-01-03 21:25:00,429:INFO:DecisionTreeRegressor(random_state=123)
2023-01-03 21:25:00,429:INFO:create_model() successfully completed......................................
2023-01-03 21:25:00,519:INFO:SubProcess create_model() end ==================================
2023-01-03 21:25:00,520:INFO:Creating metrics dataframe
2023-01-03 21:25:00,533:INFO:Initializing Random Forest Regressor
2023-01-03 21:25:00,533:INFO:Total runtime is 0.18650348186492924 minutes
2023-01-03 21:25:00,538:INFO:SubProcess create_model() called ==================================
2023-01-03 21:25:00,538:INFO:Initializing create_model()
2023-01-03 21:25:00,539:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002073D3E9490>, estimator=rf, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020749117D90>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:25:00,539:INFO:Checking exceptions
2023-01-03 21:25:00,539:INFO:Importing libraries
2023-01-03 21:25:00,539:INFO:Copying training dataset
2023-01-03 21:25:00,548:INFO:Defining folds
2023-01-03 21:25:00,548:INFO:Declaring metric variables
2023-01-03 21:25:00,553:INFO:Importing untrained model
2023-01-03 21:25:00,557:INFO:Random Forest Regressor Imported successfully
2023-01-03 21:25:00,566:INFO:Starting cross validation
2023-01-03 21:25:00,567:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:25:07,881:INFO:Calculating mean and std
2023-01-03 21:25:07,883:INFO:Creating metrics dataframe
2023-01-03 21:25:07,886:INFO:Uploading results into container
2023-01-03 21:25:07,887:INFO:Uploading model into container now
2023-01-03 21:25:07,887:INFO:_master_model_container: 13
2023-01-03 21:25:07,888:INFO:_display_container: 2
2023-01-03 21:25:07,888:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-01-03 21:25:07,888:INFO:create_model() successfully completed......................................
2023-01-03 21:25:07,986:INFO:SubProcess create_model() end ==================================
2023-01-03 21:25:07,987:INFO:Creating metrics dataframe
2023-01-03 21:25:08,000:INFO:Initializing Extra Trees Regressor
2023-01-03 21:25:08,001:INFO:Total runtime is 0.31097006797790533 minutes
2023-01-03 21:25:08,005:INFO:SubProcess create_model() called ==================================
2023-01-03 21:25:08,005:INFO:Initializing create_model()
2023-01-03 21:25:08,006:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002073D3E9490>, estimator=et, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020749117D90>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:25:08,006:INFO:Checking exceptions
2023-01-03 21:25:08,006:INFO:Importing libraries
2023-01-03 21:25:08,006:INFO:Copying training dataset
2023-01-03 21:25:08,014:INFO:Defining folds
2023-01-03 21:25:08,014:INFO:Declaring metric variables
2023-01-03 21:25:08,018:INFO:Importing untrained model
2023-01-03 21:25:08,023:INFO:Extra Trees Regressor Imported successfully
2023-01-03 21:25:08,030:INFO:Starting cross validation
2023-01-03 21:25:08,033:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:25:11,559:INFO:Calculating mean and std
2023-01-03 21:25:11,561:INFO:Creating metrics dataframe
2023-01-03 21:25:11,564:INFO:Uploading results into container
2023-01-03 21:25:11,565:INFO:Uploading model into container now
2023-01-03 21:25:11,566:INFO:_master_model_container: 14
2023-01-03 21:25:11,566:INFO:_display_container: 2
2023-01-03 21:25:11,566:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-01-03 21:25:11,566:INFO:create_model() successfully completed......................................
2023-01-03 21:25:11,663:INFO:SubProcess create_model() end ==================================
2023-01-03 21:25:11,663:INFO:Creating metrics dataframe
2023-01-03 21:25:11,676:INFO:Initializing AdaBoost Regressor
2023-01-03 21:25:11,677:INFO:Total runtime is 0.37223012447357184 minutes
2023-01-03 21:25:11,681:INFO:SubProcess create_model() called ==================================
2023-01-03 21:25:11,681:INFO:Initializing create_model()
2023-01-03 21:25:11,681:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002073D3E9490>, estimator=ada, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020749117D90>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:25:11,681:INFO:Checking exceptions
2023-01-03 21:25:11,681:INFO:Importing libraries
2023-01-03 21:25:11,681:INFO:Copying training dataset
2023-01-03 21:25:11,691:INFO:Defining folds
2023-01-03 21:25:11,691:INFO:Declaring metric variables
2023-01-03 21:25:11,696:INFO:Importing untrained model
2023-01-03 21:25:11,700:INFO:AdaBoost Regressor Imported successfully
2023-01-03 21:25:11,710:INFO:Starting cross validation
2023-01-03 21:25:11,711:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:25:12,381:INFO:Calculating mean and std
2023-01-03 21:25:12,383:INFO:Creating metrics dataframe
2023-01-03 21:25:12,389:INFO:Uploading results into container
2023-01-03 21:25:12,390:INFO:Uploading model into container now
2023-01-03 21:25:12,391:INFO:_master_model_container: 15
2023-01-03 21:25:12,391:INFO:_display_container: 2
2023-01-03 21:25:12,391:INFO:AdaBoostRegressor(random_state=123)
2023-01-03 21:25:12,391:INFO:create_model() successfully completed......................................
2023-01-03 21:25:12,493:INFO:SubProcess create_model() end ==================================
2023-01-03 21:25:12,494:INFO:Creating metrics dataframe
2023-01-03 21:25:12,506:INFO:Initializing Gradient Boosting Regressor
2023-01-03 21:25:12,507:INFO:Total runtime is 0.38606315851211553 minutes
2023-01-03 21:25:12,511:INFO:SubProcess create_model() called ==================================
2023-01-03 21:25:12,511:INFO:Initializing create_model()
2023-01-03 21:25:12,511:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002073D3E9490>, estimator=gbr, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020749117D90>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:25:12,511:INFO:Checking exceptions
2023-01-03 21:25:12,511:INFO:Importing libraries
2023-01-03 21:25:12,512:INFO:Copying training dataset
2023-01-03 21:25:12,521:INFO:Defining folds
2023-01-03 21:25:12,522:INFO:Declaring metric variables
2023-01-03 21:25:12,526:INFO:Importing untrained model
2023-01-03 21:25:12,530:INFO:Gradient Boosting Regressor Imported successfully
2023-01-03 21:25:12,540:INFO:Starting cross validation
2023-01-03 21:25:12,542:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:25:16,881:INFO:Calculating mean and std
2023-01-03 21:25:16,883:INFO:Creating metrics dataframe
2023-01-03 21:25:16,889:INFO:Uploading results into container
2023-01-03 21:25:16,890:INFO:Uploading model into container now
2023-01-03 21:25:16,890:INFO:_master_model_container: 16
2023-01-03 21:25:16,890:INFO:_display_container: 2
2023-01-03 21:25:16,891:INFO:GradientBoostingRegressor(random_state=123)
2023-01-03 21:25:16,891:INFO:create_model() successfully completed......................................
2023-01-03 21:25:17,022:INFO:SubProcess create_model() end ==================================
2023-01-03 21:25:17,023:INFO:Creating metrics dataframe
2023-01-03 21:25:17,038:INFO:Initializing Light Gradient Boosting Machine
2023-01-03 21:25:17,039:INFO:Total runtime is 0.46160140434900926 minutes
2023-01-03 21:25:17,042:INFO:SubProcess create_model() called ==================================
2023-01-03 21:25:17,042:INFO:Initializing create_model()
2023-01-03 21:25:17,043:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002073D3E9490>, estimator=lightgbm, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020749117D90>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:25:17,043:INFO:Checking exceptions
2023-01-03 21:25:17,043:INFO:Importing libraries
2023-01-03 21:25:17,043:INFO:Copying training dataset
2023-01-03 21:25:17,052:INFO:Defining folds
2023-01-03 21:25:17,052:INFO:Declaring metric variables
2023-01-03 21:25:17,056:INFO:Importing untrained model
2023-01-03 21:25:17,060:INFO:Light Gradient Boosting Machine Imported successfully
2023-01-03 21:25:17,068:INFO:Starting cross validation
2023-01-03 21:25:17,070:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:25:19,049:INFO:Calculating mean and std
2023-01-03 21:25:19,051:INFO:Creating metrics dataframe
2023-01-03 21:25:19,054:INFO:Uploading results into container
2023-01-03 21:25:19,055:INFO:Uploading model into container now
2023-01-03 21:25:19,056:INFO:_master_model_container: 17
2023-01-03 21:25:19,056:INFO:_display_container: 2
2023-01-03 21:25:19,056:INFO:LGBMRegressor(random_state=123)
2023-01-03 21:25:19,057:INFO:create_model() successfully completed......................................
2023-01-03 21:25:19,158:INFO:SubProcess create_model() end ==================================
2023-01-03 21:25:19,158:INFO:Creating metrics dataframe
2023-01-03 21:25:19,171:INFO:Initializing Dummy Regressor
2023-01-03 21:25:19,171:INFO:Total runtime is 0.4971370657285055 minutes
2023-01-03 21:25:19,176:INFO:SubProcess create_model() called ==================================
2023-01-03 21:25:19,176:INFO:Initializing create_model()
2023-01-03 21:25:19,176:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002073D3E9490>, estimator=dummy, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020749117D90>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:25:19,176:INFO:Checking exceptions
2023-01-03 21:25:19,176:INFO:Importing libraries
2023-01-03 21:25:19,176:INFO:Copying training dataset
2023-01-03 21:25:19,185:INFO:Defining folds
2023-01-03 21:25:19,185:INFO:Declaring metric variables
2023-01-03 21:25:19,190:INFO:Importing untrained model
2023-01-03 21:25:19,194:INFO:Dummy Regressor Imported successfully
2023-01-03 21:25:19,203:INFO:Starting cross validation
2023-01-03 21:25:19,205:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:25:19,445:INFO:Calculating mean and std
2023-01-03 21:25:19,447:INFO:Creating metrics dataframe
2023-01-03 21:25:19,450:INFO:Uploading results into container
2023-01-03 21:25:19,450:INFO:Uploading model into container now
2023-01-03 21:25:19,451:INFO:_master_model_container: 18
2023-01-03 21:25:19,451:INFO:_display_container: 2
2023-01-03 21:25:19,451:INFO:DummyRegressor()
2023-01-03 21:25:19,451:INFO:create_model() successfully completed......................................
2023-01-03 21:25:19,550:INFO:SubProcess create_model() end ==================================
2023-01-03 21:25:19,550:INFO:Creating metrics dataframe
2023-01-03 21:25:19,580:INFO:Initializing create_model()
2023-01-03 21:25:19,581:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002073D3E9490>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:25:19,581:INFO:Checking exceptions
2023-01-03 21:25:19,583:INFO:Importing libraries
2023-01-03 21:25:19,584:INFO:Copying training dataset
2023-01-03 21:25:19,593:INFO:Defining folds
2023-01-03 21:25:19,594:INFO:Declaring metric variables
2023-01-03 21:25:19,594:INFO:Importing untrained model
2023-01-03 21:25:19,594:INFO:Declaring custom model
2023-01-03 21:25:19,595:INFO:Extra Trees Regressor Imported successfully
2023-01-03 21:25:19,595:INFO:Cross validation set to False
2023-01-03 21:25:19,595:INFO:Fitting Model
2023-01-03 21:25:21,103:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-01-03 21:25:21,103:INFO:create_model() successfully completed......................................
2023-01-03 21:25:21,245:INFO:_master_model_container: 18
2023-01-03 21:25:21,245:INFO:_display_container: 2
2023-01-03 21:25:21,245:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-01-03 21:25:21,246:INFO:compare_models() successfully completed......................................
2023-01-03 21:25:21,246:INFO:Initializing tune_model()
2023-01-03 21:25:21,246:INFO:tune_model(estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=3, custom_grid=None, optimize=MAE, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002073D3E9490>)
2023-01-03 21:25:21,246:INFO:Checking exceptions
2023-01-03 21:25:21,306:INFO:Copying training dataset
2023-01-03 21:25:21,315:INFO:Checking base model
2023-01-03 21:25:21,315:INFO:Base model : Extra Trees Regressor
2023-01-03 21:25:21,319:INFO:Declaring metric variables
2023-01-03 21:25:21,324:INFO:Defining Hyperparameters
2023-01-03 21:25:21,449:INFO:Tuning with n_jobs=-1
2023-01-03 21:25:21,449:INFO:Initializing RandomizedSearchCV
2023-01-03 21:25:21,499:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:25:21,500:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:25:21,508:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:25:21,524:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:25:21,782:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:25:21,807:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:25:21,819:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:25:21,913:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:25:22,193:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:25:22,227:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:25:22,338:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:25:22,476:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:25:22,908:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:25:22,950:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:25:23,028:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:25:23,455:INFO:best_params: {'actual_estimator__n_estimators': 100, 'actual_estimator__min_samples_split': 7, 'actual_estimator__min_samples_leaf': 4, 'actual_estimator__min_impurity_decrease': 0.1, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 9, 'actual_estimator__criterion': 'mse', 'actual_estimator__bootstrap': True}
2023-01-03 21:25:23,456:INFO:Hyperparameter search completed
2023-01-03 21:25:23,456:INFO:SubProcess create_model() called ==================================
2023-01-03 21:25:23,457:INFO:Initializing create_model()
2023-01-03 21:25:23,457:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002073D3E9490>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020748458F40>, model_only=True, return_train_score=False, kwargs={'n_estimators': 100, 'min_samples_split': 7, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.1, 'max_features': 1.0, 'max_depth': 9, 'criterion': 'mse', 'bootstrap': True})
2023-01-03 21:25:23,457:INFO:Checking exceptions
2023-01-03 21:25:23,457:INFO:Importing libraries
2023-01-03 21:25:23,457:INFO:Copying training dataset
2023-01-03 21:25:23,468:INFO:Defining folds
2023-01-03 21:25:23,468:INFO:Declaring metric variables
2023-01-03 21:25:23,471:INFO:Importing untrained model
2023-01-03 21:25:23,471:INFO:Declaring custom model
2023-01-03 21:25:23,476:INFO:Extra Trees Regressor Imported successfully
2023-01-03 21:25:23,483:INFO:Starting cross validation
2023-01-03 21:25:23,485:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:25:23,569:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:25:23,573:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:25:23,594:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:25:23,609:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:25:24,129:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:25:24,562:INFO:Calculating mean and std
2023-01-03 21:25:24,564:INFO:Creating metrics dataframe
2023-01-03 21:25:24,569:INFO:Finalizing model
2023-01-03 21:25:24,895:INFO:Uploading results into container
2023-01-03 21:25:24,896:INFO:Uploading model into container now
2023-01-03 21:25:24,897:INFO:_master_model_container: 19
2023-01-03 21:25:24,897:INFO:_display_container: 3
2023-01-03 21:25:24,897:INFO:ExtraTreesRegressor(bootstrap=True, criterion='mse', max_depth=9,
                    max_features=1.0, min_impurity_decrease=0.1,
                    min_samples_leaf=4, min_samples_split=7, n_jobs=-1,
                    random_state=123)
2023-01-03 21:25:24,897:INFO:create_model() successfully completed......................................
2023-01-03 21:25:25,001:INFO:SubProcess create_model() end ==================================
2023-01-03 21:25:25,001:INFO:choose_better activated
2023-01-03 21:25:25,005:INFO:SubProcess create_model() called ==================================
2023-01-03 21:25:25,006:INFO:Initializing create_model()
2023-01-03 21:25:25,006:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002073D3E9490>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:25:25,006:INFO:Checking exceptions
2023-01-03 21:25:25,008:INFO:Importing libraries
2023-01-03 21:25:25,008:INFO:Copying training dataset
2023-01-03 21:25:25,015:INFO:Defining folds
2023-01-03 21:25:25,015:INFO:Declaring metric variables
2023-01-03 21:25:25,015:INFO:Importing untrained model
2023-01-03 21:25:25,016:INFO:Declaring custom model
2023-01-03 21:25:25,016:INFO:Extra Trees Regressor Imported successfully
2023-01-03 21:25:25,016:INFO:Starting cross validation
2023-01-03 21:25:25,017:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:25:28,701:INFO:Calculating mean and std
2023-01-03 21:25:28,702:INFO:Creating metrics dataframe
2023-01-03 21:25:28,704:INFO:Finalizing model
2023-01-03 21:25:30,130:INFO:Uploading results into container
2023-01-03 21:25:30,130:INFO:Uploading model into container now
2023-01-03 21:25:30,131:INFO:_master_model_container: 20
2023-01-03 21:25:30,131:INFO:_display_container: 4
2023-01-03 21:25:30,131:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-01-03 21:25:30,131:INFO:create_model() successfully completed......................................
2023-01-03 21:25:30,230:INFO:SubProcess create_model() end ==================================
2023-01-03 21:25:30,231:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123) result for MAE is 3.6075
2023-01-03 21:25:30,231:INFO:ExtraTreesRegressor(bootstrap=True, criterion='mse', max_depth=9,
                    max_features=1.0, min_impurity_decrease=0.1,
                    min_samples_leaf=4, min_samples_split=7, n_jobs=-1,
                    random_state=123) result for MAE is 4.6273
2023-01-03 21:25:30,232:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123) is best model
2023-01-03 21:25:30,232:INFO:choose_better completed
2023-01-03 21:25:30,232:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-01-03 21:25:30,242:INFO:_master_model_container: 20
2023-01-03 21:25:30,242:INFO:_display_container: 3
2023-01-03 21:25:30,242:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-01-03 21:25:30,242:INFO:tune_model() successfully completed......................................
2023-01-03 21:25:30,345:INFO:Initializing plot_model()
2023-01-03 21:25:30,345:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002073D3E9490>, system=True)
2023-01-03 21:25:30,345:INFO:Checking exceptions
2023-01-03 21:25:30,375:INFO:Preloading libraries
2023-01-03 21:25:30,520:INFO:Copying training dataset
2023-01-03 21:25:30,520:INFO:Plot type: error
2023-01-03 21:25:30,691:INFO:Fitting Model
2023-01-03 21:25:30,691:INFO:Scoring test/hold-out set
2023-01-03 21:25:31,202:INFO:Visual Rendered Successfully
2023-01-03 21:25:31,315:INFO:plot_model() successfully completed......................................
2023-01-03 21:25:31,328:INFO:Initializing predict_model()
2023-01-03 21:25:31,328:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002073D3E9490>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x0000020748D8F9D0>)
2023-01-03 21:25:31,328:INFO:Checking exceptions
2023-01-03 21:25:31,328:INFO:Preloading libraries
2023-01-03 21:25:31,526:INFO:Initializing finalize_model()
2023-01-03 21:25:31,526:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002073D3E9490>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-01-03 21:25:31,526:INFO:Finalizing ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-01-03 21:25:31,534:INFO:Initializing create_model()
2023-01-03 21:25:31,534:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002073D3E9490>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-01-03 21:25:31,534:INFO:Checking exceptions
2023-01-03 21:25:31,535:INFO:Importing libraries
2023-01-03 21:25:31,536:INFO:Copying training dataset
2023-01-03 21:25:31,536:INFO:Defining folds
2023-01-03 21:25:31,536:INFO:Declaring metric variables
2023-01-03 21:25:31,536:INFO:Importing untrained model
2023-01-03 21:25:31,536:INFO:Declaring custom model
2023-01-03 21:25:31,537:INFO:Extra Trees Regressor Imported successfully
2023-01-03 21:25:31,538:INFO:Cross validation set to False
2023-01-03 21:25:31,538:INFO:Fitting Model
2023-01-03 21:25:34,204:INFO:Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))])
2023-01-03 21:25:34,205:INFO:create_model() successfully completed......................................
2023-01-03 21:25:34,299:INFO:_master_model_container: 20
2023-01-03 21:25:34,299:INFO:_display_container: 4
2023-01-03 21:25:34,306:INFO:Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))])
2023-01-03 21:25:34,306:INFO:finalize_model() successfully completed......................................
2023-01-03 21:25:34,402:INFO:Initializing predict_model()
2023-01-03 21:25:34,403:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002073D3E9490>, estimator=Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x0000020748F8E310>)
2023-01-03 21:25:34,403:INFO:Checking exceptions
2023-01-03 21:25:34,403:INFO:Preloading libraries
2023-01-03 21:25:34,405:INFO:Set up data.
2023-01-03 21:25:34,416:INFO:Set up index.
2023-01-03 21:26:45,306:INFO:PyCaret RegressionExperiment
2023-01-03 21:26:45,306:INFO:Logging name: reg-default-name
2023-01-03 21:26:45,306:INFO:ML Usecase: MLUsecase.REGRESSION
2023-01-03 21:26:45,306:INFO:version 3.0.0.rc6
2023-01-03 21:26:45,306:INFO:Initializing setup()
2023-01-03 21:26:45,306:INFO:self.USI: bc42
2023-01-03 21:26:45,306:INFO:self._variable_keys: {'y_train', 'pipeline', 'exp_id', 'idx', 'data', '_ml_usecase', 'fold_shuffle_param', 'n_jobs_param', 'seed', 'logging_param', 'y_test', 'fold_groups_param', 'target_param', 'transform_target_param', 'y', 'gpu_param', 'X', 'fold_generator', 'html_param', 'log_plots_param', 'exp_name_log', 'memory', 'USI', 'gpu_n_jobs_param', '_available_plots', 'X_test', 'X_train'}
2023-01-03 21:26:45,306:INFO:Checking environment
2023-01-03 21:26:45,306:INFO:python_version: 3.9.13
2023-01-03 21:26:45,306:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-01-03 21:26:45,306:INFO:machine: AMD64
2023-01-03 21:26:45,306:INFO:platform: Windows-10-10.0.19044-SP0
2023-01-03 21:26:45,306:INFO:Memory: svmem(total=17114804224, available=9570926592, percent=44.1, used=7543877632, free=9570926592)
2023-01-03 21:26:45,306:INFO:Physical Core: 4
2023-01-03 21:26:45,306:INFO:Logical Core: 4
2023-01-03 21:26:45,307:INFO:Checking libraries
2023-01-03 21:26:45,307:INFO:System:
2023-01-03 21:26:45,307:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-01-03 21:26:45,307:INFO:executable: c:\Users\Kodotautas\anaconda3\python.exe
2023-01-03 21:26:45,307:INFO:   machine: Windows-10-10.0.19044-SP0
2023-01-03 21:26:45,307:INFO:PyCaret required dependencies:
2023-01-03 21:26:45,307:INFO:                 pip: 22.2.2
2023-01-03 21:26:45,307:INFO:          setuptools: 63.4.1
2023-01-03 21:26:45,307:INFO:             pycaret: 3.0.0rc6
2023-01-03 21:26:45,307:INFO:             IPython: 7.31.1
2023-01-03 21:26:45,307:INFO:          ipywidgets: 7.6.5
2023-01-03 21:26:45,307:INFO:                tqdm: 4.64.1
2023-01-03 21:26:45,307:INFO:               numpy: 1.21.5
2023-01-03 21:26:45,307:INFO:              pandas: 1.4.4
2023-01-03 21:26:45,307:INFO:              jinja2: 2.11.3
2023-01-03 21:26:45,307:INFO:               scipy: 1.9.1
2023-01-03 21:26:45,307:INFO:              joblib: 1.2.0
2023-01-03 21:26:45,307:INFO:             sklearn: 1.0.2
2023-01-03 21:26:45,307:INFO:                pyod: 1.0.7
2023-01-03 21:26:45,307:INFO:            imblearn: 0.10.1
2023-01-03 21:26:45,308:INFO:   category_encoders: 2.5.1.post0
2023-01-03 21:26:45,308:INFO:            lightgbm: 3.3.3
2023-01-03 21:26:45,308:INFO:               numba: 0.55.1
2023-01-03 21:26:45,308:INFO:            requests: 2.28.1
2023-01-03 21:26:45,308:INFO:          matplotlib: 3.5.2
2023-01-03 21:26:45,308:INFO:          scikitplot: 0.3.7
2023-01-03 21:26:45,308:INFO:         yellowbrick: 1.5
2023-01-03 21:26:45,308:INFO:              plotly: 5.9.0
2023-01-03 21:26:45,308:INFO:             kaleido: 0.2.1
2023-01-03 21:26:45,308:INFO:         statsmodels: 0.13.2
2023-01-03 21:26:45,308:INFO:              sktime: 0.14.1
2023-01-03 21:26:45,308:INFO:               tbats: 1.1.2
2023-01-03 21:26:45,309:INFO:            pmdarima: 2.0.2
2023-01-03 21:26:45,309:INFO:              psutil: 5.9.0
2023-01-03 21:26:45,309:INFO:PyCaret optional dependencies:
2023-01-03 21:26:45,309:INFO:                shap: 0.41.0
2023-01-03 21:26:45,309:INFO:           interpret: Not installed
2023-01-03 21:26:45,309:INFO:                umap: Not installed
2023-01-03 21:26:45,309:INFO:    pandas_profiling: Not installed
2023-01-03 21:26:45,309:INFO:  explainerdashboard: Not installed
2023-01-03 21:26:45,309:INFO:             autoviz: Not installed
2023-01-03 21:26:45,309:INFO:           fairlearn: Not installed
2023-01-03 21:26:45,309:INFO:             xgboost: Not installed
2023-01-03 21:26:45,309:INFO:            catboost: Not installed
2023-01-03 21:26:45,309:INFO:              kmodes: Not installed
2023-01-03 21:26:45,310:INFO:             mlxtend: Not installed
2023-01-03 21:26:45,310:INFO:       statsforecast: Not installed
2023-01-03 21:26:45,310:INFO:        tune_sklearn: 0.4.3
2023-01-03 21:26:45,310:INFO:                 ray: 2.0.0
2023-01-03 21:26:45,310:INFO:            hyperopt: 0.2.7
2023-01-03 21:26:45,310:INFO:              optuna: 3.0.1
2023-01-03 21:26:45,310:INFO:               skopt: 0.9.0
2023-01-03 21:26:45,310:INFO:              mlflow: Not installed
2023-01-03 21:26:45,310:INFO:              gradio: Not installed
2023-01-03 21:26:45,310:INFO:             fastapi: 0.88.0
2023-01-03 21:26:45,310:INFO:             uvicorn: 0.20.0
2023-01-03 21:26:45,310:INFO:              m2cgen: Not installed
2023-01-03 21:26:45,310:INFO:           evidently: Not installed
2023-01-03 21:26:45,310:INFO:                nltk: 3.7
2023-01-03 21:26:45,310:INFO:            pyLDAvis: Not installed
2023-01-03 21:26:45,310:INFO:              gensim: 4.1.2
2023-01-03 21:26:45,310:INFO:               spacy: 3.4.2
2023-01-03 21:26:45,310:INFO:           wordcloud: Not installed
2023-01-03 21:26:45,310:INFO:            textblob: Not installed
2023-01-03 21:26:45,311:INFO:               fugue: Not installed
2023-01-03 21:26:45,311:INFO:           streamlit: Not installed
2023-01-03 21:26:45,311:INFO:             prophet: Not installed
2023-01-03 21:26:45,311:INFO:None
2023-01-03 21:26:45,311:INFO:Set up data.
2023-01-03 21:26:45,327:INFO:Set up train/test split.
2023-01-03 21:26:45,337:INFO:Set up index.
2023-01-03 21:26:45,339:INFO:Set up folding strategy.
2023-01-03 21:26:45,339:INFO:Assigning column types.
2023-01-03 21:26:45,348:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-01-03 21:26:45,349:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-01-03 21:26:45,354:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-03 21:26:45,359:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 21:26:45,424:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 21:26:45,471:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 21:26:45,471:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:26:45,472:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:26:45,472:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-01-03 21:26:45,477:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-03 21:26:45,482:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 21:26:45,547:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 21:26:45,593:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 21:26:45,594:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:26:45,594:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:26:45,594:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-01-03 21:26:45,599:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-03 21:26:45,604:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 21:26:45,671:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 21:26:45,718:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 21:26:45,718:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:26:45,719:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:26:45,724:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-03 21:26:45,729:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 21:26:45,799:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 21:26:45,846:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 21:26:45,847:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:26:45,847:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:26:45,847:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-01-03 21:26:45,857:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 21:26:45,924:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 21:26:45,972:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 21:26:45,972:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:26:45,973:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:26:45,983:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 21:26:46,056:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 21:26:46,107:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 21:26:46,107:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:26:46,108:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:26:46,108:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-01-03 21:26:46,183:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 21:26:46,229:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 21:26:46,229:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:26:46,229:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:26:46,309:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 21:26:46,355:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 21:26:46,356:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:26:46,356:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:26:46,356:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-01-03 21:26:46,432:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 21:26:46,478:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:26:46,479:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:26:46,554:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 21:26:46,602:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:26:46,603:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:26:46,603:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-01-03 21:26:46,729:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:26:46,730:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:26:46,852:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:26:46,853:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:26:46,854:INFO:Preparing preprocessing pipeline...
2023-01-03 21:26:46,856:INFO:Set up simple imputation.
2023-01-03 21:26:46,856:INFO:Set up column transformation.
2023-01-03 21:26:46,856:INFO:Set up feature normalization.
2023-01-03 21:26:46,896:INFO:Finished creating preprocessing pipeline.
2023-01-03 21:26:46,904:INFO:Pipeline: Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2023-01-03 21:26:46,904:INFO:Creating final display dataframe.
2023-01-03 21:26:47,136:INFO:Setup _display_container:                Description             Value
0               Session id               123
1                   Target        b2b+b2c+vt
2              Target type        Regression
3               Data shape       (11081, 38)
4         Train data shape        (7756, 38)
5          Test data shape        (3325, 38)
6         Numeric features                 8
7               Preprocess              True
8          Imputation type            simple
9       Numeric imputation              mean
10  Categorical imputation              mode
11          Transformation              True
12   Transformation method       yeo-johnson
13               Normalize              True
14        Normalize method            zscore
15          Fold Generator   TimeSeriesSplit
16             Fold Number                 5
17                CPU Jobs                -1
18                 Use GPU             False
19          Log Experiment             False
20         Experiment Name  reg-default-name
21                     USI              bc42
2023-01-03 21:26:47,277:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:26:47,278:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:26:47,402:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:26:47,402:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:26:47,403:INFO:setup() successfully completed in 2.1s...............
2023-01-03 21:26:47,403:INFO:Initializing compare_models()
2023-01-03 21:26:47,403:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020748CE5E80>, include=None, fold=None, round=4, cross_validation=True, sort=MAE, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x0000020748CE5E80>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'MAE', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-01-03 21:26:47,403:INFO:Checking exceptions
2023-01-03 21:26:47,409:INFO:Preparing display monitor
2023-01-03 21:26:47,451:INFO:Initializing Linear Regression
2023-01-03 21:26:47,451:INFO:Total runtime is 0.0 minutes
2023-01-03 21:26:47,456:INFO:SubProcess create_model() called ==================================
2023-01-03 21:26:47,457:INFO:Initializing create_model()
2023-01-03 21:26:47,457:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020748CE5E80>, estimator=lr, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002073D3A5040>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:26:47,457:INFO:Checking exceptions
2023-01-03 21:26:47,457:INFO:Importing libraries
2023-01-03 21:26:47,457:INFO:Copying training dataset
2023-01-03 21:26:47,467:INFO:Defining folds
2023-01-03 21:26:47,467:INFO:Declaring metric variables
2023-01-03 21:26:47,472:INFO:Importing untrained model
2023-01-03 21:26:47,476:INFO:Linear Regression Imported successfully
2023-01-03 21:26:47,485:INFO:Starting cross validation
2023-01-03 21:26:47,486:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:26:47,843:INFO:Calculating mean and std
2023-01-03 21:26:47,844:INFO:Creating metrics dataframe
2023-01-03 21:26:47,848:INFO:Uploading results into container
2023-01-03 21:26:47,848:INFO:Uploading model into container now
2023-01-03 21:26:47,849:INFO:_master_model_container: 1
2023-01-03 21:26:47,849:INFO:_display_container: 2
2023-01-03 21:26:47,849:INFO:LinearRegression(n_jobs=-1)
2023-01-03 21:26:47,849:INFO:create_model() successfully completed......................................
2023-01-03 21:26:47,970:INFO:SubProcess create_model() end ==================================
2023-01-03 21:26:47,970:INFO:Creating metrics dataframe
2023-01-03 21:26:47,979:INFO:Initializing Lasso Regression
2023-01-03 21:26:47,979:INFO:Total runtime is 0.008799990018208822 minutes
2023-01-03 21:26:47,982:INFO:SubProcess create_model() called ==================================
2023-01-03 21:26:47,983:INFO:Initializing create_model()
2023-01-03 21:26:47,983:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020748CE5E80>, estimator=lasso, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002073D3A5040>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:26:47,983:INFO:Checking exceptions
2023-01-03 21:26:47,984:INFO:Importing libraries
2023-01-03 21:26:47,984:INFO:Copying training dataset
2023-01-03 21:26:47,991:INFO:Defining folds
2023-01-03 21:26:47,991:INFO:Declaring metric variables
2023-01-03 21:26:47,995:INFO:Importing untrained model
2023-01-03 21:26:47,998:INFO:Lasso Regression Imported successfully
2023-01-03 21:26:48,009:INFO:Starting cross validation
2023-01-03 21:26:48,011:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:26:48,256:INFO:Calculating mean and std
2023-01-03 21:26:48,256:INFO:Creating metrics dataframe
2023-01-03 21:26:48,260:INFO:Uploading results into container
2023-01-03 21:26:48,261:INFO:Uploading model into container now
2023-01-03 21:26:48,261:INFO:_master_model_container: 2
2023-01-03 21:26:48,261:INFO:_display_container: 2
2023-01-03 21:26:48,261:INFO:Lasso(random_state=123)
2023-01-03 21:26:48,261:INFO:create_model() successfully completed......................................
2023-01-03 21:26:48,373:INFO:SubProcess create_model() end ==================================
2023-01-03 21:26:48,374:INFO:Creating metrics dataframe
2023-01-03 21:26:48,386:INFO:Initializing Ridge Regression
2023-01-03 21:26:48,386:INFO:Total runtime is 0.015583336353302002 minutes
2023-01-03 21:26:48,392:INFO:SubProcess create_model() called ==================================
2023-01-03 21:26:48,394:INFO:Initializing create_model()
2023-01-03 21:26:48,394:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020748CE5E80>, estimator=ridge, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002073D3A5040>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:26:48,394:INFO:Checking exceptions
2023-01-03 21:26:48,394:INFO:Importing libraries
2023-01-03 21:26:48,394:INFO:Copying training dataset
2023-01-03 21:26:48,407:INFO:Defining folds
2023-01-03 21:26:48,407:INFO:Declaring metric variables
2023-01-03 21:26:48,417:INFO:Importing untrained model
2023-01-03 21:26:48,422:INFO:Ridge Regression Imported successfully
2023-01-03 21:26:48,433:INFO:Starting cross validation
2023-01-03 21:26:48,435:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:26:48,668:INFO:Calculating mean and std
2023-01-03 21:26:48,669:INFO:Creating metrics dataframe
2023-01-03 21:26:48,674:INFO:Uploading results into container
2023-01-03 21:26:48,675:INFO:Uploading model into container now
2023-01-03 21:26:48,676:INFO:_master_model_container: 3
2023-01-03 21:26:48,676:INFO:_display_container: 2
2023-01-03 21:26:48,676:INFO:Ridge(random_state=123)
2023-01-03 21:26:48,676:INFO:create_model() successfully completed......................................
2023-01-03 21:26:48,787:INFO:SubProcess create_model() end ==================================
2023-01-03 21:26:48,787:INFO:Creating metrics dataframe
2023-01-03 21:26:48,799:INFO:Initializing Elastic Net
2023-01-03 21:26:48,799:INFO:Total runtime is 0.022466655572255453 minutes
2023-01-03 21:26:48,803:INFO:SubProcess create_model() called ==================================
2023-01-03 21:26:48,803:INFO:Initializing create_model()
2023-01-03 21:26:48,803:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020748CE5E80>, estimator=en, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002073D3A5040>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:26:48,804:INFO:Checking exceptions
2023-01-03 21:26:48,804:INFO:Importing libraries
2023-01-03 21:26:48,804:INFO:Copying training dataset
2023-01-03 21:26:48,813:INFO:Defining folds
2023-01-03 21:26:48,814:INFO:Declaring metric variables
2023-01-03 21:26:48,817:INFO:Importing untrained model
2023-01-03 21:26:48,822:INFO:Elastic Net Imported successfully
2023-01-03 21:26:48,832:INFO:Starting cross validation
2023-01-03 21:26:48,833:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:26:49,187:INFO:Calculating mean and std
2023-01-03 21:26:49,189:INFO:Creating metrics dataframe
2023-01-03 21:26:49,192:INFO:Uploading results into container
2023-01-03 21:26:49,193:INFO:Uploading model into container now
2023-01-03 21:26:49,193:INFO:_master_model_container: 4
2023-01-03 21:26:49,193:INFO:_display_container: 2
2023-01-03 21:26:49,193:INFO:ElasticNet(random_state=123)
2023-01-03 21:26:49,193:INFO:create_model() successfully completed......................................
2023-01-03 21:26:49,292:INFO:SubProcess create_model() end ==================================
2023-01-03 21:26:49,293:INFO:Creating metrics dataframe
2023-01-03 21:26:49,305:INFO:Initializing Least Angle Regression
2023-01-03 21:26:49,305:INFO:Total runtime is 0.030891398588816326 minutes
2023-01-03 21:26:49,309:INFO:SubProcess create_model() called ==================================
2023-01-03 21:26:49,309:INFO:Initializing create_model()
2023-01-03 21:26:49,309:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020748CE5E80>, estimator=lar, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002073D3A5040>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:26:49,310:INFO:Checking exceptions
2023-01-03 21:26:49,310:INFO:Importing libraries
2023-01-03 21:26:49,310:INFO:Copying training dataset
2023-01-03 21:26:49,320:INFO:Defining folds
2023-01-03 21:26:49,320:INFO:Declaring metric variables
2023-01-03 21:26:49,323:INFO:Importing untrained model
2023-01-03 21:26:49,330:INFO:Least Angle Regression Imported successfully
2023-01-03 21:26:49,340:INFO:Starting cross validation
2023-01-03 21:26:49,341:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:26:49,390:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 21:26:49,396:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 21:26:49,406:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 21:26:49,422:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 21:26:49,454:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 21:26:49,586:INFO:Calculating mean and std
2023-01-03 21:26:49,588:INFO:Creating metrics dataframe
2023-01-03 21:26:49,591:INFO:Uploading results into container
2023-01-03 21:26:49,592:INFO:Uploading model into container now
2023-01-03 21:26:49,593:INFO:_master_model_container: 5
2023-01-03 21:26:49,593:INFO:_display_container: 2
2023-01-03 21:26:49,593:INFO:Lars(random_state=123)
2023-01-03 21:26:49,593:INFO:create_model() successfully completed......................................
2023-01-03 21:26:49,695:INFO:SubProcess create_model() end ==================================
2023-01-03 21:26:49,696:INFO:Creating metrics dataframe
2023-01-03 21:26:49,705:INFO:Initializing Lasso Least Angle Regression
2023-01-03 21:26:49,705:INFO:Total runtime is 0.03756165901819865 minutes
2023-01-03 21:26:49,709:INFO:SubProcess create_model() called ==================================
2023-01-03 21:26:49,709:INFO:Initializing create_model()
2023-01-03 21:26:49,709:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020748CE5E80>, estimator=llar, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002073D3A5040>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:26:49,709:INFO:Checking exceptions
2023-01-03 21:26:49,710:INFO:Importing libraries
2023-01-03 21:26:49,710:INFO:Copying training dataset
2023-01-03 21:26:49,719:INFO:Defining folds
2023-01-03 21:26:49,719:INFO:Declaring metric variables
2023-01-03 21:26:49,724:INFO:Importing untrained model
2023-01-03 21:26:49,728:INFO:Lasso Least Angle Regression Imported successfully
2023-01-03 21:26:49,738:INFO:Starting cross validation
2023-01-03 21:26:49,739:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:26:49,792:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-03 21:26:49,797:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-03 21:26:49,806:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-03 21:26:49,818:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-03 21:26:49,851:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-03 21:26:49,981:INFO:Calculating mean and std
2023-01-03 21:26:49,983:INFO:Creating metrics dataframe
2023-01-03 21:26:49,986:INFO:Uploading results into container
2023-01-03 21:26:49,986:INFO:Uploading model into container now
2023-01-03 21:26:49,986:INFO:_master_model_container: 6
2023-01-03 21:26:49,987:INFO:_display_container: 2
2023-01-03 21:26:49,987:INFO:LassoLars(random_state=123)
2023-01-03 21:26:49,987:INFO:create_model() successfully completed......................................
2023-01-03 21:26:50,091:INFO:SubProcess create_model() end ==================================
2023-01-03 21:26:50,092:INFO:Creating metrics dataframe
2023-01-03 21:26:50,104:INFO:Initializing Orthogonal Matching Pursuit
2023-01-03 21:26:50,105:INFO:Total runtime is 0.044228939215342204 minutes
2023-01-03 21:26:50,108:INFO:SubProcess create_model() called ==================================
2023-01-03 21:26:50,108:INFO:Initializing create_model()
2023-01-03 21:26:50,109:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020748CE5E80>, estimator=omp, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002073D3A5040>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:26:50,109:INFO:Checking exceptions
2023-01-03 21:26:50,109:INFO:Importing libraries
2023-01-03 21:26:50,109:INFO:Copying training dataset
2023-01-03 21:26:50,119:INFO:Defining folds
2023-01-03 21:26:50,120:INFO:Declaring metric variables
2023-01-03 21:26:50,123:INFO:Importing untrained model
2023-01-03 21:26:50,129:INFO:Orthogonal Matching Pursuit Imported successfully
2023-01-03 21:26:50,138:INFO:Starting cross validation
2023-01-03 21:26:50,140:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:26:50,190:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 21:26:50,195:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 21:26:50,204:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 21:26:50,223:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 21:26:50,251:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 21:26:50,377:INFO:Calculating mean and std
2023-01-03 21:26:50,379:INFO:Creating metrics dataframe
2023-01-03 21:26:50,382:INFO:Uploading results into container
2023-01-03 21:26:50,383:INFO:Uploading model into container now
2023-01-03 21:26:50,383:INFO:_master_model_container: 7
2023-01-03 21:26:50,383:INFO:_display_container: 2
2023-01-03 21:26:50,383:INFO:OrthogonalMatchingPursuit()
2023-01-03 21:26:50,383:INFO:create_model() successfully completed......................................
2023-01-03 21:26:50,485:INFO:SubProcess create_model() end ==================================
2023-01-03 21:26:50,485:INFO:Creating metrics dataframe
2023-01-03 21:26:50,500:INFO:Initializing Bayesian Ridge
2023-01-03 21:26:50,500:INFO:Total runtime is 0.050813257694244385 minutes
2023-01-03 21:26:50,504:INFO:SubProcess create_model() called ==================================
2023-01-03 21:26:50,504:INFO:Initializing create_model()
2023-01-03 21:26:50,504:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020748CE5E80>, estimator=br, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002073D3A5040>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:26:50,504:INFO:Checking exceptions
2023-01-03 21:26:50,504:INFO:Importing libraries
2023-01-03 21:26:50,505:INFO:Copying training dataset
2023-01-03 21:26:50,516:INFO:Defining folds
2023-01-03 21:26:50,517:INFO:Declaring metric variables
2023-01-03 21:26:50,521:INFO:Importing untrained model
2023-01-03 21:26:50,526:INFO:Bayesian Ridge Imported successfully
2023-01-03 21:26:50,536:INFO:Starting cross validation
2023-01-03 21:26:50,537:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:26:50,786:INFO:Calculating mean and std
2023-01-03 21:26:50,788:INFO:Creating metrics dataframe
2023-01-03 21:26:50,791:INFO:Uploading results into container
2023-01-03 21:26:50,791:INFO:Uploading model into container now
2023-01-03 21:26:50,792:INFO:_master_model_container: 8
2023-01-03 21:26:50,792:INFO:_display_container: 2
2023-01-03 21:26:50,792:INFO:BayesianRidge()
2023-01-03 21:26:50,792:INFO:create_model() successfully completed......................................
2023-01-03 21:26:50,943:INFO:SubProcess create_model() end ==================================
2023-01-03 21:26:50,943:INFO:Creating metrics dataframe
2023-01-03 21:26:50,955:INFO:Initializing Passive Aggressive Regressor
2023-01-03 21:26:50,955:INFO:Total runtime is 0.05839986006418864 minutes
2023-01-03 21:26:50,960:INFO:SubProcess create_model() called ==================================
2023-01-03 21:26:50,960:INFO:Initializing create_model()
2023-01-03 21:26:50,961:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020748CE5E80>, estimator=par, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002073D3A5040>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:26:50,961:INFO:Checking exceptions
2023-01-03 21:26:50,961:INFO:Importing libraries
2023-01-03 21:26:50,961:INFO:Copying training dataset
2023-01-03 21:26:50,969:INFO:Defining folds
2023-01-03 21:26:50,970:INFO:Declaring metric variables
2023-01-03 21:26:50,974:INFO:Importing untrained model
2023-01-03 21:26:50,978:INFO:Passive Aggressive Regressor Imported successfully
2023-01-03 21:26:50,986:INFO:Starting cross validation
2023-01-03 21:26:50,987:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:26:51,225:INFO:Calculating mean and std
2023-01-03 21:26:51,227:INFO:Creating metrics dataframe
2023-01-03 21:26:51,230:INFO:Uploading results into container
2023-01-03 21:26:51,230:INFO:Uploading model into container now
2023-01-03 21:26:51,230:INFO:_master_model_container: 9
2023-01-03 21:26:51,230:INFO:_display_container: 2
2023-01-03 21:26:51,231:INFO:PassiveAggressiveRegressor(random_state=123)
2023-01-03 21:26:51,231:INFO:create_model() successfully completed......................................
2023-01-03 21:26:51,329:INFO:SubProcess create_model() end ==================================
2023-01-03 21:26:51,329:INFO:Creating metrics dataframe
2023-01-03 21:26:51,342:INFO:Initializing Huber Regressor
2023-01-03 21:26:51,342:INFO:Total runtime is 0.06485586563746135 minutes
2023-01-03 21:26:51,347:INFO:SubProcess create_model() called ==================================
2023-01-03 21:26:51,347:INFO:Initializing create_model()
2023-01-03 21:26:51,347:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020748CE5E80>, estimator=huber, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002073D3A5040>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:26:51,347:INFO:Checking exceptions
2023-01-03 21:26:51,347:INFO:Importing libraries
2023-01-03 21:26:51,347:INFO:Copying training dataset
2023-01-03 21:26:51,356:INFO:Defining folds
2023-01-03 21:26:51,356:INFO:Declaring metric variables
2023-01-03 21:26:51,360:INFO:Importing untrained model
2023-01-03 21:26:51,365:INFO:Huber Regressor Imported successfully
2023-01-03 21:26:51,373:INFO:Starting cross validation
2023-01-03 21:26:51,375:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:26:51,484:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-03 21:26:51,545:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-03 21:26:51,639:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-03 21:26:51,711:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-03 21:26:51,841:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-03 21:26:51,968:INFO:Calculating mean and std
2023-01-03 21:26:51,970:INFO:Creating metrics dataframe
2023-01-03 21:26:51,973:INFO:Uploading results into container
2023-01-03 21:26:51,973:INFO:Uploading model into container now
2023-01-03 21:26:51,974:INFO:_master_model_container: 10
2023-01-03 21:26:51,974:INFO:_display_container: 2
2023-01-03 21:26:51,974:INFO:HuberRegressor()
2023-01-03 21:26:51,974:INFO:create_model() successfully completed......................................
2023-01-03 21:26:52,069:INFO:SubProcess create_model() end ==================================
2023-01-03 21:26:52,069:INFO:Creating metrics dataframe
2023-01-03 21:26:52,084:INFO:Initializing K Neighbors Regressor
2023-01-03 21:26:52,084:INFO:Total runtime is 0.07722328106562297 minutes
2023-01-03 21:26:52,088:INFO:SubProcess create_model() called ==================================
2023-01-03 21:26:52,088:INFO:Initializing create_model()
2023-01-03 21:26:52,089:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020748CE5E80>, estimator=knn, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002073D3A5040>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:26:52,089:INFO:Checking exceptions
2023-01-03 21:26:52,089:INFO:Importing libraries
2023-01-03 21:26:52,089:INFO:Copying training dataset
2023-01-03 21:26:52,098:INFO:Defining folds
2023-01-03 21:26:52,098:INFO:Declaring metric variables
2023-01-03 21:26:52,102:INFO:Importing untrained model
2023-01-03 21:26:52,106:INFO:K Neighbors Regressor Imported successfully
2023-01-03 21:26:52,115:INFO:Starting cross validation
2023-01-03 21:26:52,116:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:26:52,842:INFO:Calculating mean and std
2023-01-03 21:26:52,844:INFO:Creating metrics dataframe
2023-01-03 21:26:52,849:INFO:Uploading results into container
2023-01-03 21:26:52,850:INFO:Uploading model into container now
2023-01-03 21:26:52,850:INFO:_master_model_container: 11
2023-01-03 21:26:52,850:INFO:_display_container: 2
2023-01-03 21:26:52,851:INFO:KNeighborsRegressor(n_jobs=-1)
2023-01-03 21:26:52,851:INFO:create_model() successfully completed......................................
2023-01-03 21:26:52,958:INFO:SubProcess create_model() end ==================================
2023-01-03 21:26:52,958:INFO:Creating metrics dataframe
2023-01-03 21:26:52,972:INFO:Initializing Decision Tree Regressor
2023-01-03 21:26:52,972:INFO:Total runtime is 0.09201651414235433 minutes
2023-01-03 21:26:52,977:INFO:SubProcess create_model() called ==================================
2023-01-03 21:26:52,978:INFO:Initializing create_model()
2023-01-03 21:26:52,978:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020748CE5E80>, estimator=dt, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002073D3A5040>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:26:52,978:INFO:Checking exceptions
2023-01-03 21:26:52,978:INFO:Importing libraries
2023-01-03 21:26:52,978:INFO:Copying training dataset
2023-01-03 21:26:52,988:INFO:Defining folds
2023-01-03 21:26:52,988:INFO:Declaring metric variables
2023-01-03 21:26:52,993:INFO:Importing untrained model
2023-01-03 21:26:52,997:INFO:Decision Tree Regressor Imported successfully
2023-01-03 21:26:53,006:INFO:Starting cross validation
2023-01-03 21:26:53,008:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:26:53,438:INFO:Calculating mean and std
2023-01-03 21:26:53,440:INFO:Creating metrics dataframe
2023-01-03 21:26:53,443:INFO:Uploading results into container
2023-01-03 21:26:53,444:INFO:Uploading model into container now
2023-01-03 21:26:53,444:INFO:_master_model_container: 12
2023-01-03 21:26:53,444:INFO:_display_container: 2
2023-01-03 21:26:53,444:INFO:DecisionTreeRegressor(random_state=123)
2023-01-03 21:26:53,444:INFO:create_model() successfully completed......................................
2023-01-03 21:26:53,541:INFO:SubProcess create_model() end ==================================
2023-01-03 21:26:53,541:INFO:Creating metrics dataframe
2023-01-03 21:26:53,557:INFO:Initializing Random Forest Regressor
2023-01-03 21:26:53,557:INFO:Total runtime is 0.10175846020380656 minutes
2023-01-03 21:26:53,561:INFO:SubProcess create_model() called ==================================
2023-01-03 21:26:53,562:INFO:Initializing create_model()
2023-01-03 21:26:53,562:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020748CE5E80>, estimator=rf, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002073D3A5040>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:26:53,562:INFO:Checking exceptions
2023-01-03 21:26:53,563:INFO:Importing libraries
2023-01-03 21:26:53,563:INFO:Copying training dataset
2023-01-03 21:26:53,578:INFO:Defining folds
2023-01-03 21:26:53,578:INFO:Declaring metric variables
2023-01-03 21:26:53,584:INFO:Importing untrained model
2023-01-03 21:26:53,588:INFO:Random Forest Regressor Imported successfully
2023-01-03 21:26:53,601:INFO:Starting cross validation
2023-01-03 21:26:53,602:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:27:01,286:INFO:Calculating mean and std
2023-01-03 21:27:01,288:INFO:Creating metrics dataframe
2023-01-03 21:27:01,291:INFO:Uploading results into container
2023-01-03 21:27:01,291:INFO:Uploading model into container now
2023-01-03 21:27:01,291:INFO:_master_model_container: 13
2023-01-03 21:27:01,291:INFO:_display_container: 2
2023-01-03 21:27:01,292:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-01-03 21:27:01,292:INFO:create_model() successfully completed......................................
2023-01-03 21:27:01,387:INFO:SubProcess create_model() end ==================================
2023-01-03 21:27:01,387:INFO:Creating metrics dataframe
2023-01-03 21:27:01,402:INFO:Initializing Extra Trees Regressor
2023-01-03 21:27:01,402:INFO:Total runtime is 0.23250846068064374 minutes
2023-01-03 21:27:01,407:INFO:SubProcess create_model() called ==================================
2023-01-03 21:27:01,408:INFO:Initializing create_model()
2023-01-03 21:27:01,408:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020748CE5E80>, estimator=et, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002073D3A5040>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:27:01,408:INFO:Checking exceptions
2023-01-03 21:27:01,408:INFO:Importing libraries
2023-01-03 21:27:01,408:INFO:Copying training dataset
2023-01-03 21:27:01,418:INFO:Defining folds
2023-01-03 21:27:01,419:INFO:Declaring metric variables
2023-01-03 21:27:01,423:INFO:Importing untrained model
2023-01-03 21:27:01,428:INFO:Extra Trees Regressor Imported successfully
2023-01-03 21:27:01,447:INFO:Starting cross validation
2023-01-03 21:27:01,448:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:27:04,936:INFO:Calculating mean and std
2023-01-03 21:27:04,938:INFO:Creating metrics dataframe
2023-01-03 21:27:04,941:INFO:Uploading results into container
2023-01-03 21:27:04,942:INFO:Uploading model into container now
2023-01-03 21:27:04,942:INFO:_master_model_container: 14
2023-01-03 21:27:04,943:INFO:_display_container: 2
2023-01-03 21:27:04,943:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-01-03 21:27:04,943:INFO:create_model() successfully completed......................................
2023-01-03 21:27:05,040:INFO:SubProcess create_model() end ==================================
2023-01-03 21:27:05,040:INFO:Creating metrics dataframe
2023-01-03 21:27:05,052:INFO:Initializing AdaBoost Regressor
2023-01-03 21:27:05,052:INFO:Total runtime is 0.29334162473678593 minutes
2023-01-03 21:27:05,056:INFO:SubProcess create_model() called ==================================
2023-01-03 21:27:05,056:INFO:Initializing create_model()
2023-01-03 21:27:05,056:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020748CE5E80>, estimator=ada, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002073D3A5040>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:27:05,056:INFO:Checking exceptions
2023-01-03 21:27:05,057:INFO:Importing libraries
2023-01-03 21:27:05,057:INFO:Copying training dataset
2023-01-03 21:27:05,065:INFO:Defining folds
2023-01-03 21:27:05,066:INFO:Declaring metric variables
2023-01-03 21:27:05,070:INFO:Importing untrained model
2023-01-03 21:27:05,074:INFO:AdaBoost Regressor Imported successfully
2023-01-03 21:27:05,090:INFO:Starting cross validation
2023-01-03 21:27:05,093:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:27:05,885:INFO:Calculating mean and std
2023-01-03 21:27:05,887:INFO:Creating metrics dataframe
2023-01-03 21:27:05,890:INFO:Uploading results into container
2023-01-03 21:27:05,890:INFO:Uploading model into container now
2023-01-03 21:27:05,890:INFO:_master_model_container: 15
2023-01-03 21:27:05,890:INFO:_display_container: 2
2023-01-03 21:27:05,891:INFO:AdaBoostRegressor(random_state=123)
2023-01-03 21:27:05,891:INFO:create_model() successfully completed......................................
2023-01-03 21:27:05,986:INFO:SubProcess create_model() end ==================================
2023-01-03 21:27:05,987:INFO:Creating metrics dataframe
2023-01-03 21:27:06,001:INFO:Initializing Gradient Boosting Regressor
2023-01-03 21:27:06,001:INFO:Total runtime is 0.30917071898778287 minutes
2023-01-03 21:27:06,005:INFO:SubProcess create_model() called ==================================
2023-01-03 21:27:06,005:INFO:Initializing create_model()
2023-01-03 21:27:06,005:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020748CE5E80>, estimator=gbr, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002073D3A5040>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:27:06,005:INFO:Checking exceptions
2023-01-03 21:27:06,006:INFO:Importing libraries
2023-01-03 21:27:06,006:INFO:Copying training dataset
2023-01-03 21:27:06,015:INFO:Defining folds
2023-01-03 21:27:06,016:INFO:Declaring metric variables
2023-01-03 21:27:06,019:INFO:Importing untrained model
2023-01-03 21:27:06,024:INFO:Gradient Boosting Regressor Imported successfully
2023-01-03 21:27:06,033:INFO:Starting cross validation
2023-01-03 21:27:06,035:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:27:10,081:INFO:Calculating mean and std
2023-01-03 21:27:10,083:INFO:Creating metrics dataframe
2023-01-03 21:27:10,086:INFO:Uploading results into container
2023-01-03 21:27:10,086:INFO:Uploading model into container now
2023-01-03 21:27:10,086:INFO:_master_model_container: 16
2023-01-03 21:27:10,087:INFO:_display_container: 2
2023-01-03 21:27:10,087:INFO:GradientBoostingRegressor(random_state=123)
2023-01-03 21:27:10,087:INFO:create_model() successfully completed......................................
2023-01-03 21:27:10,182:INFO:SubProcess create_model() end ==================================
2023-01-03 21:27:10,182:INFO:Creating metrics dataframe
2023-01-03 21:27:10,197:INFO:Initializing Light Gradient Boosting Machine
2023-01-03 21:27:10,197:INFO:Total runtime is 0.37909235556920373 minutes
2023-01-03 21:27:10,201:INFO:SubProcess create_model() called ==================================
2023-01-03 21:27:10,201:INFO:Initializing create_model()
2023-01-03 21:27:10,202:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020748CE5E80>, estimator=lightgbm, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002073D3A5040>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:27:10,202:INFO:Checking exceptions
2023-01-03 21:27:10,202:INFO:Importing libraries
2023-01-03 21:27:10,202:INFO:Copying training dataset
2023-01-03 21:27:10,211:INFO:Defining folds
2023-01-03 21:27:10,212:INFO:Declaring metric variables
2023-01-03 21:27:10,216:INFO:Importing untrained model
2023-01-03 21:27:10,220:INFO:Light Gradient Boosting Machine Imported successfully
2023-01-03 21:27:10,230:INFO:Starting cross validation
2023-01-03 21:27:10,231:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:27:11,195:INFO:Calculating mean and std
2023-01-03 21:27:11,197:INFO:Creating metrics dataframe
2023-01-03 21:27:11,200:INFO:Uploading results into container
2023-01-03 21:27:11,200:INFO:Uploading model into container now
2023-01-03 21:27:11,200:INFO:_master_model_container: 17
2023-01-03 21:27:11,200:INFO:_display_container: 2
2023-01-03 21:27:11,201:INFO:LGBMRegressor(random_state=123)
2023-01-03 21:27:11,201:INFO:create_model() successfully completed......................................
2023-01-03 21:27:11,298:INFO:SubProcess create_model() end ==================================
2023-01-03 21:27:11,299:INFO:Creating metrics dataframe
2023-01-03 21:27:11,313:INFO:Initializing Dummy Regressor
2023-01-03 21:27:11,314:INFO:Total runtime is 0.3977199912071228 minutes
2023-01-03 21:27:11,317:INFO:SubProcess create_model() called ==================================
2023-01-03 21:27:11,318:INFO:Initializing create_model()
2023-01-03 21:27:11,318:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020748CE5E80>, estimator=dummy, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002073D3A5040>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:27:11,318:INFO:Checking exceptions
2023-01-03 21:27:11,318:INFO:Importing libraries
2023-01-03 21:27:11,318:INFO:Copying training dataset
2023-01-03 21:27:11,328:INFO:Defining folds
2023-01-03 21:27:11,328:INFO:Declaring metric variables
2023-01-03 21:27:11,333:INFO:Importing untrained model
2023-01-03 21:27:11,337:INFO:Dummy Regressor Imported successfully
2023-01-03 21:27:11,347:INFO:Starting cross validation
2023-01-03 21:27:11,348:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:27:11,574:INFO:Calculating mean and std
2023-01-03 21:27:11,576:INFO:Creating metrics dataframe
2023-01-03 21:27:11,581:INFO:Uploading results into container
2023-01-03 21:27:11,582:INFO:Uploading model into container now
2023-01-03 21:27:11,582:INFO:_master_model_container: 18
2023-01-03 21:27:11,582:INFO:_display_container: 2
2023-01-03 21:27:11,582:INFO:DummyRegressor()
2023-01-03 21:27:11,582:INFO:create_model() successfully completed......................................
2023-01-03 21:27:11,682:INFO:SubProcess create_model() end ==================================
2023-01-03 21:27:11,682:INFO:Creating metrics dataframe
2023-01-03 21:27:11,710:INFO:Initializing create_model()
2023-01-03 21:27:11,710:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020748CE5E80>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:27:11,710:INFO:Checking exceptions
2023-01-03 21:27:11,713:INFO:Importing libraries
2023-01-03 21:27:11,713:INFO:Copying training dataset
2023-01-03 21:27:11,721:INFO:Defining folds
2023-01-03 21:27:11,721:INFO:Declaring metric variables
2023-01-03 21:27:11,721:INFO:Importing untrained model
2023-01-03 21:27:11,721:INFO:Declaring custom model
2023-01-03 21:27:11,722:INFO:Extra Trees Regressor Imported successfully
2023-01-03 21:27:11,722:INFO:Cross validation set to False
2023-01-03 21:27:11,722:INFO:Fitting Model
2023-01-03 21:27:13,117:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-01-03 21:27:13,117:INFO:create_model() successfully completed......................................
2023-01-03 21:27:13,254:INFO:_master_model_container: 18
2023-01-03 21:27:13,254:INFO:_display_container: 2
2023-01-03 21:27:13,255:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-01-03 21:27:13,255:INFO:compare_models() successfully completed......................................
2023-01-03 21:27:13,267:INFO:Initializing tune_model()
2023-01-03 21:27:13,267:INFO:tune_model(estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=3, custom_grid=None, optimize=MAE, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020748CE5E80>)
2023-01-03 21:27:13,267:INFO:Checking exceptions
2023-01-03 21:27:13,311:INFO:Copying training dataset
2023-01-03 21:27:13,321:INFO:Checking base model
2023-01-03 21:27:13,321:INFO:Base model : Extra Trees Regressor
2023-01-03 21:27:13,325:INFO:Declaring metric variables
2023-01-03 21:27:13,329:INFO:Defining Hyperparameters
2023-01-03 21:27:13,503:INFO:Tuning with n_jobs=-1
2023-01-03 21:27:13,503:INFO:Initializing RandomizedSearchCV
2023-01-03 21:27:13,551:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:27:13,554:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:27:13,561:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:27:13,575:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:27:13,757:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:27:13,772:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:27:13,773:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:27:14,104:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:27:14,117:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:27:14,135:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:27:14,136:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:27:14,615:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:27:14,685:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:27:14,873:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:27:14,950:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:27:15,285:INFO:best_params: {'actual_estimator__n_estimators': 100, 'actual_estimator__min_samples_split': 7, 'actual_estimator__min_samples_leaf': 4, 'actual_estimator__min_impurity_decrease': 0.1, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 9, 'actual_estimator__criterion': 'mse', 'actual_estimator__bootstrap': True}
2023-01-03 21:27:15,286:INFO:Hyperparameter search completed
2023-01-03 21:27:15,286:INFO:SubProcess create_model() called ==================================
2023-01-03 21:27:15,287:INFO:Initializing create_model()
2023-01-03 21:27:15,287:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020748CE5E80>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000207484E9040>, model_only=True, return_train_score=False, kwargs={'n_estimators': 100, 'min_samples_split': 7, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.1, 'max_features': 1.0, 'max_depth': 9, 'criterion': 'mse', 'bootstrap': True})
2023-01-03 21:27:15,287:INFO:Checking exceptions
2023-01-03 21:27:15,287:INFO:Importing libraries
2023-01-03 21:27:15,287:INFO:Copying training dataset
2023-01-03 21:27:15,297:INFO:Defining folds
2023-01-03 21:27:15,298:INFO:Declaring metric variables
2023-01-03 21:27:15,301:INFO:Importing untrained model
2023-01-03 21:27:15,301:INFO:Declaring custom model
2023-01-03 21:27:15,305:INFO:Extra Trees Regressor Imported successfully
2023-01-03 21:27:15,314:INFO:Starting cross validation
2023-01-03 21:27:15,316:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:27:15,370:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:27:15,372:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:27:15,377:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:27:15,397:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:27:15,745:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:27:16,244:INFO:Calculating mean and std
2023-01-03 21:27:16,246:INFO:Creating metrics dataframe
2023-01-03 21:27:16,252:INFO:Finalizing model
2023-01-03 21:27:16,564:INFO:Uploading results into container
2023-01-03 21:27:16,565:INFO:Uploading model into container now
2023-01-03 21:27:16,566:INFO:_master_model_container: 19
2023-01-03 21:27:16,566:INFO:_display_container: 3
2023-01-03 21:27:16,566:INFO:ExtraTreesRegressor(bootstrap=True, criterion='mse', max_depth=9,
                    max_features=1.0, min_impurity_decrease=0.1,
                    min_samples_leaf=4, min_samples_split=7, n_jobs=-1,
                    random_state=123)
2023-01-03 21:27:16,566:INFO:create_model() successfully completed......................................
2023-01-03 21:27:16,667:INFO:SubProcess create_model() end ==================================
2023-01-03 21:27:16,667:INFO:choose_better activated
2023-01-03 21:27:16,671:INFO:SubProcess create_model() called ==================================
2023-01-03 21:27:16,671:INFO:Initializing create_model()
2023-01-03 21:27:16,671:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020748CE5E80>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:27:16,671:INFO:Checking exceptions
2023-01-03 21:27:16,673:INFO:Importing libraries
2023-01-03 21:27:16,673:INFO:Copying training dataset
2023-01-03 21:27:16,681:INFO:Defining folds
2023-01-03 21:27:16,681:INFO:Declaring metric variables
2023-01-03 21:27:16,681:INFO:Importing untrained model
2023-01-03 21:27:16,681:INFO:Declaring custom model
2023-01-03 21:27:16,682:INFO:Extra Trees Regressor Imported successfully
2023-01-03 21:27:16,682:INFO:Starting cross validation
2023-01-03 21:27:16,683:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:27:20,137:INFO:Calculating mean and std
2023-01-03 21:27:20,138:INFO:Creating metrics dataframe
2023-01-03 21:27:20,140:INFO:Finalizing model
2023-01-03 21:27:21,505:INFO:Uploading results into container
2023-01-03 21:27:21,506:INFO:Uploading model into container now
2023-01-03 21:27:21,506:INFO:_master_model_container: 20
2023-01-03 21:27:21,506:INFO:_display_container: 4
2023-01-03 21:27:21,506:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-01-03 21:27:21,506:INFO:create_model() successfully completed......................................
2023-01-03 21:27:21,603:INFO:SubProcess create_model() end ==================================
2023-01-03 21:27:21,604:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123) result for MAE is 3.6075
2023-01-03 21:27:21,604:INFO:ExtraTreesRegressor(bootstrap=True, criterion='mse', max_depth=9,
                    max_features=1.0, min_impurity_decrease=0.1,
                    min_samples_leaf=4, min_samples_split=7, n_jobs=-1,
                    random_state=123) result for MAE is 4.6273
2023-01-03 21:27:21,605:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123) is best model
2023-01-03 21:27:21,605:INFO:choose_better completed
2023-01-03 21:27:21,605:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-01-03 21:27:21,614:INFO:_master_model_container: 20
2023-01-03 21:27:21,614:INFO:_display_container: 3
2023-01-03 21:27:21,614:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-01-03 21:27:21,614:INFO:tune_model() successfully completed......................................
2023-01-03 21:27:21,729:INFO:Initializing plot_model()
2023-01-03 21:27:21,729:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020748CE5E80>, system=True)
2023-01-03 21:27:21,729:INFO:Checking exceptions
2023-01-03 21:27:21,756:INFO:Preloading libraries
2023-01-03 21:27:21,896:INFO:Copying training dataset
2023-01-03 21:27:21,896:INFO:Plot type: error
2023-01-03 21:27:22,001:INFO:Fitting Model
2023-01-03 21:27:22,002:INFO:Scoring test/hold-out set
2023-01-03 21:27:22,301:INFO:Visual Rendered Successfully
2023-01-03 21:27:22,406:INFO:plot_model() successfully completed......................................
2023-01-03 21:27:22,417:INFO:Initializing predict_model()
2023-01-03 21:27:22,417:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020748CE5E80>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x0000020748D6FEE0>)
2023-01-03 21:27:22,417:INFO:Checking exceptions
2023-01-03 21:27:22,417:INFO:Preloading libraries
2023-01-03 21:27:22,609:INFO:Initializing finalize_model()
2023-01-03 21:27:22,609:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020748CE5E80>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-01-03 21:27:22,610:INFO:Finalizing ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-01-03 21:27:22,617:INFO:Initializing create_model()
2023-01-03 21:27:22,618:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020748CE5E80>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-01-03 21:27:22,618:INFO:Checking exceptions
2023-01-03 21:27:22,619:INFO:Importing libraries
2023-01-03 21:27:22,619:INFO:Copying training dataset
2023-01-03 21:27:22,620:INFO:Defining folds
2023-01-03 21:27:22,620:INFO:Declaring metric variables
2023-01-03 21:27:22,620:INFO:Importing untrained model
2023-01-03 21:27:22,620:INFO:Declaring custom model
2023-01-03 21:27:22,621:INFO:Extra Trees Regressor Imported successfully
2023-01-03 21:27:22,622:INFO:Cross validation set to False
2023-01-03 21:27:22,622:INFO:Fitting Model
2023-01-03 21:27:24,666:INFO:Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))])
2023-01-03 21:27:24,667:INFO:create_model() successfully completed......................................
2023-01-03 21:27:24,761:INFO:_master_model_container: 20
2023-01-03 21:27:24,761:INFO:_display_container: 4
2023-01-03 21:27:24,770:INFO:Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))])
2023-01-03 21:27:24,770:INFO:finalize_model() successfully completed......................................
2023-01-03 21:27:24,891:INFO:Initializing predict_model()
2023-01-03 21:27:24,891:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020748CE5E80>, estimator=Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000002073D8BF1F0>)
2023-01-03 21:27:24,891:INFO:Checking exceptions
2023-01-03 21:27:24,891:INFO:Preloading libraries
2023-01-03 21:27:24,893:INFO:Set up data.
2023-01-03 21:27:24,908:INFO:Set up index.
2023-01-03 21:30:14,968:INFO:PyCaret RegressionExperiment
2023-01-03 21:30:14,968:INFO:Logging name: reg-default-name
2023-01-03 21:30:14,968:INFO:ML Usecase: MLUsecase.REGRESSION
2023-01-03 21:30:14,968:INFO:version 3.0.0.rc6
2023-01-03 21:30:14,968:INFO:Initializing setup()
2023-01-03 21:30:14,968:INFO:self.USI: d6c8
2023-01-03 21:30:14,968:INFO:self._variable_keys: {'y_train', 'pipeline', 'exp_id', 'idx', 'data', '_ml_usecase', 'fold_shuffle_param', 'n_jobs_param', 'seed', 'logging_param', 'y_test', 'fold_groups_param', 'target_param', 'transform_target_param', 'y', 'gpu_param', 'X', 'fold_generator', 'html_param', 'log_plots_param', 'exp_name_log', 'memory', 'USI', 'gpu_n_jobs_param', '_available_plots', 'X_test', 'X_train'}
2023-01-03 21:30:14,968:INFO:Checking environment
2023-01-03 21:30:14,969:INFO:python_version: 3.9.13
2023-01-03 21:30:14,969:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-01-03 21:30:14,969:INFO:machine: AMD64
2023-01-03 21:30:14,969:INFO:platform: Windows-10-10.0.19044-SP0
2023-01-03 21:30:14,969:INFO:Memory: svmem(total=17114804224, available=9585651712, percent=44.0, used=7529152512, free=9585651712)
2023-01-03 21:30:14,969:INFO:Physical Core: 4
2023-01-03 21:30:14,969:INFO:Logical Core: 4
2023-01-03 21:30:14,969:INFO:Checking libraries
2023-01-03 21:30:14,969:INFO:System:
2023-01-03 21:30:14,969:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-01-03 21:30:14,969:INFO:executable: c:\Users\Kodotautas\anaconda3\python.exe
2023-01-03 21:30:14,969:INFO:   machine: Windows-10-10.0.19044-SP0
2023-01-03 21:30:14,969:INFO:PyCaret required dependencies:
2023-01-03 21:30:14,969:INFO:                 pip: 22.2.2
2023-01-03 21:30:14,969:INFO:          setuptools: 63.4.1
2023-01-03 21:30:14,969:INFO:             pycaret: 3.0.0rc6
2023-01-03 21:30:14,969:INFO:             IPython: 7.31.1
2023-01-03 21:30:14,969:INFO:          ipywidgets: 7.6.5
2023-01-03 21:30:14,970:INFO:                tqdm: 4.64.1
2023-01-03 21:30:14,970:INFO:               numpy: 1.21.5
2023-01-03 21:30:14,970:INFO:              pandas: 1.4.4
2023-01-03 21:30:14,970:INFO:              jinja2: 2.11.3
2023-01-03 21:30:14,970:INFO:               scipy: 1.9.1
2023-01-03 21:30:14,970:INFO:              joblib: 1.2.0
2023-01-03 21:30:14,970:INFO:             sklearn: 1.0.2
2023-01-03 21:30:14,970:INFO:                pyod: 1.0.7
2023-01-03 21:30:14,970:INFO:            imblearn: 0.10.1
2023-01-03 21:30:14,970:INFO:   category_encoders: 2.5.1.post0
2023-01-03 21:30:14,970:INFO:            lightgbm: 3.3.3
2023-01-03 21:30:14,970:INFO:               numba: 0.55.1
2023-01-03 21:30:14,970:INFO:            requests: 2.28.1
2023-01-03 21:30:14,970:INFO:          matplotlib: 3.5.2
2023-01-03 21:30:14,970:INFO:          scikitplot: 0.3.7
2023-01-03 21:30:14,970:INFO:         yellowbrick: 1.5
2023-01-03 21:30:14,971:INFO:              plotly: 5.9.0
2023-01-03 21:30:14,971:INFO:             kaleido: 0.2.1
2023-01-03 21:30:14,971:INFO:         statsmodels: 0.13.2
2023-01-03 21:30:14,971:INFO:              sktime: 0.14.1
2023-01-03 21:30:14,971:INFO:               tbats: 1.1.2
2023-01-03 21:30:14,971:INFO:            pmdarima: 2.0.2
2023-01-03 21:30:14,971:INFO:              psutil: 5.9.0
2023-01-03 21:30:14,971:INFO:PyCaret optional dependencies:
2023-01-03 21:30:14,971:INFO:                shap: 0.41.0
2023-01-03 21:30:14,971:INFO:           interpret: Not installed
2023-01-03 21:30:14,971:INFO:                umap: Not installed
2023-01-03 21:30:14,971:INFO:    pandas_profiling: Not installed
2023-01-03 21:30:14,971:INFO:  explainerdashboard: Not installed
2023-01-03 21:30:14,971:INFO:             autoviz: Not installed
2023-01-03 21:30:14,971:INFO:           fairlearn: Not installed
2023-01-03 21:30:14,971:INFO:             xgboost: Not installed
2023-01-03 21:30:14,971:INFO:            catboost: Not installed
2023-01-03 21:30:14,971:INFO:              kmodes: Not installed
2023-01-03 21:30:14,971:INFO:             mlxtend: Not installed
2023-01-03 21:30:14,972:INFO:       statsforecast: Not installed
2023-01-03 21:30:14,972:INFO:        tune_sklearn: 0.4.3
2023-01-03 21:30:14,972:INFO:                 ray: 2.0.0
2023-01-03 21:30:14,972:INFO:            hyperopt: 0.2.7
2023-01-03 21:30:14,972:INFO:              optuna: 3.0.1
2023-01-03 21:30:14,972:INFO:               skopt: 0.9.0
2023-01-03 21:30:14,972:INFO:              mlflow: Not installed
2023-01-03 21:30:14,972:INFO:              gradio: Not installed
2023-01-03 21:30:14,972:INFO:             fastapi: 0.88.0
2023-01-03 21:30:14,972:INFO:             uvicorn: 0.20.0
2023-01-03 21:30:14,972:INFO:              m2cgen: Not installed
2023-01-03 21:30:14,972:INFO:           evidently: Not installed
2023-01-03 21:30:14,972:INFO:                nltk: 3.7
2023-01-03 21:30:14,972:INFO:            pyLDAvis: Not installed
2023-01-03 21:30:14,972:INFO:              gensim: 4.1.2
2023-01-03 21:30:14,972:INFO:               spacy: 3.4.2
2023-01-03 21:30:14,972:INFO:           wordcloud: Not installed
2023-01-03 21:30:14,973:INFO:            textblob: Not installed
2023-01-03 21:30:14,973:INFO:               fugue: Not installed
2023-01-03 21:30:14,973:INFO:           streamlit: Not installed
2023-01-03 21:30:14,973:INFO:             prophet: Not installed
2023-01-03 21:30:14,973:INFO:None
2023-01-03 21:30:14,973:INFO:Set up data.
2023-01-03 21:30:14,989:INFO:Set up train/test split.
2023-01-03 21:30:14,999:INFO:Set up index.
2023-01-03 21:30:15,002:INFO:Set up folding strategy.
2023-01-03 21:30:15,002:INFO:Assigning column types.
2023-01-03 21:30:15,012:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-01-03 21:30:15,012:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-01-03 21:30:15,017:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-03 21:30:15,023:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 21:30:15,095:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 21:30:15,156:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 21:30:15,157:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:30:15,157:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:30:15,158:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-01-03 21:30:15,163:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-03 21:30:15,171:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 21:30:15,331:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 21:30:15,380:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 21:30:15,380:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:30:15,381:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:30:15,381:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-01-03 21:30:15,386:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-03 21:30:15,391:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 21:30:15,460:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 21:30:15,509:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 21:30:15,509:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:30:15,509:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:30:15,515:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-03 21:30:15,520:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 21:30:15,589:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 21:30:15,638:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 21:30:15,638:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:30:15,639:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:30:15,639:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-01-03 21:30:15,649:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 21:30:15,722:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 21:30:15,775:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 21:30:15,776:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:30:15,776:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:30:15,787:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 21:30:15,857:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 21:30:15,904:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 21:30:15,905:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:30:15,905:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:30:15,906:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-01-03 21:30:15,983:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 21:30:16,030:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 21:30:16,030:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:30:16,030:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:30:16,107:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 21:30:16,153:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 21:30:16,154:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:30:16,154:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:30:16,155:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-01-03 21:30:16,232:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 21:30:16,278:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:30:16,278:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:30:16,355:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 21:30:16,403:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:30:16,403:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:30:16,403:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-01-03 21:30:16,524:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:30:16,525:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:30:16,639:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:30:16,639:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:30:16,640:INFO:Preparing preprocessing pipeline...
2023-01-03 21:30:16,642:INFO:Set up simple imputation.
2023-01-03 21:30:16,642:INFO:Set up column transformation.
2023-01-03 21:30:16,642:INFO:Set up feature normalization.
2023-01-03 21:30:16,675:INFO:Finished creating preprocessing pipeline.
2023-01-03 21:30:16,680:INFO:Pipeline: Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2023-01-03 21:30:16,680:INFO:Creating final display dataframe.
2023-01-03 21:30:16,896:INFO:Setup _display_container:                Description             Value
0               Session id               123
1                   Target        b2b+b2c+vt
2              Target type        Regression
3               Data shape       (11081, 38)
4         Train data shape        (7756, 38)
5          Test data shape        (3325, 38)
6         Numeric features                 8
7               Preprocess              True
8          Imputation type            simple
9       Numeric imputation              mean
10  Categorical imputation              mode
11          Transformation              True
12   Transformation method       yeo-johnson
13               Normalize              True
14        Normalize method            zscore
15          Fold Generator   TimeSeriesSplit
16             Fold Number                 5
17                CPU Jobs                -1
18                 Use GPU             False
19          Log Experiment             False
20         Experiment Name  reg-default-name
21                     USI              d6c8
2023-01-03 21:30:17,026:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:30:17,026:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:30:17,149:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:30:17,150:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:30:17,151:INFO:setup() successfully completed in 2.18s...............
2023-01-03 21:30:17,152:INFO:Initializing compare_models()
2023-01-03 21:30:17,152:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000207634A99A0>, include=None, fold=None, round=4, cross_validation=True, sort=MAE, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000207634A99A0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'MAE', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-01-03 21:30:17,152:INFO:Checking exceptions
2023-01-03 21:30:17,156:INFO:Preparing display monitor
2023-01-03 21:30:17,196:INFO:Initializing Linear Regression
2023-01-03 21:30:17,196:INFO:Total runtime is 0.0 minutes
2023-01-03 21:30:17,202:INFO:SubProcess create_model() called ==================================
2023-01-03 21:30:17,202:INFO:Initializing create_model()
2023-01-03 21:30:17,202:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000207634A99A0>, estimator=lr, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020749009280>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:30:17,202:INFO:Checking exceptions
2023-01-03 21:30:17,204:INFO:Importing libraries
2023-01-03 21:30:17,204:INFO:Copying training dataset
2023-01-03 21:30:17,223:INFO:Defining folds
2023-01-03 21:30:17,223:INFO:Declaring metric variables
2023-01-03 21:30:17,228:INFO:Importing untrained model
2023-01-03 21:30:17,253:INFO:Linear Regression Imported successfully
2023-01-03 21:30:17,271:INFO:Starting cross validation
2023-01-03 21:30:17,272:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:30:17,536:INFO:Calculating mean and std
2023-01-03 21:30:17,536:INFO:Creating metrics dataframe
2023-01-03 21:30:17,539:INFO:Uploading results into container
2023-01-03 21:30:17,539:INFO:Uploading model into container now
2023-01-03 21:30:17,540:INFO:_master_model_container: 1
2023-01-03 21:30:17,540:INFO:_display_container: 2
2023-01-03 21:30:17,540:INFO:LinearRegression(n_jobs=-1)
2023-01-03 21:30:17,540:INFO:create_model() successfully completed......................................
2023-01-03 21:30:17,649:INFO:SubProcess create_model() end ==================================
2023-01-03 21:30:17,649:INFO:Creating metrics dataframe
2023-01-03 21:30:17,659:INFO:Initializing Lasso Regression
2023-01-03 21:30:17,659:INFO:Total runtime is 0.007720478375752767 minutes
2023-01-03 21:30:17,663:INFO:SubProcess create_model() called ==================================
2023-01-03 21:30:17,664:INFO:Initializing create_model()
2023-01-03 21:30:17,664:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000207634A99A0>, estimator=lasso, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020749009280>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:30:17,664:INFO:Checking exceptions
2023-01-03 21:30:17,664:INFO:Importing libraries
2023-01-03 21:30:17,664:INFO:Copying training dataset
2023-01-03 21:30:17,673:INFO:Defining folds
2023-01-03 21:30:17,673:INFO:Declaring metric variables
2023-01-03 21:30:17,676:INFO:Importing untrained model
2023-01-03 21:30:17,680:INFO:Lasso Regression Imported successfully
2023-01-03 21:30:17,690:INFO:Starting cross validation
2023-01-03 21:30:17,691:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:30:17,933:INFO:Calculating mean and std
2023-01-03 21:30:17,934:INFO:Creating metrics dataframe
2023-01-03 21:30:17,938:INFO:Uploading results into container
2023-01-03 21:30:17,938:INFO:Uploading model into container now
2023-01-03 21:30:17,938:INFO:_master_model_container: 2
2023-01-03 21:30:17,939:INFO:_display_container: 2
2023-01-03 21:30:17,939:INFO:Lasso(random_state=123)
2023-01-03 21:30:17,939:INFO:create_model() successfully completed......................................
2023-01-03 21:30:18,037:INFO:SubProcess create_model() end ==================================
2023-01-03 21:30:18,037:INFO:Creating metrics dataframe
2023-01-03 21:30:18,046:INFO:Initializing Ridge Regression
2023-01-03 21:30:18,046:INFO:Total runtime is 0.014157418409983316 minutes
2023-01-03 21:30:18,049:INFO:SubProcess create_model() called ==================================
2023-01-03 21:30:18,050:INFO:Initializing create_model()
2023-01-03 21:30:18,050:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000207634A99A0>, estimator=ridge, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020749009280>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:30:18,050:INFO:Checking exceptions
2023-01-03 21:30:18,050:INFO:Importing libraries
2023-01-03 21:30:18,050:INFO:Copying training dataset
2023-01-03 21:30:18,058:INFO:Defining folds
2023-01-03 21:30:18,058:INFO:Declaring metric variables
2023-01-03 21:30:18,061:INFO:Importing untrained model
2023-01-03 21:30:18,065:INFO:Ridge Regression Imported successfully
2023-01-03 21:30:18,076:INFO:Starting cross validation
2023-01-03 21:30:18,077:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:30:18,312:INFO:Calculating mean and std
2023-01-03 21:30:18,314:INFO:Creating metrics dataframe
2023-01-03 21:30:18,317:INFO:Uploading results into container
2023-01-03 21:30:18,318:INFO:Uploading model into container now
2023-01-03 21:30:18,319:INFO:_master_model_container: 3
2023-01-03 21:30:18,319:INFO:_display_container: 2
2023-01-03 21:30:18,320:INFO:Ridge(random_state=123)
2023-01-03 21:30:18,320:INFO:create_model() successfully completed......................................
2023-01-03 21:30:18,414:INFO:SubProcess create_model() end ==================================
2023-01-03 21:30:18,414:INFO:Creating metrics dataframe
2023-01-03 21:30:18,423:INFO:Initializing Elastic Net
2023-01-03 21:30:18,423:INFO:Total runtime is 0.020447301864624023 minutes
2023-01-03 21:30:18,427:INFO:SubProcess create_model() called ==================================
2023-01-03 21:30:18,427:INFO:Initializing create_model()
2023-01-03 21:30:18,427:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000207634A99A0>, estimator=en, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020749009280>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:30:18,428:INFO:Checking exceptions
2023-01-03 21:30:18,428:INFO:Importing libraries
2023-01-03 21:30:18,428:INFO:Copying training dataset
2023-01-03 21:30:18,436:INFO:Defining folds
2023-01-03 21:30:18,437:INFO:Declaring metric variables
2023-01-03 21:30:18,441:INFO:Importing untrained model
2023-01-03 21:30:18,446:INFO:Elastic Net Imported successfully
2023-01-03 21:30:18,458:INFO:Starting cross validation
2023-01-03 21:30:18,459:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:30:18,706:INFO:Calculating mean and std
2023-01-03 21:30:18,707:INFO:Creating metrics dataframe
2023-01-03 21:30:18,711:INFO:Uploading results into container
2023-01-03 21:30:18,711:INFO:Uploading model into container now
2023-01-03 21:30:18,712:INFO:_master_model_container: 4
2023-01-03 21:30:18,712:INFO:_display_container: 2
2023-01-03 21:30:18,712:INFO:ElasticNet(random_state=123)
2023-01-03 21:30:18,713:INFO:create_model() successfully completed......................................
2023-01-03 21:30:18,820:INFO:SubProcess create_model() end ==================================
2023-01-03 21:30:18,821:INFO:Creating metrics dataframe
2023-01-03 21:30:18,831:INFO:Initializing Least Angle Regression
2023-01-03 21:30:18,831:INFO:Total runtime is 0.027247389157613117 minutes
2023-01-03 21:30:18,836:INFO:SubProcess create_model() called ==================================
2023-01-03 21:30:18,836:INFO:Initializing create_model()
2023-01-03 21:30:18,837:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000207634A99A0>, estimator=lar, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020749009280>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:30:18,837:INFO:Checking exceptions
2023-01-03 21:30:18,837:INFO:Importing libraries
2023-01-03 21:30:18,837:INFO:Copying training dataset
2023-01-03 21:30:18,846:INFO:Defining folds
2023-01-03 21:30:18,846:INFO:Declaring metric variables
2023-01-03 21:30:18,852:INFO:Importing untrained model
2023-01-03 21:30:18,857:INFO:Least Angle Regression Imported successfully
2023-01-03 21:30:18,868:INFO:Starting cross validation
2023-01-03 21:30:18,869:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:30:18,960:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 21:30:18,978:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 21:30:19,016:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 21:30:19,027:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 21:30:19,060:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 21:30:19,194:INFO:Calculating mean and std
2023-01-03 21:30:19,196:INFO:Creating metrics dataframe
2023-01-03 21:30:19,199:INFO:Uploading results into container
2023-01-03 21:30:19,199:INFO:Uploading model into container now
2023-01-03 21:30:19,200:INFO:_master_model_container: 5
2023-01-03 21:30:19,200:INFO:_display_container: 2
2023-01-03 21:30:19,200:INFO:Lars(random_state=123)
2023-01-03 21:30:19,200:INFO:create_model() successfully completed......................................
2023-01-03 21:30:19,309:INFO:SubProcess create_model() end ==================================
2023-01-03 21:30:19,310:INFO:Creating metrics dataframe
2023-01-03 21:30:19,321:INFO:Initializing Lasso Least Angle Regression
2023-01-03 21:30:19,322:INFO:Total runtime is 0.03542431195576985 minutes
2023-01-03 21:30:19,325:INFO:SubProcess create_model() called ==================================
2023-01-03 21:30:19,326:INFO:Initializing create_model()
2023-01-03 21:30:19,326:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000207634A99A0>, estimator=llar, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020749009280>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:30:19,327:INFO:Checking exceptions
2023-01-03 21:30:19,327:INFO:Importing libraries
2023-01-03 21:30:19,327:INFO:Copying training dataset
2023-01-03 21:30:19,337:INFO:Defining folds
2023-01-03 21:30:19,337:INFO:Declaring metric variables
2023-01-03 21:30:19,342:INFO:Importing untrained model
2023-01-03 21:30:19,346:INFO:Lasso Least Angle Regression Imported successfully
2023-01-03 21:30:19,373:INFO:Starting cross validation
2023-01-03 21:30:19,375:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:30:19,430:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-03 21:30:19,432:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-03 21:30:19,443:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-03 21:30:19,465:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-03 21:30:19,504:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-03 21:30:19,640:INFO:Calculating mean and std
2023-01-03 21:30:19,642:INFO:Creating metrics dataframe
2023-01-03 21:30:19,645:INFO:Uploading results into container
2023-01-03 21:30:19,646:INFO:Uploading model into container now
2023-01-03 21:30:19,646:INFO:_master_model_container: 6
2023-01-03 21:30:19,646:INFO:_display_container: 2
2023-01-03 21:30:19,647:INFO:LassoLars(random_state=123)
2023-01-03 21:30:19,647:INFO:create_model() successfully completed......................................
2023-01-03 21:30:19,756:INFO:SubProcess create_model() end ==================================
2023-01-03 21:30:19,756:INFO:Creating metrics dataframe
2023-01-03 21:30:19,768:INFO:Initializing Orthogonal Matching Pursuit
2023-01-03 21:30:19,768:INFO:Total runtime is 0.042857583363850905 minutes
2023-01-03 21:30:19,773:INFO:SubProcess create_model() called ==================================
2023-01-03 21:30:19,774:INFO:Initializing create_model()
2023-01-03 21:30:19,774:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000207634A99A0>, estimator=omp, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020749009280>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:30:19,774:INFO:Checking exceptions
2023-01-03 21:30:19,774:INFO:Importing libraries
2023-01-03 21:30:19,774:INFO:Copying training dataset
2023-01-03 21:30:19,783:INFO:Defining folds
2023-01-03 21:30:19,784:INFO:Declaring metric variables
2023-01-03 21:30:19,788:INFO:Importing untrained model
2023-01-03 21:30:19,793:INFO:Orthogonal Matching Pursuit Imported successfully
2023-01-03 21:30:19,802:INFO:Starting cross validation
2023-01-03 21:30:19,804:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:30:19,850:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 21:30:19,855:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 21:30:19,867:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 21:30:19,882:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 21:30:19,905:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 21:30:20,034:INFO:Calculating mean and std
2023-01-03 21:30:20,036:INFO:Creating metrics dataframe
2023-01-03 21:30:20,040:INFO:Uploading results into container
2023-01-03 21:30:20,041:INFO:Uploading model into container now
2023-01-03 21:30:20,042:INFO:_master_model_container: 7
2023-01-03 21:30:20,042:INFO:_display_container: 2
2023-01-03 21:30:20,043:INFO:OrthogonalMatchingPursuit()
2023-01-03 21:30:20,043:INFO:create_model() successfully completed......................................
2023-01-03 21:30:20,148:INFO:SubProcess create_model() end ==================================
2023-01-03 21:30:20,148:INFO:Creating metrics dataframe
2023-01-03 21:30:20,160:INFO:Initializing Bayesian Ridge
2023-01-03 21:30:20,161:INFO:Total runtime is 0.04940862258275349 minutes
2023-01-03 21:30:20,165:INFO:SubProcess create_model() called ==================================
2023-01-03 21:30:20,165:INFO:Initializing create_model()
2023-01-03 21:30:20,165:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000207634A99A0>, estimator=br, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020749009280>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:30:20,165:INFO:Checking exceptions
2023-01-03 21:30:20,165:INFO:Importing libraries
2023-01-03 21:30:20,165:INFO:Copying training dataset
2023-01-03 21:30:20,175:INFO:Defining folds
2023-01-03 21:30:20,176:INFO:Declaring metric variables
2023-01-03 21:30:20,180:INFO:Importing untrained model
2023-01-03 21:30:20,185:INFO:Bayesian Ridge Imported successfully
2023-01-03 21:30:20,194:INFO:Starting cross validation
2023-01-03 21:30:20,195:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:30:20,446:INFO:Calculating mean and std
2023-01-03 21:30:20,448:INFO:Creating metrics dataframe
2023-01-03 21:30:20,451:INFO:Uploading results into container
2023-01-03 21:30:20,452:INFO:Uploading model into container now
2023-01-03 21:30:20,453:INFO:_master_model_container: 8
2023-01-03 21:30:20,453:INFO:_display_container: 2
2023-01-03 21:30:20,453:INFO:BayesianRidge()
2023-01-03 21:30:20,454:INFO:create_model() successfully completed......................................
2023-01-03 21:30:20,561:INFO:SubProcess create_model() end ==================================
2023-01-03 21:30:20,561:INFO:Creating metrics dataframe
2023-01-03 21:30:20,572:INFO:Initializing Passive Aggressive Regressor
2023-01-03 21:30:20,572:INFO:Total runtime is 0.056261857350667306 minutes
2023-01-03 21:30:20,576:INFO:SubProcess create_model() called ==================================
2023-01-03 21:30:20,576:INFO:Initializing create_model()
2023-01-03 21:30:20,576:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000207634A99A0>, estimator=par, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020749009280>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:30:20,576:INFO:Checking exceptions
2023-01-03 21:30:20,576:INFO:Importing libraries
2023-01-03 21:30:20,576:INFO:Copying training dataset
2023-01-03 21:30:20,586:INFO:Defining folds
2023-01-03 21:30:20,586:INFO:Declaring metric variables
2023-01-03 21:30:20,590:INFO:Importing untrained model
2023-01-03 21:30:20,594:INFO:Passive Aggressive Regressor Imported successfully
2023-01-03 21:30:20,604:INFO:Starting cross validation
2023-01-03 21:30:20,606:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:30:20,857:INFO:Calculating mean and std
2023-01-03 21:30:20,859:INFO:Creating metrics dataframe
2023-01-03 21:30:20,862:INFO:Uploading results into container
2023-01-03 21:30:20,863:INFO:Uploading model into container now
2023-01-03 21:30:20,864:INFO:_master_model_container: 9
2023-01-03 21:30:20,864:INFO:_display_container: 2
2023-01-03 21:30:20,864:INFO:PassiveAggressiveRegressor(random_state=123)
2023-01-03 21:30:20,864:INFO:create_model() successfully completed......................................
2023-01-03 21:30:20,965:INFO:SubProcess create_model() end ==================================
2023-01-03 21:30:20,965:INFO:Creating metrics dataframe
2023-01-03 21:30:20,978:INFO:Initializing Huber Regressor
2023-01-03 21:30:20,978:INFO:Total runtime is 0.06303133567174274 minutes
2023-01-03 21:30:20,982:INFO:SubProcess create_model() called ==================================
2023-01-03 21:30:20,983:INFO:Initializing create_model()
2023-01-03 21:30:20,983:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000207634A99A0>, estimator=huber, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020749009280>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:30:20,983:INFO:Checking exceptions
2023-01-03 21:30:20,983:INFO:Importing libraries
2023-01-03 21:30:20,983:INFO:Copying training dataset
2023-01-03 21:30:20,992:INFO:Defining folds
2023-01-03 21:30:20,993:INFO:Declaring metric variables
2023-01-03 21:30:20,996:INFO:Importing untrained model
2023-01-03 21:30:21,001:INFO:Huber Regressor Imported successfully
2023-01-03 21:30:21,010:INFO:Starting cross validation
2023-01-03 21:30:21,011:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:30:21,119:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-03 21:30:21,182:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-03 21:30:21,261:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-03 21:30:21,372:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-03 21:30:21,484:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-03 21:30:21,604:INFO:Calculating mean and std
2023-01-03 21:30:21,606:INFO:Creating metrics dataframe
2023-01-03 21:30:21,609:INFO:Uploading results into container
2023-01-03 21:30:21,609:INFO:Uploading model into container now
2023-01-03 21:30:21,609:INFO:_master_model_container: 10
2023-01-03 21:30:21,609:INFO:_display_container: 2
2023-01-03 21:30:21,610:INFO:HuberRegressor()
2023-01-03 21:30:21,610:INFO:create_model() successfully completed......................................
2023-01-03 21:30:21,704:INFO:SubProcess create_model() end ==================================
2023-01-03 21:30:21,705:INFO:Creating metrics dataframe
2023-01-03 21:30:21,717:INFO:Initializing K Neighbors Regressor
2023-01-03 21:30:21,718:INFO:Total runtime is 0.07535943587621051 minutes
2023-01-03 21:30:21,722:INFO:SubProcess create_model() called ==================================
2023-01-03 21:30:21,723:INFO:Initializing create_model()
2023-01-03 21:30:21,723:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000207634A99A0>, estimator=knn, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020749009280>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:30:21,723:INFO:Checking exceptions
2023-01-03 21:30:21,723:INFO:Importing libraries
2023-01-03 21:30:21,724:INFO:Copying training dataset
2023-01-03 21:30:21,733:INFO:Defining folds
2023-01-03 21:30:21,734:INFO:Declaring metric variables
2023-01-03 21:30:21,739:INFO:Importing untrained model
2023-01-03 21:30:21,743:INFO:K Neighbors Regressor Imported successfully
2023-01-03 21:30:21,752:INFO:Starting cross validation
2023-01-03 21:30:21,754:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:30:22,489:INFO:Calculating mean and std
2023-01-03 21:30:22,491:INFO:Creating metrics dataframe
2023-01-03 21:30:22,495:INFO:Uploading results into container
2023-01-03 21:30:22,495:INFO:Uploading model into container now
2023-01-03 21:30:22,496:INFO:_master_model_container: 11
2023-01-03 21:30:22,496:INFO:_display_container: 2
2023-01-03 21:30:22,496:INFO:KNeighborsRegressor(n_jobs=-1)
2023-01-03 21:30:22,496:INFO:create_model() successfully completed......................................
2023-01-03 21:30:22,637:INFO:SubProcess create_model() end ==================================
2023-01-03 21:30:22,637:INFO:Creating metrics dataframe
2023-01-03 21:30:22,655:INFO:Initializing Decision Tree Regressor
2023-01-03 21:30:22,655:INFO:Total runtime is 0.0909875194231669 minutes
2023-01-03 21:30:22,659:INFO:SubProcess create_model() called ==================================
2023-01-03 21:30:22,659:INFO:Initializing create_model()
2023-01-03 21:30:22,659:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000207634A99A0>, estimator=dt, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020749009280>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:30:22,660:INFO:Checking exceptions
2023-01-03 21:30:22,660:INFO:Importing libraries
2023-01-03 21:30:22,660:INFO:Copying training dataset
2023-01-03 21:30:22,671:INFO:Defining folds
2023-01-03 21:30:22,671:INFO:Declaring metric variables
2023-01-03 21:30:22,674:INFO:Importing untrained model
2023-01-03 21:30:22,678:INFO:Decision Tree Regressor Imported successfully
2023-01-03 21:30:22,690:INFO:Starting cross validation
2023-01-03 21:30:22,692:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:30:23,442:INFO:Calculating mean and std
2023-01-03 21:30:23,444:INFO:Creating metrics dataframe
2023-01-03 21:30:23,448:INFO:Uploading results into container
2023-01-03 21:30:23,450:INFO:Uploading model into container now
2023-01-03 21:30:23,450:INFO:_master_model_container: 12
2023-01-03 21:30:23,450:INFO:_display_container: 2
2023-01-03 21:30:23,451:INFO:DecisionTreeRegressor(random_state=123)
2023-01-03 21:30:23,451:INFO:create_model() successfully completed......................................
2023-01-03 21:30:23,556:INFO:SubProcess create_model() end ==================================
2023-01-03 21:30:23,556:INFO:Creating metrics dataframe
2023-01-03 21:30:23,568:INFO:Initializing Random Forest Regressor
2023-01-03 21:30:23,568:INFO:Total runtime is 0.10620414415995279 minutes
2023-01-03 21:30:23,573:INFO:SubProcess create_model() called ==================================
2023-01-03 21:30:23,573:INFO:Initializing create_model()
2023-01-03 21:30:23,573:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000207634A99A0>, estimator=rf, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020749009280>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:30:23,574:INFO:Checking exceptions
2023-01-03 21:30:23,574:INFO:Importing libraries
2023-01-03 21:30:23,574:INFO:Copying training dataset
2023-01-03 21:30:23,582:INFO:Defining folds
2023-01-03 21:30:23,583:INFO:Declaring metric variables
2023-01-03 21:30:23,587:INFO:Importing untrained model
2023-01-03 21:30:23,592:INFO:Random Forest Regressor Imported successfully
2023-01-03 21:30:23,600:INFO:Starting cross validation
2023-01-03 21:30:23,602:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:30:32,380:INFO:Calculating mean and std
2023-01-03 21:30:32,382:INFO:Creating metrics dataframe
2023-01-03 21:30:32,388:INFO:Uploading results into container
2023-01-03 21:30:32,389:INFO:Uploading model into container now
2023-01-03 21:30:32,389:INFO:_master_model_container: 13
2023-01-03 21:30:32,389:INFO:_display_container: 2
2023-01-03 21:30:32,390:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-01-03 21:30:32,390:INFO:create_model() successfully completed......................................
2023-01-03 21:30:32,505:INFO:SubProcess create_model() end ==================================
2023-01-03 21:30:32,505:INFO:Creating metrics dataframe
2023-01-03 21:30:32,518:INFO:Initializing Extra Trees Regressor
2023-01-03 21:30:32,518:INFO:Total runtime is 0.25537081559499103 minutes
2023-01-03 21:30:32,522:INFO:SubProcess create_model() called ==================================
2023-01-03 21:30:32,522:INFO:Initializing create_model()
2023-01-03 21:30:32,522:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000207634A99A0>, estimator=et, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020749009280>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:30:32,522:INFO:Checking exceptions
2023-01-03 21:30:32,523:INFO:Importing libraries
2023-01-03 21:30:32,523:INFO:Copying training dataset
2023-01-03 21:30:32,532:INFO:Defining folds
2023-01-03 21:30:32,533:INFO:Declaring metric variables
2023-01-03 21:30:32,537:INFO:Importing untrained model
2023-01-03 21:30:32,541:INFO:Extra Trees Regressor Imported successfully
2023-01-03 21:30:32,551:INFO:Starting cross validation
2023-01-03 21:30:32,577:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:30:36,702:INFO:Calculating mean and std
2023-01-03 21:30:36,704:INFO:Creating metrics dataframe
2023-01-03 21:30:36,707:INFO:Uploading results into container
2023-01-03 21:30:36,707:INFO:Uploading model into container now
2023-01-03 21:30:36,708:INFO:_master_model_container: 14
2023-01-03 21:30:36,708:INFO:_display_container: 2
2023-01-03 21:30:36,708:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-01-03 21:30:36,708:INFO:create_model() successfully completed......................................
2023-01-03 21:30:36,801:INFO:SubProcess create_model() end ==================================
2023-01-03 21:30:36,802:INFO:Creating metrics dataframe
2023-01-03 21:30:36,816:INFO:Initializing AdaBoost Regressor
2023-01-03 21:30:36,816:INFO:Total runtime is 0.32698953946431475 minutes
2023-01-03 21:30:36,820:INFO:SubProcess create_model() called ==================================
2023-01-03 21:30:36,821:INFO:Initializing create_model()
2023-01-03 21:30:36,821:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000207634A99A0>, estimator=ada, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020749009280>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:30:36,821:INFO:Checking exceptions
2023-01-03 21:30:36,821:INFO:Importing libraries
2023-01-03 21:30:36,821:INFO:Copying training dataset
2023-01-03 21:30:36,831:INFO:Defining folds
2023-01-03 21:30:36,831:INFO:Declaring metric variables
2023-01-03 21:30:36,836:INFO:Importing untrained model
2023-01-03 21:30:36,841:INFO:AdaBoost Regressor Imported successfully
2023-01-03 21:30:36,849:INFO:Starting cross validation
2023-01-03 21:30:36,850:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:30:37,671:INFO:Calculating mean and std
2023-01-03 21:30:37,673:INFO:Creating metrics dataframe
2023-01-03 21:30:37,678:INFO:Uploading results into container
2023-01-03 21:30:37,678:INFO:Uploading model into container now
2023-01-03 21:30:37,679:INFO:_master_model_container: 15
2023-01-03 21:30:37,679:INFO:_display_container: 2
2023-01-03 21:30:37,680:INFO:AdaBoostRegressor(random_state=123)
2023-01-03 21:30:37,680:INFO:create_model() successfully completed......................................
2023-01-03 21:30:37,777:INFO:SubProcess create_model() end ==================================
2023-01-03 21:30:37,777:INFO:Creating metrics dataframe
2023-01-03 21:30:37,790:INFO:Initializing Gradient Boosting Regressor
2023-01-03 21:30:37,790:INFO:Total runtime is 0.34322546323140457 minutes
2023-01-03 21:30:37,794:INFO:SubProcess create_model() called ==================================
2023-01-03 21:30:37,794:INFO:Initializing create_model()
2023-01-03 21:30:37,795:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000207634A99A0>, estimator=gbr, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020749009280>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:30:37,795:INFO:Checking exceptions
2023-01-03 21:30:37,795:INFO:Importing libraries
2023-01-03 21:30:37,795:INFO:Copying training dataset
2023-01-03 21:30:37,804:INFO:Defining folds
2023-01-03 21:30:37,804:INFO:Declaring metric variables
2023-01-03 21:30:37,809:INFO:Importing untrained model
2023-01-03 21:30:37,813:INFO:Gradient Boosting Regressor Imported successfully
2023-01-03 21:30:37,822:INFO:Starting cross validation
2023-01-03 21:30:37,824:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:30:41,847:INFO:Calculating mean and std
2023-01-03 21:30:41,849:INFO:Creating metrics dataframe
2023-01-03 21:30:41,852:INFO:Uploading results into container
2023-01-03 21:30:41,853:INFO:Uploading model into container now
2023-01-03 21:30:41,853:INFO:_master_model_container: 16
2023-01-03 21:30:41,853:INFO:_display_container: 2
2023-01-03 21:30:41,854:INFO:GradientBoostingRegressor(random_state=123)
2023-01-03 21:30:41,854:INFO:create_model() successfully completed......................................
2023-01-03 21:30:41,952:INFO:SubProcess create_model() end ==================================
2023-01-03 21:30:41,952:INFO:Creating metrics dataframe
2023-01-03 21:30:41,964:INFO:Initializing Light Gradient Boosting Machine
2023-01-03 21:30:41,964:INFO:Total runtime is 0.412803316116333 minutes
2023-01-03 21:30:41,968:INFO:SubProcess create_model() called ==================================
2023-01-03 21:30:41,969:INFO:Initializing create_model()
2023-01-03 21:30:41,969:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000207634A99A0>, estimator=lightgbm, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020749009280>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:30:41,969:INFO:Checking exceptions
2023-01-03 21:30:41,969:INFO:Importing libraries
2023-01-03 21:30:41,969:INFO:Copying training dataset
2023-01-03 21:30:41,979:INFO:Defining folds
2023-01-03 21:30:41,979:INFO:Declaring metric variables
2023-01-03 21:30:41,984:INFO:Importing untrained model
2023-01-03 21:30:41,988:INFO:Light Gradient Boosting Machine Imported successfully
2023-01-03 21:30:41,998:INFO:Starting cross validation
2023-01-03 21:30:41,999:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:30:42,999:INFO:Calculating mean and std
2023-01-03 21:30:43,000:INFO:Creating metrics dataframe
2023-01-03 21:30:43,004:INFO:Uploading results into container
2023-01-03 21:30:43,004:INFO:Uploading model into container now
2023-01-03 21:30:43,005:INFO:_master_model_container: 17
2023-01-03 21:30:43,005:INFO:_display_container: 2
2023-01-03 21:30:43,005:INFO:LGBMRegressor(random_state=123)
2023-01-03 21:30:43,005:INFO:create_model() successfully completed......................................
2023-01-03 21:30:43,102:INFO:SubProcess create_model() end ==================================
2023-01-03 21:30:43,103:INFO:Creating metrics dataframe
2023-01-03 21:30:43,117:INFO:Initializing Dummy Regressor
2023-01-03 21:30:43,117:INFO:Total runtime is 0.43200562000274656 minutes
2023-01-03 21:30:43,121:INFO:SubProcess create_model() called ==================================
2023-01-03 21:30:43,122:INFO:Initializing create_model()
2023-01-03 21:30:43,122:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000207634A99A0>, estimator=dummy, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020749009280>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:30:43,122:INFO:Checking exceptions
2023-01-03 21:30:43,122:INFO:Importing libraries
2023-01-03 21:30:43,122:INFO:Copying training dataset
2023-01-03 21:30:43,131:INFO:Defining folds
2023-01-03 21:30:43,131:INFO:Declaring metric variables
2023-01-03 21:30:43,137:INFO:Importing untrained model
2023-01-03 21:30:43,141:INFO:Dummy Regressor Imported successfully
2023-01-03 21:30:43,151:INFO:Starting cross validation
2023-01-03 21:30:43,152:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:30:43,392:INFO:Calculating mean and std
2023-01-03 21:30:43,393:INFO:Creating metrics dataframe
2023-01-03 21:30:43,396:INFO:Uploading results into container
2023-01-03 21:30:43,397:INFO:Uploading model into container now
2023-01-03 21:30:43,397:INFO:_master_model_container: 18
2023-01-03 21:30:43,398:INFO:_display_container: 2
2023-01-03 21:30:43,398:INFO:DummyRegressor()
2023-01-03 21:30:43,398:INFO:create_model() successfully completed......................................
2023-01-03 21:30:43,503:INFO:SubProcess create_model() end ==================================
2023-01-03 21:30:43,503:INFO:Creating metrics dataframe
2023-01-03 21:30:43,527:INFO:Initializing create_model()
2023-01-03 21:30:43,528:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000207634A99A0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:30:43,528:INFO:Checking exceptions
2023-01-03 21:30:43,529:INFO:Importing libraries
2023-01-03 21:30:43,529:INFO:Copying training dataset
2023-01-03 21:30:43,538:INFO:Defining folds
2023-01-03 21:30:43,538:INFO:Declaring metric variables
2023-01-03 21:30:43,538:INFO:Importing untrained model
2023-01-03 21:30:43,538:INFO:Declaring custom model
2023-01-03 21:30:43,540:INFO:Extra Trees Regressor Imported successfully
2023-01-03 21:30:43,541:INFO:Cross validation set to False
2023-01-03 21:30:43,541:INFO:Fitting Model
2023-01-03 21:30:45,008:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-01-03 21:30:45,008:INFO:create_model() successfully completed......................................
2023-01-03 21:30:45,146:INFO:_master_model_container: 18
2023-01-03 21:30:45,146:INFO:_display_container: 2
2023-01-03 21:30:45,146:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-01-03 21:30:45,147:INFO:compare_models() successfully completed......................................
2023-01-03 21:30:45,158:INFO:Initializing tune_model()
2023-01-03 21:30:45,158:INFO:tune_model(estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=3, custom_grid=None, optimize=MAE, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000207634A99A0>)
2023-01-03 21:30:45,158:INFO:Checking exceptions
2023-01-03 21:30:45,200:INFO:Copying training dataset
2023-01-03 21:30:45,209:INFO:Checking base model
2023-01-03 21:30:45,209:INFO:Base model : Extra Trees Regressor
2023-01-03 21:30:45,213:INFO:Declaring metric variables
2023-01-03 21:30:45,218:INFO:Defining Hyperparameters
2023-01-03 21:30:45,382:INFO:Tuning with n_jobs=-1
2023-01-03 21:30:45,382:INFO:Initializing RandomizedSearchCV
2023-01-03 21:30:45,434:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:30:45,437:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:30:45,443:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:30:45,456:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:30:45,654:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:30:45,664:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:30:45,667:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:30:45,868:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:30:45,956:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:30:45,957:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:30:46,005:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:30:46,412:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:30:46,597:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:30:46,623:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:30:46,644:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:30:47,037:INFO:best_params: {'actual_estimator__n_estimators': 100, 'actual_estimator__min_samples_split': 7, 'actual_estimator__min_samples_leaf': 4, 'actual_estimator__min_impurity_decrease': 0.1, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 9, 'actual_estimator__criterion': 'mse', 'actual_estimator__bootstrap': True}
2023-01-03 21:30:47,038:INFO:Hyperparameter search completed
2023-01-03 21:30:47,038:INFO:SubProcess create_model() called ==================================
2023-01-03 21:30:47,038:INFO:Initializing create_model()
2023-01-03 21:30:47,039:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000207634A99A0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000207487CD4F0>, model_only=True, return_train_score=False, kwargs={'n_estimators': 100, 'min_samples_split': 7, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.1, 'max_features': 1.0, 'max_depth': 9, 'criterion': 'mse', 'bootstrap': True})
2023-01-03 21:30:47,039:INFO:Checking exceptions
2023-01-03 21:30:47,039:INFO:Importing libraries
2023-01-03 21:30:47,039:INFO:Copying training dataset
2023-01-03 21:30:47,048:INFO:Defining folds
2023-01-03 21:30:47,048:INFO:Declaring metric variables
2023-01-03 21:30:47,051:INFO:Importing untrained model
2023-01-03 21:30:47,052:INFO:Declaring custom model
2023-01-03 21:30:47,057:INFO:Extra Trees Regressor Imported successfully
2023-01-03 21:30:47,065:INFO:Starting cross validation
2023-01-03 21:30:47,066:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:30:47,113:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:30:47,118:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:30:47,129:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:30:47,145:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:30:47,512:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:30:48,000:INFO:Calculating mean and std
2023-01-03 21:30:48,004:INFO:Creating metrics dataframe
2023-01-03 21:30:48,010:INFO:Finalizing model
2023-01-03 21:30:48,315:INFO:Uploading results into container
2023-01-03 21:30:48,316:INFO:Uploading model into container now
2023-01-03 21:30:48,317:INFO:_master_model_container: 19
2023-01-03 21:30:48,317:INFO:_display_container: 3
2023-01-03 21:30:48,317:INFO:ExtraTreesRegressor(bootstrap=True, criterion='mse', max_depth=9,
                    max_features=1.0, min_impurity_decrease=0.1,
                    min_samples_leaf=4, min_samples_split=7, n_jobs=-1,
                    random_state=123)
2023-01-03 21:30:48,317:INFO:create_model() successfully completed......................................
2023-01-03 21:30:48,422:INFO:SubProcess create_model() end ==================================
2023-01-03 21:30:48,422:INFO:choose_better activated
2023-01-03 21:30:48,426:INFO:SubProcess create_model() called ==================================
2023-01-03 21:30:48,426:INFO:Initializing create_model()
2023-01-03 21:30:48,426:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000207634A99A0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:30:48,426:INFO:Checking exceptions
2023-01-03 21:30:48,428:INFO:Importing libraries
2023-01-03 21:30:48,428:INFO:Copying training dataset
2023-01-03 21:30:48,436:INFO:Defining folds
2023-01-03 21:30:48,437:INFO:Declaring metric variables
2023-01-03 21:30:48,437:INFO:Importing untrained model
2023-01-03 21:30:48,437:INFO:Declaring custom model
2023-01-03 21:30:48,438:INFO:Extra Trees Regressor Imported successfully
2023-01-03 21:30:48,438:INFO:Starting cross validation
2023-01-03 21:30:48,439:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:30:51,906:INFO:Calculating mean and std
2023-01-03 21:30:51,907:INFO:Creating metrics dataframe
2023-01-03 21:30:51,908:INFO:Finalizing model
2023-01-03 21:30:53,293:INFO:Uploading results into container
2023-01-03 21:30:53,293:INFO:Uploading model into container now
2023-01-03 21:30:53,294:INFO:_master_model_container: 20
2023-01-03 21:30:53,294:INFO:_display_container: 4
2023-01-03 21:30:53,294:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-01-03 21:30:53,294:INFO:create_model() successfully completed......................................
2023-01-03 21:30:53,391:INFO:SubProcess create_model() end ==================================
2023-01-03 21:30:53,391:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123) result for MAE is 3.6075
2023-01-03 21:30:53,392:INFO:ExtraTreesRegressor(bootstrap=True, criterion='mse', max_depth=9,
                    max_features=1.0, min_impurity_decrease=0.1,
                    min_samples_leaf=4, min_samples_split=7, n_jobs=-1,
                    random_state=123) result for MAE is 4.6273
2023-01-03 21:30:53,392:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123) is best model
2023-01-03 21:30:53,392:INFO:choose_better completed
2023-01-03 21:30:53,392:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-01-03 21:30:53,401:INFO:_master_model_container: 20
2023-01-03 21:30:53,402:INFO:_display_container: 3
2023-01-03 21:30:53,402:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-01-03 21:30:53,402:INFO:tune_model() successfully completed......................................
2023-01-03 21:30:53,543:INFO:Initializing plot_model()
2023-01-03 21:30:53,543:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000207634A99A0>, system=True)
2023-01-03 21:30:53,543:INFO:Checking exceptions
2023-01-03 21:30:53,568:INFO:Preloading libraries
2023-01-03 21:30:53,715:INFO:Copying training dataset
2023-01-03 21:30:53,715:INFO:Plot type: error
2023-01-03 21:30:53,834:INFO:Fitting Model
2023-01-03 21:30:53,834:INFO:Scoring test/hold-out set
2023-01-03 21:30:54,154:INFO:Visual Rendered Successfully
2023-01-03 21:30:54,272:INFO:plot_model() successfully completed......................................
2023-01-03 21:30:54,286:INFO:Initializing predict_model()
2023-01-03 21:30:54,287:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000207634A99A0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000002074914EB80>)
2023-01-03 21:30:54,287:INFO:Checking exceptions
2023-01-03 21:30:54,287:INFO:Preloading libraries
2023-01-03 21:30:54,488:INFO:Initializing finalize_model()
2023-01-03 21:30:54,488:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000207634A99A0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-01-03 21:30:54,489:INFO:Finalizing ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-01-03 21:30:54,496:INFO:Initializing create_model()
2023-01-03 21:30:54,496:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000207634A99A0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-01-03 21:30:54,496:INFO:Checking exceptions
2023-01-03 21:30:54,498:INFO:Importing libraries
2023-01-03 21:30:54,498:INFO:Copying training dataset
2023-01-03 21:30:54,499:INFO:Defining folds
2023-01-03 21:30:54,499:INFO:Declaring metric variables
2023-01-03 21:30:54,499:INFO:Importing untrained model
2023-01-03 21:30:54,499:INFO:Declaring custom model
2023-01-03 21:30:54,500:INFO:Extra Trees Regressor Imported successfully
2023-01-03 21:30:54,501:INFO:Cross validation set to False
2023-01-03 21:30:54,501:INFO:Fitting Model
2023-01-03 21:30:56,497:INFO:Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))])
2023-01-03 21:30:56,497:INFO:create_model() successfully completed......................................
2023-01-03 21:30:56,593:INFO:_master_model_container: 20
2023-01-03 21:30:56,593:INFO:_display_container: 4
2023-01-03 21:30:56,600:INFO:Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))])
2023-01-03 21:30:56,600:INFO:finalize_model() successfully completed......................................
2023-01-03 21:30:56,707:INFO:Initializing predict_model()
2023-01-03 21:30:56,707:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000207634A99A0>, estimator=Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000002074914E820>)
2023-01-03 21:30:56,707:INFO:Checking exceptions
2023-01-03 21:30:56,707:INFO:Preloading libraries
2023-01-03 21:30:56,709:INFO:Set up data.
2023-01-03 21:30:56,722:INFO:Set up index.
2023-01-03 21:39:56,549:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-01-03 21:39:56,549:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-01-03 21:39:56,550:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-01-03 21:39:56,550:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-01-03 21:39:57,241:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-01-03 21:39:57,629:INFO:PyCaret RegressionExperiment
2023-01-03 21:39:57,629:INFO:Logging name: reg-default-name
2023-01-03 21:39:57,629:INFO:ML Usecase: MLUsecase.REGRESSION
2023-01-03 21:39:57,629:INFO:version 3.0.0.rc6
2023-01-03 21:39:57,629:INFO:Initializing setup()
2023-01-03 21:39:57,629:INFO:self.USI: 47fc
2023-01-03 21:39:57,629:INFO:self._variable_keys: {'transform_target_param', 'memory', 'pipeline', 'X_train', 'idx', 'logging_param', '_available_plots', 'fold_groups_param', 'n_jobs_param', 'log_plots_param', 'seed', 'fold_shuffle_param', 'target_param', 'html_param', 'gpu_param', 'USI', 'exp_id', 'X_test', 'gpu_n_jobs_param', 'data', 'y_train', 'y_test', 'y', 'fold_generator', 'X', '_ml_usecase', 'exp_name_log'}
2023-01-03 21:39:57,629:INFO:Checking environment
2023-01-03 21:39:57,629:INFO:python_version: 3.9.13
2023-01-03 21:39:57,629:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-01-03 21:39:57,630:INFO:machine: AMD64
2023-01-03 21:39:57,630:INFO:platform: Windows-10-10.0.19044-SP0
2023-01-03 21:39:57,630:INFO:Memory: svmem(total=17114804224, available=10072641536, percent=41.1, used=7042162688, free=10072641536)
2023-01-03 21:39:57,630:INFO:Physical Core: 4
2023-01-03 21:39:57,630:INFO:Logical Core: 4
2023-01-03 21:39:57,630:INFO:Checking libraries
2023-01-03 21:39:57,630:INFO:System:
2023-01-03 21:39:57,630:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-01-03 21:39:57,630:INFO:executable: c:\Users\Kodotautas\anaconda3\python.exe
2023-01-03 21:39:57,630:INFO:   machine: Windows-10-10.0.19044-SP0
2023-01-03 21:39:57,630:INFO:PyCaret required dependencies:
2023-01-03 21:39:57,630:INFO:                 pip: 22.2.2
2023-01-03 21:39:57,630:INFO:          setuptools: 63.4.1
2023-01-03 21:39:57,630:INFO:             pycaret: 3.0.0rc6
2023-01-03 21:39:57,630:INFO:             IPython: 7.31.1
2023-01-03 21:39:57,630:INFO:          ipywidgets: 7.6.5
2023-01-03 21:39:57,630:INFO:                tqdm: 4.64.1
2023-01-03 21:39:57,630:INFO:               numpy: 1.21.5
2023-01-03 21:39:57,630:INFO:              pandas: 1.4.4
2023-01-03 21:39:57,631:INFO:              jinja2: 2.11.3
2023-01-03 21:39:57,631:INFO:               scipy: 1.9.1
2023-01-03 21:39:57,631:INFO:              joblib: 1.2.0
2023-01-03 21:39:57,631:INFO:             sklearn: 1.0.2
2023-01-03 21:39:57,631:INFO:                pyod: 1.0.7
2023-01-03 21:39:57,631:INFO:            imblearn: 0.10.1
2023-01-03 21:39:57,631:INFO:   category_encoders: 2.5.1.post0
2023-01-03 21:39:57,631:INFO:            lightgbm: 3.3.3
2023-01-03 21:39:57,631:INFO:               numba: 0.55.1
2023-01-03 21:39:57,631:INFO:            requests: 2.28.1
2023-01-03 21:39:57,631:INFO:          matplotlib: 3.5.2
2023-01-03 21:39:57,631:INFO:          scikitplot: 0.3.7
2023-01-03 21:39:57,631:INFO:         yellowbrick: 1.5
2023-01-03 21:39:57,631:INFO:              plotly: 5.9.0
2023-01-03 21:39:57,631:INFO:             kaleido: 0.2.1
2023-01-03 21:39:57,631:INFO:         statsmodels: 0.13.2
2023-01-03 21:39:57,631:INFO:              sktime: 0.14.1
2023-01-03 21:39:57,631:INFO:               tbats: 1.1.2
2023-01-03 21:39:57,631:INFO:            pmdarima: 2.0.2
2023-01-03 21:39:57,631:INFO:              psutil: 5.9.0
2023-01-03 21:39:57,631:INFO:PyCaret optional dependencies:
2023-01-03 21:39:57,890:INFO:                shap: 0.41.0
2023-01-03 21:39:57,890:INFO:           interpret: Not installed
2023-01-03 21:39:57,890:INFO:                umap: Not installed
2023-01-03 21:39:57,890:INFO:    pandas_profiling: Not installed
2023-01-03 21:39:57,890:INFO:  explainerdashboard: Not installed
2023-01-03 21:39:57,890:INFO:             autoviz: Not installed
2023-01-03 21:39:57,890:INFO:           fairlearn: Not installed
2023-01-03 21:39:57,890:INFO:             xgboost: Not installed
2023-01-03 21:39:57,890:INFO:            catboost: Not installed
2023-01-03 21:39:57,890:INFO:              kmodes: Not installed
2023-01-03 21:39:57,890:INFO:             mlxtend: Not installed
2023-01-03 21:39:57,891:INFO:       statsforecast: Not installed
2023-01-03 21:39:57,891:INFO:        tune_sklearn: 0.4.3
2023-01-03 21:39:57,891:INFO:                 ray: 2.0.0
2023-01-03 21:39:57,891:INFO:            hyperopt: 0.2.7
2023-01-03 21:39:57,891:INFO:              optuna: 3.0.1
2023-01-03 21:39:57,891:INFO:               skopt: 0.9.0
2023-01-03 21:39:57,891:INFO:              mlflow: Not installed
2023-01-03 21:39:57,891:INFO:              gradio: Not installed
2023-01-03 21:39:57,891:INFO:             fastapi: 0.88.0
2023-01-03 21:39:57,891:INFO:             uvicorn: 0.20.0
2023-01-03 21:39:57,891:INFO:              m2cgen: Not installed
2023-01-03 21:39:57,891:INFO:           evidently: Not installed
2023-01-03 21:39:57,891:INFO:                nltk: 3.7
2023-01-03 21:39:57,891:INFO:            pyLDAvis: Not installed
2023-01-03 21:39:57,891:INFO:              gensim: 4.1.2
2023-01-03 21:39:57,891:INFO:               spacy: 3.4.2
2023-01-03 21:39:57,891:INFO:           wordcloud: Not installed
2023-01-03 21:39:57,891:INFO:            textblob: Not installed
2023-01-03 21:39:57,891:INFO:               fugue: Not installed
2023-01-03 21:39:57,891:INFO:           streamlit: Not installed
2023-01-03 21:39:57,891:INFO:             prophet: Not installed
2023-01-03 21:39:57,891:INFO:None
2023-01-03 21:39:57,891:INFO:Set up data.
2023-01-03 21:39:57,913:INFO:Set up train/test split.
2023-01-03 21:39:57,924:INFO:Set up index.
2023-01-03 21:39:57,928:INFO:Set up folding strategy.
2023-01-03 21:39:57,928:INFO:Assigning column types.
2023-01-03 21:39:57,938:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-01-03 21:39:57,938:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-01-03 21:39:57,944:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-03 21:39:57,949:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 21:39:58,019:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 21:39:58,067:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 21:39:58,068:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:39:58,202:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:39:58,203:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-01-03 21:39:58,207:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-03 21:39:58,213:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 21:39:58,280:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 21:39:58,327:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 21:39:58,328:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:39:58,329:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:39:58,329:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-01-03 21:39:58,334:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-03 21:39:58,339:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 21:39:58,409:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 21:39:58,460:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 21:39:58,461:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:39:58,461:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:39:58,467:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-03 21:39:58,471:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 21:39:58,539:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 21:39:58,587:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 21:39:58,588:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:39:58,588:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:39:58,589:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-01-03 21:39:58,599:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 21:39:58,673:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 21:39:58,723:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 21:39:58,724:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:39:58,724:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:39:58,736:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 21:39:58,806:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 21:39:58,855:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 21:39:58,856:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:39:58,856:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:39:58,856:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-01-03 21:39:58,939:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 21:39:58,988:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 21:39:58,988:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:39:58,989:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:39:59,070:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 21:39:59,118:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 21:39:59,118:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:39:59,119:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:39:59,119:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-01-03 21:39:59,200:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 21:39:59,250:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:39:59,250:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:39:59,337:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 21:39:59,396:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:39:59,397:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:39:59,397:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-01-03 21:39:59,534:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:39:59,535:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:39:59,668:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:39:59,668:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:39:59,669:INFO:Preparing preprocessing pipeline...
2023-01-03 21:39:59,671:INFO:Set up simple imputation.
2023-01-03 21:39:59,671:INFO:Set up column transformation.
2023-01-03 21:39:59,671:INFO:Set up feature normalization.
2023-01-03 21:40:00,422:INFO:Finished creating preprocessing pipeline.
2023-01-03 21:40:00,429:INFO:Pipeline: Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2023-01-03 21:40:00,430:INFO:Creating final display dataframe.
2023-01-03 21:40:01,067:INFO:Setup _display_container:                Description             Value
0               Session id               123
1                   Target        b2b+b2c+vt
2              Target type        Regression
3               Data shape       (10506, 50)
4         Train data shape        (7354, 50)
5          Test data shape        (3152, 50)
6         Numeric features                 8
7               Preprocess              True
8          Imputation type            simple
9       Numeric imputation              mean
10  Categorical imputation              mode
11          Transformation              True
12   Transformation method       yeo-johnson
13               Normalize              True
14        Normalize method            zscore
15          Fold Generator   TimeSeriesSplit
16             Fold Number                 5
17                CPU Jobs                -1
18                 Use GPU             False
19          Log Experiment             False
20         Experiment Name  reg-default-name
21                     USI              47fc
2023-01-03 21:40:01,234:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:40:01,234:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:40:01,367:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:40:01,367:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:40:01,368:INFO:setup() successfully completed in 3.74s...............
2023-01-03 21:40:01,368:INFO:Initializing compare_models()
2023-01-03 21:40:01,368:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DF292E2E80>, include=None, fold=None, round=4, cross_validation=True, sort=MAE, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001DF292E2E80>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'MAE', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-01-03 21:40:01,368:INFO:Checking exceptions
2023-01-03 21:40:01,373:INFO:Preparing display monitor
2023-01-03 21:40:01,421:INFO:Initializing Linear Regression
2023-01-03 21:40:01,421:INFO:Total runtime is 0.0 minutes
2023-01-03 21:40:01,426:INFO:SubProcess create_model() called ==================================
2023-01-03 21:40:01,427:INFO:Initializing create_model()
2023-01-03 21:40:01,427:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DF292E2E80>, estimator=lr, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DF2CED4D30>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:40:01,428:INFO:Checking exceptions
2023-01-03 21:40:01,428:INFO:Importing libraries
2023-01-03 21:40:01,428:INFO:Copying training dataset
2023-01-03 21:40:01,439:INFO:Defining folds
2023-01-03 21:40:01,439:INFO:Declaring metric variables
2023-01-03 21:40:01,444:INFO:Importing untrained model
2023-01-03 21:40:01,450:INFO:Linear Regression Imported successfully
2023-01-03 21:40:01,464:INFO:Starting cross validation
2023-01-03 21:40:01,470:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:40:09,310:INFO:Calculating mean and std
2023-01-03 21:40:09,312:INFO:Creating metrics dataframe
2023-01-03 21:40:09,315:INFO:Uploading results into container
2023-01-03 21:40:09,315:INFO:Uploading model into container now
2023-01-03 21:40:09,316:INFO:_master_model_container: 1
2023-01-03 21:40:09,316:INFO:_display_container: 2
2023-01-03 21:40:09,316:INFO:LinearRegression(n_jobs=-1)
2023-01-03 21:40:09,316:INFO:create_model() successfully completed......................................
2023-01-03 21:40:09,415:INFO:SubProcess create_model() end ==================================
2023-01-03 21:40:09,415:INFO:Creating metrics dataframe
2023-01-03 21:40:09,428:INFO:Initializing Lasso Regression
2023-01-03 21:40:09,428:INFO:Total runtime is 0.13345694939295452 minutes
2023-01-03 21:40:09,432:INFO:SubProcess create_model() called ==================================
2023-01-03 21:40:09,433:INFO:Initializing create_model()
2023-01-03 21:40:09,433:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DF292E2E80>, estimator=lasso, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DF2CED4D30>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:40:09,433:INFO:Checking exceptions
2023-01-03 21:40:09,433:INFO:Importing libraries
2023-01-03 21:40:09,434:INFO:Copying training dataset
2023-01-03 21:40:09,446:INFO:Defining folds
2023-01-03 21:40:09,446:INFO:Declaring metric variables
2023-01-03 21:40:09,450:INFO:Importing untrained model
2023-01-03 21:40:09,456:INFO:Lasso Regression Imported successfully
2023-01-03 21:40:09,465:INFO:Starting cross validation
2023-01-03 21:40:09,467:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:40:09,835:INFO:Calculating mean and std
2023-01-03 21:40:09,837:INFO:Creating metrics dataframe
2023-01-03 21:40:09,840:INFO:Uploading results into container
2023-01-03 21:40:09,840:INFO:Uploading model into container now
2023-01-03 21:40:09,840:INFO:_master_model_container: 2
2023-01-03 21:40:09,840:INFO:_display_container: 2
2023-01-03 21:40:09,841:INFO:Lasso(random_state=123)
2023-01-03 21:40:09,841:INFO:create_model() successfully completed......................................
2023-01-03 21:40:09,936:INFO:SubProcess create_model() end ==================================
2023-01-03 21:40:09,936:INFO:Creating metrics dataframe
2023-01-03 21:40:09,950:INFO:Initializing Ridge Regression
2023-01-03 21:40:09,950:INFO:Total runtime is 0.1421480735143026 minutes
2023-01-03 21:40:09,954:INFO:SubProcess create_model() called ==================================
2023-01-03 21:40:09,955:INFO:Initializing create_model()
2023-01-03 21:40:09,955:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DF292E2E80>, estimator=ridge, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DF2CED4D30>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:40:09,955:INFO:Checking exceptions
2023-01-03 21:40:09,955:INFO:Importing libraries
2023-01-03 21:40:09,955:INFO:Copying training dataset
2023-01-03 21:40:09,965:INFO:Defining folds
2023-01-03 21:40:09,965:INFO:Declaring metric variables
2023-01-03 21:40:09,970:INFO:Importing untrained model
2023-01-03 21:40:09,976:INFO:Ridge Regression Imported successfully
2023-01-03 21:40:09,986:INFO:Starting cross validation
2023-01-03 21:40:09,987:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:40:10,244:INFO:Calculating mean and std
2023-01-03 21:40:10,246:INFO:Creating metrics dataframe
2023-01-03 21:40:10,252:INFO:Uploading results into container
2023-01-03 21:40:10,253:INFO:Uploading model into container now
2023-01-03 21:40:10,253:INFO:_master_model_container: 3
2023-01-03 21:40:10,253:INFO:_display_container: 2
2023-01-03 21:40:10,253:INFO:Ridge(random_state=123)
2023-01-03 21:40:10,253:INFO:create_model() successfully completed......................................
2023-01-03 21:40:10,350:INFO:SubProcess create_model() end ==================================
2023-01-03 21:40:10,350:INFO:Creating metrics dataframe
2023-01-03 21:40:10,359:INFO:Initializing Elastic Net
2023-01-03 21:40:10,359:INFO:Total runtime is 0.14896950721740723 minutes
2023-01-03 21:40:10,363:INFO:SubProcess create_model() called ==================================
2023-01-03 21:40:10,364:INFO:Initializing create_model()
2023-01-03 21:40:10,364:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DF292E2E80>, estimator=en, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DF2CED4D30>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:40:10,364:INFO:Checking exceptions
2023-01-03 21:40:10,364:INFO:Importing libraries
2023-01-03 21:40:10,364:INFO:Copying training dataset
2023-01-03 21:40:10,374:INFO:Defining folds
2023-01-03 21:40:10,374:INFO:Declaring metric variables
2023-01-03 21:40:10,379:INFO:Importing untrained model
2023-01-03 21:40:10,384:INFO:Elastic Net Imported successfully
2023-01-03 21:40:10,392:INFO:Starting cross validation
2023-01-03 21:40:10,394:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:40:10,655:INFO:Calculating mean and std
2023-01-03 21:40:10,657:INFO:Creating metrics dataframe
2023-01-03 21:40:10,660:INFO:Uploading results into container
2023-01-03 21:40:10,661:INFO:Uploading model into container now
2023-01-03 21:40:10,662:INFO:_master_model_container: 4
2023-01-03 21:40:10,662:INFO:_display_container: 2
2023-01-03 21:40:10,662:INFO:ElasticNet(random_state=123)
2023-01-03 21:40:10,662:INFO:create_model() successfully completed......................................
2023-01-03 21:40:10,765:INFO:SubProcess create_model() end ==================================
2023-01-03 21:40:10,765:INFO:Creating metrics dataframe
2023-01-03 21:40:10,774:INFO:Initializing Least Angle Regression
2023-01-03 21:40:10,775:INFO:Total runtime is 0.15590264399846396 minutes
2023-01-03 21:40:10,779:INFO:SubProcess create_model() called ==================================
2023-01-03 21:40:10,779:INFO:Initializing create_model()
2023-01-03 21:40:10,779:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DF292E2E80>, estimator=lar, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DF2CED4D30>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:40:10,779:INFO:Checking exceptions
2023-01-03 21:40:10,779:INFO:Importing libraries
2023-01-03 21:40:10,779:INFO:Copying training dataset
2023-01-03 21:40:10,789:INFO:Defining folds
2023-01-03 21:40:10,789:INFO:Declaring metric variables
2023-01-03 21:40:10,792:INFO:Importing untrained model
2023-01-03 21:40:10,798:INFO:Least Angle Regression Imported successfully
2023-01-03 21:40:10,806:INFO:Starting cross validation
2023-01-03 21:40:10,807:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:40:10,894:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 21:40:10,897:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 21:40:10,901:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 21:40:10,903:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 21:40:10,961:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 21:40:11,094:INFO:Calculating mean and std
2023-01-03 21:40:11,096:INFO:Creating metrics dataframe
2023-01-03 21:40:11,102:INFO:Uploading results into container
2023-01-03 21:40:11,102:INFO:Uploading model into container now
2023-01-03 21:40:11,103:INFO:_master_model_container: 5
2023-01-03 21:40:11,103:INFO:_display_container: 2
2023-01-03 21:40:11,103:INFO:Lars(random_state=123)
2023-01-03 21:40:11,103:INFO:create_model() successfully completed......................................
2023-01-03 21:40:11,202:INFO:SubProcess create_model() end ==================================
2023-01-03 21:40:11,202:INFO:Creating metrics dataframe
2023-01-03 21:40:11,211:INFO:Initializing Lasso Least Angle Regression
2023-01-03 21:40:11,212:INFO:Total runtime is 0.16318819522857667 minutes
2023-01-03 21:40:11,216:INFO:SubProcess create_model() called ==================================
2023-01-03 21:40:11,217:INFO:Initializing create_model()
2023-01-03 21:40:11,217:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DF292E2E80>, estimator=llar, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DF2CED4D30>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:40:11,217:INFO:Checking exceptions
2023-01-03 21:40:11,217:INFO:Importing libraries
2023-01-03 21:40:11,217:INFO:Copying training dataset
2023-01-03 21:40:11,226:INFO:Defining folds
2023-01-03 21:40:11,227:INFO:Declaring metric variables
2023-01-03 21:40:11,231:INFO:Importing untrained model
2023-01-03 21:40:11,235:INFO:Lasso Least Angle Regression Imported successfully
2023-01-03 21:40:11,245:INFO:Starting cross validation
2023-01-03 21:40:11,247:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:40:11,318:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-03 21:40:11,321:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-03 21:40:11,324:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-03 21:40:11,328:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-03 21:40:11,374:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-03 21:40:11,507:INFO:Calculating mean and std
2023-01-03 21:40:11,509:INFO:Creating metrics dataframe
2023-01-03 21:40:11,512:INFO:Uploading results into container
2023-01-03 21:40:11,513:INFO:Uploading model into container now
2023-01-03 21:40:11,514:INFO:_master_model_container: 6
2023-01-03 21:40:11,514:INFO:_display_container: 2
2023-01-03 21:40:11,515:INFO:LassoLars(random_state=123)
2023-01-03 21:40:11,515:INFO:create_model() successfully completed......................................
2023-01-03 21:40:11,618:INFO:SubProcess create_model() end ==================================
2023-01-03 21:40:11,618:INFO:Creating metrics dataframe
2023-01-03 21:40:11,628:INFO:Initializing Orthogonal Matching Pursuit
2023-01-03 21:40:11,628:INFO:Total runtime is 0.17011420329411825 minutes
2023-01-03 21:40:11,632:INFO:SubProcess create_model() called ==================================
2023-01-03 21:40:11,632:INFO:Initializing create_model()
2023-01-03 21:40:11,633:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DF292E2E80>, estimator=omp, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DF2CED4D30>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:40:11,633:INFO:Checking exceptions
2023-01-03 21:40:11,633:INFO:Importing libraries
2023-01-03 21:40:11,633:INFO:Copying training dataset
2023-01-03 21:40:11,642:INFO:Defining folds
2023-01-03 21:40:11,642:INFO:Declaring metric variables
2023-01-03 21:40:11,647:INFO:Importing untrained model
2023-01-03 21:40:11,651:INFO:Orthogonal Matching Pursuit Imported successfully
2023-01-03 21:40:11,661:INFO:Starting cross validation
2023-01-03 21:40:11,662:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:40:11,751:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 21:40:11,764:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 21:40:11,768:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 21:40:11,787:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 21:40:11,838:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 21:40:11,966:INFO:Calculating mean and std
2023-01-03 21:40:11,968:INFO:Creating metrics dataframe
2023-01-03 21:40:11,971:INFO:Uploading results into container
2023-01-03 21:40:11,971:INFO:Uploading model into container now
2023-01-03 21:40:11,972:INFO:_master_model_container: 7
2023-01-03 21:40:11,972:INFO:_display_container: 2
2023-01-03 21:40:11,972:INFO:OrthogonalMatchingPursuit()
2023-01-03 21:40:11,972:INFO:create_model() successfully completed......................................
2023-01-03 21:40:12,069:INFO:SubProcess create_model() end ==================================
2023-01-03 21:40:12,070:INFO:Creating metrics dataframe
2023-01-03 21:40:12,083:INFO:Initializing Bayesian Ridge
2023-01-03 21:40:12,083:INFO:Total runtime is 0.17770028909047444 minutes
2023-01-03 21:40:12,087:INFO:SubProcess create_model() called ==================================
2023-01-03 21:40:12,087:INFO:Initializing create_model()
2023-01-03 21:40:12,087:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DF292E2E80>, estimator=br, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DF2CED4D30>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:40:12,088:INFO:Checking exceptions
2023-01-03 21:40:12,088:INFO:Importing libraries
2023-01-03 21:40:12,088:INFO:Copying training dataset
2023-01-03 21:40:12,098:INFO:Defining folds
2023-01-03 21:40:12,098:INFO:Declaring metric variables
2023-01-03 21:40:12,102:INFO:Importing untrained model
2023-01-03 21:40:12,106:INFO:Bayesian Ridge Imported successfully
2023-01-03 21:40:12,115:INFO:Starting cross validation
2023-01-03 21:40:12,117:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:40:12,391:INFO:Calculating mean and std
2023-01-03 21:40:12,393:INFO:Creating metrics dataframe
2023-01-03 21:40:12,396:INFO:Uploading results into container
2023-01-03 21:40:12,397:INFO:Uploading model into container now
2023-01-03 21:40:12,397:INFO:_master_model_container: 8
2023-01-03 21:40:12,397:INFO:_display_container: 2
2023-01-03 21:40:12,397:INFO:BayesianRidge()
2023-01-03 21:40:12,397:INFO:create_model() successfully completed......................................
2023-01-03 21:40:12,495:INFO:SubProcess create_model() end ==================================
2023-01-03 21:40:12,495:INFO:Creating metrics dataframe
2023-01-03 21:40:12,508:INFO:Initializing Passive Aggressive Regressor
2023-01-03 21:40:12,508:INFO:Total runtime is 0.18477691411972047 minutes
2023-01-03 21:40:12,513:INFO:SubProcess create_model() called ==================================
2023-01-03 21:40:12,513:INFO:Initializing create_model()
2023-01-03 21:40:12,514:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DF292E2E80>, estimator=par, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DF2CED4D30>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:40:12,514:INFO:Checking exceptions
2023-01-03 21:40:12,514:INFO:Importing libraries
2023-01-03 21:40:12,514:INFO:Copying training dataset
2023-01-03 21:40:12,523:INFO:Defining folds
2023-01-03 21:40:12,524:INFO:Declaring metric variables
2023-01-03 21:40:12,528:INFO:Importing untrained model
2023-01-03 21:40:12,533:INFO:Passive Aggressive Regressor Imported successfully
2023-01-03 21:40:12,541:INFO:Starting cross validation
2023-01-03 21:40:12,543:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:40:12,819:INFO:Calculating mean and std
2023-01-03 21:40:12,821:INFO:Creating metrics dataframe
2023-01-03 21:40:12,824:INFO:Uploading results into container
2023-01-03 21:40:12,825:INFO:Uploading model into container now
2023-01-03 21:40:12,825:INFO:_master_model_container: 9
2023-01-03 21:40:12,826:INFO:_display_container: 2
2023-01-03 21:40:12,826:INFO:PassiveAggressiveRegressor(random_state=123)
2023-01-03 21:40:12,826:INFO:create_model() successfully completed......................................
2023-01-03 21:40:12,929:INFO:SubProcess create_model() end ==================================
2023-01-03 21:40:12,929:INFO:Creating metrics dataframe
2023-01-03 21:40:12,940:INFO:Initializing Huber Regressor
2023-01-03 21:40:12,940:INFO:Total runtime is 0.19197968244552613 minutes
2023-01-03 21:40:12,944:INFO:SubProcess create_model() called ==================================
2023-01-03 21:40:12,944:INFO:Initializing create_model()
2023-01-03 21:40:12,944:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DF292E2E80>, estimator=huber, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DF2CED4D30>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:40:12,945:INFO:Checking exceptions
2023-01-03 21:40:12,945:INFO:Importing libraries
2023-01-03 21:40:12,945:INFO:Copying training dataset
2023-01-03 21:40:12,954:INFO:Defining folds
2023-01-03 21:40:12,954:INFO:Declaring metric variables
2023-01-03 21:40:12,958:INFO:Importing untrained model
2023-01-03 21:40:12,963:INFO:Huber Regressor Imported successfully
2023-01-03 21:40:12,972:INFO:Starting cross validation
2023-01-03 21:40:12,973:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:40:13,125:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-03 21:40:13,233:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-03 21:40:13,307:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-03 21:40:13,413:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-03 21:40:13,582:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-03 21:40:13,706:INFO:Calculating mean and std
2023-01-03 21:40:13,708:INFO:Creating metrics dataframe
2023-01-03 21:40:13,711:INFO:Uploading results into container
2023-01-03 21:40:13,712:INFO:Uploading model into container now
2023-01-03 21:40:13,713:INFO:_master_model_container: 10
2023-01-03 21:40:13,713:INFO:_display_container: 2
2023-01-03 21:40:13,713:INFO:HuberRegressor()
2023-01-03 21:40:13,713:INFO:create_model() successfully completed......................................
2023-01-03 21:40:13,816:INFO:SubProcess create_model() end ==================================
2023-01-03 21:40:13,816:INFO:Creating metrics dataframe
2023-01-03 21:40:13,827:INFO:Initializing K Neighbors Regressor
2023-01-03 21:40:13,828:INFO:Total runtime is 0.20678275426228843 minutes
2023-01-03 21:40:13,832:INFO:SubProcess create_model() called ==================================
2023-01-03 21:40:13,832:INFO:Initializing create_model()
2023-01-03 21:40:13,832:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DF292E2E80>, estimator=knn, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DF2CED4D30>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:40:13,832:INFO:Checking exceptions
2023-01-03 21:40:13,832:INFO:Importing libraries
2023-01-03 21:40:13,832:INFO:Copying training dataset
2023-01-03 21:40:13,841:INFO:Defining folds
2023-01-03 21:40:13,842:INFO:Declaring metric variables
2023-01-03 21:40:13,847:INFO:Importing untrained model
2023-01-03 21:40:13,851:INFO:K Neighbors Regressor Imported successfully
2023-01-03 21:40:13,860:INFO:Starting cross validation
2023-01-03 21:40:13,862:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:40:14,530:INFO:Calculating mean and std
2023-01-03 21:40:14,532:INFO:Creating metrics dataframe
2023-01-03 21:40:14,535:INFO:Uploading results into container
2023-01-03 21:40:14,535:INFO:Uploading model into container now
2023-01-03 21:40:14,535:INFO:_master_model_container: 11
2023-01-03 21:40:14,536:INFO:_display_container: 2
2023-01-03 21:40:14,536:INFO:KNeighborsRegressor(n_jobs=-1)
2023-01-03 21:40:14,536:INFO:create_model() successfully completed......................................
2023-01-03 21:40:14,631:INFO:SubProcess create_model() end ==================================
2023-01-03 21:40:14,631:INFO:Creating metrics dataframe
2023-01-03 21:40:14,645:INFO:Initializing Decision Tree Regressor
2023-01-03 21:40:14,645:INFO:Total runtime is 0.22040325005849204 minutes
2023-01-03 21:40:14,650:INFO:SubProcess create_model() called ==================================
2023-01-03 21:40:14,651:INFO:Initializing create_model()
2023-01-03 21:40:14,651:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DF292E2E80>, estimator=dt, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DF2CED4D30>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:40:14,651:INFO:Checking exceptions
2023-01-03 21:40:14,651:INFO:Importing libraries
2023-01-03 21:40:14,652:INFO:Copying training dataset
2023-01-03 21:40:14,662:INFO:Defining folds
2023-01-03 21:40:14,662:INFO:Declaring metric variables
2023-01-03 21:40:14,667:INFO:Importing untrained model
2023-01-03 21:40:14,671:INFO:Decision Tree Regressor Imported successfully
2023-01-03 21:40:14,680:INFO:Starting cross validation
2023-01-03 21:40:14,682:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:40:15,209:INFO:Calculating mean and std
2023-01-03 21:40:15,211:INFO:Creating metrics dataframe
2023-01-03 21:40:15,214:INFO:Uploading results into container
2023-01-03 21:40:15,215:INFO:Uploading model into container now
2023-01-03 21:40:15,216:INFO:_master_model_container: 12
2023-01-03 21:40:15,217:INFO:_display_container: 2
2023-01-03 21:40:15,217:INFO:DecisionTreeRegressor(random_state=123)
2023-01-03 21:40:15,217:INFO:create_model() successfully completed......................................
2023-01-03 21:40:15,316:INFO:SubProcess create_model() end ==================================
2023-01-03 21:40:15,316:INFO:Creating metrics dataframe
2023-01-03 21:40:15,327:INFO:Initializing Random Forest Regressor
2023-01-03 21:40:15,327:INFO:Total runtime is 0.2317608992258708 minutes
2023-01-03 21:40:15,331:INFO:SubProcess create_model() called ==================================
2023-01-03 21:40:15,332:INFO:Initializing create_model()
2023-01-03 21:40:15,332:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DF292E2E80>, estimator=rf, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DF2CED4D30>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:40:15,332:INFO:Checking exceptions
2023-01-03 21:40:15,332:INFO:Importing libraries
2023-01-03 21:40:15,332:INFO:Copying training dataset
2023-01-03 21:40:15,341:INFO:Defining folds
2023-01-03 21:40:15,342:INFO:Declaring metric variables
2023-01-03 21:40:15,347:INFO:Importing untrained model
2023-01-03 21:40:15,351:INFO:Random Forest Regressor Imported successfully
2023-01-03 21:40:15,360:INFO:Starting cross validation
2023-01-03 21:40:15,362:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:40:26,098:INFO:Calculating mean and std
2023-01-03 21:40:26,100:INFO:Creating metrics dataframe
2023-01-03 21:40:26,103:INFO:Uploading results into container
2023-01-03 21:40:26,103:INFO:Uploading model into container now
2023-01-03 21:40:26,103:INFO:_master_model_container: 13
2023-01-03 21:40:26,103:INFO:_display_container: 2
2023-01-03 21:40:26,104:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-01-03 21:40:26,104:INFO:create_model() successfully completed......................................
2023-01-03 21:40:26,199:INFO:SubProcess create_model() end ==================================
2023-01-03 21:40:26,199:INFO:Creating metrics dataframe
2023-01-03 21:40:26,211:INFO:Initializing Extra Trees Regressor
2023-01-03 21:40:26,211:INFO:Total runtime is 0.4131626685460409 minutes
2023-01-03 21:40:26,218:INFO:SubProcess create_model() called ==================================
2023-01-03 21:40:26,219:INFO:Initializing create_model()
2023-01-03 21:40:26,219:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DF292E2E80>, estimator=et, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DF2CED4D30>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:40:26,219:INFO:Checking exceptions
2023-01-03 21:40:26,219:INFO:Importing libraries
2023-01-03 21:40:26,219:INFO:Copying training dataset
2023-01-03 21:40:26,230:INFO:Defining folds
2023-01-03 21:40:26,230:INFO:Declaring metric variables
2023-01-03 21:40:26,234:INFO:Importing untrained model
2023-01-03 21:40:26,239:INFO:Extra Trees Regressor Imported successfully
2023-01-03 21:40:26,249:INFO:Starting cross validation
2023-01-03 21:40:26,250:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:40:31,264:INFO:Calculating mean and std
2023-01-03 21:40:31,267:INFO:Creating metrics dataframe
2023-01-03 21:40:31,270:INFO:Uploading results into container
2023-01-03 21:40:31,270:INFO:Uploading model into container now
2023-01-03 21:40:31,270:INFO:_master_model_container: 14
2023-01-03 21:40:31,270:INFO:_display_container: 2
2023-01-03 21:40:31,271:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-01-03 21:40:31,271:INFO:create_model() successfully completed......................................
2023-01-03 21:40:31,366:INFO:SubProcess create_model() end ==================================
2023-01-03 21:40:31,366:INFO:Creating metrics dataframe
2023-01-03 21:40:31,381:INFO:Initializing AdaBoost Regressor
2023-01-03 21:40:31,381:INFO:Total runtime is 0.49933797518412276 minutes
2023-01-03 21:40:31,386:INFO:SubProcess create_model() called ==================================
2023-01-03 21:40:31,386:INFO:Initializing create_model()
2023-01-03 21:40:31,386:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DF292E2E80>, estimator=ada, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DF2CED4D30>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:40:31,387:INFO:Checking exceptions
2023-01-03 21:40:31,387:INFO:Importing libraries
2023-01-03 21:40:31,387:INFO:Copying training dataset
2023-01-03 21:40:31,398:INFO:Defining folds
2023-01-03 21:40:31,398:INFO:Declaring metric variables
2023-01-03 21:40:31,403:INFO:Importing untrained model
2023-01-03 21:40:31,407:INFO:AdaBoost Regressor Imported successfully
2023-01-03 21:40:31,415:INFO:Starting cross validation
2023-01-03 21:40:31,416:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:40:33,933:INFO:Calculating mean and std
2023-01-03 21:40:33,935:INFO:Creating metrics dataframe
2023-01-03 21:40:33,938:INFO:Uploading results into container
2023-01-03 21:40:33,938:INFO:Uploading model into container now
2023-01-03 21:40:33,938:INFO:_master_model_container: 15
2023-01-03 21:40:33,938:INFO:_display_container: 2
2023-01-03 21:40:33,939:INFO:AdaBoostRegressor(random_state=123)
2023-01-03 21:40:33,939:INFO:create_model() successfully completed......................................
2023-01-03 21:40:34,036:INFO:SubProcess create_model() end ==================================
2023-01-03 21:40:34,037:INFO:Creating metrics dataframe
2023-01-03 21:40:34,052:INFO:Initializing Gradient Boosting Regressor
2023-01-03 21:40:34,052:INFO:Total runtime is 0.5438514669736226 minutes
2023-01-03 21:40:34,056:INFO:SubProcess create_model() called ==================================
2023-01-03 21:40:34,057:INFO:Initializing create_model()
2023-01-03 21:40:34,057:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DF292E2E80>, estimator=gbr, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DF2CED4D30>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:40:34,057:INFO:Checking exceptions
2023-01-03 21:40:34,057:INFO:Importing libraries
2023-01-03 21:40:34,057:INFO:Copying training dataset
2023-01-03 21:40:34,067:INFO:Defining folds
2023-01-03 21:40:34,067:INFO:Declaring metric variables
2023-01-03 21:40:34,072:INFO:Importing untrained model
2023-01-03 21:40:34,076:INFO:Gradient Boosting Regressor Imported successfully
2023-01-03 21:40:34,086:INFO:Starting cross validation
2023-01-03 21:40:34,087:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:40:39,967:INFO:Calculating mean and std
2023-01-03 21:40:39,969:INFO:Creating metrics dataframe
2023-01-03 21:40:39,972:INFO:Uploading results into container
2023-01-03 21:40:39,973:INFO:Uploading model into container now
2023-01-03 21:40:39,974:INFO:_master_model_container: 16
2023-01-03 21:40:39,975:INFO:_display_container: 2
2023-01-03 21:40:39,975:INFO:GradientBoostingRegressor(random_state=123)
2023-01-03 21:40:39,976:INFO:create_model() successfully completed......................................
2023-01-03 21:40:40,085:INFO:SubProcess create_model() end ==================================
2023-01-03 21:40:40,085:INFO:Creating metrics dataframe
2023-01-03 21:40:40,098:INFO:Initializing Light Gradient Boosting Machine
2023-01-03 21:40:40,099:INFO:Total runtime is 0.6446369250615438 minutes
2023-01-03 21:40:40,103:INFO:SubProcess create_model() called ==================================
2023-01-03 21:40:40,103:INFO:Initializing create_model()
2023-01-03 21:40:40,103:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DF292E2E80>, estimator=lightgbm, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DF2CED4D30>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:40:40,103:INFO:Checking exceptions
2023-01-03 21:40:40,103:INFO:Importing libraries
2023-01-03 21:40:40,103:INFO:Copying training dataset
2023-01-03 21:40:40,114:INFO:Defining folds
2023-01-03 21:40:40,115:INFO:Declaring metric variables
2023-01-03 21:40:40,119:INFO:Importing untrained model
2023-01-03 21:40:40,123:INFO:Light Gradient Boosting Machine Imported successfully
2023-01-03 21:40:40,134:INFO:Starting cross validation
2023-01-03 21:40:40,135:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:40:43,068:INFO:Calculating mean and std
2023-01-03 21:40:43,070:INFO:Creating metrics dataframe
2023-01-03 21:40:43,074:INFO:Uploading results into container
2023-01-03 21:40:43,074:INFO:Uploading model into container now
2023-01-03 21:40:43,075:INFO:_master_model_container: 17
2023-01-03 21:40:43,075:INFO:_display_container: 2
2023-01-03 21:40:43,076:INFO:LGBMRegressor(random_state=123)
2023-01-03 21:40:43,076:INFO:create_model() successfully completed......................................
2023-01-03 21:40:43,220:INFO:SubProcess create_model() end ==================================
2023-01-03 21:40:43,220:INFO:Creating metrics dataframe
2023-01-03 21:40:43,236:INFO:Initializing Dummy Regressor
2023-01-03 21:40:43,236:INFO:Total runtime is 0.6969202796618144 minutes
2023-01-03 21:40:43,240:INFO:SubProcess create_model() called ==================================
2023-01-03 21:40:43,240:INFO:Initializing create_model()
2023-01-03 21:40:43,240:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DF292E2E80>, estimator=dummy, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DF2CED4D30>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:40:43,240:INFO:Checking exceptions
2023-01-03 21:40:43,241:INFO:Importing libraries
2023-01-03 21:40:43,241:INFO:Copying training dataset
2023-01-03 21:40:43,253:INFO:Defining folds
2023-01-03 21:40:43,253:INFO:Declaring metric variables
2023-01-03 21:40:43,258:INFO:Importing untrained model
2023-01-03 21:40:43,264:INFO:Dummy Regressor Imported successfully
2023-01-03 21:40:43,276:INFO:Starting cross validation
2023-01-03 21:40:43,279:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:40:43,585:INFO:Calculating mean and std
2023-01-03 21:40:43,587:INFO:Creating metrics dataframe
2023-01-03 21:40:43,590:INFO:Uploading results into container
2023-01-03 21:40:43,591:INFO:Uploading model into container now
2023-01-03 21:40:43,591:INFO:_master_model_container: 18
2023-01-03 21:40:43,591:INFO:_display_container: 2
2023-01-03 21:40:43,591:INFO:DummyRegressor()
2023-01-03 21:40:43,592:INFO:create_model() successfully completed......................................
2023-01-03 21:40:43,704:INFO:SubProcess create_model() end ==================================
2023-01-03 21:40:43,704:INFO:Creating metrics dataframe
2023-01-03 21:40:43,730:INFO:Initializing create_model()
2023-01-03 21:40:43,730:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DF292E2E80>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:40:43,730:INFO:Checking exceptions
2023-01-03 21:40:43,733:INFO:Importing libraries
2023-01-03 21:40:43,733:INFO:Copying training dataset
2023-01-03 21:40:43,742:INFO:Defining folds
2023-01-03 21:40:43,742:INFO:Declaring metric variables
2023-01-03 21:40:43,742:INFO:Importing untrained model
2023-01-03 21:40:43,742:INFO:Declaring custom model
2023-01-03 21:40:43,743:INFO:Extra Trees Regressor Imported successfully
2023-01-03 21:40:43,744:INFO:Cross validation set to False
2023-01-03 21:40:43,745:INFO:Fitting Model
2023-01-03 21:40:46,040:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-01-03 21:40:46,040:INFO:create_model() successfully completed......................................
2023-01-03 21:40:46,174:INFO:_master_model_container: 18
2023-01-03 21:40:46,175:INFO:_display_container: 2
2023-01-03 21:40:46,175:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-01-03 21:40:46,175:INFO:compare_models() successfully completed......................................
2023-01-03 21:40:46,176:INFO:Initializing tune_model()
2023-01-03 21:40:46,176:INFO:tune_model(estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=3, custom_grid=None, optimize=MAE, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DF292E2E80>)
2023-01-03 21:40:46,176:INFO:Checking exceptions
2023-01-03 21:40:46,212:INFO:Copying training dataset
2023-01-03 21:40:46,221:INFO:Checking base model
2023-01-03 21:40:46,221:INFO:Base model : Extra Trees Regressor
2023-01-03 21:40:46,225:INFO:Declaring metric variables
2023-01-03 21:40:46,229:INFO:Defining Hyperparameters
2023-01-03 21:40:46,354:INFO:Tuning with n_jobs=-1
2023-01-03 21:40:46,354:INFO:Initializing RandomizedSearchCV
2023-01-03 21:40:46,432:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:40:46,439:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:40:46,440:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:40:46,472:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:40:46,673:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:40:46,710:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:40:46,718:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:40:47,020:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:40:47,035:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:40:47,071:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:40:47,123:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:40:47,742:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:40:47,818:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:40:47,857:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:40:47,971:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:40:48,339:INFO:best_params: {'actual_estimator__n_estimators': 100, 'actual_estimator__min_samples_split': 7, 'actual_estimator__min_samples_leaf': 4, 'actual_estimator__min_impurity_decrease': 0.1, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 9, 'actual_estimator__criterion': 'mse', 'actual_estimator__bootstrap': True}
2023-01-03 21:40:48,342:INFO:Hyperparameter search completed
2023-01-03 21:40:48,342:INFO:SubProcess create_model() called ==================================
2023-01-03 21:40:48,343:INFO:Initializing create_model()
2023-01-03 21:40:48,343:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DF292E2E80>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DF2CED4DF0>, model_only=True, return_train_score=False, kwargs={'n_estimators': 100, 'min_samples_split': 7, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.1, 'max_features': 1.0, 'max_depth': 9, 'criterion': 'mse', 'bootstrap': True})
2023-01-03 21:40:48,343:INFO:Checking exceptions
2023-01-03 21:40:48,343:INFO:Importing libraries
2023-01-03 21:40:48,343:INFO:Copying training dataset
2023-01-03 21:40:48,352:INFO:Defining folds
2023-01-03 21:40:48,352:INFO:Declaring metric variables
2023-01-03 21:40:48,356:INFO:Importing untrained model
2023-01-03 21:40:48,356:INFO:Declaring custom model
2023-01-03 21:40:48,360:INFO:Extra Trees Regressor Imported successfully
2023-01-03 21:40:48,369:INFO:Starting cross validation
2023-01-03 21:40:48,370:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:40:48,497:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:40:48,501:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:40:48,503:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:40:48,540:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:40:49,082:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:40:49,604:INFO:Calculating mean and std
2023-01-03 21:40:49,608:INFO:Creating metrics dataframe
2023-01-03 21:40:49,616:INFO:Finalizing model
2023-01-03 21:40:49,952:INFO:Uploading results into container
2023-01-03 21:40:49,954:INFO:Uploading model into container now
2023-01-03 21:40:49,955:INFO:_master_model_container: 19
2023-01-03 21:40:49,955:INFO:_display_container: 3
2023-01-03 21:40:49,956:INFO:ExtraTreesRegressor(bootstrap=True, criterion='mse', max_depth=9,
                    max_features=1.0, min_impurity_decrease=0.1,
                    min_samples_leaf=4, min_samples_split=7, n_jobs=-1,
                    random_state=123)
2023-01-03 21:40:49,956:INFO:create_model() successfully completed......................................
2023-01-03 21:40:50,078:INFO:SubProcess create_model() end ==================================
2023-01-03 21:40:50,078:INFO:choose_better activated
2023-01-03 21:40:50,084:INFO:SubProcess create_model() called ==================================
2023-01-03 21:40:50,084:INFO:Initializing create_model()
2023-01-03 21:40:50,084:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DF292E2E80>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:40:50,084:INFO:Checking exceptions
2023-01-03 21:40:50,087:INFO:Importing libraries
2023-01-03 21:40:50,087:INFO:Copying training dataset
2023-01-03 21:40:50,097:INFO:Defining folds
2023-01-03 21:40:50,097:INFO:Declaring metric variables
2023-01-03 21:40:50,097:INFO:Importing untrained model
2023-01-03 21:40:50,097:INFO:Declaring custom model
2023-01-03 21:40:50,098:INFO:Extra Trees Regressor Imported successfully
2023-01-03 21:40:50,098:INFO:Starting cross validation
2023-01-03 21:40:50,099:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:40:55,816:INFO:Calculating mean and std
2023-01-03 21:40:55,816:INFO:Creating metrics dataframe
2023-01-03 21:40:55,818:INFO:Finalizing model
2023-01-03 21:40:57,995:INFO:Uploading results into container
2023-01-03 21:40:57,995:INFO:Uploading model into container now
2023-01-03 21:40:57,996:INFO:_master_model_container: 20
2023-01-03 21:40:57,996:INFO:_display_container: 4
2023-01-03 21:40:57,997:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-01-03 21:40:57,997:INFO:create_model() successfully completed......................................
2023-01-03 21:40:58,105:INFO:SubProcess create_model() end ==================================
2023-01-03 21:40:58,106:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123) result for MAE is 0.1297
2023-01-03 21:40:58,106:INFO:ExtraTreesRegressor(bootstrap=True, criterion='mse', max_depth=9,
                    max_features=1.0, min_impurity_decrease=0.1,
                    min_samples_leaf=4, min_samples_split=7, n_jobs=-1,
                    random_state=123) result for MAE is 0.4724
2023-01-03 21:40:58,107:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123) is best model
2023-01-03 21:40:58,107:INFO:choose_better completed
2023-01-03 21:40:58,107:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-01-03 21:40:58,117:INFO:_master_model_container: 20
2023-01-03 21:40:58,117:INFO:_display_container: 3
2023-01-03 21:40:58,117:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-01-03 21:40:58,117:INFO:tune_model() successfully completed......................................
2023-01-03 21:40:58,272:INFO:Initializing plot_model()
2023-01-03 21:40:58,273:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DF292E2E80>, system=True)
2023-01-03 21:40:58,273:INFO:Checking exceptions
2023-01-03 21:40:58,300:INFO:Preloading libraries
2023-01-03 21:40:58,460:INFO:Copying training dataset
2023-01-03 21:40:58,460:INFO:Plot type: error
2023-01-03 21:40:58,646:INFO:Fitting Model
2023-01-03 21:40:58,646:INFO:Scoring test/hold-out set
2023-01-03 21:40:59,291:INFO:Visual Rendered Successfully
2023-01-03 21:40:59,414:INFO:plot_model() successfully completed......................................
2023-01-03 21:40:59,424:INFO:Initializing predict_model()
2023-01-03 21:40:59,424:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DF292E2E80>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001DF32B8F790>)
2023-01-03 21:40:59,424:INFO:Checking exceptions
2023-01-03 21:40:59,424:INFO:Preloading libraries
2023-01-03 21:40:59,636:INFO:Initializing finalize_model()
2023-01-03 21:40:59,636:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DF292E2E80>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-01-03 21:40:59,636:INFO:Finalizing ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-01-03 21:40:59,646:INFO:Initializing create_model()
2023-01-03 21:40:59,646:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DF292E2E80>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-01-03 21:40:59,647:INFO:Checking exceptions
2023-01-03 21:40:59,648:INFO:Importing libraries
2023-01-03 21:40:59,649:INFO:Copying training dataset
2023-01-03 21:40:59,649:INFO:Defining folds
2023-01-03 21:40:59,649:INFO:Declaring metric variables
2023-01-03 21:40:59,650:INFO:Importing untrained model
2023-01-03 21:40:59,650:INFO:Declaring custom model
2023-01-03 21:40:59,650:INFO:Extra Trees Regressor Imported successfully
2023-01-03 21:40:59,651:INFO:Cross validation set to False
2023-01-03 21:40:59,651:INFO:Fitting Model
2023-01-03 21:41:03,911:INFO:Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))])
2023-01-03 21:41:03,911:INFO:create_model() successfully completed......................................
2023-01-03 21:41:04,035:INFO:_master_model_container: 20
2023-01-03 21:41:04,035:INFO:_display_container: 4
2023-01-03 21:41:04,042:INFO:Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))])
2023-01-03 21:41:04,042:INFO:finalize_model() successfully completed......................................
2023-01-03 21:41:04,154:INFO:Initializing predict_model()
2023-01-03 21:41:04,154:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DF292E2E80>, estimator=Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001DF331EC310>)
2023-01-03 21:41:04,154:INFO:Checking exceptions
2023-01-03 21:41:04,154:INFO:Preloading libraries
2023-01-03 21:41:04,156:INFO:Set up data.
2023-01-03 21:41:04,174:INFO:Set up index.
2023-01-03 21:46:44,609:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-01-03 21:46:44,609:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-01-03 21:46:44,609:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-01-03 21:46:44,609:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-01-03 21:46:45,305:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-01-03 21:46:45,673:INFO:PyCaret RegressionExperiment
2023-01-03 21:46:45,673:INFO:Logging name: reg-default-name
2023-01-03 21:46:45,673:INFO:ML Usecase: MLUsecase.REGRESSION
2023-01-03 21:46:45,673:INFO:version 3.0.0.rc6
2023-01-03 21:46:45,673:INFO:Initializing setup()
2023-01-03 21:46:45,673:INFO:self.USI: 8e34
2023-01-03 21:46:45,673:INFO:self._variable_keys: {'fold_groups_param', 'gpu_param', 'idx', 'y_train', 'pipeline', 'USI', 'target_param', 'transform_target_param', 'fold_shuffle_param', '_available_plots', 'html_param', 'X', '_ml_usecase', 'memory', 'y_test', 'gpu_n_jobs_param', 'y', 'data', 'fold_generator', 'exp_id', 'exp_name_log', 'log_plots_param', 'logging_param', 'X_train', 'X_test', 'n_jobs_param', 'seed'}
2023-01-03 21:46:45,673:INFO:Checking environment
2023-01-03 21:46:45,674:INFO:python_version: 3.9.13
2023-01-03 21:46:45,674:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-01-03 21:46:45,674:INFO:machine: AMD64
2023-01-03 21:46:45,674:INFO:platform: Windows-10-10.0.19044-SP0
2023-01-03 21:46:45,674:INFO:Memory: svmem(total=17114804224, available=9964457984, percent=41.8, used=7150346240, free=9964457984)
2023-01-03 21:46:45,674:INFO:Physical Core: 4
2023-01-03 21:46:45,674:INFO:Logical Core: 4
2023-01-03 21:46:45,674:INFO:Checking libraries
2023-01-03 21:46:45,674:INFO:System:
2023-01-03 21:46:45,674:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-01-03 21:46:45,674:INFO:executable: c:\Users\Kodotautas\anaconda3\python.exe
2023-01-03 21:46:45,674:INFO:   machine: Windows-10-10.0.19044-SP0
2023-01-03 21:46:45,674:INFO:PyCaret required dependencies:
2023-01-03 21:46:45,674:INFO:                 pip: 22.2.2
2023-01-03 21:46:45,674:INFO:          setuptools: 63.4.1
2023-01-03 21:46:45,674:INFO:             pycaret: 3.0.0rc6
2023-01-03 21:46:45,674:INFO:             IPython: 7.31.1
2023-01-03 21:46:45,674:INFO:          ipywidgets: 7.6.5
2023-01-03 21:46:45,675:INFO:                tqdm: 4.64.1
2023-01-03 21:46:45,675:INFO:               numpy: 1.21.5
2023-01-03 21:46:45,675:INFO:              pandas: 1.4.4
2023-01-03 21:46:45,675:INFO:              jinja2: 2.11.3
2023-01-03 21:46:45,675:INFO:               scipy: 1.9.1
2023-01-03 21:46:45,675:INFO:              joblib: 1.2.0
2023-01-03 21:46:45,675:INFO:             sklearn: 1.0.2
2023-01-03 21:46:45,675:INFO:                pyod: 1.0.7
2023-01-03 21:46:45,675:INFO:            imblearn: 0.10.1
2023-01-03 21:46:45,675:INFO:   category_encoders: 2.5.1.post0
2023-01-03 21:46:45,675:INFO:            lightgbm: 3.3.3
2023-01-03 21:46:45,675:INFO:               numba: 0.55.1
2023-01-03 21:46:45,675:INFO:            requests: 2.28.1
2023-01-03 21:46:45,675:INFO:          matplotlib: 3.5.2
2023-01-03 21:46:45,675:INFO:          scikitplot: 0.3.7
2023-01-03 21:46:45,675:INFO:         yellowbrick: 1.5
2023-01-03 21:46:45,675:INFO:              plotly: 5.9.0
2023-01-03 21:46:45,675:INFO:             kaleido: 0.2.1
2023-01-03 21:46:45,675:INFO:         statsmodels: 0.13.2
2023-01-03 21:46:45,675:INFO:              sktime: 0.14.1
2023-01-03 21:46:45,675:INFO:               tbats: 1.1.2
2023-01-03 21:46:45,675:INFO:            pmdarima: 2.0.2
2023-01-03 21:46:45,675:INFO:              psutil: 5.9.0
2023-01-03 21:46:45,676:INFO:PyCaret optional dependencies:
2023-01-03 21:46:45,938:INFO:                shap: 0.41.0
2023-01-03 21:46:45,938:INFO:           interpret: Not installed
2023-01-03 21:46:45,938:INFO:                umap: Not installed
2023-01-03 21:46:45,938:INFO:    pandas_profiling: Not installed
2023-01-03 21:46:45,939:INFO:  explainerdashboard: Not installed
2023-01-03 21:46:45,939:INFO:             autoviz: Not installed
2023-01-03 21:46:45,939:INFO:           fairlearn: Not installed
2023-01-03 21:46:45,939:INFO:             xgboost: Not installed
2023-01-03 21:46:45,939:INFO:            catboost: Not installed
2023-01-03 21:46:45,939:INFO:              kmodes: Not installed
2023-01-03 21:46:45,939:INFO:             mlxtend: Not installed
2023-01-03 21:46:45,939:INFO:       statsforecast: Not installed
2023-01-03 21:46:45,939:INFO:        tune_sklearn: 0.4.3
2023-01-03 21:46:45,939:INFO:                 ray: 2.0.0
2023-01-03 21:46:45,939:INFO:            hyperopt: 0.2.7
2023-01-03 21:46:45,939:INFO:              optuna: 3.0.1
2023-01-03 21:46:45,939:INFO:               skopt: 0.9.0
2023-01-03 21:46:45,939:INFO:              mlflow: Not installed
2023-01-03 21:46:45,939:INFO:              gradio: Not installed
2023-01-03 21:46:45,939:INFO:             fastapi: 0.88.0
2023-01-03 21:46:45,939:INFO:             uvicorn: 0.20.0
2023-01-03 21:46:45,939:INFO:              m2cgen: Not installed
2023-01-03 21:46:45,939:INFO:           evidently: Not installed
2023-01-03 21:46:45,939:INFO:                nltk: 3.7
2023-01-03 21:46:45,939:INFO:            pyLDAvis: Not installed
2023-01-03 21:46:45,939:INFO:              gensim: 4.1.2
2023-01-03 21:46:45,939:INFO:               spacy: 3.4.2
2023-01-03 21:46:45,939:INFO:           wordcloud: Not installed
2023-01-03 21:46:45,940:INFO:            textblob: Not installed
2023-01-03 21:46:45,940:INFO:               fugue: Not installed
2023-01-03 21:46:45,940:INFO:           streamlit: Not installed
2023-01-03 21:46:45,940:INFO:             prophet: Not installed
2023-01-03 21:46:45,940:INFO:None
2023-01-03 21:46:45,940:INFO:Set up data.
2023-01-03 21:46:45,967:INFO:Set up train/test split.
2023-01-03 21:46:45,978:INFO:Set up index.
2023-01-03 21:46:45,981:INFO:Set up folding strategy.
2023-01-03 21:46:45,982:INFO:Assigning column types.
2023-01-03 21:46:45,992:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-01-03 21:46:45,992:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-01-03 21:46:45,997:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-03 21:46:46,002:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 21:46:46,068:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 21:46:46,113:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 21:46:46,114:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:46:46,248:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:46:46,249:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-01-03 21:46:46,253:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-03 21:46:46,258:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 21:46:46,323:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 21:46:46,370:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 21:46:46,371:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:46:46,371:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:46:46,371:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-01-03 21:46:46,376:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-03 21:46:46,382:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 21:46:46,449:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 21:46:46,495:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 21:46:46,496:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:46:46,496:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:46:46,501:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-03 21:46:46,506:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 21:46:46,570:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 21:46:46,616:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 21:46:46,616:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:46:46,616:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:46:46,617:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-01-03 21:46:46,626:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 21:46:46,691:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 21:46:46,740:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 21:46:46,740:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:46:46,740:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:46:46,750:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 21:46:46,815:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 21:46:46,861:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 21:46:46,861:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:46:46,862:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:46:46,862:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-01-03 21:46:46,937:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 21:46:46,985:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 21:46:46,986:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:46:46,986:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:46:47,060:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 21:46:47,106:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 21:46:47,106:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:46:47,107:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:46:47,107:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-01-03 21:46:47,181:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 21:46:47,230:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:46:47,230:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:46:47,304:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 21:46:47,353:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:46:47,353:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:46:47,353:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-01-03 21:46:47,476:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:46:47,575:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:46:47,696:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:46:47,696:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:46:47,697:INFO:Preparing preprocessing pipeline...
2023-01-03 21:46:47,699:INFO:Set up simple imputation.
2023-01-03 21:46:47,699:INFO:Set up column transformation.
2023-01-03 21:46:47,699:INFO:Set up feature normalization.
2023-01-03 21:46:48,307:INFO:Finished creating preprocessing pipeline.
2023-01-03 21:46:48,314:INFO:Pipeline: Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2023-01-03 21:46:48,314:INFO:Creating final display dataframe.
2023-01-03 21:46:48,869:INFO:Setup _display_container:                Description             Value
0               Session id               123
1                   Target        b2b+b2c+vt
2              Target type        Regression
3               Data shape       (10505, 50)
4         Train data shape        (7353, 50)
5          Test data shape        (3152, 50)
6         Numeric features                 8
7               Preprocess              True
8          Imputation type            simple
9       Numeric imputation              mean
10  Categorical imputation              mode
11          Transformation              True
12   Transformation method       yeo-johnson
13               Normalize              True
14        Normalize method            zscore
15          Fold Generator   TimeSeriesSplit
16             Fold Number                 5
17                CPU Jobs                -1
18                 Use GPU             False
19          Log Experiment             False
20         Experiment Name  reg-default-name
21                     USI              8e34
2023-01-03 21:46:49,024:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:46:49,025:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:46:49,223:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:46:49,224:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:46:49,225:INFO:setup() successfully completed in 3.55s...............
2023-01-03 21:46:49,225:INFO:Initializing compare_models()
2023-01-03 21:46:49,225:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CCA14C0580>, include=None, fold=None, round=4, cross_validation=True, sort=MAE, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001CCA14C0580>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'MAE', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-01-03 21:46:49,225:INFO:Checking exceptions
2023-01-03 21:46:49,232:INFO:Preparing display monitor
2023-01-03 21:46:49,287:INFO:Initializing Linear Regression
2023-01-03 21:46:49,288:INFO:Total runtime is 1.6661485036214194e-05 minutes
2023-01-03 21:46:49,292:INFO:SubProcess create_model() called ==================================
2023-01-03 21:46:49,293:INFO:Initializing create_model()
2023-01-03 21:46:49,293:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CCA14C0580>, estimator=lr, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CCA6F98FD0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:46:49,293:INFO:Checking exceptions
2023-01-03 21:46:49,293:INFO:Importing libraries
2023-01-03 21:46:49,293:INFO:Copying training dataset
2023-01-03 21:46:49,304:INFO:Defining folds
2023-01-03 21:46:49,304:INFO:Declaring metric variables
2023-01-03 21:46:49,310:INFO:Importing untrained model
2023-01-03 21:46:49,315:INFO:Linear Regression Imported successfully
2023-01-03 21:46:49,324:INFO:Starting cross validation
2023-01-03 21:46:49,330:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:46:55,847:INFO:Calculating mean and std
2023-01-03 21:46:55,849:INFO:Creating metrics dataframe
2023-01-03 21:46:55,852:INFO:Uploading results into container
2023-01-03 21:46:55,852:INFO:Uploading model into container now
2023-01-03 21:46:55,853:INFO:_master_model_container: 1
2023-01-03 21:46:55,853:INFO:_display_container: 2
2023-01-03 21:46:55,854:INFO:LinearRegression(n_jobs=-1)
2023-01-03 21:46:55,854:INFO:create_model() successfully completed......................................
2023-01-03 21:46:55,959:INFO:SubProcess create_model() end ==================================
2023-01-03 21:46:55,959:INFO:Creating metrics dataframe
2023-01-03 21:46:55,968:INFO:Initializing Lasso Regression
2023-01-03 21:46:55,969:INFO:Total runtime is 0.11136652231216432 minutes
2023-01-03 21:46:55,973:INFO:SubProcess create_model() called ==================================
2023-01-03 21:46:55,974:INFO:Initializing create_model()
2023-01-03 21:46:55,974:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CCA14C0580>, estimator=lasso, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CCA6F98FD0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:46:55,974:INFO:Checking exceptions
2023-01-03 21:46:55,974:INFO:Importing libraries
2023-01-03 21:46:55,974:INFO:Copying training dataset
2023-01-03 21:46:55,985:INFO:Defining folds
2023-01-03 21:46:55,985:INFO:Declaring metric variables
2023-01-03 21:46:55,988:INFO:Importing untrained model
2023-01-03 21:46:55,993:INFO:Lasso Regression Imported successfully
2023-01-03 21:46:56,003:INFO:Starting cross validation
2023-01-03 21:46:56,004:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:46:56,369:INFO:Calculating mean and std
2023-01-03 21:46:56,371:INFO:Creating metrics dataframe
2023-01-03 21:46:56,376:INFO:Uploading results into container
2023-01-03 21:46:56,377:INFO:Uploading model into container now
2023-01-03 21:46:56,377:INFO:_master_model_container: 2
2023-01-03 21:46:56,377:INFO:_display_container: 2
2023-01-03 21:46:56,377:INFO:Lasso(random_state=123)
2023-01-03 21:46:56,378:INFO:create_model() successfully completed......................................
2023-01-03 21:46:56,488:INFO:SubProcess create_model() end ==================================
2023-01-03 21:46:56,488:INFO:Creating metrics dataframe
2023-01-03 21:46:56,497:INFO:Initializing Ridge Regression
2023-01-03 21:46:56,497:INFO:Total runtime is 0.12017196814219158 minutes
2023-01-03 21:46:56,502:INFO:SubProcess create_model() called ==================================
2023-01-03 21:46:56,502:INFO:Initializing create_model()
2023-01-03 21:46:56,503:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CCA14C0580>, estimator=ridge, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CCA6F98FD0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:46:56,503:INFO:Checking exceptions
2023-01-03 21:46:56,503:INFO:Importing libraries
2023-01-03 21:46:56,503:INFO:Copying training dataset
2023-01-03 21:46:56,515:INFO:Defining folds
2023-01-03 21:46:56,515:INFO:Declaring metric variables
2023-01-03 21:46:56,519:INFO:Importing untrained model
2023-01-03 21:46:56,524:INFO:Ridge Regression Imported successfully
2023-01-03 21:46:56,534:INFO:Starting cross validation
2023-01-03 21:46:56,536:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:46:56,844:INFO:Calculating mean and std
2023-01-03 21:46:56,846:INFO:Creating metrics dataframe
2023-01-03 21:46:56,850:INFO:Uploading results into container
2023-01-03 21:46:56,850:INFO:Uploading model into container now
2023-01-03 21:46:56,850:INFO:_master_model_container: 3
2023-01-03 21:46:56,851:INFO:_display_container: 2
2023-01-03 21:46:56,851:INFO:Ridge(random_state=123)
2023-01-03 21:46:56,851:INFO:create_model() successfully completed......................................
2023-01-03 21:46:56,965:INFO:SubProcess create_model() end ==================================
2023-01-03 21:46:56,965:INFO:Creating metrics dataframe
2023-01-03 21:46:56,976:INFO:Initializing Elastic Net
2023-01-03 21:46:56,976:INFO:Total runtime is 0.12815531492233279 minutes
2023-01-03 21:46:56,980:INFO:SubProcess create_model() called ==================================
2023-01-03 21:46:56,980:INFO:Initializing create_model()
2023-01-03 21:46:56,980:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CCA14C0580>, estimator=en, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CCA6F98FD0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:46:56,981:INFO:Checking exceptions
2023-01-03 21:46:56,981:INFO:Importing libraries
2023-01-03 21:46:56,981:INFO:Copying training dataset
2023-01-03 21:46:56,991:INFO:Defining folds
2023-01-03 21:46:56,991:INFO:Declaring metric variables
2023-01-03 21:46:56,994:INFO:Importing untrained model
2023-01-03 21:46:56,999:INFO:Elastic Net Imported successfully
2023-01-03 21:46:57,006:INFO:Starting cross validation
2023-01-03 21:46:57,008:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:46:57,251:INFO:Calculating mean and std
2023-01-03 21:46:57,253:INFO:Creating metrics dataframe
2023-01-03 21:46:57,256:INFO:Uploading results into container
2023-01-03 21:46:57,256:INFO:Uploading model into container now
2023-01-03 21:46:57,256:INFO:_master_model_container: 4
2023-01-03 21:46:57,256:INFO:_display_container: 2
2023-01-03 21:46:57,257:INFO:ElasticNet(random_state=123)
2023-01-03 21:46:57,257:INFO:create_model() successfully completed......................................
2023-01-03 21:46:57,375:INFO:SubProcess create_model() end ==================================
2023-01-03 21:46:57,376:INFO:Creating metrics dataframe
2023-01-03 21:46:57,386:INFO:Initializing Least Angle Regression
2023-01-03 21:46:57,387:INFO:Total runtime is 0.13500352303187055 minutes
2023-01-03 21:46:57,390:INFO:SubProcess create_model() called ==================================
2023-01-03 21:46:57,391:INFO:Initializing create_model()
2023-01-03 21:46:57,391:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CCA14C0580>, estimator=lar, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CCA6F98FD0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:46:57,391:INFO:Checking exceptions
2023-01-03 21:46:57,391:INFO:Importing libraries
2023-01-03 21:46:57,391:INFO:Copying training dataset
2023-01-03 21:46:57,401:INFO:Defining folds
2023-01-03 21:46:57,401:INFO:Declaring metric variables
2023-01-03 21:46:57,407:INFO:Importing untrained model
2023-01-03 21:46:57,413:INFO:Least Angle Regression Imported successfully
2023-01-03 21:46:57,423:INFO:Starting cross validation
2023-01-03 21:46:57,424:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:46:57,475:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 21:46:57,480:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 21:46:57,489:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 21:46:57,520:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 21:46:57,551:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 21:46:57,697:INFO:Calculating mean and std
2023-01-03 21:46:57,700:INFO:Creating metrics dataframe
2023-01-03 21:46:57,703:INFO:Uploading results into container
2023-01-03 21:46:57,704:INFO:Uploading model into container now
2023-01-03 21:46:57,705:INFO:_master_model_container: 5
2023-01-03 21:46:57,705:INFO:_display_container: 2
2023-01-03 21:46:57,706:INFO:Lars(random_state=123)
2023-01-03 21:46:57,706:INFO:create_model() successfully completed......................................
2023-01-03 21:46:57,816:INFO:SubProcess create_model() end ==================================
2023-01-03 21:46:57,817:INFO:Creating metrics dataframe
2023-01-03 21:46:57,827:INFO:Initializing Lasso Least Angle Regression
2023-01-03 21:46:57,827:INFO:Total runtime is 0.1423368255297343 minutes
2023-01-03 21:46:57,830:INFO:SubProcess create_model() called ==================================
2023-01-03 21:46:57,831:INFO:Initializing create_model()
2023-01-03 21:46:57,831:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CCA14C0580>, estimator=llar, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CCA6F98FD0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:46:57,831:INFO:Checking exceptions
2023-01-03 21:46:57,831:INFO:Importing libraries
2023-01-03 21:46:57,831:INFO:Copying training dataset
2023-01-03 21:46:57,841:INFO:Defining folds
2023-01-03 21:46:57,841:INFO:Declaring metric variables
2023-01-03 21:46:57,845:INFO:Importing untrained model
2023-01-03 21:46:57,849:INFO:Lasso Least Angle Regression Imported successfully
2023-01-03 21:46:57,857:INFO:Starting cross validation
2023-01-03 21:46:57,858:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:46:57,904:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-03 21:46:57,911:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-03 21:46:57,924:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-03 21:46:57,948:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-03 21:46:57,966:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-03 21:46:58,094:INFO:Calculating mean and std
2023-01-03 21:46:58,097:INFO:Creating metrics dataframe
2023-01-03 21:46:58,101:INFO:Uploading results into container
2023-01-03 21:46:58,102:INFO:Uploading model into container now
2023-01-03 21:46:58,102:INFO:_master_model_container: 6
2023-01-03 21:46:58,102:INFO:_display_container: 2
2023-01-03 21:46:58,103:INFO:LassoLars(random_state=123)
2023-01-03 21:46:58,103:INFO:create_model() successfully completed......................................
2023-01-03 21:46:58,214:INFO:SubProcess create_model() end ==================================
2023-01-03 21:46:58,215:INFO:Creating metrics dataframe
2023-01-03 21:46:58,225:INFO:Initializing Orthogonal Matching Pursuit
2023-01-03 21:46:58,225:INFO:Total runtime is 0.14897017876307173 minutes
2023-01-03 21:46:58,229:INFO:SubProcess create_model() called ==================================
2023-01-03 21:46:58,230:INFO:Initializing create_model()
2023-01-03 21:46:58,230:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CCA14C0580>, estimator=omp, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CCA6F98FD0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:46:58,230:INFO:Checking exceptions
2023-01-03 21:46:58,230:INFO:Importing libraries
2023-01-03 21:46:58,230:INFO:Copying training dataset
2023-01-03 21:46:58,240:INFO:Defining folds
2023-01-03 21:46:58,240:INFO:Declaring metric variables
2023-01-03 21:46:58,243:INFO:Importing untrained model
2023-01-03 21:46:58,248:INFO:Orthogonal Matching Pursuit Imported successfully
2023-01-03 21:46:58,256:INFO:Starting cross validation
2023-01-03 21:46:58,257:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:46:58,304:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 21:46:58,309:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 21:46:58,331:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 21:46:58,332:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 21:46:58,367:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 21:46:58,503:INFO:Calculating mean and std
2023-01-03 21:46:58,505:INFO:Creating metrics dataframe
2023-01-03 21:46:58,509:INFO:Uploading results into container
2023-01-03 21:46:58,509:INFO:Uploading model into container now
2023-01-03 21:46:58,510:INFO:_master_model_container: 7
2023-01-03 21:46:58,510:INFO:_display_container: 2
2023-01-03 21:46:58,510:INFO:OrthogonalMatchingPursuit()
2023-01-03 21:46:58,511:INFO:create_model() successfully completed......................................
2023-01-03 21:46:58,622:INFO:SubProcess create_model() end ==================================
2023-01-03 21:46:58,623:INFO:Creating metrics dataframe
2023-01-03 21:46:58,634:INFO:Initializing Bayesian Ridge
2023-01-03 21:46:58,634:INFO:Total runtime is 0.15578227440516157 minutes
2023-01-03 21:46:58,638:INFO:SubProcess create_model() called ==================================
2023-01-03 21:46:58,639:INFO:Initializing create_model()
2023-01-03 21:46:58,639:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CCA14C0580>, estimator=br, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CCA6F98FD0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:46:58,639:INFO:Checking exceptions
2023-01-03 21:46:58,639:INFO:Importing libraries
2023-01-03 21:46:58,639:INFO:Copying training dataset
2023-01-03 21:46:58,650:INFO:Defining folds
2023-01-03 21:46:58,650:INFO:Declaring metric variables
2023-01-03 21:46:58,654:INFO:Importing untrained model
2023-01-03 21:46:58,658:INFO:Bayesian Ridge Imported successfully
2023-01-03 21:46:58,667:INFO:Starting cross validation
2023-01-03 21:46:58,668:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:46:58,916:INFO:Calculating mean and std
2023-01-03 21:46:58,918:INFO:Creating metrics dataframe
2023-01-03 21:46:58,921:INFO:Uploading results into container
2023-01-03 21:46:58,921:INFO:Uploading model into container now
2023-01-03 21:46:58,922:INFO:_master_model_container: 8
2023-01-03 21:46:58,922:INFO:_display_container: 2
2023-01-03 21:46:58,922:INFO:BayesianRidge()
2023-01-03 21:46:58,922:INFO:create_model() successfully completed......................................
2023-01-03 21:46:59,035:INFO:SubProcess create_model() end ==================================
2023-01-03 21:46:59,035:INFO:Creating metrics dataframe
2023-01-03 21:46:59,047:INFO:Initializing Passive Aggressive Regressor
2023-01-03 21:46:59,048:INFO:Total runtime is 0.16268636385599775 minutes
2023-01-03 21:46:59,051:INFO:SubProcess create_model() called ==================================
2023-01-03 21:46:59,052:INFO:Initializing create_model()
2023-01-03 21:46:59,052:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CCA14C0580>, estimator=par, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CCA6F98FD0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:46:59,052:INFO:Checking exceptions
2023-01-03 21:46:59,052:INFO:Importing libraries
2023-01-03 21:46:59,052:INFO:Copying training dataset
2023-01-03 21:46:59,063:INFO:Defining folds
2023-01-03 21:46:59,063:INFO:Declaring metric variables
2023-01-03 21:46:59,067:INFO:Importing untrained model
2023-01-03 21:46:59,071:INFO:Passive Aggressive Regressor Imported successfully
2023-01-03 21:46:59,079:INFO:Starting cross validation
2023-01-03 21:46:59,080:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:46:59,328:INFO:Calculating mean and std
2023-01-03 21:46:59,331:INFO:Creating metrics dataframe
2023-01-03 21:46:59,334:INFO:Uploading results into container
2023-01-03 21:46:59,335:INFO:Uploading model into container now
2023-01-03 21:46:59,336:INFO:_master_model_container: 9
2023-01-03 21:46:59,336:INFO:_display_container: 2
2023-01-03 21:46:59,336:INFO:PassiveAggressiveRegressor(random_state=123)
2023-01-03 21:46:59,336:INFO:create_model() successfully completed......................................
2023-01-03 21:46:59,453:INFO:SubProcess create_model() end ==================================
2023-01-03 21:46:59,453:INFO:Creating metrics dataframe
2023-01-03 21:46:59,464:INFO:Initializing Huber Regressor
2023-01-03 21:46:59,464:INFO:Total runtime is 0.169623072942098 minutes
2023-01-03 21:46:59,467:INFO:SubProcess create_model() called ==================================
2023-01-03 21:46:59,468:INFO:Initializing create_model()
2023-01-03 21:46:59,468:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CCA14C0580>, estimator=huber, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CCA6F98FD0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:46:59,468:INFO:Checking exceptions
2023-01-03 21:46:59,468:INFO:Importing libraries
2023-01-03 21:46:59,468:INFO:Copying training dataset
2023-01-03 21:46:59,480:INFO:Defining folds
2023-01-03 21:46:59,481:INFO:Declaring metric variables
2023-01-03 21:46:59,486:INFO:Importing untrained model
2023-01-03 21:46:59,490:INFO:Huber Regressor Imported successfully
2023-01-03 21:46:59,499:INFO:Starting cross validation
2023-01-03 21:46:59,500:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:46:59,642:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-03 21:46:59,728:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-03 21:46:59,838:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-03 21:47:00,001:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-03 21:47:00,127:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-03 21:47:00,247:INFO:Calculating mean and std
2023-01-03 21:47:00,249:INFO:Creating metrics dataframe
2023-01-03 21:47:00,252:INFO:Uploading results into container
2023-01-03 21:47:00,252:INFO:Uploading model into container now
2023-01-03 21:47:00,253:INFO:_master_model_container: 10
2023-01-03 21:47:00,253:INFO:_display_container: 2
2023-01-03 21:47:00,254:INFO:HuberRegressor()
2023-01-03 21:47:00,254:INFO:create_model() successfully completed......................................
2023-01-03 21:47:00,376:INFO:SubProcess create_model() end ==================================
2023-01-03 21:47:00,376:INFO:Creating metrics dataframe
2023-01-03 21:47:00,388:INFO:Initializing K Neighbors Regressor
2023-01-03 21:47:00,389:INFO:Total runtime is 0.18504261573155723 minutes
2023-01-03 21:47:00,392:INFO:SubProcess create_model() called ==================================
2023-01-03 21:47:00,393:INFO:Initializing create_model()
2023-01-03 21:47:00,393:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CCA14C0580>, estimator=knn, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CCA6F98FD0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:47:00,393:INFO:Checking exceptions
2023-01-03 21:47:00,393:INFO:Importing libraries
2023-01-03 21:47:00,393:INFO:Copying training dataset
2023-01-03 21:47:00,403:INFO:Defining folds
2023-01-03 21:47:00,403:INFO:Declaring metric variables
2023-01-03 21:47:00,407:INFO:Importing untrained model
2023-01-03 21:47:00,411:INFO:K Neighbors Regressor Imported successfully
2023-01-03 21:47:00,418:INFO:Starting cross validation
2023-01-03 21:47:00,420:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:47:01,144:INFO:Calculating mean and std
2023-01-03 21:47:01,149:INFO:Creating metrics dataframe
2023-01-03 21:47:01,152:INFO:Uploading results into container
2023-01-03 21:47:01,153:INFO:Uploading model into container now
2023-01-03 21:47:01,154:INFO:_master_model_container: 11
2023-01-03 21:47:01,154:INFO:_display_container: 2
2023-01-03 21:47:01,154:INFO:KNeighborsRegressor(n_jobs=-1)
2023-01-03 21:47:01,154:INFO:create_model() successfully completed......................................
2023-01-03 21:47:01,264:INFO:SubProcess create_model() end ==================================
2023-01-03 21:47:01,264:INFO:Creating metrics dataframe
2023-01-03 21:47:01,276:INFO:Initializing Decision Tree Regressor
2023-01-03 21:47:01,276:INFO:Total runtime is 0.19982078075408938 minutes
2023-01-03 21:47:01,281:INFO:SubProcess create_model() called ==================================
2023-01-03 21:47:01,282:INFO:Initializing create_model()
2023-01-03 21:47:01,282:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CCA14C0580>, estimator=dt, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CCA6F98FD0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:47:01,282:INFO:Checking exceptions
2023-01-03 21:47:01,282:INFO:Importing libraries
2023-01-03 21:47:01,282:INFO:Copying training dataset
2023-01-03 21:47:01,293:INFO:Defining folds
2023-01-03 21:47:01,294:INFO:Declaring metric variables
2023-01-03 21:47:01,299:INFO:Importing untrained model
2023-01-03 21:47:01,303:INFO:Decision Tree Regressor Imported successfully
2023-01-03 21:47:01,310:INFO:Starting cross validation
2023-01-03 21:47:01,311:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:47:01,777:INFO:Calculating mean and std
2023-01-03 21:47:01,780:INFO:Creating metrics dataframe
2023-01-03 21:47:01,784:INFO:Uploading results into container
2023-01-03 21:47:01,785:INFO:Uploading model into container now
2023-01-03 21:47:01,785:INFO:_master_model_container: 12
2023-01-03 21:47:01,785:INFO:_display_container: 2
2023-01-03 21:47:01,785:INFO:DecisionTreeRegressor(random_state=123)
2023-01-03 21:47:01,785:INFO:create_model() successfully completed......................................
2023-01-03 21:47:01,974:INFO:SubProcess create_model() end ==================================
2023-01-03 21:47:01,974:INFO:Creating metrics dataframe
2023-01-03 21:47:02,022:INFO:Initializing Random Forest Regressor
2023-01-03 21:47:02,022:INFO:Total runtime is 0.21225360234578453 minutes
2023-01-03 21:47:02,026:INFO:SubProcess create_model() called ==================================
2023-01-03 21:47:02,027:INFO:Initializing create_model()
2023-01-03 21:47:02,027:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CCA14C0580>, estimator=rf, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CCA6F98FD0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:47:02,027:INFO:Checking exceptions
2023-01-03 21:47:02,027:INFO:Importing libraries
2023-01-03 21:47:02,027:INFO:Copying training dataset
2023-01-03 21:47:02,043:INFO:Defining folds
2023-01-03 21:47:02,043:INFO:Declaring metric variables
2023-01-03 21:47:02,049:INFO:Importing untrained model
2023-01-03 21:47:02,082:INFO:Random Forest Regressor Imported successfully
2023-01-03 21:47:02,096:INFO:Starting cross validation
2023-01-03 21:47:02,098:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:47:14,029:INFO:Calculating mean and std
2023-01-03 21:47:14,031:INFO:Creating metrics dataframe
2023-01-03 21:47:14,034:INFO:Uploading results into container
2023-01-03 21:47:14,035:INFO:Uploading model into container now
2023-01-03 21:47:14,036:INFO:_master_model_container: 13
2023-01-03 21:47:14,036:INFO:_display_container: 2
2023-01-03 21:47:14,036:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-01-03 21:47:14,036:INFO:create_model() successfully completed......................................
2023-01-03 21:47:14,157:INFO:SubProcess create_model() end ==================================
2023-01-03 21:47:14,157:INFO:Creating metrics dataframe
2023-01-03 21:47:14,170:INFO:Initializing Extra Trees Regressor
2023-01-03 21:47:14,170:INFO:Total runtime is 0.4147202769915263 minutes
2023-01-03 21:47:14,174:INFO:SubProcess create_model() called ==================================
2023-01-03 21:47:14,175:INFO:Initializing create_model()
2023-01-03 21:47:14,175:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CCA14C0580>, estimator=et, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CCA6F98FD0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:47:14,175:INFO:Checking exceptions
2023-01-03 21:47:14,175:INFO:Importing libraries
2023-01-03 21:47:14,175:INFO:Copying training dataset
2023-01-03 21:47:14,185:INFO:Defining folds
2023-01-03 21:47:14,186:INFO:Declaring metric variables
2023-01-03 21:47:14,190:INFO:Importing untrained model
2023-01-03 21:47:14,195:INFO:Extra Trees Regressor Imported successfully
2023-01-03 21:47:14,204:INFO:Starting cross validation
2023-01-03 21:47:14,205:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:47:19,182:INFO:Calculating mean and std
2023-01-03 21:47:19,184:INFO:Creating metrics dataframe
2023-01-03 21:47:19,187:INFO:Uploading results into container
2023-01-03 21:47:19,188:INFO:Uploading model into container now
2023-01-03 21:47:19,188:INFO:_master_model_container: 14
2023-01-03 21:47:19,188:INFO:_display_container: 2
2023-01-03 21:47:19,189:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-01-03 21:47:19,189:INFO:create_model() successfully completed......................................
2023-01-03 21:47:19,294:INFO:SubProcess create_model() end ==================================
2023-01-03 21:47:19,294:INFO:Creating metrics dataframe
2023-01-03 21:47:19,307:INFO:Initializing AdaBoost Regressor
2023-01-03 21:47:19,307:INFO:Total runtime is 0.5003372669219971 minutes
2023-01-03 21:47:19,310:INFO:SubProcess create_model() called ==================================
2023-01-03 21:47:19,311:INFO:Initializing create_model()
2023-01-03 21:47:19,311:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CCA14C0580>, estimator=ada, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CCA6F98FD0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:47:19,311:INFO:Checking exceptions
2023-01-03 21:47:19,311:INFO:Importing libraries
2023-01-03 21:47:19,311:INFO:Copying training dataset
2023-01-03 21:47:19,321:INFO:Defining folds
2023-01-03 21:47:19,321:INFO:Declaring metric variables
2023-01-03 21:47:19,326:INFO:Importing untrained model
2023-01-03 21:47:19,330:INFO:AdaBoost Regressor Imported successfully
2023-01-03 21:47:19,338:INFO:Starting cross validation
2023-01-03 21:47:19,339:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:47:21,885:INFO:Calculating mean and std
2023-01-03 21:47:21,887:INFO:Creating metrics dataframe
2023-01-03 21:47:21,892:INFO:Uploading results into container
2023-01-03 21:47:21,892:INFO:Uploading model into container now
2023-01-03 21:47:21,892:INFO:_master_model_container: 15
2023-01-03 21:47:21,892:INFO:_display_container: 2
2023-01-03 21:47:21,893:INFO:AdaBoostRegressor(random_state=123)
2023-01-03 21:47:21,893:INFO:create_model() successfully completed......................................
2023-01-03 21:47:22,001:INFO:SubProcess create_model() end ==================================
2023-01-03 21:47:22,001:INFO:Creating metrics dataframe
2023-01-03 21:47:22,014:INFO:Initializing Gradient Boosting Regressor
2023-01-03 21:47:22,014:INFO:Total runtime is 0.5454461057980855 minutes
2023-01-03 21:47:22,018:INFO:SubProcess create_model() called ==================================
2023-01-03 21:47:22,018:INFO:Initializing create_model()
2023-01-03 21:47:22,018:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CCA14C0580>, estimator=gbr, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CCA6F98FD0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:47:22,018:INFO:Checking exceptions
2023-01-03 21:47:22,018:INFO:Importing libraries
2023-01-03 21:47:22,018:INFO:Copying training dataset
2023-01-03 21:47:22,028:INFO:Defining folds
2023-01-03 21:47:22,028:INFO:Declaring metric variables
2023-01-03 21:47:22,033:INFO:Importing untrained model
2023-01-03 21:47:22,037:INFO:Gradient Boosting Regressor Imported successfully
2023-01-03 21:47:22,044:INFO:Starting cross validation
2023-01-03 21:47:22,045:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:47:27,935:INFO:Calculating mean and std
2023-01-03 21:47:27,937:INFO:Creating metrics dataframe
2023-01-03 21:47:27,940:INFO:Uploading results into container
2023-01-03 21:47:27,940:INFO:Uploading model into container now
2023-01-03 21:47:27,940:INFO:_master_model_container: 16
2023-01-03 21:47:27,940:INFO:_display_container: 2
2023-01-03 21:47:27,941:INFO:GradientBoostingRegressor(random_state=123)
2023-01-03 21:47:27,941:INFO:create_model() successfully completed......................................
2023-01-03 21:47:28,052:INFO:SubProcess create_model() end ==================================
2023-01-03 21:47:28,053:INFO:Creating metrics dataframe
2023-01-03 21:47:28,066:INFO:Initializing Light Gradient Boosting Machine
2023-01-03 21:47:28,066:INFO:Total runtime is 0.6463207324345907 minutes
2023-01-03 21:47:28,070:INFO:SubProcess create_model() called ==================================
2023-01-03 21:47:28,071:INFO:Initializing create_model()
2023-01-03 21:47:28,071:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CCA14C0580>, estimator=lightgbm, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CCA6F98FD0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:47:28,071:INFO:Checking exceptions
2023-01-03 21:47:28,071:INFO:Importing libraries
2023-01-03 21:47:28,071:INFO:Copying training dataset
2023-01-03 21:47:28,081:INFO:Defining folds
2023-01-03 21:47:28,081:INFO:Declaring metric variables
2023-01-03 21:47:28,085:INFO:Importing untrained model
2023-01-03 21:47:28,090:INFO:Light Gradient Boosting Machine Imported successfully
2023-01-03 21:47:28,097:INFO:Starting cross validation
2023-01-03 21:47:28,099:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:47:30,409:INFO:Calculating mean and std
2023-01-03 21:47:30,412:INFO:Creating metrics dataframe
2023-01-03 21:47:30,418:INFO:Uploading results into container
2023-01-03 21:47:30,419:INFO:Uploading model into container now
2023-01-03 21:47:30,419:INFO:_master_model_container: 17
2023-01-03 21:47:30,419:INFO:_display_container: 2
2023-01-03 21:47:30,420:INFO:LGBMRegressor(random_state=123)
2023-01-03 21:47:30,420:INFO:create_model() successfully completed......................................
2023-01-03 21:47:30,529:INFO:SubProcess create_model() end ==================================
2023-01-03 21:47:30,529:INFO:Creating metrics dataframe
2023-01-03 21:47:30,544:INFO:Initializing Dummy Regressor
2023-01-03 21:47:30,544:INFO:Total runtime is 0.6876277764638264 minutes
2023-01-03 21:47:30,549:INFO:SubProcess create_model() called ==================================
2023-01-03 21:47:30,549:INFO:Initializing create_model()
2023-01-03 21:47:30,549:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CCA14C0580>, estimator=dummy, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CCA6F98FD0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:47:30,550:INFO:Checking exceptions
2023-01-03 21:47:30,550:INFO:Importing libraries
2023-01-03 21:47:30,550:INFO:Copying training dataset
2023-01-03 21:47:30,560:INFO:Defining folds
2023-01-03 21:47:30,560:INFO:Declaring metric variables
2023-01-03 21:47:30,564:INFO:Importing untrained model
2023-01-03 21:47:30,569:INFO:Dummy Regressor Imported successfully
2023-01-03 21:47:30,575:INFO:Starting cross validation
2023-01-03 21:47:30,577:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:47:30,805:INFO:Calculating mean and std
2023-01-03 21:47:30,807:INFO:Creating metrics dataframe
2023-01-03 21:47:30,810:INFO:Uploading results into container
2023-01-03 21:47:30,811:INFO:Uploading model into container now
2023-01-03 21:47:30,811:INFO:_master_model_container: 18
2023-01-03 21:47:30,811:INFO:_display_container: 2
2023-01-03 21:47:30,811:INFO:DummyRegressor()
2023-01-03 21:47:30,811:INFO:create_model() successfully completed......................................
2023-01-03 21:47:30,916:INFO:SubProcess create_model() end ==================================
2023-01-03 21:47:30,916:INFO:Creating metrics dataframe
2023-01-03 21:47:30,939:INFO:Initializing create_model()
2023-01-03 21:47:30,940:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CCA14C0580>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:47:30,940:INFO:Checking exceptions
2023-01-03 21:47:30,942:INFO:Importing libraries
2023-01-03 21:47:30,942:INFO:Copying training dataset
2023-01-03 21:47:30,951:INFO:Defining folds
2023-01-03 21:47:30,951:INFO:Declaring metric variables
2023-01-03 21:47:30,952:INFO:Importing untrained model
2023-01-03 21:47:30,952:INFO:Declaring custom model
2023-01-03 21:47:30,952:INFO:Extra Trees Regressor Imported successfully
2023-01-03 21:47:30,953:INFO:Cross validation set to False
2023-01-03 21:47:30,953:INFO:Fitting Model
2023-01-03 21:47:33,195:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-01-03 21:47:33,195:INFO:create_model() successfully completed......................................
2023-01-03 21:47:33,343:INFO:_master_model_container: 18
2023-01-03 21:47:33,343:INFO:_display_container: 2
2023-01-03 21:47:33,344:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-01-03 21:47:33,344:INFO:compare_models() successfully completed......................................
2023-01-03 21:47:33,345:INFO:Initializing tune_model()
2023-01-03 21:47:33,345:INFO:tune_model(estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=3, custom_grid=None, optimize=MAE, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CCA14C0580>)
2023-01-03 21:47:33,345:INFO:Checking exceptions
2023-01-03 21:47:33,377:INFO:Copying training dataset
2023-01-03 21:47:33,387:INFO:Checking base model
2023-01-03 21:47:33,387:INFO:Base model : Extra Trees Regressor
2023-01-03 21:47:33,391:INFO:Declaring metric variables
2023-01-03 21:47:33,395:INFO:Defining Hyperparameters
2023-01-03 21:47:33,507:INFO:Tuning with n_jobs=-1
2023-01-03 21:47:33,507:INFO:Initializing RandomizedSearchCV
2023-01-03 21:47:33,559:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:47:33,563:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:47:33,571:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:47:33,589:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:47:33,794:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:47:33,802:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:47:33,810:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:47:34,014:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:47:34,095:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:47:34,137:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:47:34,140:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:47:34,506:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:47:34,745:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:47:34,788:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:47:34,867:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:47:35,365:INFO:best_params: {'actual_estimator__n_estimators': 100, 'actual_estimator__min_samples_split': 7, 'actual_estimator__min_samples_leaf': 4, 'actual_estimator__min_impurity_decrease': 0.1, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 9, 'actual_estimator__criterion': 'mse', 'actual_estimator__bootstrap': True}
2023-01-03 21:47:35,368:INFO:Hyperparameter search completed
2023-01-03 21:47:35,368:INFO:SubProcess create_model() called ==================================
2023-01-03 21:47:35,369:INFO:Initializing create_model()
2023-01-03 21:47:35,369:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CCA14C0580>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CCA74DACA0>, model_only=True, return_train_score=False, kwargs={'n_estimators': 100, 'min_samples_split': 7, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.1, 'max_features': 1.0, 'max_depth': 9, 'criterion': 'mse', 'bootstrap': True})
2023-01-03 21:47:35,369:INFO:Checking exceptions
2023-01-03 21:47:35,369:INFO:Importing libraries
2023-01-03 21:47:35,369:INFO:Copying training dataset
2023-01-03 21:47:35,379:INFO:Defining folds
2023-01-03 21:47:35,379:INFO:Declaring metric variables
2023-01-03 21:47:35,384:INFO:Importing untrained model
2023-01-03 21:47:35,384:INFO:Declaring custom model
2023-01-03 21:47:35,388:INFO:Extra Trees Regressor Imported successfully
2023-01-03 21:47:35,396:INFO:Starting cross validation
2023-01-03 21:47:35,398:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:47:35,448:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:47:35,452:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:47:35,482:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:47:35,496:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:47:36,036:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:47:36,410:INFO:Calculating mean and std
2023-01-03 21:47:36,416:INFO:Creating metrics dataframe
2023-01-03 21:47:36,423:INFO:Finalizing model
2023-01-03 21:47:36,740:INFO:Uploading results into container
2023-01-03 21:47:36,741:INFO:Uploading model into container now
2023-01-03 21:47:36,742:INFO:_master_model_container: 19
2023-01-03 21:47:36,742:INFO:_display_container: 3
2023-01-03 21:47:36,743:INFO:ExtraTreesRegressor(bootstrap=True, criterion='mse', max_depth=9,
                    max_features=1.0, min_impurity_decrease=0.1,
                    min_samples_leaf=4, min_samples_split=7, n_jobs=-1,
                    random_state=123)
2023-01-03 21:47:36,743:INFO:create_model() successfully completed......................................
2023-01-03 21:47:36,850:INFO:SubProcess create_model() end ==================================
2023-01-03 21:47:36,850:INFO:choose_better activated
2023-01-03 21:47:36,854:INFO:SubProcess create_model() called ==================================
2023-01-03 21:47:36,854:INFO:Initializing create_model()
2023-01-03 21:47:36,854:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CCA14C0580>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:47:36,855:INFO:Checking exceptions
2023-01-03 21:47:36,857:INFO:Importing libraries
2023-01-03 21:47:36,857:INFO:Copying training dataset
2023-01-03 21:47:36,867:INFO:Defining folds
2023-01-03 21:47:36,867:INFO:Declaring metric variables
2023-01-03 21:47:36,868:INFO:Importing untrained model
2023-01-03 21:47:36,868:INFO:Declaring custom model
2023-01-03 21:47:36,868:INFO:Extra Trees Regressor Imported successfully
2023-01-03 21:47:36,869:INFO:Starting cross validation
2023-01-03 21:47:36,870:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:47:41,762:INFO:Calculating mean and std
2023-01-03 21:47:41,763:INFO:Creating metrics dataframe
2023-01-03 21:47:41,765:INFO:Finalizing model
2023-01-03 21:47:43,712:INFO:Uploading results into container
2023-01-03 21:47:43,713:INFO:Uploading model into container now
2023-01-03 21:47:43,714:INFO:_master_model_container: 20
2023-01-03 21:47:43,714:INFO:_display_container: 4
2023-01-03 21:47:43,714:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-01-03 21:47:43,714:INFO:create_model() successfully completed......................................
2023-01-03 21:47:43,812:INFO:SubProcess create_model() end ==================================
2023-01-03 21:47:43,813:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123) result for MAE is 0.1313
2023-01-03 21:47:43,814:INFO:ExtraTreesRegressor(bootstrap=True, criterion='mse', max_depth=9,
                    max_features=1.0, min_impurity_decrease=0.1,
                    min_samples_leaf=4, min_samples_split=7, n_jobs=-1,
                    random_state=123) result for MAE is 0.4948
2023-01-03 21:47:43,814:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123) is best model
2023-01-03 21:47:43,814:INFO:choose_better completed
2023-01-03 21:47:43,814:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-01-03 21:47:43,823:INFO:_master_model_container: 20
2023-01-03 21:47:43,824:INFO:_display_container: 3
2023-01-03 21:47:43,824:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-01-03 21:47:43,824:INFO:tune_model() successfully completed......................................
2023-01-03 21:47:43,939:INFO:Initializing plot_model()
2023-01-03 21:47:43,939:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CCA14C0580>, system=True)
2023-01-03 21:47:43,939:INFO:Checking exceptions
2023-01-03 21:47:43,968:INFO:Preloading libraries
2023-01-03 21:47:44,109:INFO:Copying training dataset
2023-01-03 21:47:44,109:INFO:Plot type: error
2023-01-03 21:47:44,280:INFO:Fitting Model
2023-01-03 21:47:44,280:INFO:Scoring test/hold-out set
2023-01-03 21:47:44,732:INFO:Visual Rendered Successfully
2023-01-03 21:47:44,848:INFO:plot_model() successfully completed......................................
2023-01-03 21:47:44,860:INFO:Initializing predict_model()
2023-01-03 21:47:44,860:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CCA14C0580>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001CCAAE68550>)
2023-01-03 21:47:44,860:INFO:Checking exceptions
2023-01-03 21:47:44,860:INFO:Preloading libraries
2023-01-03 21:47:45,059:INFO:Initializing finalize_model()
2023-01-03 21:47:45,060:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CCA14C0580>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-01-03 21:47:45,060:INFO:Finalizing ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-01-03 21:47:45,069:INFO:Initializing create_model()
2023-01-03 21:47:45,069:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CCA14C0580>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-01-03 21:47:45,069:INFO:Checking exceptions
2023-01-03 21:47:45,070:INFO:Importing libraries
2023-01-03 21:47:45,071:INFO:Copying training dataset
2023-01-03 21:47:45,071:INFO:Defining folds
2023-01-03 21:47:45,071:INFO:Declaring metric variables
2023-01-03 21:47:45,072:INFO:Importing untrained model
2023-01-03 21:47:45,072:INFO:Declaring custom model
2023-01-03 21:47:45,073:INFO:Extra Trees Regressor Imported successfully
2023-01-03 21:47:45,074:INFO:Cross validation set to False
2023-01-03 21:47:45,074:INFO:Fitting Model
2023-01-03 21:47:48,992:INFO:Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))])
2023-01-03 21:47:48,993:INFO:create_model() successfully completed......................................
2023-01-03 21:47:49,096:INFO:_master_model_container: 20
2023-01-03 21:47:49,096:INFO:_display_container: 4
2023-01-03 21:47:49,103:INFO:Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))])
2023-01-03 21:47:49,103:INFO:finalize_model() successfully completed......................................
2023-01-03 21:47:49,210:INFO:Initializing predict_model()
2023-01-03 21:47:49,211:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CCA14C0580>, estimator=Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001CCA74B0DC0>)
2023-01-03 21:47:49,211:INFO:Checking exceptions
2023-01-03 21:47:49,211:INFO:Preloading libraries
2023-01-03 21:47:49,213:INFO:Set up data.
2023-01-03 21:47:49,233:INFO:Set up index.
2023-01-03 21:47:49,702:INFO:Initializing save_model()
2023-01-03 21:47:49,702:INFO:save_model(model=Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))]), model_name=c:\Users\Kodotautas\Desktop\Data_science\7_TIME_SERIES_FORECAST_PYCARET/models/final_model.pkl, prep_pipe_=Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-01-03 21:47:49,702:INFO:Adding model into prep_pipe
2023-01-03 21:47:49,885:WARNING:Only Model saved as it was a pipeline.
2023-01-03 21:47:50,025:INFO:c:\Users\Kodotautas\Desktop\Data_science\7_TIME_SERIES_FORECAST_PYCARET/models/final_model.pkl.pkl saved in current working directory
2023-01-03 21:47:50,032:INFO:Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))])
2023-01-03 21:47:50,032:INFO:save_model() successfully completed......................................
2023-01-03 21:51:57,352:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-01-03 21:51:57,353:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-01-03 21:51:57,353:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-01-03 21:51:57,353:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-01-03 21:51:58,071:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-01-03 21:51:58,476:INFO:PyCaret RegressionExperiment
2023-01-03 21:51:58,477:INFO:Logging name: reg-default-name
2023-01-03 21:51:58,477:INFO:ML Usecase: MLUsecase.REGRESSION
2023-01-03 21:51:58,477:INFO:version 3.0.0.rc6
2023-01-03 21:51:58,477:INFO:Initializing setup()
2023-01-03 21:51:58,477:INFO:self.USI: 97a0
2023-01-03 21:51:58,477:INFO:self._variable_keys: {'data', 'fold_groups_param', 'n_jobs_param', 'target_param', 'exp_id', 'y_test', 'X', 'X_test', 'log_plots_param', 'y', 'gpu_n_jobs_param', 'pipeline', 'logging_param', 'USI', 'X_train', 'memory', 'html_param', 'y_train', '_available_plots', 'seed', 'exp_name_log', 'transform_target_param', 'fold_generator', 'idx', 'gpu_param', 'fold_shuffle_param', '_ml_usecase'}
2023-01-03 21:51:58,477:INFO:Checking environment
2023-01-03 21:51:58,477:INFO:python_version: 3.9.13
2023-01-03 21:51:58,477:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-01-03 21:51:58,477:INFO:machine: AMD64
2023-01-03 21:51:58,477:INFO:platform: Windows-10-10.0.19044-SP0
2023-01-03 21:51:58,477:INFO:Memory: svmem(total=17114804224, available=9797791744, percent=42.8, used=7317012480, free=9797791744)
2023-01-03 21:51:58,477:INFO:Physical Core: 4
2023-01-03 21:51:58,477:INFO:Logical Core: 4
2023-01-03 21:51:58,477:INFO:Checking libraries
2023-01-03 21:51:58,477:INFO:System:
2023-01-03 21:51:58,477:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-01-03 21:51:58,477:INFO:executable: c:\Users\Kodotautas\anaconda3\python.exe
2023-01-03 21:51:58,478:INFO:   machine: Windows-10-10.0.19044-SP0
2023-01-03 21:51:58,478:INFO:PyCaret required dependencies:
2023-01-03 21:51:58,478:INFO:                 pip: 22.2.2
2023-01-03 21:51:58,478:INFO:          setuptools: 63.4.1
2023-01-03 21:51:58,478:INFO:             pycaret: 3.0.0rc6
2023-01-03 21:51:58,478:INFO:             IPython: 7.31.1
2023-01-03 21:51:58,478:INFO:          ipywidgets: 7.6.5
2023-01-03 21:51:58,478:INFO:                tqdm: 4.64.1
2023-01-03 21:51:58,478:INFO:               numpy: 1.21.5
2023-01-03 21:51:58,478:INFO:              pandas: 1.4.4
2023-01-03 21:51:58,478:INFO:              jinja2: 2.11.3
2023-01-03 21:51:58,478:INFO:               scipy: 1.9.1
2023-01-03 21:51:58,478:INFO:              joblib: 1.2.0
2023-01-03 21:51:58,478:INFO:             sklearn: 1.0.2
2023-01-03 21:51:58,478:INFO:                pyod: 1.0.7
2023-01-03 21:51:58,478:INFO:            imblearn: 0.10.1
2023-01-03 21:51:58,478:INFO:   category_encoders: 2.5.1.post0
2023-01-03 21:51:58,478:INFO:            lightgbm: 3.3.3
2023-01-03 21:51:58,479:INFO:               numba: 0.55.1
2023-01-03 21:51:58,479:INFO:            requests: 2.28.1
2023-01-03 21:51:58,479:INFO:          matplotlib: 3.5.2
2023-01-03 21:51:58,479:INFO:          scikitplot: 0.3.7
2023-01-03 21:51:58,479:INFO:         yellowbrick: 1.5
2023-01-03 21:51:58,479:INFO:              plotly: 5.9.0
2023-01-03 21:51:58,479:INFO:             kaleido: 0.2.1
2023-01-03 21:51:58,479:INFO:         statsmodels: 0.13.2
2023-01-03 21:51:58,479:INFO:              sktime: 0.14.1
2023-01-03 21:51:58,479:INFO:               tbats: 1.1.2
2023-01-03 21:51:58,479:INFO:            pmdarima: 2.0.2
2023-01-03 21:51:58,479:INFO:              psutil: 5.9.0
2023-01-03 21:51:58,479:INFO:PyCaret optional dependencies:
2023-01-03 21:51:58,765:INFO:                shap: 0.41.0
2023-01-03 21:51:58,765:INFO:           interpret: Not installed
2023-01-03 21:51:58,765:INFO:                umap: Not installed
2023-01-03 21:51:58,765:INFO:    pandas_profiling: Not installed
2023-01-03 21:51:58,765:INFO:  explainerdashboard: Not installed
2023-01-03 21:51:58,765:INFO:             autoviz: Not installed
2023-01-03 21:51:58,765:INFO:           fairlearn: Not installed
2023-01-03 21:51:58,766:INFO:             xgboost: Not installed
2023-01-03 21:51:58,766:INFO:            catboost: Not installed
2023-01-03 21:51:58,766:INFO:              kmodes: Not installed
2023-01-03 21:51:58,766:INFO:             mlxtend: Not installed
2023-01-03 21:51:58,766:INFO:       statsforecast: Not installed
2023-01-03 21:51:58,766:INFO:        tune_sklearn: 0.4.3
2023-01-03 21:51:58,766:INFO:                 ray: 2.0.0
2023-01-03 21:51:58,766:INFO:            hyperopt: 0.2.7
2023-01-03 21:51:58,766:INFO:              optuna: 3.0.1
2023-01-03 21:51:58,766:INFO:               skopt: 0.9.0
2023-01-03 21:51:58,766:INFO:              mlflow: Not installed
2023-01-03 21:51:58,766:INFO:              gradio: Not installed
2023-01-03 21:51:58,766:INFO:             fastapi: 0.88.0
2023-01-03 21:51:58,766:INFO:             uvicorn: 0.20.0
2023-01-03 21:51:58,766:INFO:              m2cgen: Not installed
2023-01-03 21:51:58,766:INFO:           evidently: Not installed
2023-01-03 21:51:58,766:INFO:                nltk: 3.7
2023-01-03 21:51:58,766:INFO:            pyLDAvis: Not installed
2023-01-03 21:51:58,766:INFO:              gensim: 4.1.2
2023-01-03 21:51:58,766:INFO:               spacy: 3.4.2
2023-01-03 21:51:58,767:INFO:           wordcloud: Not installed
2023-01-03 21:51:58,767:INFO:            textblob: Not installed
2023-01-03 21:51:58,767:INFO:               fugue: Not installed
2023-01-03 21:51:58,767:INFO:           streamlit: Not installed
2023-01-03 21:51:58,767:INFO:             prophet: Not installed
2023-01-03 21:51:58,767:INFO:None
2023-01-03 21:51:58,767:INFO:Set up data.
2023-01-03 21:51:58,796:INFO:Set up train/test split.
2023-01-03 21:51:58,814:INFO:Set up index.
2023-01-03 21:51:58,817:INFO:Set up folding strategy.
2023-01-03 21:51:58,817:INFO:Assigning column types.
2023-01-03 21:51:58,828:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-01-03 21:51:58,828:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-01-03 21:51:58,834:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-03 21:51:58,838:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 21:51:58,911:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 21:51:58,963:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 21:51:58,964:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:51:59,099:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:51:59,099:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-01-03 21:51:59,104:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-03 21:51:59,109:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 21:51:59,183:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 21:51:59,234:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 21:51:59,235:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:51:59,235:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:51:59,235:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-01-03 21:51:59,240:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-03 21:51:59,246:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 21:51:59,321:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 21:51:59,390:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 21:51:59,391:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:51:59,392:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:51:59,398:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-03 21:51:59,403:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 21:51:59,477:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 21:51:59,524:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 21:51:59,526:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:51:59,526:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:51:59,527:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-01-03 21:51:59,536:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 21:51:59,612:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 21:51:59,662:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 21:51:59,663:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:51:59,663:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:51:59,676:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 21:51:59,746:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 21:51:59,796:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 21:51:59,797:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:51:59,797:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:51:59,797:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-01-03 21:51:59,881:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 21:51:59,932:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 21:51:59,932:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:51:59,932:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:52:00,013:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 21:52:00,063:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 21:52:00,063:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:52:00,063:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:52:00,064:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-01-03 21:52:00,143:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 21:52:00,194:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:52:00,195:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:52:00,275:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 21:52:00,325:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:52:00,326:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:52:00,326:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-01-03 21:52:00,463:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:52:00,463:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:52:00,593:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:52:00,594:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:52:00,595:INFO:Preparing preprocessing pipeline...
2023-01-03 21:52:00,597:INFO:Set up simple imputation.
2023-01-03 21:52:00,597:INFO:Set up column transformation.
2023-01-03 21:52:00,597:INFO:Set up feature normalization.
2023-01-03 21:52:01,217:INFO:Finished creating preprocessing pipeline.
2023-01-03 21:52:01,223:INFO:Pipeline: Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2023-01-03 21:52:01,223:INFO:Creating final display dataframe.
2023-01-03 21:52:01,820:INFO:Setup _display_container:                Description             Value
0               Session id               123
1                   Target        b2b+b2c+vt
2              Target type        Regression
3               Data shape       (10505, 44)
4         Train data shape        (7353, 44)
5          Test data shape        (3152, 44)
6         Numeric features                 8
7               Preprocess              True
8          Imputation type            simple
9       Numeric imputation              mean
10  Categorical imputation              mode
11          Transformation              True
12   Transformation method       yeo-johnson
13               Normalize              True
14        Normalize method            zscore
15          Fold Generator   TimeSeriesSplit
16             Fold Number                 5
17                CPU Jobs                -1
18                 Use GPU             False
19          Log Experiment             False
20         Experiment Name  reg-default-name
21                     USI              97a0
2023-01-03 21:52:02,083:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:52:02,084:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:52:02,219:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:52:02,219:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 21:52:02,220:INFO:setup() successfully completed in 3.75s...............
2023-01-03 21:52:02,221:INFO:Initializing compare_models()
2023-01-03 21:52:02,221:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000267F94E37C0>, include=None, fold=None, round=4, cross_validation=True, sort=MAE, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000267F94E37C0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'MAE', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-01-03 21:52:02,221:INFO:Checking exceptions
2023-01-03 21:52:02,226:INFO:Preparing display monitor
2023-01-03 21:52:02,272:INFO:Initializing Linear Regression
2023-01-03 21:52:02,272:INFO:Total runtime is 0.0 minutes
2023-01-03 21:52:02,295:INFO:SubProcess create_model() called ==================================
2023-01-03 21:52:02,295:INFO:Initializing create_model()
2023-01-03 21:52:02,295:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000267F94E37C0>, estimator=lr, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026786E3E190>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:52:02,295:INFO:Checking exceptions
2023-01-03 21:52:02,296:INFO:Importing libraries
2023-01-03 21:52:02,296:INFO:Copying training dataset
2023-01-03 21:52:02,305:INFO:Defining folds
2023-01-03 21:52:02,306:INFO:Declaring metric variables
2023-01-03 21:52:02,310:INFO:Importing untrained model
2023-01-03 21:52:02,314:INFO:Linear Regression Imported successfully
2023-01-03 21:52:02,323:INFO:Starting cross validation
2023-01-03 21:52:02,332:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:52:12,160:INFO:Calculating mean and std
2023-01-03 21:52:12,162:INFO:Creating metrics dataframe
2023-01-03 21:52:12,165:INFO:Uploading results into container
2023-01-03 21:52:12,166:INFO:Uploading model into container now
2023-01-03 21:52:12,167:INFO:_master_model_container: 1
2023-01-03 21:52:12,167:INFO:_display_container: 2
2023-01-03 21:52:12,168:INFO:LinearRegression(n_jobs=-1)
2023-01-03 21:52:12,168:INFO:create_model() successfully completed......................................
2023-01-03 21:52:12,297:INFO:SubProcess create_model() end ==================================
2023-01-03 21:52:12,297:INFO:Creating metrics dataframe
2023-01-03 21:52:12,307:INFO:Initializing Lasso Regression
2023-01-03 21:52:12,307:INFO:Total runtime is 0.1672499934832255 minutes
2023-01-03 21:52:12,312:INFO:SubProcess create_model() called ==================================
2023-01-03 21:52:12,312:INFO:Initializing create_model()
2023-01-03 21:52:12,313:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000267F94E37C0>, estimator=lasso, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026786E3E190>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:52:12,313:INFO:Checking exceptions
2023-01-03 21:52:12,313:INFO:Importing libraries
2023-01-03 21:52:12,313:INFO:Copying training dataset
2023-01-03 21:52:12,323:INFO:Defining folds
2023-01-03 21:52:12,323:INFO:Declaring metric variables
2023-01-03 21:52:12,328:INFO:Importing untrained model
2023-01-03 21:52:12,333:INFO:Lasso Regression Imported successfully
2023-01-03 21:52:12,344:INFO:Starting cross validation
2023-01-03 21:52:12,348:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:52:12,746:INFO:Calculating mean and std
2023-01-03 21:52:12,748:INFO:Creating metrics dataframe
2023-01-03 21:52:12,752:INFO:Uploading results into container
2023-01-03 21:52:12,752:INFO:Uploading model into container now
2023-01-03 21:52:12,752:INFO:_master_model_container: 2
2023-01-03 21:52:12,753:INFO:_display_container: 2
2023-01-03 21:52:12,753:INFO:Lasso(random_state=123)
2023-01-03 21:52:12,753:INFO:create_model() successfully completed......................................
2023-01-03 21:52:12,884:INFO:SubProcess create_model() end ==================================
2023-01-03 21:52:12,884:INFO:Creating metrics dataframe
2023-01-03 21:52:12,895:INFO:Initializing Ridge Regression
2023-01-03 21:52:12,896:INFO:Total runtime is 0.1770499626795451 minutes
2023-01-03 21:52:12,899:INFO:SubProcess create_model() called ==================================
2023-01-03 21:52:12,899:INFO:Initializing create_model()
2023-01-03 21:52:12,899:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000267F94E37C0>, estimator=ridge, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026786E3E190>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:52:12,900:INFO:Checking exceptions
2023-01-03 21:52:12,900:INFO:Importing libraries
2023-01-03 21:52:12,900:INFO:Copying training dataset
2023-01-03 21:52:12,910:INFO:Defining folds
2023-01-03 21:52:12,910:INFO:Declaring metric variables
2023-01-03 21:52:12,914:INFO:Importing untrained model
2023-01-03 21:52:12,918:INFO:Ridge Regression Imported successfully
2023-01-03 21:52:12,927:INFO:Starting cross validation
2023-01-03 21:52:12,929:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:52:13,169:INFO:Calculating mean and std
2023-01-03 21:52:13,171:INFO:Creating metrics dataframe
2023-01-03 21:52:13,176:INFO:Uploading results into container
2023-01-03 21:52:13,177:INFO:Uploading model into container now
2023-01-03 21:52:13,178:INFO:_master_model_container: 3
2023-01-03 21:52:13,178:INFO:_display_container: 2
2023-01-03 21:52:13,178:INFO:Ridge(random_state=123)
2023-01-03 21:52:13,178:INFO:create_model() successfully completed......................................
2023-01-03 21:52:13,289:INFO:SubProcess create_model() end ==================================
2023-01-03 21:52:13,289:INFO:Creating metrics dataframe
2023-01-03 21:52:13,299:INFO:Initializing Elastic Net
2023-01-03 21:52:13,299:INFO:Total runtime is 0.18378330866495768 minutes
2023-01-03 21:52:13,303:INFO:SubProcess create_model() called ==================================
2023-01-03 21:52:13,304:INFO:Initializing create_model()
2023-01-03 21:52:13,304:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000267F94E37C0>, estimator=en, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026786E3E190>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:52:13,304:INFO:Checking exceptions
2023-01-03 21:52:13,304:INFO:Importing libraries
2023-01-03 21:52:13,304:INFO:Copying training dataset
2023-01-03 21:52:13,314:INFO:Defining folds
2023-01-03 21:52:13,315:INFO:Declaring metric variables
2023-01-03 21:52:13,318:INFO:Importing untrained model
2023-01-03 21:52:13,323:INFO:Elastic Net Imported successfully
2023-01-03 21:52:13,332:INFO:Starting cross validation
2023-01-03 21:52:13,333:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:52:13,622:INFO:Calculating mean and std
2023-01-03 21:52:13,624:INFO:Creating metrics dataframe
2023-01-03 21:52:13,628:INFO:Uploading results into container
2023-01-03 21:52:13,630:INFO:Uploading model into container now
2023-01-03 21:52:13,630:INFO:_master_model_container: 4
2023-01-03 21:52:13,630:INFO:_display_container: 2
2023-01-03 21:52:13,630:INFO:ElasticNet(random_state=123)
2023-01-03 21:52:13,630:INFO:create_model() successfully completed......................................
2023-01-03 21:52:13,741:INFO:SubProcess create_model() end ==================================
2023-01-03 21:52:13,741:INFO:Creating metrics dataframe
2023-01-03 21:52:13,751:INFO:Initializing Least Angle Regression
2023-01-03 21:52:13,751:INFO:Total runtime is 0.1913169264793396 minutes
2023-01-03 21:52:13,755:INFO:SubProcess create_model() called ==================================
2023-01-03 21:52:13,756:INFO:Initializing create_model()
2023-01-03 21:52:13,756:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000267F94E37C0>, estimator=lar, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026786E3E190>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:52:13,756:INFO:Checking exceptions
2023-01-03 21:52:13,756:INFO:Importing libraries
2023-01-03 21:52:13,756:INFO:Copying training dataset
2023-01-03 21:52:13,768:INFO:Defining folds
2023-01-03 21:52:13,769:INFO:Declaring metric variables
2023-01-03 21:52:13,774:INFO:Importing untrained model
2023-01-03 21:52:13,779:INFO:Least Angle Regression Imported successfully
2023-01-03 21:52:13,787:INFO:Starting cross validation
2023-01-03 21:52:13,788:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:52:13,841:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 21:52:13,846:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 21:52:13,854:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 21:52:13,888:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 21:52:13,917:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 21:52:14,048:INFO:Calculating mean and std
2023-01-03 21:52:14,050:INFO:Creating metrics dataframe
2023-01-03 21:52:14,053:INFO:Uploading results into container
2023-01-03 21:52:14,054:INFO:Uploading model into container now
2023-01-03 21:52:14,054:INFO:_master_model_container: 5
2023-01-03 21:52:14,054:INFO:_display_container: 2
2023-01-03 21:52:14,055:INFO:Lars(random_state=123)
2023-01-03 21:52:14,055:INFO:create_model() successfully completed......................................
2023-01-03 21:52:14,163:INFO:SubProcess create_model() end ==================================
2023-01-03 21:52:14,163:INFO:Creating metrics dataframe
2023-01-03 21:52:14,175:INFO:Initializing Lasso Least Angle Regression
2023-01-03 21:52:14,175:INFO:Total runtime is 0.19838332335154216 minutes
2023-01-03 21:52:14,179:INFO:SubProcess create_model() called ==================================
2023-01-03 21:52:14,179:INFO:Initializing create_model()
2023-01-03 21:52:14,180:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000267F94E37C0>, estimator=llar, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026786E3E190>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:52:14,180:INFO:Checking exceptions
2023-01-03 21:52:14,180:INFO:Importing libraries
2023-01-03 21:52:14,180:INFO:Copying training dataset
2023-01-03 21:52:14,189:INFO:Defining folds
2023-01-03 21:52:14,190:INFO:Declaring metric variables
2023-01-03 21:52:14,194:INFO:Importing untrained model
2023-01-03 21:52:14,198:INFO:Lasso Least Angle Regression Imported successfully
2023-01-03 21:52:14,206:INFO:Starting cross validation
2023-01-03 21:52:14,207:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:52:14,273:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-03 21:52:14,279:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-03 21:52:14,284:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-03 21:52:14,310:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-03 21:52:14,329:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-03 21:52:14,457:INFO:Calculating mean and std
2023-01-03 21:52:14,459:INFO:Creating metrics dataframe
2023-01-03 21:52:14,463:INFO:Uploading results into container
2023-01-03 21:52:14,464:INFO:Uploading model into container now
2023-01-03 21:52:14,464:INFO:_master_model_container: 6
2023-01-03 21:52:14,464:INFO:_display_container: 2
2023-01-03 21:52:14,465:INFO:LassoLars(random_state=123)
2023-01-03 21:52:14,465:INFO:create_model() successfully completed......................................
2023-01-03 21:52:14,581:INFO:SubProcess create_model() end ==================================
2023-01-03 21:52:14,581:INFO:Creating metrics dataframe
2023-01-03 21:52:14,592:INFO:Initializing Orthogonal Matching Pursuit
2023-01-03 21:52:14,592:INFO:Total runtime is 0.20533329645792645 minutes
2023-01-03 21:52:14,596:INFO:SubProcess create_model() called ==================================
2023-01-03 21:52:14,597:INFO:Initializing create_model()
2023-01-03 21:52:14,597:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000267F94E37C0>, estimator=omp, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026786E3E190>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:52:14,597:INFO:Checking exceptions
2023-01-03 21:52:14,597:INFO:Importing libraries
2023-01-03 21:52:14,597:INFO:Copying training dataset
2023-01-03 21:52:14,607:INFO:Defining folds
2023-01-03 21:52:14,607:INFO:Declaring metric variables
2023-01-03 21:52:14,611:INFO:Importing untrained model
2023-01-03 21:52:14,616:INFO:Orthogonal Matching Pursuit Imported successfully
2023-01-03 21:52:14,624:INFO:Starting cross validation
2023-01-03 21:52:14,626:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:52:14,688:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 21:52:14,693:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 21:52:14,707:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 21:52:14,733:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 21:52:14,756:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 21:52:14,899:INFO:Calculating mean and std
2023-01-03 21:52:14,901:INFO:Creating metrics dataframe
2023-01-03 21:52:14,904:INFO:Uploading results into container
2023-01-03 21:52:14,905:INFO:Uploading model into container now
2023-01-03 21:52:14,905:INFO:_master_model_container: 7
2023-01-03 21:52:14,905:INFO:_display_container: 2
2023-01-03 21:52:14,905:INFO:OrthogonalMatchingPursuit()
2023-01-03 21:52:14,906:INFO:create_model() successfully completed......................................
2023-01-03 21:52:15,017:INFO:SubProcess create_model() end ==================================
2023-01-03 21:52:15,017:INFO:Creating metrics dataframe
2023-01-03 21:52:15,030:INFO:Initializing Bayesian Ridge
2023-01-03 21:52:15,030:INFO:Total runtime is 0.2126332998275757 minutes
2023-01-03 21:52:15,034:INFO:SubProcess create_model() called ==================================
2023-01-03 21:52:15,034:INFO:Initializing create_model()
2023-01-03 21:52:15,034:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000267F94E37C0>, estimator=br, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026786E3E190>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:52:15,034:INFO:Checking exceptions
2023-01-03 21:52:15,034:INFO:Importing libraries
2023-01-03 21:52:15,034:INFO:Copying training dataset
2023-01-03 21:52:15,045:INFO:Defining folds
2023-01-03 21:52:15,045:INFO:Declaring metric variables
2023-01-03 21:52:15,049:INFO:Importing untrained model
2023-01-03 21:52:15,052:INFO:Bayesian Ridge Imported successfully
2023-01-03 21:52:15,062:INFO:Starting cross validation
2023-01-03 21:52:15,063:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:52:15,319:INFO:Calculating mean and std
2023-01-03 21:52:15,323:INFO:Creating metrics dataframe
2023-01-03 21:52:15,331:INFO:Uploading results into container
2023-01-03 21:52:15,331:INFO:Uploading model into container now
2023-01-03 21:52:15,332:INFO:_master_model_container: 8
2023-01-03 21:52:15,332:INFO:_display_container: 2
2023-01-03 21:52:15,332:INFO:BayesianRidge()
2023-01-03 21:52:15,332:INFO:create_model() successfully completed......................................
2023-01-03 21:52:15,540:INFO:SubProcess create_model() end ==================================
2023-01-03 21:52:15,540:INFO:Creating metrics dataframe
2023-01-03 21:52:15,570:INFO:Initializing Passive Aggressive Regressor
2023-01-03 21:52:15,570:INFO:Total runtime is 0.22163334290186565 minutes
2023-01-03 21:52:15,575:INFO:SubProcess create_model() called ==================================
2023-01-03 21:52:15,575:INFO:Initializing create_model()
2023-01-03 21:52:15,575:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000267F94E37C0>, estimator=par, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026786E3E190>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:52:15,576:INFO:Checking exceptions
2023-01-03 21:52:15,577:INFO:Importing libraries
2023-01-03 21:52:15,577:INFO:Copying training dataset
2023-01-03 21:52:15,587:INFO:Defining folds
2023-01-03 21:52:15,588:INFO:Declaring metric variables
2023-01-03 21:52:15,593:INFO:Importing untrained model
2023-01-03 21:52:15,600:INFO:Passive Aggressive Regressor Imported successfully
2023-01-03 21:52:15,610:INFO:Starting cross validation
2023-01-03 21:52:15,612:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:52:15,880:INFO:Calculating mean and std
2023-01-03 21:52:15,882:INFO:Creating metrics dataframe
2023-01-03 21:52:15,886:INFO:Uploading results into container
2023-01-03 21:52:15,887:INFO:Uploading model into container now
2023-01-03 21:52:15,887:INFO:_master_model_container: 9
2023-01-03 21:52:15,888:INFO:_display_container: 2
2023-01-03 21:52:15,888:INFO:PassiveAggressiveRegressor(random_state=123)
2023-01-03 21:52:15,888:INFO:create_model() successfully completed......................................
2023-01-03 21:52:15,999:INFO:SubProcess create_model() end ==================================
2023-01-03 21:52:15,999:INFO:Creating metrics dataframe
2023-01-03 21:52:16,011:INFO:Initializing Huber Regressor
2023-01-03 21:52:16,011:INFO:Total runtime is 0.22898332277933758 minutes
2023-01-03 21:52:16,015:INFO:SubProcess create_model() called ==================================
2023-01-03 21:52:16,016:INFO:Initializing create_model()
2023-01-03 21:52:16,016:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000267F94E37C0>, estimator=huber, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026786E3E190>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:52:16,016:INFO:Checking exceptions
2023-01-03 21:52:16,016:INFO:Importing libraries
2023-01-03 21:52:16,016:INFO:Copying training dataset
2023-01-03 21:52:16,027:INFO:Defining folds
2023-01-03 21:52:16,031:INFO:Declaring metric variables
2023-01-03 21:52:16,036:INFO:Importing untrained model
2023-01-03 21:52:16,040:INFO:Huber Regressor Imported successfully
2023-01-03 21:52:16,052:INFO:Starting cross validation
2023-01-03 21:52:16,054:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:52:16,249:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-03 21:52:16,350:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-03 21:52:16,539:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-03 21:52:16,641:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-03 21:52:16,784:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-03 21:52:16,918:INFO:Calculating mean and std
2023-01-03 21:52:16,920:INFO:Creating metrics dataframe
2023-01-03 21:52:16,924:INFO:Uploading results into container
2023-01-03 21:52:16,924:INFO:Uploading model into container now
2023-01-03 21:52:16,925:INFO:_master_model_container: 10
2023-01-03 21:52:16,925:INFO:_display_container: 2
2023-01-03 21:52:16,927:INFO:HuberRegressor()
2023-01-03 21:52:16,927:INFO:create_model() successfully completed......................................
2023-01-03 21:52:17,064:INFO:SubProcess create_model() end ==================================
2023-01-03 21:52:17,064:INFO:Creating metrics dataframe
2023-01-03 21:52:17,078:INFO:Initializing K Neighbors Regressor
2023-01-03 21:52:17,078:INFO:Total runtime is 0.24676671425501506 minutes
2023-01-03 21:52:17,082:INFO:SubProcess create_model() called ==================================
2023-01-03 21:52:17,082:INFO:Initializing create_model()
2023-01-03 21:52:17,082:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000267F94E37C0>, estimator=knn, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026786E3E190>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:52:17,083:INFO:Checking exceptions
2023-01-03 21:52:17,083:INFO:Importing libraries
2023-01-03 21:52:17,083:INFO:Copying training dataset
2023-01-03 21:52:17,094:INFO:Defining folds
2023-01-03 21:52:17,094:INFO:Declaring metric variables
2023-01-03 21:52:17,098:INFO:Importing untrained model
2023-01-03 21:52:17,102:INFO:K Neighbors Regressor Imported successfully
2023-01-03 21:52:17,141:INFO:Starting cross validation
2023-01-03 21:52:17,143:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:52:18,572:INFO:Calculating mean and std
2023-01-03 21:52:18,575:INFO:Creating metrics dataframe
2023-01-03 21:52:18,579:INFO:Uploading results into container
2023-01-03 21:52:18,580:INFO:Uploading model into container now
2023-01-03 21:52:18,580:INFO:_master_model_container: 11
2023-01-03 21:52:18,581:INFO:_display_container: 2
2023-01-03 21:52:18,581:INFO:KNeighborsRegressor(n_jobs=-1)
2023-01-03 21:52:18,581:INFO:create_model() successfully completed......................................
2023-01-03 21:52:18,726:INFO:SubProcess create_model() end ==================================
2023-01-03 21:52:18,726:INFO:Creating metrics dataframe
2023-01-03 21:52:18,742:INFO:Initializing Decision Tree Regressor
2023-01-03 21:52:18,742:INFO:Total runtime is 0.27449997663497927 minutes
2023-01-03 21:52:18,746:INFO:SubProcess create_model() called ==================================
2023-01-03 21:52:18,747:INFO:Initializing create_model()
2023-01-03 21:52:18,747:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000267F94E37C0>, estimator=dt, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026786E3E190>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:52:18,747:INFO:Checking exceptions
2023-01-03 21:52:18,747:INFO:Importing libraries
2023-01-03 21:52:18,747:INFO:Copying training dataset
2023-01-03 21:52:18,757:INFO:Defining folds
2023-01-03 21:52:18,757:INFO:Declaring metric variables
2023-01-03 21:52:18,762:INFO:Importing untrained model
2023-01-03 21:52:18,766:INFO:Decision Tree Regressor Imported successfully
2023-01-03 21:52:18,786:INFO:Starting cross validation
2023-01-03 21:52:18,787:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:52:19,550:INFO:Calculating mean and std
2023-01-03 21:52:19,551:INFO:Creating metrics dataframe
2023-01-03 21:52:19,555:INFO:Uploading results into container
2023-01-03 21:52:19,556:INFO:Uploading model into container now
2023-01-03 21:52:19,557:INFO:_master_model_container: 12
2023-01-03 21:52:19,557:INFO:_display_container: 2
2023-01-03 21:52:19,558:INFO:DecisionTreeRegressor(random_state=123)
2023-01-03 21:52:19,558:INFO:create_model() successfully completed......................................
2023-01-03 21:52:19,721:INFO:SubProcess create_model() end ==================================
2023-01-03 21:52:19,721:INFO:Creating metrics dataframe
2023-01-03 21:52:19,735:INFO:Initializing Random Forest Regressor
2023-01-03 21:52:19,735:INFO:Total runtime is 0.2910499771436056 minutes
2023-01-03 21:52:19,739:INFO:SubProcess create_model() called ==================================
2023-01-03 21:52:19,740:INFO:Initializing create_model()
2023-01-03 21:52:19,740:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000267F94E37C0>, estimator=rf, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026786E3E190>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:52:19,740:INFO:Checking exceptions
2023-01-03 21:52:19,740:INFO:Importing libraries
2023-01-03 21:52:19,740:INFO:Copying training dataset
2023-01-03 21:52:19,751:INFO:Defining folds
2023-01-03 21:52:19,751:INFO:Declaring metric variables
2023-01-03 21:52:19,756:INFO:Importing untrained model
2023-01-03 21:52:19,760:INFO:Random Forest Regressor Imported successfully
2023-01-03 21:52:19,768:INFO:Starting cross validation
2023-01-03 21:52:19,771:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:52:30,439:INFO:Calculating mean and std
2023-01-03 21:52:30,441:INFO:Creating metrics dataframe
2023-01-03 21:52:30,445:INFO:Uploading results into container
2023-01-03 21:52:30,446:INFO:Uploading model into container now
2023-01-03 21:52:30,447:INFO:_master_model_container: 13
2023-01-03 21:52:30,447:INFO:_display_container: 2
2023-01-03 21:52:30,448:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-01-03 21:52:30,448:INFO:create_model() successfully completed......................................
2023-01-03 21:52:30,569:INFO:SubProcess create_model() end ==================================
2023-01-03 21:52:30,569:INFO:Creating metrics dataframe
2023-01-03 21:52:30,580:INFO:Initializing Extra Trees Regressor
2023-01-03 21:52:30,581:INFO:Total runtime is 0.4718166510264079 minutes
2023-01-03 21:52:30,585:INFO:SubProcess create_model() called ==================================
2023-01-03 21:52:30,585:INFO:Initializing create_model()
2023-01-03 21:52:30,585:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000267F94E37C0>, estimator=et, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026786E3E190>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:52:30,585:INFO:Checking exceptions
2023-01-03 21:52:30,585:INFO:Importing libraries
2023-01-03 21:52:30,586:INFO:Copying training dataset
2023-01-03 21:52:30,595:INFO:Defining folds
2023-01-03 21:52:30,596:INFO:Declaring metric variables
2023-01-03 21:52:30,600:INFO:Importing untrained model
2023-01-03 21:52:30,604:INFO:Extra Trees Regressor Imported successfully
2023-01-03 21:52:30,613:INFO:Starting cross validation
2023-01-03 21:52:30,614:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:52:35,146:INFO:Calculating mean and std
2023-01-03 21:52:35,148:INFO:Creating metrics dataframe
2023-01-03 21:52:35,151:INFO:Uploading results into container
2023-01-03 21:52:35,152:INFO:Uploading model into container now
2023-01-03 21:52:35,152:INFO:_master_model_container: 14
2023-01-03 21:52:35,152:INFO:_display_container: 2
2023-01-03 21:52:35,152:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-01-03 21:52:35,153:INFO:create_model() successfully completed......................................
2023-01-03 21:52:35,256:INFO:SubProcess create_model() end ==================================
2023-01-03 21:52:35,256:INFO:Creating metrics dataframe
2023-01-03 21:52:35,270:INFO:Initializing AdaBoost Regressor
2023-01-03 21:52:35,270:INFO:Total runtime is 0.5499666452407838 minutes
2023-01-03 21:52:35,275:INFO:SubProcess create_model() called ==================================
2023-01-03 21:52:35,276:INFO:Initializing create_model()
2023-01-03 21:52:35,276:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000267F94E37C0>, estimator=ada, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026786E3E190>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:52:35,276:INFO:Checking exceptions
2023-01-03 21:52:35,276:INFO:Importing libraries
2023-01-03 21:52:35,276:INFO:Copying training dataset
2023-01-03 21:52:35,286:INFO:Defining folds
2023-01-03 21:52:35,287:INFO:Declaring metric variables
2023-01-03 21:52:35,290:INFO:Importing untrained model
2023-01-03 21:52:35,295:INFO:AdaBoost Regressor Imported successfully
2023-01-03 21:52:35,303:INFO:Starting cross validation
2023-01-03 21:52:35,304:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:52:37,469:INFO:Calculating mean and std
2023-01-03 21:52:37,471:INFO:Creating metrics dataframe
2023-01-03 21:52:37,474:INFO:Uploading results into container
2023-01-03 21:52:37,475:INFO:Uploading model into container now
2023-01-03 21:52:37,475:INFO:_master_model_container: 15
2023-01-03 21:52:37,475:INFO:_display_container: 2
2023-01-03 21:52:37,476:INFO:AdaBoostRegressor(random_state=123)
2023-01-03 21:52:37,476:INFO:create_model() successfully completed......................................
2023-01-03 21:52:37,583:INFO:SubProcess create_model() end ==================================
2023-01-03 21:52:37,583:INFO:Creating metrics dataframe
2023-01-03 21:52:37,596:INFO:Initializing Gradient Boosting Regressor
2023-01-03 21:52:37,596:INFO:Total runtime is 0.5887336333592733 minutes
2023-01-03 21:52:37,599:INFO:SubProcess create_model() called ==================================
2023-01-03 21:52:37,600:INFO:Initializing create_model()
2023-01-03 21:52:37,600:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000267F94E37C0>, estimator=gbr, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026786E3E190>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:52:37,600:INFO:Checking exceptions
2023-01-03 21:52:37,600:INFO:Importing libraries
2023-01-03 21:52:37,600:INFO:Copying training dataset
2023-01-03 21:52:37,610:INFO:Defining folds
2023-01-03 21:52:37,610:INFO:Declaring metric variables
2023-01-03 21:52:37,614:INFO:Importing untrained model
2023-01-03 21:52:37,618:INFO:Gradient Boosting Regressor Imported successfully
2023-01-03 21:52:37,625:INFO:Starting cross validation
2023-01-03 21:52:37,627:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:52:42,647:INFO:Calculating mean and std
2023-01-03 21:52:42,649:INFO:Creating metrics dataframe
2023-01-03 21:52:42,652:INFO:Uploading results into container
2023-01-03 21:52:42,652:INFO:Uploading model into container now
2023-01-03 21:52:42,652:INFO:_master_model_container: 16
2023-01-03 21:52:42,652:INFO:_display_container: 2
2023-01-03 21:52:42,653:INFO:GradientBoostingRegressor(random_state=123)
2023-01-03 21:52:42,653:INFO:create_model() successfully completed......................................
2023-01-03 21:52:42,749:INFO:SubProcess create_model() end ==================================
2023-01-03 21:52:42,750:INFO:Creating metrics dataframe
2023-01-03 21:52:42,766:INFO:Initializing Light Gradient Boosting Machine
2023-01-03 21:52:42,766:INFO:Total runtime is 0.6748921195665996 minutes
2023-01-03 21:52:42,770:INFO:SubProcess create_model() called ==================================
2023-01-03 21:52:42,770:INFO:Initializing create_model()
2023-01-03 21:52:42,771:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000267F94E37C0>, estimator=lightgbm, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026786E3E190>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:52:42,771:INFO:Checking exceptions
2023-01-03 21:52:42,771:INFO:Importing libraries
2023-01-03 21:52:42,771:INFO:Copying training dataset
2023-01-03 21:52:42,780:INFO:Defining folds
2023-01-03 21:52:42,780:INFO:Declaring metric variables
2023-01-03 21:52:42,785:INFO:Importing untrained model
2023-01-03 21:52:42,789:INFO:Light Gradient Boosting Machine Imported successfully
2023-01-03 21:52:42,796:INFO:Starting cross validation
2023-01-03 21:52:42,798:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:52:44,858:INFO:Calculating mean and std
2023-01-03 21:52:44,860:INFO:Creating metrics dataframe
2023-01-03 21:52:44,863:INFO:Uploading results into container
2023-01-03 21:52:44,864:INFO:Uploading model into container now
2023-01-03 21:52:44,864:INFO:_master_model_container: 17
2023-01-03 21:52:44,864:INFO:_display_container: 2
2023-01-03 21:52:44,864:INFO:LGBMRegressor(random_state=123)
2023-01-03 21:52:44,864:INFO:create_model() successfully completed......................................
2023-01-03 21:52:44,962:INFO:SubProcess create_model() end ==================================
2023-01-03 21:52:44,963:INFO:Creating metrics dataframe
2023-01-03 21:52:44,977:INFO:Initializing Dummy Regressor
2023-01-03 21:52:44,978:INFO:Total runtime is 0.7117537577946981 minutes
2023-01-03 21:52:44,982:INFO:SubProcess create_model() called ==================================
2023-01-03 21:52:44,983:INFO:Initializing create_model()
2023-01-03 21:52:44,983:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000267F94E37C0>, estimator=dummy, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026786E3E190>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:52:44,983:INFO:Checking exceptions
2023-01-03 21:52:44,983:INFO:Importing libraries
2023-01-03 21:52:44,983:INFO:Copying training dataset
2023-01-03 21:52:44,992:INFO:Defining folds
2023-01-03 21:52:44,992:INFO:Declaring metric variables
2023-01-03 21:52:44,997:INFO:Importing untrained model
2023-01-03 21:52:45,001:INFO:Dummy Regressor Imported successfully
2023-01-03 21:52:45,009:INFO:Starting cross validation
2023-01-03 21:52:45,010:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:52:45,252:INFO:Calculating mean and std
2023-01-03 21:52:45,254:INFO:Creating metrics dataframe
2023-01-03 21:52:45,257:INFO:Uploading results into container
2023-01-03 21:52:45,257:INFO:Uploading model into container now
2023-01-03 21:52:45,258:INFO:_master_model_container: 18
2023-01-03 21:52:45,258:INFO:_display_container: 2
2023-01-03 21:52:45,258:INFO:DummyRegressor()
2023-01-03 21:52:45,258:INFO:create_model() successfully completed......................................
2023-01-03 21:52:45,358:INFO:SubProcess create_model() end ==================================
2023-01-03 21:52:45,358:INFO:Creating metrics dataframe
2023-01-03 21:52:45,388:INFO:Initializing create_model()
2023-01-03 21:52:45,388:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000267F94E37C0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:52:45,388:INFO:Checking exceptions
2023-01-03 21:52:45,390:INFO:Importing libraries
2023-01-03 21:52:45,390:INFO:Copying training dataset
2023-01-03 21:52:45,399:INFO:Defining folds
2023-01-03 21:52:45,400:INFO:Declaring metric variables
2023-01-03 21:52:45,400:INFO:Importing untrained model
2023-01-03 21:52:45,400:INFO:Declaring custom model
2023-01-03 21:52:45,400:INFO:Extra Trees Regressor Imported successfully
2023-01-03 21:52:45,401:INFO:Cross validation set to False
2023-01-03 21:52:45,401:INFO:Fitting Model
2023-01-03 21:52:47,234:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-01-03 21:52:47,234:INFO:create_model() successfully completed......................................
2023-01-03 21:52:47,374:INFO:_master_model_container: 18
2023-01-03 21:52:47,375:INFO:_display_container: 2
2023-01-03 21:52:47,375:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-01-03 21:52:47,375:INFO:compare_models() successfully completed......................................
2023-01-03 21:52:47,376:INFO:Initializing tune_model()
2023-01-03 21:52:47,376:INFO:tune_model(estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=MAE, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000267F94E37C0>)
2023-01-03 21:52:47,376:INFO:Checking exceptions
2023-01-03 21:52:47,415:INFO:Copying training dataset
2023-01-03 21:52:47,424:INFO:Checking base model
2023-01-03 21:52:47,424:INFO:Base model : Extra Trees Regressor
2023-01-03 21:52:47,429:INFO:Declaring metric variables
2023-01-03 21:52:47,433:INFO:Defining Hyperparameters
2023-01-03 21:52:47,566:INFO:Tuning with n_jobs=-1
2023-01-03 21:52:47,566:INFO:Initializing RandomizedSearchCV
2023-01-03 21:52:47,621:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:52:47,623:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:52:47,628:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:52:47,668:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:52:47,930:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:52:47,960:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:52:47,999:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:52:48,139:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:52:48,474:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:52:48,594:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:52:48,616:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:52:48,646:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:52:48,957:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:52:48,992:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:52:49,223:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:52:49,547:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:52:49,648:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:52:49,977:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:52:50,087:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:52:50,222:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:52:50,236:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:52:50,757:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:52:50,930:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:52:51,206:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:52:51,245:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:52:51,577:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:52:52,026:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:52:52,220:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:52:52,598:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:52:53,750:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:52:57,528:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:53:00,816:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:53:01,329:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:53:03,325:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:53:03,918:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:53:06,454:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:53:06,877:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:53:07,407:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:53:07,972:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:53:08,437:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:53:09,015:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:53:10,077:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:53:11,054:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:53:12,317:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:53:16,866:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 21:53:17,571:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:53:21,345:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:53:24,535:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:53:24,775:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:53:26,867:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:53:35,384:INFO:best_params: {'actual_estimator__n_estimators': 100, 'actual_estimator__min_samples_split': 7, 'actual_estimator__min_samples_leaf': 4, 'actual_estimator__min_impurity_decrease': 0.1, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 9, 'actual_estimator__criterion': 'mse', 'actual_estimator__bootstrap': True}
2023-01-03 21:53:35,386:INFO:Hyperparameter search completed
2023-01-03 21:53:35,386:INFO:SubProcess create_model() called ==================================
2023-01-03 21:53:35,387:INFO:Initializing create_model()
2023-01-03 21:53:35,387:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000267F94E37C0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000267866FABB0>, model_only=True, return_train_score=False, kwargs={'n_estimators': 100, 'min_samples_split': 7, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.1, 'max_features': 1.0, 'max_depth': 9, 'criterion': 'mse', 'bootstrap': True})
2023-01-03 21:53:35,387:INFO:Checking exceptions
2023-01-03 21:53:35,387:INFO:Importing libraries
2023-01-03 21:53:35,387:INFO:Copying training dataset
2023-01-03 21:53:35,397:INFO:Defining folds
2023-01-03 21:53:35,397:INFO:Declaring metric variables
2023-01-03 21:53:35,401:INFO:Importing untrained model
2023-01-03 21:53:35,401:INFO:Declaring custom model
2023-01-03 21:53:35,406:INFO:Extra Trees Regressor Imported successfully
2023-01-03 21:53:35,414:INFO:Starting cross validation
2023-01-03 21:53:35,415:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:53:35,467:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:53:35,470:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:53:35,479:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:53:35,508:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:53:36,023:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 21:53:36,537:INFO:Calculating mean and std
2023-01-03 21:53:36,539:INFO:Creating metrics dataframe
2023-01-03 21:53:36,544:INFO:Finalizing model
2023-01-03 21:53:36,875:INFO:Uploading results into container
2023-01-03 21:53:36,876:INFO:Uploading model into container now
2023-01-03 21:53:36,877:INFO:_master_model_container: 19
2023-01-03 21:53:36,878:INFO:_display_container: 3
2023-01-03 21:53:36,878:INFO:ExtraTreesRegressor(bootstrap=True, criterion='mse', max_depth=9,
                    max_features=1.0, min_impurity_decrease=0.1,
                    min_samples_leaf=4, min_samples_split=7, n_jobs=-1,
                    random_state=123)
2023-01-03 21:53:36,878:INFO:create_model() successfully completed......................................
2023-01-03 21:53:37,041:INFO:SubProcess create_model() end ==================================
2023-01-03 21:53:37,041:INFO:choose_better activated
2023-01-03 21:53:37,045:INFO:SubProcess create_model() called ==================================
2023-01-03 21:53:37,045:INFO:Initializing create_model()
2023-01-03 21:53:37,045:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000267F94E37C0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-01-03 21:53:37,046:INFO:Checking exceptions
2023-01-03 21:53:37,051:INFO:Importing libraries
2023-01-03 21:53:37,051:INFO:Copying training dataset
2023-01-03 21:53:37,058:INFO:Defining folds
2023-01-03 21:53:37,058:INFO:Declaring metric variables
2023-01-03 21:53:37,059:INFO:Importing untrained model
2023-01-03 21:53:37,059:INFO:Declaring custom model
2023-01-03 21:53:37,059:INFO:Extra Trees Regressor Imported successfully
2023-01-03 21:53:37,060:INFO:Starting cross validation
2023-01-03 21:53:37,060:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 21:53:41,251:INFO:Calculating mean and std
2023-01-03 21:53:41,252:INFO:Creating metrics dataframe
2023-01-03 21:53:41,254:INFO:Finalizing model
2023-01-03 21:53:42,965:INFO:Uploading results into container
2023-01-03 21:53:42,965:INFO:Uploading model into container now
2023-01-03 21:53:42,966:INFO:_master_model_container: 20
2023-01-03 21:53:42,966:INFO:_display_container: 4
2023-01-03 21:53:42,966:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-01-03 21:53:42,966:INFO:create_model() successfully completed......................................
2023-01-03 21:53:43,064:INFO:SubProcess create_model() end ==================================
2023-01-03 21:53:43,064:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123) result for MAE is 1.7892
2023-01-03 21:53:43,065:INFO:ExtraTreesRegressor(bootstrap=True, criterion='mse', max_depth=9,
                    max_features=1.0, min_impurity_decrease=0.1,
                    min_samples_leaf=4, min_samples_split=7, n_jobs=-1,
                    random_state=123) result for MAE is 2.4456
2023-01-03 21:53:43,065:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123) is best model
2023-01-03 21:53:43,065:INFO:choose_better completed
2023-01-03 21:53:43,065:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-01-03 21:53:43,075:INFO:_master_model_container: 20
2023-01-03 21:53:43,075:INFO:_display_container: 3
2023-01-03 21:53:43,075:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-01-03 21:53:43,075:INFO:tune_model() successfully completed......................................
2023-01-03 21:53:43,202:INFO:Initializing plot_model()
2023-01-03 21:53:43,202:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000267F94E37C0>, system=True)
2023-01-03 21:53:43,202:INFO:Checking exceptions
2023-01-03 21:53:43,226:INFO:Preloading libraries
2023-01-03 21:53:43,366:INFO:Copying training dataset
2023-01-03 21:53:43,366:INFO:Plot type: error
2023-01-03 21:53:43,534:INFO:Fitting Model
2023-01-03 21:53:43,535:INFO:Scoring test/hold-out set
2023-01-03 21:53:44,002:INFO:Visual Rendered Successfully
2023-01-03 21:53:44,115:INFO:plot_model() successfully completed......................................
2023-01-03 21:53:44,127:INFO:Initializing predict_model()
2023-01-03 21:53:44,127:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000267F94E37C0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x0000026787018550>)
2023-01-03 21:53:44,128:INFO:Checking exceptions
2023-01-03 21:53:44,128:INFO:Preloading libraries
2023-01-03 21:53:44,353:INFO:Initializing finalize_model()
2023-01-03 21:53:44,353:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000267F94E37C0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-01-03 21:53:44,354:INFO:Finalizing ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-01-03 21:53:44,363:INFO:Initializing create_model()
2023-01-03 21:53:44,363:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000267F94E37C0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-01-03 21:53:44,363:INFO:Checking exceptions
2023-01-03 21:53:44,365:INFO:Importing libraries
2023-01-03 21:53:44,365:INFO:Copying training dataset
2023-01-03 21:53:44,366:INFO:Defining folds
2023-01-03 21:53:44,366:INFO:Declaring metric variables
2023-01-03 21:53:44,366:INFO:Importing untrained model
2023-01-03 21:53:44,366:INFO:Declaring custom model
2023-01-03 21:53:44,368:INFO:Extra Trees Regressor Imported successfully
2023-01-03 21:53:44,368:INFO:Cross validation set to False
2023-01-03 21:53:44,368:INFO:Fitting Model
2023-01-03 21:53:47,685:INFO:Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))])
2023-01-03 21:53:47,686:INFO:create_model() successfully completed......................................
2023-01-03 21:53:47,793:INFO:_master_model_container: 20
2023-01-03 21:53:47,795:INFO:_display_container: 4
2023-01-03 21:53:47,801:INFO:Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))])
2023-01-03 21:53:47,801:INFO:finalize_model() successfully completed......................................
2023-01-03 21:53:47,915:INFO:Initializing predict_model()
2023-01-03 21:53:47,916:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000267F94E37C0>, estimator=Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x0000026787233280>)
2023-01-03 21:53:47,916:INFO:Checking exceptions
2023-01-03 21:53:47,916:INFO:Preloading libraries
2023-01-03 21:53:47,918:INFO:Set up data.
2023-01-03 21:53:47,932:INFO:Set up index.
2023-01-03 21:53:48,414:INFO:Initializing save_model()
2023-01-03 21:53:48,414:INFO:save_model(model=Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))]), model_name=c:\Users\Kodotautas\Desktop\Data_science\7_TIME_SERIES_FORECAST_PYCARET/models/final_model.pkl, prep_pipe_=Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-01-03 21:53:48,414:INFO:Adding model into prep_pipe
2023-01-03 21:53:48,597:WARNING:Only Model saved as it was a pipeline.
2023-01-03 21:53:48,745:INFO:c:\Users\Kodotautas\Desktop\Data_science\7_TIME_SERIES_FORECAST_PYCARET/models/final_model.pkl.pkl saved in current working directory
2023-01-03 21:53:48,752:INFO:Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))])
2023-01-03 21:53:48,752:INFO:save_model() successfully completed......................................
2023-01-03 22:00:40,319:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-01-03 22:00:40,320:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-01-03 22:00:40,320:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-01-03 22:00:40,320:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-01-03 22:00:41,131:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-01-03 22:00:41,521:INFO:PyCaret RegressionExperiment
2023-01-03 22:00:41,521:INFO:Logging name: reg-default-name
2023-01-03 22:00:41,521:INFO:ML Usecase: MLUsecase.REGRESSION
2023-01-03 22:00:41,521:INFO:version 3.0.0.rc6
2023-01-03 22:00:41,521:INFO:Initializing setup()
2023-01-03 22:00:41,522:INFO:self.USI: 336d
2023-01-03 22:00:41,522:INFO:self._variable_keys: {'X_train', 'fold_shuffle_param', 'exp_id', 'memory', 'logging_param', 'fold_generator', 'y_train', 'n_jobs_param', '_ml_usecase', 'USI', 'X', 'y_test', 'data', 'fold_groups_param', 'y', 'X_test', 'log_plots_param', 'seed', 'gpu_n_jobs_param', 'transform_target_param', '_available_plots', 'gpu_param', 'target_param', 'html_param', 'exp_name_log', 'pipeline', 'idx'}
2023-01-03 22:00:41,522:INFO:Checking environment
2023-01-03 22:00:41,522:INFO:python_version: 3.9.13
2023-01-03 22:00:41,522:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-01-03 22:00:41,522:INFO:machine: AMD64
2023-01-03 22:00:41,522:INFO:platform: Windows-10-10.0.19044-SP0
2023-01-03 22:00:41,522:INFO:Memory: svmem(total=17114804224, available=9558347776, percent=44.2, used=7556456448, free=9558347776)
2023-01-03 22:00:41,522:INFO:Physical Core: 4
2023-01-03 22:00:41,522:INFO:Logical Core: 4
2023-01-03 22:00:41,522:INFO:Checking libraries
2023-01-03 22:00:41,522:INFO:System:
2023-01-03 22:00:41,522:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-01-03 22:00:41,522:INFO:executable: c:\Users\Kodotautas\anaconda3\python.exe
2023-01-03 22:00:41,522:INFO:   machine: Windows-10-10.0.19044-SP0
2023-01-03 22:00:41,522:INFO:PyCaret required dependencies:
2023-01-03 22:00:41,522:INFO:                 pip: 22.2.2
2023-01-03 22:00:41,522:INFO:          setuptools: 63.4.1
2023-01-03 22:00:41,523:INFO:             pycaret: 3.0.0rc6
2023-01-03 22:00:41,523:INFO:             IPython: 7.31.1
2023-01-03 22:00:41,523:INFO:          ipywidgets: 7.6.5
2023-01-03 22:00:41,523:INFO:                tqdm: 4.64.1
2023-01-03 22:00:41,523:INFO:               numpy: 1.21.5
2023-01-03 22:00:41,523:INFO:              pandas: 1.4.4
2023-01-03 22:00:41,523:INFO:              jinja2: 2.11.3
2023-01-03 22:00:41,523:INFO:               scipy: 1.9.1
2023-01-03 22:00:41,523:INFO:              joblib: 1.2.0
2023-01-03 22:00:41,523:INFO:             sklearn: 1.0.2
2023-01-03 22:00:41,523:INFO:                pyod: 1.0.7
2023-01-03 22:00:41,523:INFO:            imblearn: 0.10.1
2023-01-03 22:00:41,523:INFO:   category_encoders: 2.5.1.post0
2023-01-03 22:00:41,523:INFO:            lightgbm: 3.3.3
2023-01-03 22:00:41,523:INFO:               numba: 0.55.1
2023-01-03 22:00:41,523:INFO:            requests: 2.28.1
2023-01-03 22:00:41,523:INFO:          matplotlib: 3.5.2
2023-01-03 22:00:41,523:INFO:          scikitplot: 0.3.7
2023-01-03 22:00:41,523:INFO:         yellowbrick: 1.5
2023-01-03 22:00:41,523:INFO:              plotly: 5.9.0
2023-01-03 22:00:41,523:INFO:             kaleido: 0.2.1
2023-01-03 22:00:41,523:INFO:         statsmodels: 0.13.2
2023-01-03 22:00:41,523:INFO:              sktime: 0.14.1
2023-01-03 22:00:41,523:INFO:               tbats: 1.1.2
2023-01-03 22:00:41,524:INFO:            pmdarima: 2.0.2
2023-01-03 22:00:41,524:INFO:              psutil: 5.9.0
2023-01-03 22:00:41,524:INFO:PyCaret optional dependencies:
2023-01-03 22:00:41,792:INFO:                shap: 0.41.0
2023-01-03 22:00:41,792:INFO:           interpret: Not installed
2023-01-03 22:00:41,792:INFO:                umap: Not installed
2023-01-03 22:00:41,792:INFO:    pandas_profiling: Not installed
2023-01-03 22:00:41,792:INFO:  explainerdashboard: Not installed
2023-01-03 22:00:41,792:INFO:             autoviz: Not installed
2023-01-03 22:00:41,792:INFO:           fairlearn: Not installed
2023-01-03 22:00:41,793:INFO:             xgboost: Not installed
2023-01-03 22:00:41,793:INFO:            catboost: Not installed
2023-01-03 22:00:41,793:INFO:              kmodes: Not installed
2023-01-03 22:00:41,793:INFO:             mlxtend: Not installed
2023-01-03 22:00:41,793:INFO:       statsforecast: Not installed
2023-01-03 22:00:41,793:INFO:        tune_sklearn: 0.4.3
2023-01-03 22:00:41,793:INFO:                 ray: 2.0.0
2023-01-03 22:00:41,793:INFO:            hyperopt: 0.2.7
2023-01-03 22:00:41,793:INFO:              optuna: 3.0.1
2023-01-03 22:00:41,793:INFO:               skopt: 0.9.0
2023-01-03 22:00:41,793:INFO:              mlflow: Not installed
2023-01-03 22:00:41,793:INFO:              gradio: Not installed
2023-01-03 22:00:41,793:INFO:             fastapi: 0.88.0
2023-01-03 22:00:41,793:INFO:             uvicorn: 0.20.0
2023-01-03 22:00:41,793:INFO:              m2cgen: Not installed
2023-01-03 22:00:41,793:INFO:           evidently: Not installed
2023-01-03 22:00:41,793:INFO:                nltk: 3.7
2023-01-03 22:00:41,793:INFO:            pyLDAvis: Not installed
2023-01-03 22:00:41,793:INFO:              gensim: 4.1.2
2023-01-03 22:00:41,793:INFO:               spacy: 3.4.2
2023-01-03 22:00:41,793:INFO:           wordcloud: Not installed
2023-01-03 22:00:41,794:INFO:            textblob: Not installed
2023-01-03 22:00:41,794:INFO:               fugue: Not installed
2023-01-03 22:00:41,794:INFO:           streamlit: Not installed
2023-01-03 22:00:41,794:INFO:             prophet: Not installed
2023-01-03 22:00:41,794:INFO:None
2023-01-03 22:00:41,794:INFO:Set up data.
2023-01-03 22:00:41,814:INFO:Set up train/test split.
2023-01-03 22:00:41,827:INFO:Set up index.
2023-01-03 22:00:41,829:INFO:Set up folding strategy.
2023-01-03 22:00:41,829:INFO:Assigning column types.
2023-01-03 22:00:41,840:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-01-03 22:00:41,840:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-01-03 22:00:41,845:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-03 22:00:41,850:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 22:00:41,919:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 22:00:41,965:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 22:00:41,967:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:00:42,096:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:00:42,097:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-01-03 22:00:42,102:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-03 22:00:42,106:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 22:00:42,175:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 22:00:42,221:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 22:00:42,222:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:00:42,222:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:00:42,222:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-01-03 22:00:42,227:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-03 22:00:42,232:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 22:00:42,298:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 22:00:42,346:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 22:00:42,346:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:00:42,347:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:00:42,352:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-03 22:00:42,358:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 22:00:42,427:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 22:00:42,474:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 22:00:42,474:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:00:42,474:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:00:42,475:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-01-03 22:00:42,485:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 22:00:42,551:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 22:00:42,597:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 22:00:42,598:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:00:42,598:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:00:42,608:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 22:00:42,676:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 22:00:42,723:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 22:00:42,724:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:00:42,724:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:00:42,724:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-01-03 22:00:42,800:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 22:00:42,847:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 22:00:42,847:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:00:42,848:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:00:42,925:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 22:00:42,971:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 22:00:42,972:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:00:42,972:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:00:42,972:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-01-03 22:00:43,047:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 22:00:43,097:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:00:43,097:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:00:43,178:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 22:00:43,225:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:00:43,225:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:00:43,226:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-01-03 22:00:43,351:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:00:43,351:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:00:43,473:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:00:43,473:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:00:43,475:INFO:Preparing preprocessing pipeline...
2023-01-03 22:00:43,477:INFO:Set up simple imputation.
2023-01-03 22:00:43,477:INFO:Set up column transformation.
2023-01-03 22:00:43,477:INFO:Set up feature normalization.
2023-01-03 22:00:44,051:INFO:Finished creating preprocessing pipeline.
2023-01-03 22:00:44,058:INFO:Pipeline: Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2023-01-03 22:00:44,058:INFO:Creating final display dataframe.
2023-01-03 22:00:44,694:INFO:Setup _display_container:                Description             Value
0               Session id               123
1                   Target        b2b+b2c+vt
2              Target type        Regression
3               Data shape       (10505, 45)
4         Train data shape        (7353, 45)
5          Test data shape        (3152, 45)
6         Numeric features                 8
7               Preprocess              True
8          Imputation type            simple
9       Numeric imputation              mean
10  Categorical imputation              mode
11          Transformation              True
12   Transformation method       yeo-johnson
13               Normalize              True
14        Normalize method            zscore
15          Fold Generator   TimeSeriesSplit
16             Fold Number                 5
17                CPU Jobs                -1
18                 Use GPU             False
19          Log Experiment             False
20         Experiment Name  reg-default-name
21                     USI              336d
2023-01-03 22:00:44,962:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:00:44,962:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:00:45,091:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:00:45,092:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:00:45,092:INFO:setup() successfully completed in 3.57s...............
2023-01-03 22:00:45,092:INFO:Initializing compare_models()
2023-01-03 22:00:45,093:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CA7E2BF190>, include=None, fold=None, round=4, cross_validation=True, sort=MAE, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001CA7E2BF190>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'MAE', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-01-03 22:00:45,093:INFO:Checking exceptions
2023-01-03 22:00:45,097:INFO:Preparing display monitor
2023-01-03 22:00:45,137:INFO:Initializing Linear Regression
2023-01-03 22:00:45,137:INFO:Total runtime is 0.0 minutes
2023-01-03 22:00:45,141:INFO:SubProcess create_model() called ==================================
2023-01-03 22:00:45,142:INFO:Initializing create_model()
2023-01-03 22:00:45,142:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CA7E2BF190>, estimator=lr, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CA06F74DF0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:00:45,142:INFO:Checking exceptions
2023-01-03 22:00:45,142:INFO:Importing libraries
2023-01-03 22:00:45,142:INFO:Copying training dataset
2023-01-03 22:00:45,152:INFO:Defining folds
2023-01-03 22:00:45,153:INFO:Declaring metric variables
2023-01-03 22:00:45,157:INFO:Importing untrained model
2023-01-03 22:00:45,162:INFO:Linear Regression Imported successfully
2023-01-03 22:00:45,171:INFO:Starting cross validation
2023-01-03 22:00:45,177:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:00:53,931:INFO:Calculating mean and std
2023-01-03 22:00:53,934:INFO:Creating metrics dataframe
2023-01-03 22:00:53,938:INFO:Uploading results into container
2023-01-03 22:00:53,939:INFO:Uploading model into container now
2023-01-03 22:00:53,940:INFO:_master_model_container: 1
2023-01-03 22:00:53,940:INFO:_display_container: 2
2023-01-03 22:00:53,941:INFO:LinearRegression(n_jobs=-1)
2023-01-03 22:00:53,941:INFO:create_model() successfully completed......................................
2023-01-03 22:00:54,051:INFO:SubProcess create_model() end ==================================
2023-01-03 22:00:54,052:INFO:Creating metrics dataframe
2023-01-03 22:00:54,060:INFO:Initializing Lasso Regression
2023-01-03 22:00:54,060:INFO:Total runtime is 0.14871469338734944 minutes
2023-01-03 22:00:54,064:INFO:SubProcess create_model() called ==================================
2023-01-03 22:00:54,065:INFO:Initializing create_model()
2023-01-03 22:00:54,065:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CA7E2BF190>, estimator=lasso, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CA06F74DF0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:00:54,065:INFO:Checking exceptions
2023-01-03 22:00:54,065:INFO:Importing libraries
2023-01-03 22:00:54,065:INFO:Copying training dataset
2023-01-03 22:00:54,078:INFO:Defining folds
2023-01-03 22:00:54,078:INFO:Declaring metric variables
2023-01-03 22:00:54,082:INFO:Importing untrained model
2023-01-03 22:00:54,088:INFO:Lasso Regression Imported successfully
2023-01-03 22:00:54,097:INFO:Starting cross validation
2023-01-03 22:00:54,098:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:00:54,451:INFO:Calculating mean and std
2023-01-03 22:00:54,453:INFO:Creating metrics dataframe
2023-01-03 22:00:54,456:INFO:Uploading results into container
2023-01-03 22:00:54,456:INFO:Uploading model into container now
2023-01-03 22:00:54,457:INFO:_master_model_container: 2
2023-01-03 22:00:54,457:INFO:_display_container: 2
2023-01-03 22:00:54,457:INFO:Lasso(random_state=123)
2023-01-03 22:00:54,457:INFO:create_model() successfully completed......................................
2023-01-03 22:00:54,559:INFO:SubProcess create_model() end ==================================
2023-01-03 22:00:54,559:INFO:Creating metrics dataframe
2023-01-03 22:00:54,573:INFO:Initializing Ridge Regression
2023-01-03 22:00:54,573:INFO:Total runtime is 0.15726605653762818 minutes
2023-01-03 22:00:54,577:INFO:SubProcess create_model() called ==================================
2023-01-03 22:00:54,578:INFO:Initializing create_model()
2023-01-03 22:00:54,578:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CA7E2BF190>, estimator=ridge, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CA06F74DF0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:00:54,578:INFO:Checking exceptions
2023-01-03 22:00:54,578:INFO:Importing libraries
2023-01-03 22:00:54,578:INFO:Copying training dataset
2023-01-03 22:00:54,588:INFO:Defining folds
2023-01-03 22:00:54,589:INFO:Declaring metric variables
2023-01-03 22:00:54,594:INFO:Importing untrained model
2023-01-03 22:00:54,598:INFO:Ridge Regression Imported successfully
2023-01-03 22:00:54,608:INFO:Starting cross validation
2023-01-03 22:00:54,609:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:00:54,902:INFO:Calculating mean and std
2023-01-03 22:00:54,904:INFO:Creating metrics dataframe
2023-01-03 22:00:54,907:INFO:Uploading results into container
2023-01-03 22:00:54,907:INFO:Uploading model into container now
2023-01-03 22:00:54,908:INFO:_master_model_container: 3
2023-01-03 22:00:54,908:INFO:_display_container: 2
2023-01-03 22:00:54,908:INFO:Ridge(random_state=123)
2023-01-03 22:00:54,908:INFO:create_model() successfully completed......................................
2023-01-03 22:00:55,012:INFO:SubProcess create_model() end ==================================
2023-01-03 22:00:55,013:INFO:Creating metrics dataframe
2023-01-03 22:00:55,026:INFO:Initializing Elastic Net
2023-01-03 22:00:55,026:INFO:Total runtime is 0.16482335329055786 minutes
2023-01-03 22:00:55,030:INFO:SubProcess create_model() called ==================================
2023-01-03 22:00:55,031:INFO:Initializing create_model()
2023-01-03 22:00:55,031:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CA7E2BF190>, estimator=en, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CA06F74DF0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:00:55,031:INFO:Checking exceptions
2023-01-03 22:00:55,031:INFO:Importing libraries
2023-01-03 22:00:55,031:INFO:Copying training dataset
2023-01-03 22:00:55,042:INFO:Defining folds
2023-01-03 22:00:55,042:INFO:Declaring metric variables
2023-01-03 22:00:55,047:INFO:Importing untrained model
2023-01-03 22:00:55,052:INFO:Elastic Net Imported successfully
2023-01-03 22:00:55,060:INFO:Starting cross validation
2023-01-03 22:00:55,062:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:00:55,312:INFO:Calculating mean and std
2023-01-03 22:00:55,314:INFO:Creating metrics dataframe
2023-01-03 22:00:55,318:INFO:Uploading results into container
2023-01-03 22:00:55,320:INFO:Uploading model into container now
2023-01-03 22:00:55,321:INFO:_master_model_container: 4
2023-01-03 22:00:55,321:INFO:_display_container: 2
2023-01-03 22:00:55,322:INFO:ElasticNet(random_state=123)
2023-01-03 22:00:55,322:INFO:create_model() successfully completed......................................
2023-01-03 22:00:55,429:INFO:SubProcess create_model() end ==================================
2023-01-03 22:00:55,429:INFO:Creating metrics dataframe
2023-01-03 22:00:55,439:INFO:Initializing Least Angle Regression
2023-01-03 22:00:55,440:INFO:Total runtime is 0.17172672748565673 minutes
2023-01-03 22:00:55,444:INFO:SubProcess create_model() called ==================================
2023-01-03 22:00:55,445:INFO:Initializing create_model()
2023-01-03 22:00:55,445:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CA7E2BF190>, estimator=lar, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CA06F74DF0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:00:55,445:INFO:Checking exceptions
2023-01-03 22:00:55,445:INFO:Importing libraries
2023-01-03 22:00:55,445:INFO:Copying training dataset
2023-01-03 22:00:55,456:INFO:Defining folds
2023-01-03 22:00:55,456:INFO:Declaring metric variables
2023-01-03 22:00:55,460:INFO:Importing untrained model
2023-01-03 22:00:55,465:INFO:Least Angle Regression Imported successfully
2023-01-03 22:00:55,475:INFO:Starting cross validation
2023-01-03 22:00:55,477:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:00:55,530:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 22:00:55,533:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=5.970e-02, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-03 22:00:55,534:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 22:00:55,535:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.477e-02, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-03 22:00:55,537:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 32 iterations, i.e. alpha=5.538e-03, with an active set of 24 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-03 22:00:55,542:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=4.202e-03, with an active set of 28 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-03 22:00:55,542:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=2.490e-03, with an active set of 32 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-03 22:00:55,545:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 59 iterations, i.e. alpha=4.528e-03, with an active set of 43 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-03 22:00:55,548:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 22:00:55,552:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=1.175e-02, with an active set of 41 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-03 22:00:55,552:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=1.147e-03, with an active set of 41 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-03 22:00:55,553:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 54 iterations, i.e. alpha=4.241e-04, with an active set of 43 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-03 22:00:55,563:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 37 iterations, i.e. alpha=5.484e-04, with an active set of 32 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-03 22:00:55,566:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=5.911e-04, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-03 22:00:55,567:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=2.882e-04, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-03 22:00:55,567:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=8.536e-05, with an active set of 42 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-03 22:00:55,567:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=8.384e-05, with an active set of 42 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-03 22:00:55,568:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 22:00:55,574:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.730e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-03 22:00:55,575:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=9.814e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-03 22:00:55,576:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=7.308e-03, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-03 22:00:55,581:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 48 iterations, i.e. alpha=5.796e-04, with an active set of 43 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-03 22:00:55,600:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 22:00:55,605:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.562e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-03 22:00:55,606:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=8.835e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-03 22:00:55,607:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=6.204e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-03 22:00:55,607:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=5.609e-03, with an active set of 15 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-03 22:00:55,611:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=8.541e-04, with an active set of 39 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-03 22:00:55,612:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 48 iterations, i.e. alpha=4.362e-04, with an active set of 41 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-03 22:00:55,612:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 48 iterations, i.e. alpha=3.623e-04, with an active set of 41 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-03 22:00:55,613:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=1.512e-05, with an active set of 43 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-03 22:00:55,740:INFO:Calculating mean and std
2023-01-03 22:00:55,742:INFO:Creating metrics dataframe
2023-01-03 22:00:55,745:INFO:Uploading results into container
2023-01-03 22:00:55,745:INFO:Uploading model into container now
2023-01-03 22:00:55,746:INFO:_master_model_container: 5
2023-01-03 22:00:55,746:INFO:_display_container: 2
2023-01-03 22:00:55,746:INFO:Lars(random_state=123)
2023-01-03 22:00:55,746:INFO:create_model() successfully completed......................................
2023-01-03 22:00:55,847:INFO:SubProcess create_model() end ==================================
2023-01-03 22:00:55,848:INFO:Creating metrics dataframe
2023-01-03 22:00:55,860:INFO:Initializing Lasso Least Angle Regression
2023-01-03 22:00:55,860:INFO:Total runtime is 0.17871753374735513 minutes
2023-01-03 22:00:55,864:INFO:SubProcess create_model() called ==================================
2023-01-03 22:00:55,865:INFO:Initializing create_model()
2023-01-03 22:00:55,865:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CA7E2BF190>, estimator=llar, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CA06F74DF0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:00:55,865:INFO:Checking exceptions
2023-01-03 22:00:55,865:INFO:Importing libraries
2023-01-03 22:00:55,865:INFO:Copying training dataset
2023-01-03 22:00:55,876:INFO:Defining folds
2023-01-03 22:00:55,876:INFO:Declaring metric variables
2023-01-03 22:00:55,881:INFO:Importing untrained model
2023-01-03 22:00:55,885:INFO:Lasso Least Angle Regression Imported successfully
2023-01-03 22:00:55,894:INFO:Starting cross validation
2023-01-03 22:00:55,895:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:00:55,944:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-03 22:00:55,949:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-03 22:00:55,959:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-03 22:00:55,981:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-03 22:00:56,004:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-03 22:00:56,137:INFO:Calculating mean and std
2023-01-03 22:00:56,139:INFO:Creating metrics dataframe
2023-01-03 22:00:56,142:INFO:Uploading results into container
2023-01-03 22:00:56,142:INFO:Uploading model into container now
2023-01-03 22:00:56,142:INFO:_master_model_container: 6
2023-01-03 22:00:56,143:INFO:_display_container: 2
2023-01-03 22:00:56,143:INFO:LassoLars(random_state=123)
2023-01-03 22:00:56,144:INFO:create_model() successfully completed......................................
2023-01-03 22:00:56,270:INFO:SubProcess create_model() end ==================================
2023-01-03 22:00:56,270:INFO:Creating metrics dataframe
2023-01-03 22:00:56,282:INFO:Initializing Orthogonal Matching Pursuit
2023-01-03 22:00:56,282:INFO:Total runtime is 0.18575452168782552 minutes
2023-01-03 22:00:56,286:INFO:SubProcess create_model() called ==================================
2023-01-03 22:00:56,286:INFO:Initializing create_model()
2023-01-03 22:00:56,287:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CA7E2BF190>, estimator=omp, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CA06F74DF0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:00:56,287:INFO:Checking exceptions
2023-01-03 22:00:56,287:INFO:Importing libraries
2023-01-03 22:00:56,287:INFO:Copying training dataset
2023-01-03 22:00:56,296:INFO:Defining folds
2023-01-03 22:00:56,296:INFO:Declaring metric variables
2023-01-03 22:00:56,301:INFO:Importing untrained model
2023-01-03 22:00:56,305:INFO:Orthogonal Matching Pursuit Imported successfully
2023-01-03 22:00:56,313:INFO:Starting cross validation
2023-01-03 22:00:56,315:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:00:56,366:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 22:00:56,371:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 22:00:56,381:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 22:00:56,400:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 22:00:56,429:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 22:00:56,562:INFO:Calculating mean and std
2023-01-03 22:00:56,564:INFO:Creating metrics dataframe
2023-01-03 22:00:56,568:INFO:Uploading results into container
2023-01-03 22:00:56,569:INFO:Uploading model into container now
2023-01-03 22:00:56,569:INFO:_master_model_container: 7
2023-01-03 22:00:56,569:INFO:_display_container: 2
2023-01-03 22:00:56,570:INFO:OrthogonalMatchingPursuit()
2023-01-03 22:00:56,570:INFO:create_model() successfully completed......................................
2023-01-03 22:00:56,671:INFO:SubProcess create_model() end ==================================
2023-01-03 22:00:56,671:INFO:Creating metrics dataframe
2023-01-03 22:00:56,681:INFO:Initializing Bayesian Ridge
2023-01-03 22:00:56,681:INFO:Total runtime is 0.19239708582560222 minutes
2023-01-03 22:00:56,685:INFO:SubProcess create_model() called ==================================
2023-01-03 22:00:56,686:INFO:Initializing create_model()
2023-01-03 22:00:56,686:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CA7E2BF190>, estimator=br, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CA06F74DF0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:00:56,686:INFO:Checking exceptions
2023-01-03 22:00:56,686:INFO:Importing libraries
2023-01-03 22:00:56,686:INFO:Copying training dataset
2023-01-03 22:00:56,695:INFO:Defining folds
2023-01-03 22:00:56,696:INFO:Declaring metric variables
2023-01-03 22:00:56,701:INFO:Importing untrained model
2023-01-03 22:00:56,705:INFO:Bayesian Ridge Imported successfully
2023-01-03 22:00:56,715:INFO:Starting cross validation
2023-01-03 22:00:56,716:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:00:56,969:INFO:Calculating mean and std
2023-01-03 22:00:56,971:INFO:Creating metrics dataframe
2023-01-03 22:00:56,974:INFO:Uploading results into container
2023-01-03 22:00:56,975:INFO:Uploading model into container now
2023-01-03 22:00:56,975:INFO:_master_model_container: 8
2023-01-03 22:00:56,975:INFO:_display_container: 2
2023-01-03 22:00:56,975:INFO:BayesianRidge()
2023-01-03 22:00:56,976:INFO:create_model() successfully completed......................................
2023-01-03 22:00:57,084:INFO:SubProcess create_model() end ==================================
2023-01-03 22:00:57,084:INFO:Creating metrics dataframe
2023-01-03 22:00:57,096:INFO:Initializing Passive Aggressive Regressor
2023-01-03 22:00:57,096:INFO:Total runtime is 0.19931527376174926 minutes
2023-01-03 22:00:57,101:INFO:SubProcess create_model() called ==================================
2023-01-03 22:00:57,102:INFO:Initializing create_model()
2023-01-03 22:00:57,102:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CA7E2BF190>, estimator=par, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CA06F74DF0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:00:57,102:INFO:Checking exceptions
2023-01-03 22:00:57,102:INFO:Importing libraries
2023-01-03 22:00:57,103:INFO:Copying training dataset
2023-01-03 22:00:57,112:INFO:Defining folds
2023-01-03 22:00:57,113:INFO:Declaring metric variables
2023-01-03 22:00:57,117:INFO:Importing untrained model
2023-01-03 22:00:57,121:INFO:Passive Aggressive Regressor Imported successfully
2023-01-03 22:00:57,131:INFO:Starting cross validation
2023-01-03 22:00:57,132:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:00:57,395:INFO:Calculating mean and std
2023-01-03 22:00:57,397:INFO:Creating metrics dataframe
2023-01-03 22:00:57,401:INFO:Uploading results into container
2023-01-03 22:00:57,402:INFO:Uploading model into container now
2023-01-03 22:00:57,402:INFO:_master_model_container: 9
2023-01-03 22:00:57,403:INFO:_display_container: 2
2023-01-03 22:00:57,404:INFO:PassiveAggressiveRegressor(random_state=123)
2023-01-03 22:00:57,404:INFO:create_model() successfully completed......................................
2023-01-03 22:00:57,512:INFO:SubProcess create_model() end ==================================
2023-01-03 22:00:57,512:INFO:Creating metrics dataframe
2023-01-03 22:00:57,523:INFO:Initializing Huber Regressor
2023-01-03 22:00:57,524:INFO:Total runtime is 0.20643316904703776 minutes
2023-01-03 22:00:57,528:INFO:SubProcess create_model() called ==================================
2023-01-03 22:00:57,528:INFO:Initializing create_model()
2023-01-03 22:00:57,528:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CA7E2BF190>, estimator=huber, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CA06F74DF0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:00:57,528:INFO:Checking exceptions
2023-01-03 22:00:57,529:INFO:Importing libraries
2023-01-03 22:00:57,529:INFO:Copying training dataset
2023-01-03 22:00:57,538:INFO:Defining folds
2023-01-03 22:00:57,538:INFO:Declaring metric variables
2023-01-03 22:00:57,542:INFO:Importing untrained model
2023-01-03 22:00:57,547:INFO:Huber Regressor Imported successfully
2023-01-03 22:00:57,555:INFO:Starting cross validation
2023-01-03 22:00:57,557:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:00:57,665:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-03 22:00:57,801:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-03 22:00:57,903:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-03 22:00:57,997:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-03 22:00:58,126:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-03 22:00:58,244:INFO:Calculating mean and std
2023-01-03 22:00:58,246:INFO:Creating metrics dataframe
2023-01-03 22:00:58,252:INFO:Uploading results into container
2023-01-03 22:00:58,252:INFO:Uploading model into container now
2023-01-03 22:00:58,253:INFO:_master_model_container: 10
2023-01-03 22:00:58,253:INFO:_display_container: 2
2023-01-03 22:00:58,254:INFO:HuberRegressor()
2023-01-03 22:00:58,254:INFO:create_model() successfully completed......................................
2023-01-03 22:00:58,360:INFO:SubProcess create_model() end ==================================
2023-01-03 22:00:58,360:INFO:Creating metrics dataframe
2023-01-03 22:00:58,372:INFO:Initializing K Neighbors Regressor
2023-01-03 22:00:58,373:INFO:Total runtime is 0.22061071395874024 minutes
2023-01-03 22:00:58,377:INFO:SubProcess create_model() called ==================================
2023-01-03 22:00:58,377:INFO:Initializing create_model()
2023-01-03 22:00:58,377:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CA7E2BF190>, estimator=knn, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CA06F74DF0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:00:58,377:INFO:Checking exceptions
2023-01-03 22:00:58,377:INFO:Importing libraries
2023-01-03 22:00:58,377:INFO:Copying training dataset
2023-01-03 22:00:58,388:INFO:Defining folds
2023-01-03 22:00:58,388:INFO:Declaring metric variables
2023-01-03 22:00:58,392:INFO:Importing untrained model
2023-01-03 22:00:58,396:INFO:K Neighbors Regressor Imported successfully
2023-01-03 22:00:58,406:INFO:Starting cross validation
2023-01-03 22:00:58,407:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:00:59,098:INFO:Calculating mean and std
2023-01-03 22:00:59,100:INFO:Creating metrics dataframe
2023-01-03 22:00:59,105:INFO:Uploading results into container
2023-01-03 22:00:59,106:INFO:Uploading model into container now
2023-01-03 22:00:59,107:INFO:_master_model_container: 11
2023-01-03 22:00:59,107:INFO:_display_container: 2
2023-01-03 22:00:59,107:INFO:KNeighborsRegressor(n_jobs=-1)
2023-01-03 22:00:59,108:INFO:create_model() successfully completed......................................
2023-01-03 22:00:59,207:INFO:SubProcess create_model() end ==================================
2023-01-03 22:00:59,207:INFO:Creating metrics dataframe
2023-01-03 22:00:59,220:INFO:Initializing Decision Tree Regressor
2023-01-03 22:00:59,221:INFO:Total runtime is 0.23473281462987264 minutes
2023-01-03 22:00:59,225:INFO:SubProcess create_model() called ==================================
2023-01-03 22:00:59,225:INFO:Initializing create_model()
2023-01-03 22:00:59,225:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CA7E2BF190>, estimator=dt, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CA06F74DF0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:00:59,225:INFO:Checking exceptions
2023-01-03 22:00:59,226:INFO:Importing libraries
2023-01-03 22:00:59,226:INFO:Copying training dataset
2023-01-03 22:00:59,236:INFO:Defining folds
2023-01-03 22:00:59,236:INFO:Declaring metric variables
2023-01-03 22:00:59,240:INFO:Importing untrained model
2023-01-03 22:00:59,244:INFO:Decision Tree Regressor Imported successfully
2023-01-03 22:00:59,252:INFO:Starting cross validation
2023-01-03 22:00:59,254:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:00:59,712:INFO:Calculating mean and std
2023-01-03 22:00:59,714:INFO:Creating metrics dataframe
2023-01-03 22:00:59,717:INFO:Uploading results into container
2023-01-03 22:00:59,718:INFO:Uploading model into container now
2023-01-03 22:00:59,719:INFO:_master_model_container: 12
2023-01-03 22:00:59,719:INFO:_display_container: 2
2023-01-03 22:00:59,720:INFO:DecisionTreeRegressor(random_state=123)
2023-01-03 22:00:59,720:INFO:create_model() successfully completed......................................
2023-01-03 22:00:59,837:INFO:SubProcess create_model() end ==================================
2023-01-03 22:00:59,837:INFO:Creating metrics dataframe
2023-01-03 22:00:59,849:INFO:Initializing Random Forest Regressor
2023-01-03 22:00:59,849:INFO:Total runtime is 0.24520939191182453 minutes
2023-01-03 22:00:59,853:INFO:SubProcess create_model() called ==================================
2023-01-03 22:00:59,853:INFO:Initializing create_model()
2023-01-03 22:00:59,853:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CA7E2BF190>, estimator=rf, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CA06F74DF0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:00:59,853:INFO:Checking exceptions
2023-01-03 22:00:59,853:INFO:Importing libraries
2023-01-03 22:00:59,854:INFO:Copying training dataset
2023-01-03 22:00:59,862:INFO:Defining folds
2023-01-03 22:00:59,863:INFO:Declaring metric variables
2023-01-03 22:00:59,867:INFO:Importing untrained model
2023-01-03 22:00:59,871:INFO:Random Forest Regressor Imported successfully
2023-01-03 22:00:59,880:INFO:Starting cross validation
2023-01-03 22:00:59,881:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:01:09,388:INFO:Calculating mean and std
2023-01-03 22:01:09,390:INFO:Creating metrics dataframe
2023-01-03 22:01:09,393:INFO:Uploading results into container
2023-01-03 22:01:09,393:INFO:Uploading model into container now
2023-01-03 22:01:09,394:INFO:_master_model_container: 13
2023-01-03 22:01:09,394:INFO:_display_container: 2
2023-01-03 22:01:09,394:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-01-03 22:01:09,394:INFO:create_model() successfully completed......................................
2023-01-03 22:01:09,492:INFO:SubProcess create_model() end ==================================
2023-01-03 22:01:09,493:INFO:Creating metrics dataframe
2023-01-03 22:01:09,507:INFO:Initializing Extra Trees Regressor
2023-01-03 22:01:09,508:INFO:Total runtime is 0.40619277159372963 minutes
2023-01-03 22:01:09,512:INFO:SubProcess create_model() called ==================================
2023-01-03 22:01:09,512:INFO:Initializing create_model()
2023-01-03 22:01:09,513:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CA7E2BF190>, estimator=et, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CA06F74DF0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:01:09,513:INFO:Checking exceptions
2023-01-03 22:01:09,513:INFO:Importing libraries
2023-01-03 22:01:09,513:INFO:Copying training dataset
2023-01-03 22:01:09,524:INFO:Defining folds
2023-01-03 22:01:09,524:INFO:Declaring metric variables
2023-01-03 22:01:09,528:INFO:Importing untrained model
2023-01-03 22:01:09,533:INFO:Extra Trees Regressor Imported successfully
2023-01-03 22:01:09,540:INFO:Starting cross validation
2023-01-03 22:01:09,542:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:01:13,960:INFO:Calculating mean and std
2023-01-03 22:01:13,963:INFO:Creating metrics dataframe
2023-01-03 22:01:13,967:INFO:Uploading results into container
2023-01-03 22:01:13,968:INFO:Uploading model into container now
2023-01-03 22:01:13,968:INFO:_master_model_container: 14
2023-01-03 22:01:13,968:INFO:_display_container: 2
2023-01-03 22:01:13,969:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-01-03 22:01:13,969:INFO:create_model() successfully completed......................................
2023-01-03 22:01:14,097:INFO:SubProcess create_model() end ==================================
2023-01-03 22:01:14,097:INFO:Creating metrics dataframe
2023-01-03 22:01:14,114:INFO:Initializing AdaBoost Regressor
2023-01-03 22:01:14,114:INFO:Total runtime is 0.48295943339665726 minutes
2023-01-03 22:01:14,119:INFO:SubProcess create_model() called ==================================
2023-01-03 22:01:14,119:INFO:Initializing create_model()
2023-01-03 22:01:14,119:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CA7E2BF190>, estimator=ada, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CA06F74DF0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:01:14,119:INFO:Checking exceptions
2023-01-03 22:01:14,119:INFO:Importing libraries
2023-01-03 22:01:14,120:INFO:Copying training dataset
2023-01-03 22:01:14,130:INFO:Defining folds
2023-01-03 22:01:14,130:INFO:Declaring metric variables
2023-01-03 22:01:14,140:INFO:Importing untrained model
2023-01-03 22:01:14,147:INFO:AdaBoost Regressor Imported successfully
2023-01-03 22:01:14,164:INFO:Starting cross validation
2023-01-03 22:01:14,165:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:01:16,318:INFO:Calculating mean and std
2023-01-03 22:01:16,321:INFO:Creating metrics dataframe
2023-01-03 22:01:16,325:INFO:Uploading results into container
2023-01-03 22:01:16,326:INFO:Uploading model into container now
2023-01-03 22:01:16,327:INFO:_master_model_container: 15
2023-01-03 22:01:16,327:INFO:_display_container: 2
2023-01-03 22:01:16,327:INFO:AdaBoostRegressor(random_state=123)
2023-01-03 22:01:16,327:INFO:create_model() successfully completed......................................
2023-01-03 22:01:16,463:INFO:SubProcess create_model() end ==================================
2023-01-03 22:01:16,464:INFO:Creating metrics dataframe
2023-01-03 22:01:16,484:INFO:Initializing Gradient Boosting Regressor
2023-01-03 22:01:16,484:INFO:Total runtime is 0.5224594990412393 minutes
2023-01-03 22:01:16,490:INFO:SubProcess create_model() called ==================================
2023-01-03 22:01:16,490:INFO:Initializing create_model()
2023-01-03 22:01:16,490:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CA7E2BF190>, estimator=gbr, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CA06F74DF0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:01:16,491:INFO:Checking exceptions
2023-01-03 22:01:16,491:INFO:Importing libraries
2023-01-03 22:01:16,491:INFO:Copying training dataset
2023-01-03 22:01:16,502:INFO:Defining folds
2023-01-03 22:01:16,502:INFO:Declaring metric variables
2023-01-03 22:01:16,507:INFO:Importing untrained model
2023-01-03 22:01:16,511:INFO:Gradient Boosting Regressor Imported successfully
2023-01-03 22:01:16,521:INFO:Starting cross validation
2023-01-03 22:01:16,522:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:01:22,240:INFO:Calculating mean and std
2023-01-03 22:01:22,242:INFO:Creating metrics dataframe
2023-01-03 22:01:22,245:INFO:Uploading results into container
2023-01-03 22:01:22,245:INFO:Uploading model into container now
2023-01-03 22:01:22,246:INFO:_master_model_container: 16
2023-01-03 22:01:22,246:INFO:_display_container: 2
2023-01-03 22:01:22,247:INFO:GradientBoostingRegressor(random_state=123)
2023-01-03 22:01:22,247:INFO:create_model() successfully completed......................................
2023-01-03 22:01:22,353:INFO:SubProcess create_model() end ==================================
2023-01-03 22:01:22,353:INFO:Creating metrics dataframe
2023-01-03 22:01:22,369:INFO:Initializing Light Gradient Boosting Machine
2023-01-03 22:01:22,370:INFO:Total runtime is 0.6205539385477701 minutes
2023-01-03 22:01:22,376:INFO:SubProcess create_model() called ==================================
2023-01-03 22:01:22,376:INFO:Initializing create_model()
2023-01-03 22:01:22,376:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CA7E2BF190>, estimator=lightgbm, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CA06F74DF0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:01:22,376:INFO:Checking exceptions
2023-01-03 22:01:22,377:INFO:Importing libraries
2023-01-03 22:01:22,377:INFO:Copying training dataset
2023-01-03 22:01:22,388:INFO:Defining folds
2023-01-03 22:01:22,388:INFO:Declaring metric variables
2023-01-03 22:01:22,395:INFO:Importing untrained model
2023-01-03 22:01:22,401:INFO:Light Gradient Boosting Machine Imported successfully
2023-01-03 22:01:22,408:INFO:Starting cross validation
2023-01-03 22:01:22,410:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:01:24,886:INFO:Calculating mean and std
2023-01-03 22:01:24,888:INFO:Creating metrics dataframe
2023-01-03 22:01:24,891:INFO:Uploading results into container
2023-01-03 22:01:24,892:INFO:Uploading model into container now
2023-01-03 22:01:24,892:INFO:_master_model_container: 17
2023-01-03 22:01:24,892:INFO:_display_container: 2
2023-01-03 22:01:24,892:INFO:LGBMRegressor(random_state=123)
2023-01-03 22:01:24,892:INFO:create_model() successfully completed......................................
2023-01-03 22:01:24,997:INFO:SubProcess create_model() end ==================================
2023-01-03 22:01:24,998:INFO:Creating metrics dataframe
2023-01-03 22:01:25,014:INFO:Initializing Dummy Regressor
2023-01-03 22:01:25,014:INFO:Total runtime is 0.664627703030904 minutes
2023-01-03 22:01:25,019:INFO:SubProcess create_model() called ==================================
2023-01-03 22:01:25,019:INFO:Initializing create_model()
2023-01-03 22:01:25,020:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CA7E2BF190>, estimator=dummy, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CA06F74DF0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:01:25,020:INFO:Checking exceptions
2023-01-03 22:01:25,020:INFO:Importing libraries
2023-01-03 22:01:25,020:INFO:Copying training dataset
2023-01-03 22:01:25,030:INFO:Defining folds
2023-01-03 22:01:25,030:INFO:Declaring metric variables
2023-01-03 22:01:25,035:INFO:Importing untrained model
2023-01-03 22:01:25,039:INFO:Dummy Regressor Imported successfully
2023-01-03 22:01:25,046:INFO:Starting cross validation
2023-01-03 22:01:25,049:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:01:25,279:INFO:Calculating mean and std
2023-01-03 22:01:25,280:INFO:Creating metrics dataframe
2023-01-03 22:01:25,283:INFO:Uploading results into container
2023-01-03 22:01:25,283:INFO:Uploading model into container now
2023-01-03 22:01:25,284:INFO:_master_model_container: 18
2023-01-03 22:01:25,284:INFO:_display_container: 2
2023-01-03 22:01:25,285:INFO:DummyRegressor()
2023-01-03 22:01:25,285:INFO:create_model() successfully completed......................................
2023-01-03 22:01:25,387:INFO:SubProcess create_model() end ==================================
2023-01-03 22:01:25,387:INFO:Creating metrics dataframe
2023-01-03 22:01:25,413:INFO:Initializing create_model()
2023-01-03 22:01:25,414:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CA7E2BF190>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:01:25,414:INFO:Checking exceptions
2023-01-03 22:01:25,416:INFO:Importing libraries
2023-01-03 22:01:25,416:INFO:Copying training dataset
2023-01-03 22:01:25,425:INFO:Defining folds
2023-01-03 22:01:25,425:INFO:Declaring metric variables
2023-01-03 22:01:25,425:INFO:Importing untrained model
2023-01-03 22:01:25,425:INFO:Declaring custom model
2023-01-03 22:01:25,426:INFO:Extra Trees Regressor Imported successfully
2023-01-03 22:01:25,427:INFO:Cross validation set to False
2023-01-03 22:01:25,427:INFO:Fitting Model
2023-01-03 22:01:27,170:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-01-03 22:01:27,171:INFO:create_model() successfully completed......................................
2023-01-03 22:01:27,311:INFO:_master_model_container: 18
2023-01-03 22:01:27,312:INFO:_display_container: 2
2023-01-03 22:01:27,312:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-01-03 22:01:27,312:INFO:compare_models() successfully completed......................................
2023-01-03 22:01:27,313:INFO:Initializing tune_model()
2023-01-03 22:01:27,313:INFO:tune_model(estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=MAE, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CA7E2BF190>)
2023-01-03 22:01:27,313:INFO:Checking exceptions
2023-01-03 22:01:27,347:INFO:Copying training dataset
2023-01-03 22:01:27,357:INFO:Checking base model
2023-01-03 22:01:27,357:INFO:Base model : Extra Trees Regressor
2023-01-03 22:01:27,362:INFO:Declaring metric variables
2023-01-03 22:01:27,366:INFO:Defining Hyperparameters
2023-01-03 22:01:27,550:INFO:Tuning with n_jobs=-1
2023-01-03 22:01:27,550:INFO:Initializing RandomizedSearchCV
2023-01-03 22:01:27,602:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:01:27,605:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:01:27,610:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:01:27,636:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:01:27,885:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:01:27,941:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:01:27,948:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:01:28,209:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:01:28,258:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:01:28,287:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:01:28,332:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:01:28,506:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:01:28,547:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:01:28,578:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:01:29,020:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:01:29,089:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:01:29,114:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:01:29,397:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:01:29,411:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:01:29,602:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:01:29,893:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:01:30,033:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:01:30,155:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:01:30,277:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:01:30,441:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:01:30,526:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 22:01:30,785:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 22:01:31,122:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 22:01:31,652:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 22:01:31,674:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 22:01:35,645:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:01:39,459:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:01:40,229:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:01:41,704:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:01:42,498:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:01:43,906:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:01:44,686:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:01:45,291:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:01:45,385:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:01:45,616:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:01:46,392:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 22:01:46,577:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 22:01:46,828:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 22:01:49,192:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 22:01:52,197:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 22:01:52,414:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:01:55,359:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:01:58,046:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:01:58,382:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:02:00,420:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:02:08,702:INFO:best_params: {'actual_estimator__n_estimators': 100, 'actual_estimator__min_samples_split': 7, 'actual_estimator__min_samples_leaf': 4, 'actual_estimator__min_impurity_decrease': 0.1, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 9, 'actual_estimator__criterion': 'mse', 'actual_estimator__bootstrap': True}
2023-01-03 22:02:08,704:INFO:Hyperparameter search completed
2023-01-03 22:02:08,704:INFO:SubProcess create_model() called ==================================
2023-01-03 22:02:08,705:INFO:Initializing create_model()
2023-01-03 22:02:08,705:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CA7E2BF190>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CA091E50A0>, model_only=True, return_train_score=False, kwargs={'n_estimators': 100, 'min_samples_split': 7, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.1, 'max_features': 1.0, 'max_depth': 9, 'criterion': 'mse', 'bootstrap': True})
2023-01-03 22:02:08,706:INFO:Checking exceptions
2023-01-03 22:02:08,706:INFO:Importing libraries
2023-01-03 22:02:08,706:INFO:Copying training dataset
2023-01-03 22:02:08,716:INFO:Defining folds
2023-01-03 22:02:08,716:INFO:Declaring metric variables
2023-01-03 22:02:08,720:INFO:Importing untrained model
2023-01-03 22:02:08,720:INFO:Declaring custom model
2023-01-03 22:02:08,725:INFO:Extra Trees Regressor Imported successfully
2023-01-03 22:02:08,732:INFO:Starting cross validation
2023-01-03 22:02:08,733:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:02:08,784:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:02:08,787:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:02:08,801:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:02:08,826:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:02:09,250:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:02:09,681:INFO:Calculating mean and std
2023-01-03 22:02:09,683:INFO:Creating metrics dataframe
2023-01-03 22:02:09,689:INFO:Finalizing model
2023-01-03 22:02:10,028:INFO:Uploading results into container
2023-01-03 22:02:10,029:INFO:Uploading model into container now
2023-01-03 22:02:10,030:INFO:_master_model_container: 19
2023-01-03 22:02:10,030:INFO:_display_container: 3
2023-01-03 22:02:10,031:INFO:ExtraTreesRegressor(bootstrap=True, criterion='mse', max_depth=9,
                    max_features=1.0, min_impurity_decrease=0.1,
                    min_samples_leaf=4, min_samples_split=7, n_jobs=-1,
                    random_state=123)
2023-01-03 22:02:10,031:INFO:create_model() successfully completed......................................
2023-01-03 22:02:10,145:INFO:SubProcess create_model() end ==================================
2023-01-03 22:02:10,145:INFO:choose_better activated
2023-01-03 22:02:10,148:INFO:SubProcess create_model() called ==================================
2023-01-03 22:02:10,149:INFO:Initializing create_model()
2023-01-03 22:02:10,149:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CA7E2BF190>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:02:10,149:INFO:Checking exceptions
2023-01-03 22:02:10,151:INFO:Importing libraries
2023-01-03 22:02:10,151:INFO:Copying training dataset
2023-01-03 22:02:10,160:INFO:Defining folds
2023-01-03 22:02:10,161:INFO:Declaring metric variables
2023-01-03 22:02:10,161:INFO:Importing untrained model
2023-01-03 22:02:10,161:INFO:Declaring custom model
2023-01-03 22:02:10,162:INFO:Extra Trees Regressor Imported successfully
2023-01-03 22:02:10,162:INFO:Starting cross validation
2023-01-03 22:02:10,163:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:02:14,371:INFO:Calculating mean and std
2023-01-03 22:02:14,372:INFO:Creating metrics dataframe
2023-01-03 22:02:14,374:INFO:Finalizing model
2023-01-03 22:02:16,051:INFO:Uploading results into container
2023-01-03 22:02:16,052:INFO:Uploading model into container now
2023-01-03 22:02:16,052:INFO:_master_model_container: 20
2023-01-03 22:02:16,052:INFO:_display_container: 4
2023-01-03 22:02:16,053:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-01-03 22:02:16,053:INFO:create_model() successfully completed......................................
2023-01-03 22:02:16,152:INFO:SubProcess create_model() end ==================================
2023-01-03 22:02:16,153:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123) result for MAE is 1.8353
2023-01-03 22:02:16,154:INFO:ExtraTreesRegressor(bootstrap=True, criterion='mse', max_depth=9,
                    max_features=1.0, min_impurity_decrease=0.1,
                    min_samples_leaf=4, min_samples_split=7, n_jobs=-1,
                    random_state=123) result for MAE is 2.5141
2023-01-03 22:02:16,154:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123) is best model
2023-01-03 22:02:16,154:INFO:choose_better completed
2023-01-03 22:02:16,154:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-01-03 22:02:16,163:INFO:_master_model_container: 20
2023-01-03 22:02:16,164:INFO:_display_container: 3
2023-01-03 22:02:16,164:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-01-03 22:02:16,164:INFO:tune_model() successfully completed......................................
2023-01-03 22:02:16,278:INFO:Initializing plot_model()
2023-01-03 22:02:16,278:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CA7E2BF190>, system=True)
2023-01-03 22:02:16,278:INFO:Checking exceptions
2023-01-03 22:02:16,305:INFO:Preloading libraries
2023-01-03 22:02:16,440:INFO:Copying training dataset
2023-01-03 22:02:16,440:INFO:Plot type: error
2023-01-03 22:02:16,598:INFO:Fitting Model
2023-01-03 22:02:16,598:INFO:Scoring test/hold-out set
2023-01-03 22:02:17,049:INFO:Visual Rendered Successfully
2023-01-03 22:02:17,151:INFO:plot_model() successfully completed......................................
2023-01-03 22:02:17,162:INFO:Initializing predict_model()
2023-01-03 22:02:17,163:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CA7E2BF190>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001CA08E8CAF0>)
2023-01-03 22:02:17,163:INFO:Checking exceptions
2023-01-03 22:02:17,163:INFO:Preloading libraries
2023-01-03 22:02:17,376:INFO:Initializing finalize_model()
2023-01-03 22:02:17,376:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CA7E2BF190>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-01-03 22:02:17,377:INFO:Finalizing ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-01-03 22:02:17,385:INFO:Initializing create_model()
2023-01-03 22:02:17,385:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CA7E2BF190>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-01-03 22:02:17,385:INFO:Checking exceptions
2023-01-03 22:02:17,387:INFO:Importing libraries
2023-01-03 22:02:17,387:INFO:Copying training dataset
2023-01-03 22:02:17,388:INFO:Defining folds
2023-01-03 22:02:17,388:INFO:Declaring metric variables
2023-01-03 22:02:17,388:INFO:Importing untrained model
2023-01-03 22:02:17,388:INFO:Declaring custom model
2023-01-03 22:02:17,389:INFO:Extra Trees Regressor Imported successfully
2023-01-03 22:02:17,389:INFO:Cross validation set to False
2023-01-03 22:02:17,390:INFO:Fitting Model
2023-01-03 22:02:20,778:INFO:Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))])
2023-01-03 22:02:20,778:INFO:create_model() successfully completed......................................
2023-01-03 22:02:20,893:INFO:_master_model_container: 20
2023-01-03 22:02:20,893:INFO:_display_container: 4
2023-01-03 22:02:20,900:INFO:Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))])
2023-01-03 22:02:20,900:INFO:finalize_model() successfully completed......................................
2023-01-03 22:02:21,004:INFO:Initializing predict_model()
2023-01-03 22:02:21,005:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CA7E2BF190>, estimator=Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001CA08ABD790>)
2023-01-03 22:02:21,005:INFO:Checking exceptions
2023-01-03 22:02:21,005:INFO:Preloading libraries
2023-01-03 22:02:21,007:INFO:Set up data.
2023-01-03 22:02:21,021:INFO:Set up index.
2023-01-03 22:02:21,479:INFO:Initializing save_model()
2023-01-03 22:02:21,480:INFO:save_model(model=Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))]), model_name=c:\Users\Kodotautas\Desktop\Data_science\7_TIME_SERIES_FORECAST_PYCARET/models/final_model.pkl, prep_pipe_=Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-01-03 22:02:21,480:INFO:Adding model into prep_pipe
2023-01-03 22:02:21,643:WARNING:Only Model saved as it was a pipeline.
2023-01-03 22:02:21,788:INFO:c:\Users\Kodotautas\Desktop\Data_science\7_TIME_SERIES_FORECAST_PYCARET/models/final_model.pkl.pkl saved in current working directory
2023-01-03 22:02:21,795:INFO:Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))])
2023-01-03 22:02:21,795:INFO:save_model() successfully completed......................................
2023-01-03 22:06:10,739:INFO:PyCaret RegressionExperiment
2023-01-03 22:06:10,740:INFO:Logging name: reg-default-name
2023-01-03 22:06:10,740:INFO:ML Usecase: MLUsecase.REGRESSION
2023-01-03 22:06:10,740:INFO:version 3.0.0.rc6
2023-01-03 22:06:10,740:INFO:Initializing setup()
2023-01-03 22:06:10,740:INFO:self.USI: 2c46
2023-01-03 22:06:10,740:INFO:self._variable_keys: {'X_train', 'fold_shuffle_param', 'exp_id', 'memory', 'logging_param', 'fold_generator', 'y_train', 'n_jobs_param', '_ml_usecase', 'USI', 'X', 'y_test', 'data', 'fold_groups_param', 'y', 'X_test', 'log_plots_param', 'seed', 'gpu_n_jobs_param', 'transform_target_param', '_available_plots', 'gpu_param', 'target_param', 'html_param', 'exp_name_log', 'pipeline', 'idx'}
2023-01-03 22:06:10,740:INFO:Checking environment
2023-01-03 22:06:10,740:INFO:python_version: 3.9.13
2023-01-03 22:06:10,740:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-01-03 22:06:10,740:INFO:machine: AMD64
2023-01-03 22:06:10,740:INFO:platform: Windows-10-10.0.19044-SP0
2023-01-03 22:06:10,740:INFO:Memory: svmem(total=17114804224, available=8314490880, percent=51.4, used=8800313344, free=8314490880)
2023-01-03 22:06:10,740:INFO:Physical Core: 4
2023-01-03 22:06:10,740:INFO:Logical Core: 4
2023-01-03 22:06:10,740:INFO:Checking libraries
2023-01-03 22:06:10,740:INFO:System:
2023-01-03 22:06:10,740:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-01-03 22:06:10,740:INFO:executable: c:\Users\Kodotautas\anaconda3\python.exe
2023-01-03 22:06:10,740:INFO:   machine: Windows-10-10.0.19044-SP0
2023-01-03 22:06:10,741:INFO:PyCaret required dependencies:
2023-01-03 22:06:10,741:INFO:                 pip: 22.2.2
2023-01-03 22:06:10,741:INFO:          setuptools: 63.4.1
2023-01-03 22:06:10,741:INFO:             pycaret: 3.0.0rc6
2023-01-03 22:06:10,741:INFO:             IPython: 7.31.1
2023-01-03 22:06:10,741:INFO:          ipywidgets: 7.6.5
2023-01-03 22:06:10,741:INFO:                tqdm: 4.64.1
2023-01-03 22:06:10,741:INFO:               numpy: 1.21.5
2023-01-03 22:06:10,741:INFO:              pandas: 1.4.4
2023-01-03 22:06:10,741:INFO:              jinja2: 2.11.3
2023-01-03 22:06:10,741:INFO:               scipy: 1.9.1
2023-01-03 22:06:10,741:INFO:              joblib: 1.2.0
2023-01-03 22:06:10,741:INFO:             sklearn: 1.0.2
2023-01-03 22:06:10,741:INFO:                pyod: 1.0.7
2023-01-03 22:06:10,741:INFO:            imblearn: 0.10.1
2023-01-03 22:06:10,741:INFO:   category_encoders: 2.5.1.post0
2023-01-03 22:06:10,741:INFO:            lightgbm: 3.3.3
2023-01-03 22:06:10,741:INFO:               numba: 0.55.1
2023-01-03 22:06:10,741:INFO:            requests: 2.28.1
2023-01-03 22:06:10,741:INFO:          matplotlib: 3.5.2
2023-01-03 22:06:10,741:INFO:          scikitplot: 0.3.7
2023-01-03 22:06:10,741:INFO:         yellowbrick: 1.5
2023-01-03 22:06:10,742:INFO:              plotly: 5.9.0
2023-01-03 22:06:10,742:INFO:             kaleido: 0.2.1
2023-01-03 22:06:10,742:INFO:         statsmodels: 0.13.2
2023-01-03 22:06:10,742:INFO:              sktime: 0.14.1
2023-01-03 22:06:10,742:INFO:               tbats: 1.1.2
2023-01-03 22:06:10,742:INFO:            pmdarima: 2.0.2
2023-01-03 22:06:10,742:INFO:              psutil: 5.9.0
2023-01-03 22:06:10,742:INFO:PyCaret optional dependencies:
2023-01-03 22:06:10,742:INFO:                shap: 0.41.0
2023-01-03 22:06:10,742:INFO:           interpret: Not installed
2023-01-03 22:06:10,742:INFO:                umap: Not installed
2023-01-03 22:06:10,742:INFO:    pandas_profiling: Not installed
2023-01-03 22:06:10,742:INFO:  explainerdashboard: Not installed
2023-01-03 22:06:10,742:INFO:             autoviz: Not installed
2023-01-03 22:06:10,742:INFO:           fairlearn: Not installed
2023-01-03 22:06:10,742:INFO:             xgboost: Not installed
2023-01-03 22:06:10,742:INFO:            catboost: Not installed
2023-01-03 22:06:10,742:INFO:              kmodes: Not installed
2023-01-03 22:06:10,742:INFO:             mlxtend: Not installed
2023-01-03 22:06:10,742:INFO:       statsforecast: Not installed
2023-01-03 22:06:10,742:INFO:        tune_sklearn: 0.4.3
2023-01-03 22:06:10,742:INFO:                 ray: 2.0.0
2023-01-03 22:06:10,743:INFO:            hyperopt: 0.2.7
2023-01-03 22:06:10,743:INFO:              optuna: 3.0.1
2023-01-03 22:06:10,743:INFO:               skopt: 0.9.0
2023-01-03 22:06:10,743:INFO:              mlflow: Not installed
2023-01-03 22:06:10,743:INFO:              gradio: Not installed
2023-01-03 22:06:10,743:INFO:             fastapi: 0.88.0
2023-01-03 22:06:10,743:INFO:             uvicorn: 0.20.0
2023-01-03 22:06:10,743:INFO:              m2cgen: Not installed
2023-01-03 22:06:10,743:INFO:           evidently: Not installed
2023-01-03 22:06:10,743:INFO:                nltk: 3.7
2023-01-03 22:06:10,743:INFO:            pyLDAvis: Not installed
2023-01-03 22:06:10,743:INFO:              gensim: 4.1.2
2023-01-03 22:06:10,743:INFO:               spacy: 3.4.2
2023-01-03 22:06:10,743:INFO:           wordcloud: Not installed
2023-01-03 22:06:10,743:INFO:            textblob: Not installed
2023-01-03 22:06:10,743:INFO:               fugue: Not installed
2023-01-03 22:06:10,743:INFO:           streamlit: Not installed
2023-01-03 22:06:10,743:INFO:             prophet: Not installed
2023-01-03 22:06:10,743:INFO:None
2023-01-03 22:06:10,743:INFO:Set up data.
2023-01-03 22:06:10,798:INFO:Set up train/test split.
2023-01-03 22:06:10,810:INFO:Set up index.
2023-01-03 22:06:10,812:INFO:Set up folding strategy.
2023-01-03 22:06:10,813:INFO:Assigning column types.
2023-01-03 22:06:10,826:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-01-03 22:06:10,826:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-01-03 22:06:10,831:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-03 22:06:10,837:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 22:06:10,914:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 22:06:10,963:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 22:06:10,964:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:06:10,964:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:06:10,965:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-01-03 22:06:10,970:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-03 22:06:10,975:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 22:06:11,042:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 22:06:11,093:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 22:06:11,093:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:06:11,094:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:06:11,094:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-01-03 22:06:11,099:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-03 22:06:11,104:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 22:06:11,177:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 22:06:11,228:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 22:06:11,228:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:06:11,228:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:06:11,234:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-03 22:06:11,239:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 22:06:11,311:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 22:06:11,361:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 22:06:11,362:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:06:11,362:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:06:11,363:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-01-03 22:06:11,373:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 22:06:11,447:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 22:06:11,496:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 22:06:11,498:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:06:11,498:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:06:11,508:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 22:06:11,576:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 22:06:11,625:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 22:06:11,626:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:06:11,626:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:06:11,626:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-01-03 22:06:11,706:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 22:06:11,755:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 22:06:11,755:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:06:11,759:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:06:11,839:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 22:06:11,891:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 22:06:11,892:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:06:11,892:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:06:11,893:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-01-03 22:06:11,976:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 22:06:12,027:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:06:12,027:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:06:12,109:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 22:06:12,158:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:06:12,158:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:06:12,159:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-01-03 22:06:12,292:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:06:12,292:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:06:12,427:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:06:12,427:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:06:12,428:INFO:Preparing preprocessing pipeline...
2023-01-03 22:06:12,430:INFO:Set up simple imputation.
2023-01-03 22:06:12,430:INFO:Set up column transformation.
2023-01-03 22:06:12,431:INFO:Set up feature normalization.
2023-01-03 22:06:13,039:INFO:Finished creating preprocessing pipeline.
2023-01-03 22:06:13,045:INFO:Pipeline: Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2023-01-03 22:06:13,045:INFO:Creating final display dataframe.
2023-01-03 22:06:13,642:INFO:Setup _display_container:                Description             Value
0               Session id               123
1                   Target        b2b+b2c+vt
2              Target type        Regression
3               Data shape       (10506, 45)
4         Train data shape        (7354, 45)
5          Test data shape        (3152, 45)
6         Numeric features                 8
7               Preprocess              True
8          Imputation type            simple
9       Numeric imputation              mean
10  Categorical imputation              mode
11          Transformation              True
12   Transformation method       yeo-johnson
13               Normalize              True
14        Normalize method            zscore
15          Fold Generator   TimeSeriesSplit
16             Fold Number                 5
17                CPU Jobs                -1
18                 Use GPU             False
19          Log Experiment             False
20         Experiment Name  reg-default-name
21                     USI              2c46
2023-01-03 22:06:13,835:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:06:13,836:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:06:14,026:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:06:14,026:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:06:14,044:INFO:setup() successfully completed in 3.3s...............
2023-01-03 22:06:14,045:INFO:Initializing compare_models()
2023-01-03 22:06:14,045:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CA7E070910>, include=None, fold=None, round=4, cross_validation=True, sort=MAE, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001CA7E070910>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'MAE', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-01-03 22:06:14,045:INFO:Checking exceptions
2023-01-03 22:06:14,054:INFO:Preparing display monitor
2023-01-03 22:06:14,112:INFO:Initializing Linear Regression
2023-01-03 22:06:14,112:INFO:Total runtime is 0.0 minutes
2023-01-03 22:06:14,116:INFO:SubProcess create_model() called ==================================
2023-01-03 22:06:14,116:INFO:Initializing create_model()
2023-01-03 22:06:14,116:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CA7E070910>, estimator=lr, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CA31825C70>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:06:14,116:INFO:Checking exceptions
2023-01-03 22:06:14,116:INFO:Importing libraries
2023-01-03 22:06:14,116:INFO:Copying training dataset
2023-01-03 22:06:14,125:INFO:Defining folds
2023-01-03 22:06:14,125:INFO:Declaring metric variables
2023-01-03 22:06:14,128:INFO:Importing untrained model
2023-01-03 22:06:14,132:INFO:Linear Regression Imported successfully
2023-01-03 22:06:14,139:INFO:Starting cross validation
2023-01-03 22:06:14,140:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:06:16,543:INFO:Calculating mean and std
2023-01-03 22:06:16,545:INFO:Creating metrics dataframe
2023-01-03 22:06:16,550:INFO:Uploading results into container
2023-01-03 22:06:16,551:INFO:Uploading model into container now
2023-01-03 22:06:16,551:INFO:_master_model_container: 1
2023-01-03 22:06:16,551:INFO:_display_container: 2
2023-01-03 22:06:16,552:INFO:LinearRegression(n_jobs=-1)
2023-01-03 22:06:16,552:INFO:create_model() successfully completed......................................
2023-01-03 22:06:16,675:INFO:SubProcess create_model() end ==================================
2023-01-03 22:06:16,676:INFO:Creating metrics dataframe
2023-01-03 22:06:16,686:INFO:Initializing Lasso Regression
2023-01-03 22:06:16,686:INFO:Total runtime is 0.04290000597635905 minutes
2023-01-03 22:06:16,690:INFO:SubProcess create_model() called ==================================
2023-01-03 22:06:16,690:INFO:Initializing create_model()
2023-01-03 22:06:16,691:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CA7E070910>, estimator=lasso, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CA31825C70>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:06:16,691:INFO:Checking exceptions
2023-01-03 22:06:16,691:INFO:Importing libraries
2023-01-03 22:06:16,691:INFO:Copying training dataset
2023-01-03 22:06:16,703:INFO:Defining folds
2023-01-03 22:06:16,703:INFO:Declaring metric variables
2023-01-03 22:06:16,707:INFO:Importing untrained model
2023-01-03 22:06:16,711:INFO:Lasso Regression Imported successfully
2023-01-03 22:06:16,720:INFO:Starting cross validation
2023-01-03 22:06:16,722:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:06:17,091:INFO:Calculating mean and std
2023-01-03 22:06:17,093:INFO:Creating metrics dataframe
2023-01-03 22:06:17,098:INFO:Uploading results into container
2023-01-03 22:06:17,099:INFO:Uploading model into container now
2023-01-03 22:06:17,100:INFO:_master_model_container: 2
2023-01-03 22:06:17,100:INFO:_display_container: 2
2023-01-03 22:06:17,101:INFO:Lasso(random_state=123)
2023-01-03 22:06:17,101:INFO:create_model() successfully completed......................................
2023-01-03 22:06:17,217:INFO:SubProcess create_model() end ==================================
2023-01-03 22:06:17,217:INFO:Creating metrics dataframe
2023-01-03 22:06:17,226:INFO:Initializing Ridge Regression
2023-01-03 22:06:17,227:INFO:Total runtime is 0.05191670656204223 minutes
2023-01-03 22:06:17,230:INFO:SubProcess create_model() called ==================================
2023-01-03 22:06:17,231:INFO:Initializing create_model()
2023-01-03 22:06:17,231:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CA7E070910>, estimator=ridge, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CA31825C70>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:06:17,231:INFO:Checking exceptions
2023-01-03 22:06:17,231:INFO:Importing libraries
2023-01-03 22:06:17,231:INFO:Copying training dataset
2023-01-03 22:06:17,240:INFO:Defining folds
2023-01-03 22:06:17,240:INFO:Declaring metric variables
2023-01-03 22:06:17,244:INFO:Importing untrained model
2023-01-03 22:06:17,249:INFO:Ridge Regression Imported successfully
2023-01-03 22:06:17,259:INFO:Starting cross validation
2023-01-03 22:06:17,260:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:06:17,517:INFO:Calculating mean and std
2023-01-03 22:06:17,519:INFO:Creating metrics dataframe
2023-01-03 22:06:17,524:INFO:Uploading results into container
2023-01-03 22:06:17,525:INFO:Uploading model into container now
2023-01-03 22:06:17,525:INFO:_master_model_container: 3
2023-01-03 22:06:17,525:INFO:_display_container: 2
2023-01-03 22:06:17,525:INFO:Ridge(random_state=123)
2023-01-03 22:06:17,525:INFO:create_model() successfully completed......................................
2023-01-03 22:06:17,635:INFO:SubProcess create_model() end ==================================
2023-01-03 22:06:17,636:INFO:Creating metrics dataframe
2023-01-03 22:06:17,645:INFO:Initializing Elastic Net
2023-01-03 22:06:17,646:INFO:Total runtime is 0.05890023310979207 minutes
2023-01-03 22:06:17,650:INFO:SubProcess create_model() called ==================================
2023-01-03 22:06:17,651:INFO:Initializing create_model()
2023-01-03 22:06:17,651:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CA7E070910>, estimator=en, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CA31825C70>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:06:17,651:INFO:Checking exceptions
2023-01-03 22:06:17,651:INFO:Importing libraries
2023-01-03 22:06:17,651:INFO:Copying training dataset
2023-01-03 22:06:17,660:INFO:Defining folds
2023-01-03 22:06:17,661:INFO:Declaring metric variables
2023-01-03 22:06:17,665:INFO:Importing untrained model
2023-01-03 22:06:17,670:INFO:Elastic Net Imported successfully
2023-01-03 22:06:17,680:INFO:Starting cross validation
2023-01-03 22:06:17,681:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:06:17,939:INFO:Calculating mean and std
2023-01-03 22:06:17,941:INFO:Creating metrics dataframe
2023-01-03 22:06:17,945:INFO:Uploading results into container
2023-01-03 22:06:17,946:INFO:Uploading model into container now
2023-01-03 22:06:17,946:INFO:_master_model_container: 4
2023-01-03 22:06:17,946:INFO:_display_container: 2
2023-01-03 22:06:17,947:INFO:ElasticNet(random_state=123)
2023-01-03 22:06:17,947:INFO:create_model() successfully completed......................................
2023-01-03 22:06:18,061:INFO:SubProcess create_model() end ==================================
2023-01-03 22:06:18,061:INFO:Creating metrics dataframe
2023-01-03 22:06:18,071:INFO:Initializing Least Angle Regression
2023-01-03 22:06:18,072:INFO:Total runtime is 0.06598660151163736 minutes
2023-01-03 22:06:18,076:INFO:SubProcess create_model() called ==================================
2023-01-03 22:06:18,077:INFO:Initializing create_model()
2023-01-03 22:06:18,077:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CA7E070910>, estimator=lar, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CA31825C70>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:06:18,077:INFO:Checking exceptions
2023-01-03 22:06:18,077:INFO:Importing libraries
2023-01-03 22:06:18,077:INFO:Copying training dataset
2023-01-03 22:06:18,087:INFO:Defining folds
2023-01-03 22:06:18,087:INFO:Declaring metric variables
2023-01-03 22:06:18,092:INFO:Importing untrained model
2023-01-03 22:06:18,096:INFO:Least Angle Regression Imported successfully
2023-01-03 22:06:18,106:INFO:Starting cross validation
2023-01-03 22:06:18,107:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:06:18,158:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 22:06:18,160:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=6.316e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-03 22:06:18,162:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 22:06:18,165:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=3.995e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-03 22:06:18,165:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 36 iterations, i.e. alpha=1.196e-02, with an active set of 31 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-03 22:06:18,169:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=2.244e-02, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-03 22:06:18,170:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=2.005e-02, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-03 22:06:18,170:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=6.296e-03, with an active set of 42 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-03 22:06:18,171:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 58 iterations, i.e. alpha=4.924e-03, with an active set of 43 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-03 22:06:18,174:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 22:06:18,179:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 34 iterations, i.e. alpha=7.293e-03, with an active set of 30 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-03 22:06:18,179:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 34 iterations, i.e. alpha=6.732e-03, with an active set of 30 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-03 22:06:18,181:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=2.919e-01, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-03 22:06:18,182:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=2.397e-01, with an active set of 43 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-03 22:06:18,184:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=2.817e-04, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-03 22:06:18,185:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=1.453e-04, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-03 22:06:18,185:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=5.656e-05, with an active set of 42 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-03 22:06:18,186:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 48 iterations, i.e. alpha=1.054e-05, with an active set of 43 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-03 22:06:18,200:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 22:06:18,208:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.477e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-03 22:06:18,209:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=4.981e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-03 22:06:18,213:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=1.768e-03, with an active set of 24 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-03 22:06:18,216:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=1.243e-03, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-03 22:06:18,217:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=4.858e-04, with an active set of 41 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-03 22:06:18,217:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=4.752e-04, with an active set of 41 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-03 22:06:18,217:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=1.250e-04, with an active set of 42 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-03 22:06:18,218:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=2.429e-05, with an active set of 43 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-03 22:06:18,230:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 22:06:18,236:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=3.194e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-03 22:06:18,237:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=6.111e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-03 22:06:18,238:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=4.138e-03, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-03 22:06:18,242:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=2.004e-03, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-03 22:06:18,242:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=1.761e-03, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-03 22:06:18,243:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 54 iterations, i.e. alpha=9.448e-04, with an active set of 41 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-03 22:06:18,243:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=5.064e-04, with an active set of 43 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-03 22:06:18,373:INFO:Calculating mean and std
2023-01-03 22:06:18,375:INFO:Creating metrics dataframe
2023-01-03 22:06:18,378:INFO:Uploading results into container
2023-01-03 22:06:18,378:INFO:Uploading model into container now
2023-01-03 22:06:18,379:INFO:_master_model_container: 5
2023-01-03 22:06:18,379:INFO:_display_container: 2
2023-01-03 22:06:18,379:INFO:Lars(random_state=123)
2023-01-03 22:06:18,379:INFO:create_model() successfully completed......................................
2023-01-03 22:06:18,487:INFO:SubProcess create_model() end ==================================
2023-01-03 22:06:18,487:INFO:Creating metrics dataframe
2023-01-03 22:06:18,499:INFO:Initializing Lasso Least Angle Regression
2023-01-03 22:06:18,500:INFO:Total runtime is 0.07312557299931843 minutes
2023-01-03 22:06:18,504:INFO:SubProcess create_model() called ==================================
2023-01-03 22:06:18,504:INFO:Initializing create_model()
2023-01-03 22:06:18,504:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CA7E070910>, estimator=llar, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CA31825C70>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:06:18,504:INFO:Checking exceptions
2023-01-03 22:06:18,504:INFO:Importing libraries
2023-01-03 22:06:18,505:INFO:Copying training dataset
2023-01-03 22:06:18,521:INFO:Defining folds
2023-01-03 22:06:18,521:INFO:Declaring metric variables
2023-01-03 22:06:18,525:INFO:Importing untrained model
2023-01-03 22:06:18,531:INFO:Lasso Least Angle Regression Imported successfully
2023-01-03 22:06:18,541:INFO:Starting cross validation
2023-01-03 22:06:18,543:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:06:18,594:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-03 22:06:18,601:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-03 22:06:18,613:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-03 22:06:18,632:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-03 22:06:18,655:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-03 22:06:18,793:INFO:Calculating mean and std
2023-01-03 22:06:18,795:INFO:Creating metrics dataframe
2023-01-03 22:06:18,799:INFO:Uploading results into container
2023-01-03 22:06:18,800:INFO:Uploading model into container now
2023-01-03 22:06:18,800:INFO:_master_model_container: 6
2023-01-03 22:06:18,800:INFO:_display_container: 2
2023-01-03 22:06:18,801:INFO:LassoLars(random_state=123)
2023-01-03 22:06:18,802:INFO:create_model() successfully completed......................................
2023-01-03 22:06:18,914:INFO:SubProcess create_model() end ==================================
2023-01-03 22:06:18,915:INFO:Creating metrics dataframe
2023-01-03 22:06:18,925:INFO:Initializing Orthogonal Matching Pursuit
2023-01-03 22:06:18,925:INFO:Total runtime is 0.08020886580149332 minutes
2023-01-03 22:06:18,929:INFO:SubProcess create_model() called ==================================
2023-01-03 22:06:18,930:INFO:Initializing create_model()
2023-01-03 22:06:18,930:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CA7E070910>, estimator=omp, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CA31825C70>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:06:18,930:INFO:Checking exceptions
2023-01-03 22:06:18,930:INFO:Importing libraries
2023-01-03 22:06:18,930:INFO:Copying training dataset
2023-01-03 22:06:18,939:INFO:Defining folds
2023-01-03 22:06:18,940:INFO:Declaring metric variables
2023-01-03 22:06:18,944:INFO:Importing untrained model
2023-01-03 22:06:18,949:INFO:Orthogonal Matching Pursuit Imported successfully
2023-01-03 22:06:18,968:INFO:Starting cross validation
2023-01-03 22:06:18,971:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:06:19,033:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 22:06:19,036:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 22:06:19,046:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 22:06:19,063:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 22:06:19,097:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 22:06:19,235:INFO:Calculating mean and std
2023-01-03 22:06:19,237:INFO:Creating metrics dataframe
2023-01-03 22:06:19,241:INFO:Uploading results into container
2023-01-03 22:06:19,242:INFO:Uploading model into container now
2023-01-03 22:06:19,243:INFO:_master_model_container: 7
2023-01-03 22:06:19,243:INFO:_display_container: 2
2023-01-03 22:06:19,243:INFO:OrthogonalMatchingPursuit()
2023-01-03 22:06:19,243:INFO:create_model() successfully completed......................................
2023-01-03 22:06:19,354:INFO:SubProcess create_model() end ==================================
2023-01-03 22:06:19,354:INFO:Creating metrics dataframe
2023-01-03 22:06:19,365:INFO:Initializing Bayesian Ridge
2023-01-03 22:06:19,365:INFO:Total runtime is 0.087542192141215 minutes
2023-01-03 22:06:19,369:INFO:SubProcess create_model() called ==================================
2023-01-03 22:06:19,369:INFO:Initializing create_model()
2023-01-03 22:06:19,370:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CA7E070910>, estimator=br, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CA31825C70>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:06:19,370:INFO:Checking exceptions
2023-01-03 22:06:19,370:INFO:Importing libraries
2023-01-03 22:06:19,370:INFO:Copying training dataset
2023-01-03 22:06:19,379:INFO:Defining folds
2023-01-03 22:06:19,380:INFO:Declaring metric variables
2023-01-03 22:06:19,384:INFO:Importing untrained model
2023-01-03 22:06:19,389:INFO:Bayesian Ridge Imported successfully
2023-01-03 22:06:19,399:INFO:Starting cross validation
2023-01-03 22:06:19,400:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:06:19,669:INFO:Calculating mean and std
2023-01-03 22:06:19,671:INFO:Creating metrics dataframe
2023-01-03 22:06:19,675:INFO:Uploading results into container
2023-01-03 22:06:19,676:INFO:Uploading model into container now
2023-01-03 22:06:19,676:INFO:_master_model_container: 8
2023-01-03 22:06:19,677:INFO:_display_container: 2
2023-01-03 22:06:19,677:INFO:BayesianRidge()
2023-01-03 22:06:19,678:INFO:create_model() successfully completed......................................
2023-01-03 22:06:19,791:INFO:SubProcess create_model() end ==================================
2023-01-03 22:06:19,791:INFO:Creating metrics dataframe
2023-01-03 22:06:19,802:INFO:Initializing Passive Aggressive Regressor
2023-01-03 22:06:19,803:INFO:Total runtime is 0.0948442538579305 minutes
2023-01-03 22:06:19,806:INFO:SubProcess create_model() called ==================================
2023-01-03 22:06:19,806:INFO:Initializing create_model()
2023-01-03 22:06:19,806:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CA7E070910>, estimator=par, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CA31825C70>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:06:19,806:INFO:Checking exceptions
2023-01-03 22:06:19,807:INFO:Importing libraries
2023-01-03 22:06:19,807:INFO:Copying training dataset
2023-01-03 22:06:19,816:INFO:Defining folds
2023-01-03 22:06:19,817:INFO:Declaring metric variables
2023-01-03 22:06:19,820:INFO:Importing untrained model
2023-01-03 22:06:19,825:INFO:Passive Aggressive Regressor Imported successfully
2023-01-03 22:06:19,833:INFO:Starting cross validation
2023-01-03 22:06:19,835:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:06:20,088:INFO:Calculating mean and std
2023-01-03 22:06:20,090:INFO:Creating metrics dataframe
2023-01-03 22:06:20,093:INFO:Uploading results into container
2023-01-03 22:06:20,094:INFO:Uploading model into container now
2023-01-03 22:06:20,094:INFO:_master_model_container: 9
2023-01-03 22:06:20,094:INFO:_display_container: 2
2023-01-03 22:06:20,095:INFO:PassiveAggressiveRegressor(random_state=123)
2023-01-03 22:06:20,095:INFO:create_model() successfully completed......................................
2023-01-03 22:06:20,210:INFO:SubProcess create_model() end ==================================
2023-01-03 22:06:20,210:INFO:Creating metrics dataframe
2023-01-03 22:06:20,221:INFO:Initializing Huber Regressor
2023-01-03 22:06:20,222:INFO:Total runtime is 0.10182763735453287 minutes
2023-01-03 22:06:20,226:INFO:SubProcess create_model() called ==================================
2023-01-03 22:06:20,226:INFO:Initializing create_model()
2023-01-03 22:06:20,226:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CA7E070910>, estimator=huber, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CA31825C70>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:06:20,226:INFO:Checking exceptions
2023-01-03 22:06:20,226:INFO:Importing libraries
2023-01-03 22:06:20,227:INFO:Copying training dataset
2023-01-03 22:06:20,236:INFO:Defining folds
2023-01-03 22:06:20,236:INFO:Declaring metric variables
2023-01-03 22:06:20,241:INFO:Importing untrained model
2023-01-03 22:06:20,248:INFO:Huber Regressor Imported successfully
2023-01-03 22:06:20,258:INFO:Starting cross validation
2023-01-03 22:06:20,259:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:06:20,382:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-03 22:06:20,462:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-03 22:06:20,549:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-03 22:06:20,645:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-03 22:06:20,808:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-03 22:06:20,931:INFO:Calculating mean and std
2023-01-03 22:06:20,933:INFO:Creating metrics dataframe
2023-01-03 22:06:20,937:INFO:Uploading results into container
2023-01-03 22:06:20,937:INFO:Uploading model into container now
2023-01-03 22:06:20,938:INFO:_master_model_container: 10
2023-01-03 22:06:20,938:INFO:_display_container: 2
2023-01-03 22:06:20,939:INFO:HuberRegressor()
2023-01-03 22:06:20,939:INFO:create_model() successfully completed......................................
2023-01-03 22:06:21,055:INFO:SubProcess create_model() end ==================================
2023-01-03 22:06:21,055:INFO:Creating metrics dataframe
2023-01-03 22:06:21,068:INFO:Initializing K Neighbors Regressor
2023-01-03 22:06:21,068:INFO:Total runtime is 0.11592759688695271 minutes
2023-01-03 22:06:21,072:INFO:SubProcess create_model() called ==================================
2023-01-03 22:06:21,072:INFO:Initializing create_model()
2023-01-03 22:06:21,073:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CA7E070910>, estimator=knn, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CA31825C70>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:06:21,073:INFO:Checking exceptions
2023-01-03 22:06:21,073:INFO:Importing libraries
2023-01-03 22:06:21,073:INFO:Copying training dataset
2023-01-03 22:06:21,083:INFO:Defining folds
2023-01-03 22:06:21,083:INFO:Declaring metric variables
2023-01-03 22:06:21,088:INFO:Importing untrained model
2023-01-03 22:06:21,092:INFO:K Neighbors Regressor Imported successfully
2023-01-03 22:06:21,102:INFO:Starting cross validation
2023-01-03 22:06:21,103:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:06:21,778:INFO:Calculating mean and std
2023-01-03 22:06:21,780:INFO:Creating metrics dataframe
2023-01-03 22:06:21,784:INFO:Uploading results into container
2023-01-03 22:06:21,785:INFO:Uploading model into container now
2023-01-03 22:06:21,785:INFO:_master_model_container: 11
2023-01-03 22:06:21,786:INFO:_display_container: 2
2023-01-03 22:06:21,786:INFO:KNeighborsRegressor(n_jobs=-1)
2023-01-03 22:06:21,786:INFO:create_model() successfully completed......................................
2023-01-03 22:06:21,898:INFO:SubProcess create_model() end ==================================
2023-01-03 22:06:21,899:INFO:Creating metrics dataframe
2023-01-03 22:06:21,911:INFO:Initializing Decision Tree Regressor
2023-01-03 22:06:21,911:INFO:Total runtime is 0.1299775997797648 minutes
2023-01-03 22:06:21,915:INFO:SubProcess create_model() called ==================================
2023-01-03 22:06:21,916:INFO:Initializing create_model()
2023-01-03 22:06:21,916:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CA7E070910>, estimator=dt, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CA31825C70>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:06:21,916:INFO:Checking exceptions
2023-01-03 22:06:21,916:INFO:Importing libraries
2023-01-03 22:06:21,916:INFO:Copying training dataset
2023-01-03 22:06:21,925:INFO:Defining folds
2023-01-03 22:06:21,925:INFO:Declaring metric variables
2023-01-03 22:06:21,929:INFO:Importing untrained model
2023-01-03 22:06:21,936:INFO:Decision Tree Regressor Imported successfully
2023-01-03 22:06:21,944:INFO:Starting cross validation
2023-01-03 22:06:21,945:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:06:22,431:INFO:Calculating mean and std
2023-01-03 22:06:22,434:INFO:Creating metrics dataframe
2023-01-03 22:06:22,440:INFO:Uploading results into container
2023-01-03 22:06:22,441:INFO:Uploading model into container now
2023-01-03 22:06:22,441:INFO:_master_model_container: 12
2023-01-03 22:06:22,441:INFO:_display_container: 2
2023-01-03 22:06:22,442:INFO:DecisionTreeRegressor(random_state=123)
2023-01-03 22:06:22,442:INFO:create_model() successfully completed......................................
2023-01-03 22:06:22,556:INFO:SubProcess create_model() end ==================================
2023-01-03 22:06:22,556:INFO:Creating metrics dataframe
2023-01-03 22:06:22,568:INFO:Initializing Random Forest Regressor
2023-01-03 22:06:22,568:INFO:Total runtime is 0.14092187484105428 minutes
2023-01-03 22:06:22,572:INFO:SubProcess create_model() called ==================================
2023-01-03 22:06:22,572:INFO:Initializing create_model()
2023-01-03 22:06:22,572:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CA7E070910>, estimator=rf, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CA31825C70>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:06:22,573:INFO:Checking exceptions
2023-01-03 22:06:22,573:INFO:Importing libraries
2023-01-03 22:06:22,573:INFO:Copying training dataset
2023-01-03 22:06:22,582:INFO:Defining folds
2023-01-03 22:06:22,582:INFO:Declaring metric variables
2023-01-03 22:06:22,586:INFO:Importing untrained model
2023-01-03 22:06:22,591:INFO:Random Forest Regressor Imported successfully
2023-01-03 22:06:22,599:INFO:Starting cross validation
2023-01-03 22:06:22,601:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:06:32,295:INFO:Calculating mean and std
2023-01-03 22:06:32,297:INFO:Creating metrics dataframe
2023-01-03 22:06:32,301:INFO:Uploading results into container
2023-01-03 22:06:32,301:INFO:Uploading model into container now
2023-01-03 22:06:32,301:INFO:_master_model_container: 13
2023-01-03 22:06:32,302:INFO:_display_container: 2
2023-01-03 22:06:32,302:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-01-03 22:06:32,302:INFO:create_model() successfully completed......................................
2023-01-03 22:06:32,413:INFO:SubProcess create_model() end ==================================
2023-01-03 22:06:32,413:INFO:Creating metrics dataframe
2023-01-03 22:06:32,427:INFO:Initializing Extra Trees Regressor
2023-01-03 22:06:32,427:INFO:Total runtime is 0.3052451014518738 minutes
2023-01-03 22:06:32,431:INFO:SubProcess create_model() called ==================================
2023-01-03 22:06:32,432:INFO:Initializing create_model()
2023-01-03 22:06:32,432:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CA7E070910>, estimator=et, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CA31825C70>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:06:32,432:INFO:Checking exceptions
2023-01-03 22:06:32,432:INFO:Importing libraries
2023-01-03 22:06:32,433:INFO:Copying training dataset
2023-01-03 22:06:32,442:INFO:Defining folds
2023-01-03 22:06:32,442:INFO:Declaring metric variables
2023-01-03 22:06:32,446:INFO:Importing untrained model
2023-01-03 22:06:32,451:INFO:Extra Trees Regressor Imported successfully
2023-01-03 22:06:32,458:INFO:Starting cross validation
2023-01-03 22:06:32,459:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:06:36,753:INFO:Calculating mean and std
2023-01-03 22:06:36,755:INFO:Creating metrics dataframe
2023-01-03 22:06:36,758:INFO:Uploading results into container
2023-01-03 22:06:36,758:INFO:Uploading model into container now
2023-01-03 22:06:36,759:INFO:_master_model_container: 14
2023-01-03 22:06:36,759:INFO:_display_container: 2
2023-01-03 22:06:36,759:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-01-03 22:06:36,759:INFO:create_model() successfully completed......................................
2023-01-03 22:06:36,867:INFO:SubProcess create_model() end ==================================
2023-01-03 22:06:36,867:INFO:Creating metrics dataframe
2023-01-03 22:06:36,881:INFO:Initializing AdaBoost Regressor
2023-01-03 22:06:36,882:INFO:Total runtime is 0.3794991691907247 minutes
2023-01-03 22:06:36,886:INFO:SubProcess create_model() called ==================================
2023-01-03 22:06:36,887:INFO:Initializing create_model()
2023-01-03 22:06:36,887:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CA7E070910>, estimator=ada, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CA31825C70>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:06:36,887:INFO:Checking exceptions
2023-01-03 22:06:36,887:INFO:Importing libraries
2023-01-03 22:06:36,887:INFO:Copying training dataset
2023-01-03 22:06:36,896:INFO:Defining folds
2023-01-03 22:06:36,896:INFO:Declaring metric variables
2023-01-03 22:06:36,902:INFO:Importing untrained model
2023-01-03 22:06:36,906:INFO:AdaBoost Regressor Imported successfully
2023-01-03 22:06:36,913:INFO:Starting cross validation
2023-01-03 22:06:36,916:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:06:37,915:INFO:Calculating mean and std
2023-01-03 22:06:37,917:INFO:Creating metrics dataframe
2023-01-03 22:06:37,920:INFO:Uploading results into container
2023-01-03 22:06:37,920:INFO:Uploading model into container now
2023-01-03 22:06:37,922:INFO:_master_model_container: 15
2023-01-03 22:06:37,922:INFO:_display_container: 2
2023-01-03 22:06:37,922:INFO:AdaBoostRegressor(random_state=123)
2023-01-03 22:06:37,922:INFO:create_model() successfully completed......................................
2023-01-03 22:06:38,035:INFO:SubProcess create_model() end ==================================
2023-01-03 22:06:38,036:INFO:Creating metrics dataframe
2023-01-03 22:06:38,050:INFO:Initializing Gradient Boosting Regressor
2023-01-03 22:06:38,050:INFO:Total runtime is 0.3989658792813619 minutes
2023-01-03 22:06:38,054:INFO:SubProcess create_model() called ==================================
2023-01-03 22:06:38,055:INFO:Initializing create_model()
2023-01-03 22:06:38,055:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CA7E070910>, estimator=gbr, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CA31825C70>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:06:38,055:INFO:Checking exceptions
2023-01-03 22:06:38,055:INFO:Importing libraries
2023-01-03 22:06:38,055:INFO:Copying training dataset
2023-01-03 22:06:38,065:INFO:Defining folds
2023-01-03 22:06:38,066:INFO:Declaring metric variables
2023-01-03 22:06:38,070:INFO:Importing untrained model
2023-01-03 22:06:38,075:INFO:Gradient Boosting Regressor Imported successfully
2023-01-03 22:06:38,083:INFO:Starting cross validation
2023-01-03 22:06:38,084:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:06:43,029:INFO:Calculating mean and std
2023-01-03 22:06:43,031:INFO:Creating metrics dataframe
2023-01-03 22:06:43,035:INFO:Uploading results into container
2023-01-03 22:06:43,037:INFO:Uploading model into container now
2023-01-03 22:06:43,037:INFO:_master_model_container: 16
2023-01-03 22:06:43,038:INFO:_display_container: 2
2023-01-03 22:06:43,038:INFO:GradientBoostingRegressor(random_state=123)
2023-01-03 22:06:43,038:INFO:create_model() successfully completed......................................
2023-01-03 22:06:43,140:INFO:SubProcess create_model() end ==================================
2023-01-03 22:06:43,140:INFO:Creating metrics dataframe
2023-01-03 22:06:43,153:INFO:Initializing Light Gradient Boosting Machine
2023-01-03 22:06:43,153:INFO:Total runtime is 0.48401581048965453 minutes
2023-01-03 22:06:43,157:INFO:SubProcess create_model() called ==================================
2023-01-03 22:06:43,157:INFO:Initializing create_model()
2023-01-03 22:06:43,157:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CA7E070910>, estimator=lightgbm, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CA31825C70>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:06:43,157:INFO:Checking exceptions
2023-01-03 22:06:43,158:INFO:Importing libraries
2023-01-03 22:06:43,158:INFO:Copying training dataset
2023-01-03 22:06:43,167:INFO:Defining folds
2023-01-03 22:06:43,167:INFO:Declaring metric variables
2023-01-03 22:06:43,172:INFO:Importing untrained model
2023-01-03 22:06:43,176:INFO:Light Gradient Boosting Machine Imported successfully
2023-01-03 22:06:43,184:INFO:Starting cross validation
2023-01-03 22:06:43,186:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:06:44,382:INFO:Calculating mean and std
2023-01-03 22:06:44,384:INFO:Creating metrics dataframe
2023-01-03 22:06:44,389:INFO:Uploading results into container
2023-01-03 22:06:44,390:INFO:Uploading model into container now
2023-01-03 22:06:44,390:INFO:_master_model_container: 17
2023-01-03 22:06:44,390:INFO:_display_container: 2
2023-01-03 22:06:44,391:INFO:LGBMRegressor(random_state=123)
2023-01-03 22:06:44,391:INFO:create_model() successfully completed......................................
2023-01-03 22:06:44,504:INFO:SubProcess create_model() end ==================================
2023-01-03 22:06:44,504:INFO:Creating metrics dataframe
2023-01-03 22:06:44,518:INFO:Initializing Dummy Regressor
2023-01-03 22:06:44,518:INFO:Total runtime is 0.5067593733469645 minutes
2023-01-03 22:06:44,522:INFO:SubProcess create_model() called ==================================
2023-01-03 22:06:44,523:INFO:Initializing create_model()
2023-01-03 22:06:44,523:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CA7E070910>, estimator=dummy, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CA31825C70>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:06:44,523:INFO:Checking exceptions
2023-01-03 22:06:44,523:INFO:Importing libraries
2023-01-03 22:06:44,523:INFO:Copying training dataset
2023-01-03 22:06:44,534:INFO:Defining folds
2023-01-03 22:06:44,534:INFO:Declaring metric variables
2023-01-03 22:06:44,538:INFO:Importing untrained model
2023-01-03 22:06:44,542:INFO:Dummy Regressor Imported successfully
2023-01-03 22:06:44,550:INFO:Starting cross validation
2023-01-03 22:06:44,552:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:06:44,790:INFO:Calculating mean and std
2023-01-03 22:06:44,792:INFO:Creating metrics dataframe
2023-01-03 22:06:44,796:INFO:Uploading results into container
2023-01-03 22:06:44,797:INFO:Uploading model into container now
2023-01-03 22:06:44,798:INFO:_master_model_container: 18
2023-01-03 22:06:44,798:INFO:_display_container: 2
2023-01-03 22:06:44,798:INFO:DummyRegressor()
2023-01-03 22:06:44,798:INFO:create_model() successfully completed......................................
2023-01-03 22:06:44,905:INFO:SubProcess create_model() end ==================================
2023-01-03 22:06:44,905:INFO:Creating metrics dataframe
2023-01-03 22:06:44,933:INFO:Initializing create_model()
2023-01-03 22:06:44,934:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CA7E070910>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:06:44,934:INFO:Checking exceptions
2023-01-03 22:06:44,937:INFO:Importing libraries
2023-01-03 22:06:44,937:INFO:Copying training dataset
2023-01-03 22:06:44,946:INFO:Defining folds
2023-01-03 22:06:44,946:INFO:Declaring metric variables
2023-01-03 22:06:44,946:INFO:Importing untrained model
2023-01-03 22:06:44,947:INFO:Declaring custom model
2023-01-03 22:06:44,947:INFO:Extra Trees Regressor Imported successfully
2023-01-03 22:06:44,949:INFO:Cross validation set to False
2023-01-03 22:06:44,949:INFO:Fitting Model
2023-01-03 22:06:46,862:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-01-03 22:06:46,862:INFO:create_model() successfully completed......................................
2023-01-03 22:06:47,016:INFO:_master_model_container: 18
2023-01-03 22:06:47,016:INFO:_display_container: 2
2023-01-03 22:06:47,017:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-01-03 22:06:47,018:INFO:compare_models() successfully completed......................................
2023-01-03 22:06:47,028:INFO:Initializing tune_model()
2023-01-03 22:06:47,029:INFO:tune_model(estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=MAE, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CA7E070910>)
2023-01-03 22:06:47,029:INFO:Checking exceptions
2023-01-03 22:06:47,086:INFO:Copying training dataset
2023-01-03 22:06:47,104:INFO:Checking base model
2023-01-03 22:06:47,105:INFO:Base model : Extra Trees Regressor
2023-01-03 22:06:47,111:INFO:Declaring metric variables
2023-01-03 22:06:47,115:INFO:Defining Hyperparameters
2023-01-03 22:06:47,255:INFO:Tuning with n_jobs=-1
2023-01-03 22:06:47,255:INFO:Initializing RandomizedSearchCV
2023-01-03 22:06:47,305:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:06:47,308:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:06:47,316:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:06:47,335:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:06:47,611:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:06:47,636:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:06:47,645:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:06:47,903:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:06:47,999:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:06:48,083:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:06:48,130:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:06:48,289:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:06:48,292:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:06:48,458:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:06:48,800:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:06:49,010:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:06:49,119:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:06:49,525:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:06:49,545:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:06:49,572:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:06:50,018:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:06:50,129:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:06:50,345:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:06:50,455:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:06:50,567:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:06:50,669:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 22:06:51,025:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 22:06:51,361:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 22:06:51,824:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 22:06:51,928:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 22:06:55,969:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:06:59,642:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:07:00,226:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:07:02,466:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:07:03,217:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:07:05,149:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:07:05,342:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:07:05,491:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:07:06,420:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:07:06,650:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:07:06,791:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 22:07:08,188:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 22:07:08,606:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 22:07:09,042:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 22:07:12,578:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 22:07:13,738:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:07:17,489:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:07:19,560:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:07:20,139:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:07:22,048:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:07:29,587:INFO:best_params: {'actual_estimator__n_estimators': 100, 'actual_estimator__min_samples_split': 7, 'actual_estimator__min_samples_leaf': 4, 'actual_estimator__min_impurity_decrease': 0.1, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 9, 'actual_estimator__criterion': 'mse', 'actual_estimator__bootstrap': True}
2023-01-03 22:07:29,589:INFO:Hyperparameter search completed
2023-01-03 22:07:29,589:INFO:SubProcess create_model() called ==================================
2023-01-03 22:07:29,590:INFO:Initializing create_model()
2023-01-03 22:07:29,590:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CA7E070910>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CA08C86F10>, model_only=True, return_train_score=False, kwargs={'n_estimators': 100, 'min_samples_split': 7, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.1, 'max_features': 1.0, 'max_depth': 9, 'criterion': 'mse', 'bootstrap': True})
2023-01-03 22:07:29,590:INFO:Checking exceptions
2023-01-03 22:07:29,590:INFO:Importing libraries
2023-01-03 22:07:29,590:INFO:Copying training dataset
2023-01-03 22:07:29,602:INFO:Defining folds
2023-01-03 22:07:29,603:INFO:Declaring metric variables
2023-01-03 22:07:29,607:INFO:Importing untrained model
2023-01-03 22:07:29,607:INFO:Declaring custom model
2023-01-03 22:07:29,612:INFO:Extra Trees Regressor Imported successfully
2023-01-03 22:07:29,621:INFO:Starting cross validation
2023-01-03 22:07:29,623:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:07:29,680:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:07:29,683:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:07:29,695:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:07:29,719:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:07:30,055:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:07:30,664:INFO:Calculating mean and std
2023-01-03 22:07:30,666:INFO:Creating metrics dataframe
2023-01-03 22:07:30,672:INFO:Finalizing model
2023-01-03 22:07:31,020:INFO:Uploading results into container
2023-01-03 22:07:31,021:INFO:Uploading model into container now
2023-01-03 22:07:31,021:INFO:_master_model_container: 19
2023-01-03 22:07:31,021:INFO:_display_container: 3
2023-01-03 22:07:31,022:INFO:ExtraTreesRegressor(bootstrap=True, criterion='mse', max_depth=9,
                    max_features=1.0, min_impurity_decrease=0.1,
                    min_samples_leaf=4, min_samples_split=7, n_jobs=-1,
                    random_state=123)
2023-01-03 22:07:31,023:INFO:create_model() successfully completed......................................
2023-01-03 22:07:31,147:INFO:SubProcess create_model() end ==================================
2023-01-03 22:07:31,147:INFO:choose_better activated
2023-01-03 22:07:31,151:INFO:SubProcess create_model() called ==================================
2023-01-03 22:07:31,152:INFO:Initializing create_model()
2023-01-03 22:07:31,152:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CA7E070910>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:07:31,152:INFO:Checking exceptions
2023-01-03 22:07:31,155:INFO:Importing libraries
2023-01-03 22:07:31,155:INFO:Copying training dataset
2023-01-03 22:07:31,163:INFO:Defining folds
2023-01-03 22:07:31,163:INFO:Declaring metric variables
2023-01-03 22:07:31,163:INFO:Importing untrained model
2023-01-03 22:07:31,163:INFO:Declaring custom model
2023-01-03 22:07:31,164:INFO:Extra Trees Regressor Imported successfully
2023-01-03 22:07:31,165:INFO:Starting cross validation
2023-01-03 22:07:31,166:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:07:35,473:INFO:Calculating mean and std
2023-01-03 22:07:35,474:INFO:Creating metrics dataframe
2023-01-03 22:07:35,476:INFO:Finalizing model
2023-01-03 22:07:37,142:INFO:Uploading results into container
2023-01-03 22:07:37,142:INFO:Uploading model into container now
2023-01-03 22:07:37,143:INFO:_master_model_container: 20
2023-01-03 22:07:37,143:INFO:_display_container: 4
2023-01-03 22:07:37,143:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-01-03 22:07:37,143:INFO:create_model() successfully completed......................................
2023-01-03 22:07:37,253:INFO:SubProcess create_model() end ==================================
2023-01-03 22:07:37,253:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123) result for MAE is 2.2531
2023-01-03 22:07:37,254:INFO:ExtraTreesRegressor(bootstrap=True, criterion='mse', max_depth=9,
                    max_features=1.0, min_impurity_decrease=0.1,
                    min_samples_leaf=4, min_samples_split=7, n_jobs=-1,
                    random_state=123) result for MAE is 2.9741
2023-01-03 22:07:37,255:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123) is best model
2023-01-03 22:07:37,255:INFO:choose_better completed
2023-01-03 22:07:37,255:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-01-03 22:07:37,263:INFO:_master_model_container: 20
2023-01-03 22:07:37,264:INFO:_display_container: 3
2023-01-03 22:07:37,264:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-01-03 22:07:37,264:INFO:tune_model() successfully completed......................................
2023-01-03 22:07:37,401:INFO:Initializing plot_model()
2023-01-03 22:07:37,402:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CA7E070910>, system=True)
2023-01-03 22:07:37,402:INFO:Checking exceptions
2023-01-03 22:07:37,428:INFO:Preloading libraries
2023-01-03 22:07:37,584:INFO:Copying training dataset
2023-01-03 22:07:37,584:INFO:Plot type: error
2023-01-03 22:07:37,708:INFO:Fitting Model
2023-01-03 22:07:37,708:INFO:Scoring test/hold-out set
2023-01-03 22:07:38,019:INFO:Visual Rendered Successfully
2023-01-03 22:07:38,145:INFO:plot_model() successfully completed......................................
2023-01-03 22:07:38,156:INFO:Initializing predict_model()
2023-01-03 22:07:38,156:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CA7E070910>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001CA094318B0>)
2023-01-03 22:07:38,156:INFO:Checking exceptions
2023-01-03 22:07:38,156:INFO:Preloading libraries
2023-01-03 22:07:38,364:INFO:Initializing finalize_model()
2023-01-03 22:07:38,364:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CA7E070910>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-01-03 22:07:38,364:INFO:Finalizing ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-01-03 22:07:38,374:INFO:Initializing create_model()
2023-01-03 22:07:38,374:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CA7E070910>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-01-03 22:07:38,374:INFO:Checking exceptions
2023-01-03 22:07:38,376:INFO:Importing libraries
2023-01-03 22:07:38,376:INFO:Copying training dataset
2023-01-03 22:07:38,377:INFO:Defining folds
2023-01-03 22:07:38,377:INFO:Declaring metric variables
2023-01-03 22:07:38,378:INFO:Importing untrained model
2023-01-03 22:07:38,378:INFO:Declaring custom model
2023-01-03 22:07:38,378:INFO:Extra Trees Regressor Imported successfully
2023-01-03 22:07:38,379:INFO:Cross validation set to False
2023-01-03 22:07:38,379:INFO:Fitting Model
2023-01-03 22:07:41,587:INFO:Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))])
2023-01-03 22:07:41,587:INFO:create_model() successfully completed......................................
2023-01-03 22:07:41,697:INFO:_master_model_container: 20
2023-01-03 22:07:41,697:INFO:_display_container: 4
2023-01-03 22:07:41,705:INFO:Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))])
2023-01-03 22:07:41,705:INFO:finalize_model() successfully completed......................................
2023-01-03 22:07:41,833:INFO:Initializing predict_model()
2023-01-03 22:07:41,833:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CA7E070910>, estimator=Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001CA094318B0>)
2023-01-03 22:07:41,833:INFO:Checking exceptions
2023-01-03 22:07:41,833:INFO:Preloading libraries
2023-01-03 22:07:41,836:INFO:Set up data.
2023-01-03 22:07:41,850:INFO:Set up index.
2023-01-03 22:07:42,355:INFO:Initializing save_model()
2023-01-03 22:07:42,355:INFO:save_model(model=Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))]), model_name=c:\Users\Kodotautas\Desktop\Data_science\7_TIME_SERIES_FORECAST_PYCARET/models/final_model.pkl, prep_pipe_=Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-01-03 22:07:42,355:INFO:Adding model into prep_pipe
2023-01-03 22:07:42,538:WARNING:Only Model saved as it was a pipeline.
2023-01-03 22:07:42,695:INFO:c:\Users\Kodotautas\Desktop\Data_science\7_TIME_SERIES_FORECAST_PYCARET/models/final_model.pkl.pkl saved in current working directory
2023-01-03 22:07:42,703:INFO:Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))])
2023-01-03 22:07:42,703:INFO:save_model() successfully completed......................................
2023-01-03 22:13:35,863:INFO:PyCaret RegressionExperiment
2023-01-03 22:13:35,863:INFO:Logging name: reg-default-name
2023-01-03 22:13:35,863:INFO:ML Usecase: MLUsecase.REGRESSION
2023-01-03 22:13:35,863:INFO:version 3.0.0.rc6
2023-01-03 22:13:35,863:INFO:Initializing setup()
2023-01-03 22:13:35,863:INFO:self.USI: fb5e
2023-01-03 22:13:35,863:INFO:self._variable_keys: {'X_train', 'fold_shuffle_param', 'exp_id', 'memory', 'logging_param', 'fold_generator', 'y_train', 'n_jobs_param', '_ml_usecase', 'USI', 'X', 'y_test', 'data', 'fold_groups_param', 'y', 'X_test', 'log_plots_param', 'seed', 'gpu_n_jobs_param', 'transform_target_param', '_available_plots', 'gpu_param', 'target_param', 'html_param', 'exp_name_log', 'pipeline', 'idx'}
2023-01-03 22:13:35,863:INFO:Checking environment
2023-01-03 22:13:35,863:INFO:python_version: 3.9.13
2023-01-03 22:13:35,863:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-01-03 22:13:35,864:INFO:machine: AMD64
2023-01-03 22:13:35,864:INFO:platform: Windows-10-10.0.19044-SP0
2023-01-03 22:13:35,864:INFO:Memory: svmem(total=17114804224, available=9823653888, percent=42.6, used=7291150336, free=9823653888)
2023-01-03 22:13:35,864:INFO:Physical Core: 4
2023-01-03 22:13:35,864:INFO:Logical Core: 4
2023-01-03 22:13:35,864:INFO:Checking libraries
2023-01-03 22:13:35,864:INFO:System:
2023-01-03 22:13:35,864:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-01-03 22:13:35,864:INFO:executable: c:\Users\Kodotautas\anaconda3\python.exe
2023-01-03 22:13:35,864:INFO:   machine: Windows-10-10.0.19044-SP0
2023-01-03 22:13:35,864:INFO:PyCaret required dependencies:
2023-01-03 22:13:35,864:INFO:                 pip: 22.2.2
2023-01-03 22:13:35,864:INFO:          setuptools: 63.4.1
2023-01-03 22:13:35,864:INFO:             pycaret: 3.0.0rc6
2023-01-03 22:13:35,864:INFO:             IPython: 7.31.1
2023-01-03 22:13:35,864:INFO:          ipywidgets: 7.6.5
2023-01-03 22:13:35,864:INFO:                tqdm: 4.64.1
2023-01-03 22:13:35,864:INFO:               numpy: 1.21.5
2023-01-03 22:13:35,865:INFO:              pandas: 1.4.4
2023-01-03 22:13:35,865:INFO:              jinja2: 2.11.3
2023-01-03 22:13:35,865:INFO:               scipy: 1.9.1
2023-01-03 22:13:35,865:INFO:              joblib: 1.2.0
2023-01-03 22:13:35,865:INFO:             sklearn: 1.0.2
2023-01-03 22:13:35,865:INFO:                pyod: 1.0.7
2023-01-03 22:13:35,865:INFO:            imblearn: 0.10.1
2023-01-03 22:13:35,865:INFO:   category_encoders: 2.5.1.post0
2023-01-03 22:13:35,865:INFO:            lightgbm: 3.3.3
2023-01-03 22:13:35,865:INFO:               numba: 0.55.1
2023-01-03 22:13:35,865:INFO:            requests: 2.28.1
2023-01-03 22:13:35,865:INFO:          matplotlib: 3.5.2
2023-01-03 22:13:35,865:INFO:          scikitplot: 0.3.7
2023-01-03 22:13:35,865:INFO:         yellowbrick: 1.5
2023-01-03 22:13:35,865:INFO:              plotly: 5.9.0
2023-01-03 22:13:35,865:INFO:             kaleido: 0.2.1
2023-01-03 22:13:35,865:INFO:         statsmodels: 0.13.2
2023-01-03 22:13:35,865:INFO:              sktime: 0.14.1
2023-01-03 22:13:35,865:INFO:               tbats: 1.1.2
2023-01-03 22:13:35,865:INFO:            pmdarima: 2.0.2
2023-01-03 22:13:35,866:INFO:              psutil: 5.9.0
2023-01-03 22:13:35,866:INFO:PyCaret optional dependencies:
2023-01-03 22:13:35,866:INFO:                shap: 0.41.0
2023-01-03 22:13:35,866:INFO:           interpret: Not installed
2023-01-03 22:13:35,866:INFO:                umap: Not installed
2023-01-03 22:13:35,866:INFO:    pandas_profiling: Not installed
2023-01-03 22:13:35,866:INFO:  explainerdashboard: Not installed
2023-01-03 22:13:35,866:INFO:             autoviz: Not installed
2023-01-03 22:13:35,866:INFO:           fairlearn: Not installed
2023-01-03 22:13:35,866:INFO:             xgboost: Not installed
2023-01-03 22:13:35,866:INFO:            catboost: Not installed
2023-01-03 22:13:35,867:INFO:              kmodes: Not installed
2023-01-03 22:13:35,867:INFO:             mlxtend: Not installed
2023-01-03 22:13:35,867:INFO:       statsforecast: Not installed
2023-01-03 22:13:35,867:INFO:        tune_sklearn: 0.4.3
2023-01-03 22:13:35,867:INFO:                 ray: 2.0.0
2023-01-03 22:13:35,867:INFO:            hyperopt: 0.2.7
2023-01-03 22:13:35,867:INFO:              optuna: 3.0.1
2023-01-03 22:13:35,867:INFO:               skopt: 0.9.0
2023-01-03 22:13:35,867:INFO:              mlflow: Not installed
2023-01-03 22:13:35,867:INFO:              gradio: Not installed
2023-01-03 22:13:35,867:INFO:             fastapi: 0.88.0
2023-01-03 22:13:35,867:INFO:             uvicorn: 0.20.0
2023-01-03 22:13:35,867:INFO:              m2cgen: Not installed
2023-01-03 22:13:35,867:INFO:           evidently: Not installed
2023-01-03 22:13:35,867:INFO:                nltk: 3.7
2023-01-03 22:13:35,867:INFO:            pyLDAvis: Not installed
2023-01-03 22:13:35,867:INFO:              gensim: 4.1.2
2023-01-03 22:13:35,867:INFO:               spacy: 3.4.2
2023-01-03 22:13:35,867:INFO:           wordcloud: Not installed
2023-01-03 22:13:35,867:INFO:            textblob: Not installed
2023-01-03 22:13:35,867:INFO:               fugue: Not installed
2023-01-03 22:13:35,867:INFO:           streamlit: Not installed
2023-01-03 22:13:35,867:INFO:             prophet: Not installed
2023-01-03 22:13:35,868:INFO:None
2023-01-03 22:13:35,868:INFO:Set up data.
2023-01-03 22:13:35,922:INFO:Set up train/test split.
2023-01-03 22:13:35,934:INFO:Set up index.
2023-01-03 22:13:35,937:INFO:Set up folding strategy.
2023-01-03 22:13:35,937:INFO:Assigning column types.
2023-01-03 22:13:35,947:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-01-03 22:13:35,947:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-01-03 22:13:35,953:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-03 22:13:35,958:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 22:13:36,043:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 22:13:36,109:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 22:13:36,110:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:13:36,110:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:13:36,110:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-01-03 22:13:36,115:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-03 22:13:36,121:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 22:13:36,192:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 22:13:36,240:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 22:13:36,240:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:13:36,241:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:13:36,241:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-01-03 22:13:36,246:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-03 22:13:36,251:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 22:13:36,323:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 22:13:36,373:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 22:13:36,373:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:13:36,374:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:13:36,379:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-03 22:13:36,384:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 22:13:36,460:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 22:13:36,510:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 22:13:36,511:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:13:36,511:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:13:36,511:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-01-03 22:13:36,523:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 22:13:36,594:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 22:13:36,642:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 22:13:36,643:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:13:36,644:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:13:36,654:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 22:13:36,726:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 22:13:36,774:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 22:13:36,775:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:13:36,775:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:13:36,775:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-01-03 22:13:36,855:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 22:13:36,905:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 22:13:36,906:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:13:36,906:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:13:36,991:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 22:13:37,040:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 22:13:37,040:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:13:37,040:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:13:37,041:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-01-03 22:13:37,122:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 22:13:37,175:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:13:37,175:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:13:37,260:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 22:13:37,310:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:13:37,311:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:13:37,311:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-01-03 22:13:37,442:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:13:37,442:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:13:37,572:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:13:37,572:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:13:37,573:INFO:Preparing preprocessing pipeline...
2023-01-03 22:13:37,575:INFO:Set up simple imputation.
2023-01-03 22:13:37,575:INFO:Set up column transformation.
2023-01-03 22:13:37,575:INFO:Set up feature normalization.
2023-01-03 22:13:37,613:INFO:Finished creating preprocessing pipeline.
2023-01-03 22:13:37,619:INFO:Pipeline: Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2023-01-03 22:13:37,620:INFO:Creating final display dataframe.
2023-01-03 22:13:37,878:INFO:Setup _display_container:                Description             Value
0               Session id               123
1                   Target        b2b+b2c+vt
2              Target type        Regression
3               Data shape       (10506, 45)
4         Train data shape        (7354, 45)
5          Test data shape        (3152, 45)
6         Numeric features                 8
7               Preprocess              True
8          Imputation type            simple
9       Numeric imputation              mean
10  Categorical imputation              mode
11          Transformation              True
12   Transformation method       yeo-johnson
13               Normalize              True
14        Normalize method            zscore
15          Fold Generator   TimeSeriesSplit
16             Fold Number                 5
17                CPU Jobs                -1
18                 Use GPU             False
19          Log Experiment             False
20         Experiment Name  reg-default-name
21                     USI              fb5e
2023-01-03 22:13:38,024:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:13:38,024:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:13:38,158:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:13:38,158:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:13:38,159:INFO:setup() successfully completed in 2.3s...............
2023-01-03 22:13:38,159:INFO:Initializing compare_models()
2023-01-03 22:13:38,160:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CA08E6D0A0>, include=None, fold=None, round=4, cross_validation=True, sort=MAE, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001CA08E6D0A0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'MAE', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-01-03 22:13:38,160:INFO:Checking exceptions
2023-01-03 22:13:38,164:INFO:Preparing display monitor
2023-01-03 22:13:38,214:INFO:Initializing Linear Regression
2023-01-03 22:13:38,215:INFO:Total runtime is 1.66932741800944e-05 minutes
2023-01-03 22:13:38,224:INFO:SubProcess create_model() called ==================================
2023-01-03 22:13:38,224:INFO:Initializing create_model()
2023-01-03 22:13:38,224:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CA08E6D0A0>, estimator=lr, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CA092BC0A0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:13:38,225:INFO:Checking exceptions
2023-01-03 22:13:38,225:INFO:Importing libraries
2023-01-03 22:13:38,225:INFO:Copying training dataset
2023-01-03 22:13:38,235:INFO:Defining folds
2023-01-03 22:13:38,235:INFO:Declaring metric variables
2023-01-03 22:13:38,239:INFO:Importing untrained model
2023-01-03 22:13:38,243:INFO:Linear Regression Imported successfully
2023-01-03 22:13:38,252:INFO:Starting cross validation
2023-01-03 22:13:38,258:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:13:45,201:INFO:Calculating mean and std
2023-01-03 22:13:45,202:INFO:Creating metrics dataframe
2023-01-03 22:13:45,206:INFO:Uploading results into container
2023-01-03 22:13:45,207:INFO:Uploading model into container now
2023-01-03 22:13:45,208:INFO:_master_model_container: 1
2023-01-03 22:13:45,208:INFO:_display_container: 2
2023-01-03 22:13:45,208:INFO:LinearRegression(n_jobs=-1)
2023-01-03 22:13:45,208:INFO:create_model() successfully completed......................................
2023-01-03 22:13:45,335:INFO:SubProcess create_model() end ==================================
2023-01-03 22:13:45,335:INFO:Creating metrics dataframe
2023-01-03 22:13:45,343:INFO:Initializing Lasso Regression
2023-01-03 22:13:45,343:INFO:Total runtime is 0.11880909601847331 minutes
2023-01-03 22:13:45,347:INFO:SubProcess create_model() called ==================================
2023-01-03 22:13:45,347:INFO:Initializing create_model()
2023-01-03 22:13:45,347:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CA08E6D0A0>, estimator=lasso, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CA092BC0A0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:13:45,347:INFO:Checking exceptions
2023-01-03 22:13:45,347:INFO:Importing libraries
2023-01-03 22:13:45,348:INFO:Copying training dataset
2023-01-03 22:13:45,357:INFO:Defining folds
2023-01-03 22:13:45,357:INFO:Declaring metric variables
2023-01-03 22:13:45,362:INFO:Importing untrained model
2023-01-03 22:13:45,366:INFO:Lasso Regression Imported successfully
2023-01-03 22:13:45,379:INFO:Starting cross validation
2023-01-03 22:13:45,381:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:13:45,641:INFO:Calculating mean and std
2023-01-03 22:13:45,642:INFO:Creating metrics dataframe
2023-01-03 22:13:45,646:INFO:Uploading results into container
2023-01-03 22:13:45,646:INFO:Uploading model into container now
2023-01-03 22:13:45,647:INFO:_master_model_container: 2
2023-01-03 22:13:45,647:INFO:_display_container: 2
2023-01-03 22:13:45,647:INFO:Lasso(random_state=123)
2023-01-03 22:13:45,648:INFO:create_model() successfully completed......................................
2023-01-03 22:13:45,762:INFO:SubProcess create_model() end ==================================
2023-01-03 22:13:45,762:INFO:Creating metrics dataframe
2023-01-03 22:13:45,772:INFO:Initializing Ridge Regression
2023-01-03 22:13:45,772:INFO:Total runtime is 0.12595910628636678 minutes
2023-01-03 22:13:45,775:INFO:SubProcess create_model() called ==================================
2023-01-03 22:13:45,776:INFO:Initializing create_model()
2023-01-03 22:13:45,776:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CA08E6D0A0>, estimator=ridge, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CA092BC0A0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:13:45,776:INFO:Checking exceptions
2023-01-03 22:13:45,776:INFO:Importing libraries
2023-01-03 22:13:45,776:INFO:Copying training dataset
2023-01-03 22:13:45,786:INFO:Defining folds
2023-01-03 22:13:45,786:INFO:Declaring metric variables
2023-01-03 22:13:45,790:INFO:Importing untrained model
2023-01-03 22:13:45,794:INFO:Ridge Regression Imported successfully
2023-01-03 22:13:45,808:INFO:Starting cross validation
2023-01-03 22:13:45,809:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:13:46,110:INFO:Calculating mean and std
2023-01-03 22:13:46,112:INFO:Creating metrics dataframe
2023-01-03 22:13:46,115:INFO:Uploading results into container
2023-01-03 22:13:46,116:INFO:Uploading model into container now
2023-01-03 22:13:46,116:INFO:_master_model_container: 3
2023-01-03 22:13:46,116:INFO:_display_container: 2
2023-01-03 22:13:46,118:INFO:Ridge(random_state=123)
2023-01-03 22:13:46,118:INFO:create_model() successfully completed......................................
2023-01-03 22:13:46,241:INFO:SubProcess create_model() end ==================================
2023-01-03 22:13:46,241:INFO:Creating metrics dataframe
2023-01-03 22:13:46,250:INFO:Initializing Elastic Net
2023-01-03 22:13:46,250:INFO:Total runtime is 0.13392574787139894 minutes
2023-01-03 22:13:46,254:INFO:SubProcess create_model() called ==================================
2023-01-03 22:13:46,255:INFO:Initializing create_model()
2023-01-03 22:13:46,255:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CA08E6D0A0>, estimator=en, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CA092BC0A0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:13:46,255:INFO:Checking exceptions
2023-01-03 22:13:46,255:INFO:Importing libraries
2023-01-03 22:13:46,255:INFO:Copying training dataset
2023-01-03 22:13:46,264:INFO:Defining folds
2023-01-03 22:13:46,264:INFO:Declaring metric variables
2023-01-03 22:13:46,268:INFO:Importing untrained model
2023-01-03 22:13:46,272:INFO:Elastic Net Imported successfully
2023-01-03 22:13:46,280:INFO:Starting cross validation
2023-01-03 22:13:46,281:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:13:46,557:INFO:Calculating mean and std
2023-01-03 22:13:46,559:INFO:Creating metrics dataframe
2023-01-03 22:13:46,563:INFO:Uploading results into container
2023-01-03 22:13:46,563:INFO:Uploading model into container now
2023-01-03 22:13:46,564:INFO:_master_model_container: 4
2023-01-03 22:13:46,564:INFO:_display_container: 2
2023-01-03 22:13:46,564:INFO:ElasticNet(random_state=123)
2023-01-03 22:13:46,564:INFO:create_model() successfully completed......................................
2023-01-03 22:13:46,734:INFO:SubProcess create_model() end ==================================
2023-01-03 22:13:46,735:INFO:Creating metrics dataframe
2023-01-03 22:13:46,765:INFO:Initializing Least Angle Regression
2023-01-03 22:13:46,765:INFO:Total runtime is 0.14250914653142294 minutes
2023-01-03 22:13:46,769:INFO:SubProcess create_model() called ==================================
2023-01-03 22:13:46,770:INFO:Initializing create_model()
2023-01-03 22:13:46,770:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CA08E6D0A0>, estimator=lar, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CA092BC0A0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:13:46,770:INFO:Checking exceptions
2023-01-03 22:13:46,770:INFO:Importing libraries
2023-01-03 22:13:46,771:INFO:Copying training dataset
2023-01-03 22:13:46,780:INFO:Defining folds
2023-01-03 22:13:46,780:INFO:Declaring metric variables
2023-01-03 22:13:46,785:INFO:Importing untrained model
2023-01-03 22:13:46,791:INFO:Least Angle Regression Imported successfully
2023-01-03 22:13:46,806:INFO:Starting cross validation
2023-01-03 22:13:46,808:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:13:46,927:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 22:13:46,930:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=6.316e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-03 22:13:46,959:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 22:13:46,969:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 36 iterations, i.e. alpha=1.196e-02, with an active set of 31 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-03 22:13:46,972:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=2.244e-02, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-03 22:13:46,972:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=2.005e-02, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-03 22:13:46,973:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=6.296e-03, with an active set of 42 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-03 22:13:46,973:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 58 iterations, i.e. alpha=4.924e-03, with an active set of 43 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-03 22:13:46,976:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 22:13:46,976:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 22:13:46,987:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.477e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-03 22:13:46,988:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=4.981e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-03 22:13:46,991:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=2.817e-04, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-03 22:13:46,991:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=1.768e-03, with an active set of 24 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-03 22:13:46,991:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=1.453e-04, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-03 22:13:46,991:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=5.656e-05, with an active set of 42 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-03 22:13:46,992:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 48 iterations, i.e. alpha=1.054e-05, with an active set of 43 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-03 22:13:46,993:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=1.243e-03, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-03 22:13:46,994:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=4.858e-04, with an active set of 41 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-03 22:13:46,994:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=4.752e-04, with an active set of 41 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-03 22:13:46,995:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=1.250e-04, with an active set of 42 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-03 22:13:46,995:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=2.429e-05, with an active set of 43 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-03 22:13:47,015:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=3.995e-02, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-03 22:13:47,021:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 34 iterations, i.e. alpha=7.293e-03, with an active set of 30 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-03 22:13:47,022:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 34 iterations, i.e. alpha=6.732e-03, with an active set of 30 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-03 22:13:47,024:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=2.919e-01, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-03 22:13:47,025:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=2.397e-01, with an active set of 43 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-03 22:13:47,051:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 22:13:47,060:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=3.194e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-03 22:13:47,061:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=6.111e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-03 22:13:47,062:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=4.138e-03, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-03 22:13:47,069:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=2.004e-03, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-03 22:13:47,070:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=1.761e-03, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-03 22:13:47,070:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 54 iterations, i.e. alpha=9.448e-04, with an active set of 41 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-03 22:13:47,071:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=5.064e-04, with an active set of 43 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-03 22:13:47,212:INFO:Calculating mean and std
2023-01-03 22:13:47,214:INFO:Creating metrics dataframe
2023-01-03 22:13:47,219:INFO:Uploading results into container
2023-01-03 22:13:47,220:INFO:Uploading model into container now
2023-01-03 22:13:47,220:INFO:_master_model_container: 5
2023-01-03 22:13:47,221:INFO:_display_container: 2
2023-01-03 22:13:47,221:INFO:Lars(random_state=123)
2023-01-03 22:13:47,221:INFO:create_model() successfully completed......................................
2023-01-03 22:13:47,355:INFO:SubProcess create_model() end ==================================
2023-01-03 22:13:47,355:INFO:Creating metrics dataframe
2023-01-03 22:13:47,365:INFO:Initializing Lasso Least Angle Regression
2023-01-03 22:13:47,365:INFO:Total runtime is 0.1525091250737508 minutes
2023-01-03 22:13:47,371:INFO:SubProcess create_model() called ==================================
2023-01-03 22:13:47,372:INFO:Initializing create_model()
2023-01-03 22:13:47,372:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CA08E6D0A0>, estimator=llar, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CA092BC0A0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:13:47,372:INFO:Checking exceptions
2023-01-03 22:13:47,372:INFO:Importing libraries
2023-01-03 22:13:47,372:INFO:Copying training dataset
2023-01-03 22:13:47,381:INFO:Defining folds
2023-01-03 22:13:47,382:INFO:Declaring metric variables
2023-01-03 22:13:47,387:INFO:Importing untrained model
2023-01-03 22:13:47,391:INFO:Lasso Least Angle Regression Imported successfully
2023-01-03 22:13:47,407:INFO:Starting cross validation
2023-01-03 22:13:47,422:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:13:47,489:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-03 22:13:47,492:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-03 22:13:47,494:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-03 22:13:47,536:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-03 22:13:47,559:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-03 22:13:47,715:INFO:Calculating mean and std
2023-01-03 22:13:47,719:INFO:Creating metrics dataframe
2023-01-03 22:13:47,723:INFO:Uploading results into container
2023-01-03 22:13:47,723:INFO:Uploading model into container now
2023-01-03 22:13:47,724:INFO:_master_model_container: 6
2023-01-03 22:13:47,724:INFO:_display_container: 2
2023-01-03 22:13:47,724:INFO:LassoLars(random_state=123)
2023-01-03 22:13:47,725:INFO:create_model() successfully completed......................................
2023-01-03 22:13:47,865:INFO:SubProcess create_model() end ==================================
2023-01-03 22:13:47,865:INFO:Creating metrics dataframe
2023-01-03 22:13:47,880:INFO:Initializing Orthogonal Matching Pursuit
2023-01-03 22:13:47,880:INFO:Total runtime is 0.161092476050059 minutes
2023-01-03 22:13:47,885:INFO:SubProcess create_model() called ==================================
2023-01-03 22:13:47,886:INFO:Initializing create_model()
2023-01-03 22:13:47,886:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CA08E6D0A0>, estimator=omp, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CA092BC0A0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:13:47,886:INFO:Checking exceptions
2023-01-03 22:13:47,886:INFO:Importing libraries
2023-01-03 22:13:47,886:INFO:Copying training dataset
2023-01-03 22:13:47,897:INFO:Defining folds
2023-01-03 22:13:47,898:INFO:Declaring metric variables
2023-01-03 22:13:47,904:INFO:Importing untrained model
2023-01-03 22:13:47,909:INFO:Orthogonal Matching Pursuit Imported successfully
2023-01-03 22:13:47,936:INFO:Starting cross validation
2023-01-03 22:13:47,937:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:13:47,986:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 22:13:47,989:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 22:13:47,998:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 22:13:48,033:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 22:13:48,081:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 22:13:48,221:INFO:Calculating mean and std
2023-01-03 22:13:48,225:INFO:Creating metrics dataframe
2023-01-03 22:13:48,229:INFO:Uploading results into container
2023-01-03 22:13:48,230:INFO:Uploading model into container now
2023-01-03 22:13:48,230:INFO:_master_model_container: 7
2023-01-03 22:13:48,230:INFO:_display_container: 2
2023-01-03 22:13:48,231:INFO:OrthogonalMatchingPursuit()
2023-01-03 22:13:48,231:INFO:create_model() successfully completed......................................
2023-01-03 22:13:48,367:INFO:SubProcess create_model() end ==================================
2023-01-03 22:13:48,367:INFO:Creating metrics dataframe
2023-01-03 22:13:48,380:INFO:Initializing Bayesian Ridge
2023-01-03 22:13:48,380:INFO:Total runtime is 0.16942578156789143 minutes
2023-01-03 22:13:48,385:INFO:SubProcess create_model() called ==================================
2023-01-03 22:13:48,385:INFO:Initializing create_model()
2023-01-03 22:13:48,385:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CA08E6D0A0>, estimator=br, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CA092BC0A0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:13:48,385:INFO:Checking exceptions
2023-01-03 22:13:48,385:INFO:Importing libraries
2023-01-03 22:13:48,385:INFO:Copying training dataset
2023-01-03 22:13:48,396:INFO:Defining folds
2023-01-03 22:13:48,396:INFO:Declaring metric variables
2023-01-03 22:13:48,403:INFO:Importing untrained model
2023-01-03 22:13:48,407:INFO:Bayesian Ridge Imported successfully
2023-01-03 22:13:48,418:INFO:Starting cross validation
2023-01-03 22:13:48,419:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:13:48,812:INFO:Calculating mean and std
2023-01-03 22:13:48,823:INFO:Creating metrics dataframe
2023-01-03 22:13:48,827:INFO:Uploading results into container
2023-01-03 22:13:48,827:INFO:Uploading model into container now
2023-01-03 22:13:48,828:INFO:_master_model_container: 8
2023-01-03 22:13:48,828:INFO:_display_container: 2
2023-01-03 22:13:48,828:INFO:BayesianRidge()
2023-01-03 22:13:48,828:INFO:create_model() successfully completed......................................
2023-01-03 22:13:49,022:INFO:SubProcess create_model() end ==================================
2023-01-03 22:13:49,023:INFO:Creating metrics dataframe
2023-01-03 22:13:49,060:INFO:Initializing Passive Aggressive Regressor
2023-01-03 22:13:49,060:INFO:Total runtime is 0.18075915177663165 minutes
2023-01-03 22:13:49,064:INFO:SubProcess create_model() called ==================================
2023-01-03 22:13:49,065:INFO:Initializing create_model()
2023-01-03 22:13:49,065:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CA08E6D0A0>, estimator=par, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CA092BC0A0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:13:49,065:INFO:Checking exceptions
2023-01-03 22:13:49,065:INFO:Importing libraries
2023-01-03 22:13:49,065:INFO:Copying training dataset
2023-01-03 22:13:49,077:INFO:Defining folds
2023-01-03 22:13:49,077:INFO:Declaring metric variables
2023-01-03 22:13:49,095:INFO:Importing untrained model
2023-01-03 22:13:49,101:INFO:Passive Aggressive Regressor Imported successfully
2023-01-03 22:13:49,111:INFO:Starting cross validation
2023-01-03 22:13:49,112:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:13:49,597:INFO:Calculating mean and std
2023-01-03 22:13:49,598:INFO:Creating metrics dataframe
2023-01-03 22:13:49,603:INFO:Uploading results into container
2023-01-03 22:13:49,604:INFO:Uploading model into container now
2023-01-03 22:13:49,604:INFO:_master_model_container: 9
2023-01-03 22:13:49,604:INFO:_display_container: 2
2023-01-03 22:13:49,604:INFO:PassiveAggressiveRegressor(random_state=123)
2023-01-03 22:13:49,605:INFO:create_model() successfully completed......................................
2023-01-03 22:13:49,724:INFO:SubProcess create_model() end ==================================
2023-01-03 22:13:49,724:INFO:Creating metrics dataframe
2023-01-03 22:13:49,739:INFO:Initializing Huber Regressor
2023-01-03 22:13:49,739:INFO:Total runtime is 0.1920757452646891 minutes
2023-01-03 22:13:49,745:INFO:SubProcess create_model() called ==================================
2023-01-03 22:13:49,746:INFO:Initializing create_model()
2023-01-03 22:13:49,746:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CA08E6D0A0>, estimator=huber, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CA092BC0A0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:13:49,746:INFO:Checking exceptions
2023-01-03 22:13:49,746:INFO:Importing libraries
2023-01-03 22:13:49,746:INFO:Copying training dataset
2023-01-03 22:13:49,756:INFO:Defining folds
2023-01-03 22:13:49,757:INFO:Declaring metric variables
2023-01-03 22:13:49,768:INFO:Importing untrained model
2023-01-03 22:13:49,773:INFO:Huber Regressor Imported successfully
2023-01-03 22:13:49,790:INFO:Starting cross validation
2023-01-03 22:13:49,791:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:13:49,959:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-03 22:13:50,054:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-03 22:13:50,368:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-03 22:13:50,482:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-03 22:13:50,597:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-03 22:13:50,735:INFO:Calculating mean and std
2023-01-03 22:13:50,736:INFO:Creating metrics dataframe
2023-01-03 22:13:50,741:INFO:Uploading results into container
2023-01-03 22:13:50,742:INFO:Uploading model into container now
2023-01-03 22:13:50,742:INFO:_master_model_container: 10
2023-01-03 22:13:50,742:INFO:_display_container: 2
2023-01-03 22:13:50,743:INFO:HuberRegressor()
2023-01-03 22:13:50,743:INFO:create_model() successfully completed......................................
2023-01-03 22:13:50,877:INFO:SubProcess create_model() end ==================================
2023-01-03 22:13:50,877:INFO:Creating metrics dataframe
2023-01-03 22:13:50,892:INFO:Initializing K Neighbors Regressor
2023-01-03 22:13:50,892:INFO:Total runtime is 0.21129867235819497 minutes
2023-01-03 22:13:50,896:INFO:SubProcess create_model() called ==================================
2023-01-03 22:13:50,897:INFO:Initializing create_model()
2023-01-03 22:13:50,897:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CA08E6D0A0>, estimator=knn, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CA092BC0A0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:13:50,897:INFO:Checking exceptions
2023-01-03 22:13:50,897:INFO:Importing libraries
2023-01-03 22:13:50,897:INFO:Copying training dataset
2023-01-03 22:13:50,907:INFO:Defining folds
2023-01-03 22:13:50,908:INFO:Declaring metric variables
2023-01-03 22:13:50,912:INFO:Importing untrained model
2023-01-03 22:13:50,915:INFO:K Neighbors Regressor Imported successfully
2023-01-03 22:13:50,924:INFO:Starting cross validation
2023-01-03 22:13:50,926:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:13:51,859:INFO:Calculating mean and std
2023-01-03 22:13:51,861:INFO:Creating metrics dataframe
2023-01-03 22:13:51,864:INFO:Uploading results into container
2023-01-03 22:13:51,865:INFO:Uploading model into container now
2023-01-03 22:13:51,865:INFO:_master_model_container: 11
2023-01-03 22:13:51,866:INFO:_display_container: 2
2023-01-03 22:13:51,866:INFO:KNeighborsRegressor(n_jobs=-1)
2023-01-03 22:13:51,866:INFO:create_model() successfully completed......................................
2023-01-03 22:13:52,057:INFO:SubProcess create_model() end ==================================
2023-01-03 22:13:52,057:INFO:Creating metrics dataframe
2023-01-03 22:13:52,071:INFO:Initializing Decision Tree Regressor
2023-01-03 22:13:52,071:INFO:Total runtime is 0.23094870249430335 minutes
2023-01-03 22:13:52,075:INFO:SubProcess create_model() called ==================================
2023-01-03 22:13:52,075:INFO:Initializing create_model()
2023-01-03 22:13:52,075:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CA08E6D0A0>, estimator=dt, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CA092BC0A0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:13:52,075:INFO:Checking exceptions
2023-01-03 22:13:52,075:INFO:Importing libraries
2023-01-03 22:13:52,075:INFO:Copying training dataset
2023-01-03 22:13:52,086:INFO:Defining folds
2023-01-03 22:13:52,088:INFO:Declaring metric variables
2023-01-03 22:13:52,095:INFO:Importing untrained model
2023-01-03 22:13:52,099:INFO:Decision Tree Regressor Imported successfully
2023-01-03 22:13:52,112:INFO:Starting cross validation
2023-01-03 22:13:52,113:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:13:52,649:INFO:Calculating mean and std
2023-01-03 22:13:52,654:INFO:Creating metrics dataframe
2023-01-03 22:13:52,658:INFO:Uploading results into container
2023-01-03 22:13:52,658:INFO:Uploading model into container now
2023-01-03 22:13:52,659:INFO:_master_model_container: 12
2023-01-03 22:13:52,659:INFO:_display_container: 2
2023-01-03 22:13:52,659:INFO:DecisionTreeRegressor(random_state=123)
2023-01-03 22:13:52,660:INFO:create_model() successfully completed......................................
2023-01-03 22:13:52,805:INFO:SubProcess create_model() end ==================================
2023-01-03 22:13:52,805:INFO:Creating metrics dataframe
2023-01-03 22:13:52,818:INFO:Initializing Random Forest Regressor
2023-01-03 22:13:52,818:INFO:Total runtime is 0.2433986941973368 minutes
2023-01-03 22:13:52,822:INFO:SubProcess create_model() called ==================================
2023-01-03 22:13:52,822:INFO:Initializing create_model()
2023-01-03 22:13:52,822:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CA08E6D0A0>, estimator=rf, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CA092BC0A0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:13:52,822:INFO:Checking exceptions
2023-01-03 22:13:52,822:INFO:Importing libraries
2023-01-03 22:13:52,822:INFO:Copying training dataset
2023-01-03 22:13:52,832:INFO:Defining folds
2023-01-03 22:13:52,832:INFO:Declaring metric variables
2023-01-03 22:13:52,836:INFO:Importing untrained model
2023-01-03 22:13:52,840:INFO:Random Forest Regressor Imported successfully
2023-01-03 22:13:52,880:INFO:Starting cross validation
2023-01-03 22:13:52,881:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:14:05,102:INFO:Calculating mean and std
2023-01-03 22:14:05,103:INFO:Creating metrics dataframe
2023-01-03 22:14:05,107:INFO:Uploading results into container
2023-01-03 22:14:05,107:INFO:Uploading model into container now
2023-01-03 22:14:05,108:INFO:_master_model_container: 13
2023-01-03 22:14:05,108:INFO:_display_container: 2
2023-01-03 22:14:05,108:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-01-03 22:14:05,109:INFO:create_model() successfully completed......................................
2023-01-03 22:14:05,221:INFO:SubProcess create_model() end ==================================
2023-01-03 22:14:05,221:INFO:Creating metrics dataframe
2023-01-03 22:14:05,232:INFO:Initializing Extra Trees Regressor
2023-01-03 22:14:05,233:INFO:Total runtime is 0.45031535228093467 minutes
2023-01-03 22:14:05,236:INFO:SubProcess create_model() called ==================================
2023-01-03 22:14:05,237:INFO:Initializing create_model()
2023-01-03 22:14:05,237:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CA08E6D0A0>, estimator=et, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CA092BC0A0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:14:05,237:INFO:Checking exceptions
2023-01-03 22:14:05,237:INFO:Importing libraries
2023-01-03 22:14:05,237:INFO:Copying training dataset
2023-01-03 22:14:05,246:INFO:Defining folds
2023-01-03 22:14:05,247:INFO:Declaring metric variables
2023-01-03 22:14:05,250:INFO:Importing untrained model
2023-01-03 22:14:05,255:INFO:Extra Trees Regressor Imported successfully
2023-01-03 22:14:05,263:INFO:Starting cross validation
2023-01-03 22:14:05,265:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:14:10,409:INFO:Calculating mean and std
2023-01-03 22:14:10,411:INFO:Creating metrics dataframe
2023-01-03 22:14:10,414:INFO:Uploading results into container
2023-01-03 22:14:10,415:INFO:Uploading model into container now
2023-01-03 22:14:10,415:INFO:_master_model_container: 14
2023-01-03 22:14:10,415:INFO:_display_container: 2
2023-01-03 22:14:10,416:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-01-03 22:14:10,416:INFO:create_model() successfully completed......................................
2023-01-03 22:14:10,521:INFO:SubProcess create_model() end ==================================
2023-01-03 22:14:10,521:INFO:Creating metrics dataframe
2023-01-03 22:14:10,534:INFO:Initializing AdaBoost Regressor
2023-01-03 22:14:10,534:INFO:Total runtime is 0.5386550545692443 minutes
2023-01-03 22:14:10,544:INFO:SubProcess create_model() called ==================================
2023-01-03 22:14:10,544:INFO:Initializing create_model()
2023-01-03 22:14:10,544:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CA08E6D0A0>, estimator=ada, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CA092BC0A0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:14:10,545:INFO:Checking exceptions
2023-01-03 22:14:10,545:INFO:Importing libraries
2023-01-03 22:14:10,545:INFO:Copying training dataset
2023-01-03 22:14:10,556:INFO:Defining folds
2023-01-03 22:14:10,557:INFO:Declaring metric variables
2023-01-03 22:14:10,561:INFO:Importing untrained model
2023-01-03 22:14:10,565:INFO:AdaBoost Regressor Imported successfully
2023-01-03 22:14:10,579:INFO:Starting cross validation
2023-01-03 22:14:10,581:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:14:12,001:INFO:Calculating mean and std
2023-01-03 22:14:12,004:INFO:Creating metrics dataframe
2023-01-03 22:14:12,008:INFO:Uploading results into container
2023-01-03 22:14:12,009:INFO:Uploading model into container now
2023-01-03 22:14:12,010:INFO:_master_model_container: 15
2023-01-03 22:14:12,010:INFO:_display_container: 2
2023-01-03 22:14:12,010:INFO:AdaBoostRegressor(random_state=123)
2023-01-03 22:14:12,010:INFO:create_model() successfully completed......................................
2023-01-03 22:14:12,128:INFO:SubProcess create_model() end ==================================
2023-01-03 22:14:12,128:INFO:Creating metrics dataframe
2023-01-03 22:14:12,142:INFO:Initializing Gradient Boosting Regressor
2023-01-03 22:14:12,142:INFO:Total runtime is 0.5654550671577453 minutes
2023-01-03 22:14:12,145:INFO:SubProcess create_model() called ==================================
2023-01-03 22:14:12,146:INFO:Initializing create_model()
2023-01-03 22:14:12,146:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CA08E6D0A0>, estimator=gbr, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CA092BC0A0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:14:12,146:INFO:Checking exceptions
2023-01-03 22:14:12,146:INFO:Importing libraries
2023-01-03 22:14:12,146:INFO:Copying training dataset
2023-01-03 22:14:12,157:INFO:Defining folds
2023-01-03 22:14:12,157:INFO:Declaring metric variables
2023-01-03 22:14:12,161:INFO:Importing untrained model
2023-01-03 22:14:12,165:INFO:Gradient Boosting Regressor Imported successfully
2023-01-03 22:14:12,176:INFO:Starting cross validation
2023-01-03 22:14:12,177:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:14:18,747:INFO:Calculating mean and std
2023-01-03 22:14:18,749:INFO:Creating metrics dataframe
2023-01-03 22:14:18,754:INFO:Uploading results into container
2023-01-03 22:14:18,755:INFO:Uploading model into container now
2023-01-03 22:14:18,756:INFO:_master_model_container: 16
2023-01-03 22:14:18,756:INFO:_display_container: 2
2023-01-03 22:14:18,756:INFO:GradientBoostingRegressor(random_state=123)
2023-01-03 22:14:18,757:INFO:create_model() successfully completed......................................
2023-01-03 22:14:18,874:INFO:SubProcess create_model() end ==================================
2023-01-03 22:14:18,874:INFO:Creating metrics dataframe
2023-01-03 22:14:18,892:INFO:Initializing Light Gradient Boosting Machine
2023-01-03 22:14:18,892:INFO:Total runtime is 0.6779550711313883 minutes
2023-01-03 22:14:18,895:INFO:SubProcess create_model() called ==================================
2023-01-03 22:14:18,896:INFO:Initializing create_model()
2023-01-03 22:14:18,896:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CA08E6D0A0>, estimator=lightgbm, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CA092BC0A0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:14:18,896:INFO:Checking exceptions
2023-01-03 22:14:18,896:INFO:Importing libraries
2023-01-03 22:14:18,896:INFO:Copying training dataset
2023-01-03 22:14:18,907:INFO:Defining folds
2023-01-03 22:14:18,907:INFO:Declaring metric variables
2023-01-03 22:14:18,912:INFO:Importing untrained model
2023-01-03 22:14:18,915:INFO:Light Gradient Boosting Machine Imported successfully
2023-01-03 22:14:18,924:INFO:Starting cross validation
2023-01-03 22:14:18,926:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:14:21,419:INFO:Calculating mean and std
2023-01-03 22:14:21,421:INFO:Creating metrics dataframe
2023-01-03 22:14:21,424:INFO:Uploading results into container
2023-01-03 22:14:21,425:INFO:Uploading model into container now
2023-01-03 22:14:21,425:INFO:_master_model_container: 17
2023-01-03 22:14:21,426:INFO:_display_container: 2
2023-01-03 22:14:21,426:INFO:LGBMRegressor(random_state=123)
2023-01-03 22:14:21,426:INFO:create_model() successfully completed......................................
2023-01-03 22:14:21,531:INFO:SubProcess create_model() end ==================================
2023-01-03 22:14:21,531:INFO:Creating metrics dataframe
2023-01-03 22:14:21,544:INFO:Initializing Dummy Regressor
2023-01-03 22:14:21,544:INFO:Total runtime is 0.7221688469250996 minutes
2023-01-03 22:14:21,548:INFO:SubProcess create_model() called ==================================
2023-01-03 22:14:21,548:INFO:Initializing create_model()
2023-01-03 22:14:21,548:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CA08E6D0A0>, estimator=dummy, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CA092BC0A0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:14:21,548:INFO:Checking exceptions
2023-01-03 22:14:21,549:INFO:Importing libraries
2023-01-03 22:14:21,549:INFO:Copying training dataset
2023-01-03 22:14:21,558:INFO:Defining folds
2023-01-03 22:14:21,559:INFO:Declaring metric variables
2023-01-03 22:14:21,563:INFO:Importing untrained model
2023-01-03 22:14:21,567:INFO:Dummy Regressor Imported successfully
2023-01-03 22:14:21,575:INFO:Starting cross validation
2023-01-03 22:14:21,577:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:14:21,826:INFO:Calculating mean and std
2023-01-03 22:14:21,828:INFO:Creating metrics dataframe
2023-01-03 22:14:21,832:INFO:Uploading results into container
2023-01-03 22:14:21,833:INFO:Uploading model into container now
2023-01-03 22:14:21,833:INFO:_master_model_container: 18
2023-01-03 22:14:21,834:INFO:_display_container: 2
2023-01-03 22:14:21,834:INFO:DummyRegressor()
2023-01-03 22:14:21,834:INFO:create_model() successfully completed......................................
2023-01-03 22:14:21,949:INFO:SubProcess create_model() end ==================================
2023-01-03 22:14:21,949:INFO:Creating metrics dataframe
2023-01-03 22:14:21,977:INFO:Initializing create_model()
2023-01-03 22:14:21,977:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CA08E6D0A0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:14:21,977:INFO:Checking exceptions
2023-01-03 22:14:21,979:INFO:Importing libraries
2023-01-03 22:14:21,979:INFO:Copying training dataset
2023-01-03 22:14:21,989:INFO:Defining folds
2023-01-03 22:14:21,989:INFO:Declaring metric variables
2023-01-03 22:14:21,989:INFO:Importing untrained model
2023-01-03 22:14:21,989:INFO:Declaring custom model
2023-01-03 22:14:21,990:INFO:Extra Trees Regressor Imported successfully
2023-01-03 22:14:21,991:INFO:Cross validation set to False
2023-01-03 22:14:21,992:INFO:Fitting Model
2023-01-03 22:14:24,401:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-01-03 22:14:24,401:INFO:create_model() successfully completed......................................
2023-01-03 22:14:24,557:INFO:_master_model_container: 18
2023-01-03 22:14:24,558:INFO:_display_container: 2
2023-01-03 22:14:24,558:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-01-03 22:14:24,558:INFO:compare_models() successfully completed......................................
2023-01-03 22:14:24,568:INFO:Initializing tune_model()
2023-01-03 22:14:24,569:INFO:tune_model(estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=MAE, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CA08E6D0A0>)
2023-01-03 22:14:24,569:INFO:Checking exceptions
2023-01-03 22:14:24,609:INFO:Copying training dataset
2023-01-03 22:14:24,622:INFO:Checking base model
2023-01-03 22:14:24,622:INFO:Base model : Extra Trees Regressor
2023-01-03 22:14:24,627:INFO:Declaring metric variables
2023-01-03 22:14:24,631:INFO:Defining Hyperparameters
2023-01-03 22:14:24,797:INFO:Tuning with n_jobs=-1
2023-01-03 22:14:24,797:INFO:Initializing RandomizedSearchCV
2023-01-03 22:14:24,846:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:14:24,849:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:14:24,856:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:14:24,877:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:14:25,261:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:14:25,275:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:14:25,296:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:14:25,490:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:14:25,683:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:14:25,687:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:14:25,794:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:14:25,991:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:14:26,027:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:14:26,038:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:14:26,760:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:14:26,782:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:14:26,810:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:14:26,830:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:14:27,160:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:14:27,249:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:14:27,643:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:14:27,938:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:14:28,042:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:14:28,113:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:14:28,313:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:14:28,672:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 22:14:28,796:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 22:14:28,807:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 22:14:30,402:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 22:14:30,938:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 22:14:33,527:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:14:36,885:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:14:36,968:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:14:39,573:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:14:39,795:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:14:42,362:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:14:42,604:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:14:43,248:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:14:43,737:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:14:43,885:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:14:44,688:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 22:14:45,322:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 22:14:45,939:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 22:14:47,890:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 22:14:51,372:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 22:14:52,339:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:14:56,123:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:14:58,197:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:14:59,053:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:15:00,914:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:15:10,477:INFO:best_params: {'actual_estimator__n_estimators': 100, 'actual_estimator__min_samples_split': 7, 'actual_estimator__min_samples_leaf': 4, 'actual_estimator__min_impurity_decrease': 0.1, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 9, 'actual_estimator__criterion': 'mse', 'actual_estimator__bootstrap': True}
2023-01-03 22:15:10,479:INFO:Hyperparameter search completed
2023-01-03 22:15:10,479:INFO:SubProcess create_model() called ==================================
2023-01-03 22:15:10,480:INFO:Initializing create_model()
2023-01-03 22:15:10,480:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CA08E6D0A0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CA08C86C40>, model_only=True, return_train_score=False, kwargs={'n_estimators': 100, 'min_samples_split': 7, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.1, 'max_features': 1.0, 'max_depth': 9, 'criterion': 'mse', 'bootstrap': True})
2023-01-03 22:15:10,480:INFO:Checking exceptions
2023-01-03 22:15:10,480:INFO:Importing libraries
2023-01-03 22:15:10,480:INFO:Copying training dataset
2023-01-03 22:15:10,491:INFO:Defining folds
2023-01-03 22:15:10,491:INFO:Declaring metric variables
2023-01-03 22:15:10,495:INFO:Importing untrained model
2023-01-03 22:15:10,495:INFO:Declaring custom model
2023-01-03 22:15:10,499:INFO:Extra Trees Regressor Imported successfully
2023-01-03 22:15:10,508:INFO:Starting cross validation
2023-01-03 22:15:10,510:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:15:10,560:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:15:10,565:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:15:10,576:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:15:10,591:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:15:11,079:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:15:11,556:INFO:Calculating mean and std
2023-01-03 22:15:11,558:INFO:Creating metrics dataframe
2023-01-03 22:15:11,564:INFO:Finalizing model
2023-01-03 22:15:12,003:INFO:Uploading results into container
2023-01-03 22:15:12,004:INFO:Uploading model into container now
2023-01-03 22:15:12,005:INFO:_master_model_container: 19
2023-01-03 22:15:12,005:INFO:_display_container: 3
2023-01-03 22:15:12,006:INFO:ExtraTreesRegressor(bootstrap=True, criterion='mse', max_depth=9,
                    max_features=1.0, min_impurity_decrease=0.1,
                    min_samples_leaf=4, min_samples_split=7, n_jobs=-1,
                    random_state=123)
2023-01-03 22:15:12,006:INFO:create_model() successfully completed......................................
2023-01-03 22:15:12,131:INFO:SubProcess create_model() end ==================================
2023-01-03 22:15:12,132:INFO:choose_better activated
2023-01-03 22:15:12,135:INFO:SubProcess create_model() called ==================================
2023-01-03 22:15:12,135:INFO:Initializing create_model()
2023-01-03 22:15:12,136:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CA08E6D0A0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:15:12,136:INFO:Checking exceptions
2023-01-03 22:15:12,139:INFO:Importing libraries
2023-01-03 22:15:12,139:INFO:Copying training dataset
2023-01-03 22:15:12,147:INFO:Defining folds
2023-01-03 22:15:12,147:INFO:Declaring metric variables
2023-01-03 22:15:12,147:INFO:Importing untrained model
2023-01-03 22:15:12,147:INFO:Declaring custom model
2023-01-03 22:15:12,148:INFO:Extra Trees Regressor Imported successfully
2023-01-03 22:15:12,148:INFO:Starting cross validation
2023-01-03 22:15:12,149:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:15:16,753:INFO:Calculating mean and std
2023-01-03 22:15:16,754:INFO:Creating metrics dataframe
2023-01-03 22:15:16,757:INFO:Finalizing model
2023-01-03 22:15:18,593:INFO:Uploading results into container
2023-01-03 22:15:18,593:INFO:Uploading model into container now
2023-01-03 22:15:18,594:INFO:_master_model_container: 20
2023-01-03 22:15:18,594:INFO:_display_container: 4
2023-01-03 22:15:18,594:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-01-03 22:15:18,594:INFO:create_model() successfully completed......................................
2023-01-03 22:15:18,710:INFO:SubProcess create_model() end ==================================
2023-01-03 22:15:18,711:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123) result for MAE is 2.2531
2023-01-03 22:15:18,712:INFO:ExtraTreesRegressor(bootstrap=True, criterion='mse', max_depth=9,
                    max_features=1.0, min_impurity_decrease=0.1,
                    min_samples_leaf=4, min_samples_split=7, n_jobs=-1,
                    random_state=123) result for MAE is 2.9741
2023-01-03 22:15:18,712:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123) is best model
2023-01-03 22:15:18,712:INFO:choose_better completed
2023-01-03 22:15:18,713:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-01-03 22:15:18,722:INFO:_master_model_container: 20
2023-01-03 22:15:18,722:INFO:_display_container: 3
2023-01-03 22:15:18,723:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-01-03 22:15:18,723:INFO:tune_model() successfully completed......................................
2023-01-03 22:15:18,854:INFO:Initializing plot_model()
2023-01-03 22:15:18,854:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CA08E6D0A0>, system=True)
2023-01-03 22:15:18,854:INFO:Checking exceptions
2023-01-03 22:15:18,879:INFO:Preloading libraries
2023-01-03 22:15:19,023:INFO:Copying training dataset
2023-01-03 22:15:19,024:INFO:Plot type: error
2023-01-03 22:15:19,140:INFO:Fitting Model
2023-01-03 22:15:19,140:INFO:Scoring test/hold-out set
2023-01-03 22:15:19,449:INFO:Visual Rendered Successfully
2023-01-03 22:15:19,567:INFO:plot_model() successfully completed......................................
2023-01-03 22:15:19,578:INFO:Initializing predict_model()
2023-01-03 22:15:19,579:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CA08E6D0A0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001CA08487550>)
2023-01-03 22:15:19,579:INFO:Checking exceptions
2023-01-03 22:15:19,579:INFO:Preloading libraries
2023-01-03 22:15:19,781:INFO:Initializing finalize_model()
2023-01-03 22:15:19,782:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CA08E6D0A0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-01-03 22:15:19,782:INFO:Finalizing ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-01-03 22:15:19,792:INFO:Initializing create_model()
2023-01-03 22:15:19,792:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CA08E6D0A0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-01-03 22:15:19,792:INFO:Checking exceptions
2023-01-03 22:15:19,794:INFO:Importing libraries
2023-01-03 22:15:19,794:INFO:Copying training dataset
2023-01-03 22:15:19,795:INFO:Defining folds
2023-01-03 22:15:19,795:INFO:Declaring metric variables
2023-01-03 22:15:19,796:INFO:Importing untrained model
2023-01-03 22:15:19,796:INFO:Declaring custom model
2023-01-03 22:15:19,796:INFO:Extra Trees Regressor Imported successfully
2023-01-03 22:15:19,797:INFO:Cross validation set to False
2023-01-03 22:15:19,797:INFO:Fitting Model
2023-01-03 22:15:22,258:INFO:Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))])
2023-01-03 22:15:22,258:INFO:create_model() successfully completed......................................
2023-01-03 22:15:22,361:INFO:_master_model_container: 20
2023-01-03 22:15:22,361:INFO:_display_container: 4
2023-01-03 22:15:22,368:INFO:Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))])
2023-01-03 22:15:22,368:INFO:finalize_model() successfully completed......................................
2023-01-03 22:15:22,491:INFO:Initializing predict_model()
2023-01-03 22:15:22,491:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CA08E6D0A0>, estimator=Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001CA7B572670>)
2023-01-03 22:15:22,491:INFO:Checking exceptions
2023-01-03 22:15:22,491:INFO:Preloading libraries
2023-01-03 22:15:22,493:INFO:Set up data.
2023-01-03 22:15:22,508:INFO:Set up index.
2023-01-03 22:15:22,907:INFO:Initializing save_model()
2023-01-03 22:15:22,908:INFO:save_model(model=Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))]), model_name=c:\Users\Kodotautas\Desktop\Data_science\7_TIME_SERIES_FORECAST_PYCARET/models/final_model.pkl, prep_pipe_=Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-01-03 22:15:22,908:INFO:Adding model into prep_pipe
2023-01-03 22:15:23,092:WARNING:Only Model saved as it was a pipeline.
2023-01-03 22:15:23,249:INFO:c:\Users\Kodotautas\Desktop\Data_science\7_TIME_SERIES_FORECAST_PYCARET/models/final_model.pkl.pkl saved in current working directory
2023-01-03 22:15:23,256:INFO:Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))])
2023-01-03 22:15:23,256:INFO:save_model() successfully completed......................................
2023-01-03 22:20:12,370:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-01-03 22:20:12,371:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-01-03 22:20:12,371:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-01-03 22:20:12,371:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-01-03 22:20:13,171:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-01-03 22:20:13,588:INFO:PyCaret RegressionExperiment
2023-01-03 22:20:13,588:INFO:Logging name: reg-default-name
2023-01-03 22:20:13,588:INFO:ML Usecase: MLUsecase.REGRESSION
2023-01-03 22:20:13,589:INFO:version 3.0.0.rc6
2023-01-03 22:20:13,589:INFO:Initializing setup()
2023-01-03 22:20:13,589:INFO:self.USI: d3ba
2023-01-03 22:20:13,589:INFO:self._variable_keys: {'USI', 'data', 'X', 'html_param', 'n_jobs_param', 'seed', 'memory', '_ml_usecase', 'fold_shuffle_param', 'y', 'exp_id', 'X_test', 'pipeline', 'transform_target_param', 'gpu_param', 'gpu_n_jobs_param', 'y_train', 'logging_param', 'log_plots_param', 'idx', 'fold_generator', '_available_plots', 'y_test', 'fold_groups_param', 'target_param', 'exp_name_log', 'X_train'}
2023-01-03 22:20:13,589:INFO:Checking environment
2023-01-03 22:20:13,589:INFO:python_version: 3.9.13
2023-01-03 22:20:13,589:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-01-03 22:20:13,589:INFO:machine: AMD64
2023-01-03 22:20:13,589:INFO:platform: Windows-10-10.0.19044-SP0
2023-01-03 22:20:13,589:INFO:Memory: svmem(total=17114804224, available=10361450496, percent=39.5, used=6753353728, free=10361450496)
2023-01-03 22:20:13,589:INFO:Physical Core: 4
2023-01-03 22:20:13,589:INFO:Logical Core: 4
2023-01-03 22:20:13,589:INFO:Checking libraries
2023-01-03 22:20:13,589:INFO:System:
2023-01-03 22:20:13,589:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-01-03 22:20:13,589:INFO:executable: c:\Users\Kodotautas\anaconda3\python.exe
2023-01-03 22:20:13,589:INFO:   machine: Windows-10-10.0.19044-SP0
2023-01-03 22:20:13,589:INFO:PyCaret required dependencies:
2023-01-03 22:20:13,589:INFO:                 pip: 22.2.2
2023-01-03 22:20:13,589:INFO:          setuptools: 63.4.1
2023-01-03 22:20:13,590:INFO:             pycaret: 3.0.0rc6
2023-01-03 22:20:13,590:INFO:             IPython: 7.31.1
2023-01-03 22:20:13,590:INFO:          ipywidgets: 7.6.5
2023-01-03 22:20:13,590:INFO:                tqdm: 4.64.1
2023-01-03 22:20:13,590:INFO:               numpy: 1.21.5
2023-01-03 22:20:13,590:INFO:              pandas: 1.4.4
2023-01-03 22:20:13,590:INFO:              jinja2: 2.11.3
2023-01-03 22:20:13,590:INFO:               scipy: 1.9.1
2023-01-03 22:20:13,590:INFO:              joblib: 1.2.0
2023-01-03 22:20:13,590:INFO:             sklearn: 1.0.2
2023-01-03 22:20:13,590:INFO:                pyod: 1.0.7
2023-01-03 22:20:13,590:INFO:            imblearn: 0.10.1
2023-01-03 22:20:13,590:INFO:   category_encoders: 2.5.1.post0
2023-01-03 22:20:13,590:INFO:            lightgbm: 3.3.3
2023-01-03 22:20:13,590:INFO:               numba: 0.55.1
2023-01-03 22:20:13,590:INFO:            requests: 2.28.1
2023-01-03 22:20:13,590:INFO:          matplotlib: 3.5.2
2023-01-03 22:20:13,590:INFO:          scikitplot: 0.3.7
2023-01-03 22:20:13,590:INFO:         yellowbrick: 1.5
2023-01-03 22:20:13,590:INFO:              plotly: 5.9.0
2023-01-03 22:20:13,590:INFO:             kaleido: 0.2.1
2023-01-03 22:20:13,590:INFO:         statsmodels: 0.13.2
2023-01-03 22:20:13,590:INFO:              sktime: 0.14.1
2023-01-03 22:20:13,590:INFO:               tbats: 1.1.2
2023-01-03 22:20:13,591:INFO:            pmdarima: 2.0.2
2023-01-03 22:20:13,591:INFO:              psutil: 5.9.0
2023-01-03 22:20:13,591:INFO:PyCaret optional dependencies:
2023-01-03 22:20:13,870:INFO:                shap: 0.41.0
2023-01-03 22:20:13,870:INFO:           interpret: Not installed
2023-01-03 22:20:13,870:INFO:                umap: Not installed
2023-01-03 22:20:13,870:INFO:    pandas_profiling: Not installed
2023-01-03 22:20:13,870:INFO:  explainerdashboard: Not installed
2023-01-03 22:20:13,870:INFO:             autoviz: Not installed
2023-01-03 22:20:13,870:INFO:           fairlearn: Not installed
2023-01-03 22:20:13,870:INFO:             xgboost: Not installed
2023-01-03 22:20:13,870:INFO:            catboost: Not installed
2023-01-03 22:20:13,870:INFO:              kmodes: Not installed
2023-01-03 22:20:13,870:INFO:             mlxtend: Not installed
2023-01-03 22:20:13,870:INFO:       statsforecast: Not installed
2023-01-03 22:20:13,870:INFO:        tune_sklearn: 0.4.3
2023-01-03 22:20:13,870:INFO:                 ray: 2.0.0
2023-01-03 22:20:13,870:INFO:            hyperopt: 0.2.7
2023-01-03 22:20:13,870:INFO:              optuna: 3.0.1
2023-01-03 22:20:13,870:INFO:               skopt: 0.9.0
2023-01-03 22:20:13,870:INFO:              mlflow: Not installed
2023-01-03 22:20:13,870:INFO:              gradio: Not installed
2023-01-03 22:20:13,871:INFO:             fastapi: 0.88.0
2023-01-03 22:20:13,871:INFO:             uvicorn: 0.20.0
2023-01-03 22:20:13,871:INFO:              m2cgen: Not installed
2023-01-03 22:20:13,871:INFO:           evidently: Not installed
2023-01-03 22:20:13,871:INFO:                nltk: 3.7
2023-01-03 22:20:13,871:INFO:            pyLDAvis: Not installed
2023-01-03 22:20:13,871:INFO:              gensim: 4.1.2
2023-01-03 22:20:13,871:INFO:               spacy: 3.4.2
2023-01-03 22:20:13,871:INFO:           wordcloud: Not installed
2023-01-03 22:20:13,871:INFO:            textblob: Not installed
2023-01-03 22:20:13,871:INFO:               fugue: Not installed
2023-01-03 22:20:13,871:INFO:           streamlit: Not installed
2023-01-03 22:20:13,871:INFO:             prophet: Not installed
2023-01-03 22:20:13,871:INFO:None
2023-01-03 22:20:13,871:INFO:Set up data.
2023-01-03 22:20:13,893:INFO:Set up train/test split.
2023-01-03 22:20:13,906:INFO:Set up index.
2023-01-03 22:20:13,908:INFO:Set up folding strategy.
2023-01-03 22:20:13,908:INFO:Assigning column types.
2023-01-03 22:20:13,920:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-01-03 22:20:13,920:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-01-03 22:20:13,925:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-03 22:20:13,930:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 22:20:14,003:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 22:20:14,052:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 22:20:14,053:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:20:14,189:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:20:14,190:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-01-03 22:20:14,195:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-03 22:20:14,200:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 22:20:14,273:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 22:20:14,324:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 22:20:14,325:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:20:14,325:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:20:14,326:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-01-03 22:20:14,331:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-03 22:20:14,336:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 22:20:14,405:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 22:20:14,454:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 22:20:14,455:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:20:14,455:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:20:14,461:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-03 22:20:14,466:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 22:20:14,540:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 22:20:14,589:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 22:20:14,590:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:20:14,590:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:20:14,590:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-01-03 22:20:14,599:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 22:20:14,670:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 22:20:14,721:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 22:20:14,722:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:20:14,722:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:20:14,733:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 22:20:14,812:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 22:20:14,863:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 22:20:14,864:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:20:14,864:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:20:14,864:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-01-03 22:20:14,950:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 22:20:15,003:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 22:20:15,003:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:20:15,003:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:20:15,088:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 22:20:15,135:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 22:20:15,135:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:20:15,136:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:20:15,136:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-01-03 22:20:15,214:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 22:20:15,265:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:20:15,265:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:20:15,348:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 22:20:15,396:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:20:15,396:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:20:15,397:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-01-03 22:20:15,527:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:20:15,527:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:20:15,653:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:20:15,653:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:20:15,654:INFO:Preparing preprocessing pipeline...
2023-01-03 22:20:15,656:INFO:Set up simple imputation.
2023-01-03 22:20:15,656:INFO:Set up column transformation.
2023-01-03 22:20:15,656:INFO:Set up feature normalization.
2023-01-03 22:20:16,222:INFO:Finished creating preprocessing pipeline.
2023-01-03 22:20:16,227:INFO:Pipeline: Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2023-01-03 22:20:16,228:INFO:Creating final display dataframe.
2023-01-03 22:20:16,751:INFO:Setup _display_container:                Description             Value
0               Session id               123
1                   Target        b2b+b2c+vt
2              Target type        Regression
3               Data shape       (10506, 45)
4         Train data shape        (7354, 45)
5          Test data shape        (3152, 45)
6         Numeric features                 8
7               Preprocess              True
8          Imputation type            simple
9       Numeric imputation              mean
10  Categorical imputation              mode
11          Transformation              True
12   Transformation method       yeo-johnson
13               Normalize              True
14        Normalize method            zscore
15          Fold Generator   TimeSeriesSplit
16             Fold Number                 5
17                CPU Jobs                -1
18                 Use GPU             False
19          Log Experiment             False
20         Experiment Name  reg-default-name
21                     USI              d3ba
2023-01-03 22:20:16,994:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:20:16,995:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:20:17,128:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:20:17,128:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:20:17,129:INFO:setup() successfully completed in 3.54s...............
2023-01-03 22:20:17,129:INFO:Initializing compare_models()
2023-01-03 22:20:17,129:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001839D8C1670>, include=None, fold=None, round=4, cross_validation=True, sort=MAE, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001839D8C1670>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'MAE', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-01-03 22:20:17,129:INFO:Checking exceptions
2023-01-03 22:20:17,135:INFO:Preparing display monitor
2023-01-03 22:20:17,175:INFO:Initializing Linear Regression
2023-01-03 22:20:17,176:INFO:Total runtime is 1.6637643178304036e-05 minutes
2023-01-03 22:20:17,180:INFO:SubProcess create_model() called ==================================
2023-01-03 22:20:17,180:INFO:Initializing create_model()
2023-01-03 22:20:17,181:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001839D8C1670>, estimator=lr, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000183A32FBFA0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:20:17,181:INFO:Checking exceptions
2023-01-03 22:20:17,181:INFO:Importing libraries
2023-01-03 22:20:17,181:INFO:Copying training dataset
2023-01-03 22:20:17,195:INFO:Defining folds
2023-01-03 22:20:17,195:INFO:Declaring metric variables
2023-01-03 22:20:17,204:INFO:Importing untrained model
2023-01-03 22:20:17,208:INFO:Linear Regression Imported successfully
2023-01-03 22:20:17,216:INFO:Starting cross validation
2023-01-03 22:20:17,223:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:20:24,218:INFO:Calculating mean and std
2023-01-03 22:20:24,220:INFO:Creating metrics dataframe
2023-01-03 22:20:24,223:INFO:Uploading results into container
2023-01-03 22:20:24,223:INFO:Uploading model into container now
2023-01-03 22:20:24,224:INFO:_master_model_container: 1
2023-01-03 22:20:24,224:INFO:_display_container: 2
2023-01-03 22:20:24,225:INFO:LinearRegression(n_jobs=-1)
2023-01-03 22:20:24,225:INFO:create_model() successfully completed......................................
2023-01-03 22:20:24,329:INFO:SubProcess create_model() end ==================================
2023-01-03 22:20:24,329:INFO:Creating metrics dataframe
2023-01-03 22:20:24,341:INFO:Initializing Lasso Regression
2023-01-03 22:20:24,342:INFO:Total runtime is 0.11944468816121419 minutes
2023-01-03 22:20:24,346:INFO:SubProcess create_model() called ==================================
2023-01-03 22:20:24,346:INFO:Initializing create_model()
2023-01-03 22:20:24,346:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001839D8C1670>, estimator=lasso, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000183A32FBFA0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:20:24,346:INFO:Checking exceptions
2023-01-03 22:20:24,346:INFO:Importing libraries
2023-01-03 22:20:24,346:INFO:Copying training dataset
2023-01-03 22:20:24,355:INFO:Defining folds
2023-01-03 22:20:24,356:INFO:Declaring metric variables
2023-01-03 22:20:24,360:INFO:Importing untrained model
2023-01-03 22:20:24,365:INFO:Lasso Regression Imported successfully
2023-01-03 22:20:24,372:INFO:Starting cross validation
2023-01-03 22:20:24,374:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:20:24,786:INFO:Calculating mean and std
2023-01-03 22:20:24,788:INFO:Creating metrics dataframe
2023-01-03 22:20:24,791:INFO:Uploading results into container
2023-01-03 22:20:24,791:INFO:Uploading model into container now
2023-01-03 22:20:24,792:INFO:_master_model_container: 2
2023-01-03 22:20:24,792:INFO:_display_container: 2
2023-01-03 22:20:24,792:INFO:Lasso(random_state=123)
2023-01-03 22:20:24,792:INFO:create_model() successfully completed......................................
2023-01-03 22:20:24,898:INFO:SubProcess create_model() end ==================================
2023-01-03 22:20:24,898:INFO:Creating metrics dataframe
2023-01-03 22:20:24,910:INFO:Initializing Ridge Regression
2023-01-03 22:20:24,910:INFO:Total runtime is 0.12892624139785766 minutes
2023-01-03 22:20:24,914:INFO:SubProcess create_model() called ==================================
2023-01-03 22:20:24,914:INFO:Initializing create_model()
2023-01-03 22:20:24,915:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001839D8C1670>, estimator=ridge, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000183A32FBFA0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:20:24,915:INFO:Checking exceptions
2023-01-03 22:20:24,915:INFO:Importing libraries
2023-01-03 22:20:24,915:INFO:Copying training dataset
2023-01-03 22:20:24,925:INFO:Defining folds
2023-01-03 22:20:24,926:INFO:Declaring metric variables
2023-01-03 22:20:24,930:INFO:Importing untrained model
2023-01-03 22:20:24,935:INFO:Ridge Regression Imported successfully
2023-01-03 22:20:24,944:INFO:Starting cross validation
2023-01-03 22:20:24,946:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:20:25,072:INFO:Calculating mean and std
2023-01-03 22:20:25,074:INFO:Creating metrics dataframe
2023-01-03 22:20:25,077:INFO:Uploading results into container
2023-01-03 22:20:25,078:INFO:Uploading model into container now
2023-01-03 22:20:25,078:INFO:_master_model_container: 3
2023-01-03 22:20:25,078:INFO:_display_container: 2
2023-01-03 22:20:25,079:INFO:Ridge(random_state=123)
2023-01-03 22:20:25,079:INFO:create_model() successfully completed......................................
2023-01-03 22:20:25,183:INFO:SubProcess create_model() end ==================================
2023-01-03 22:20:25,183:INFO:Creating metrics dataframe
2023-01-03 22:20:25,195:INFO:Initializing Elastic Net
2023-01-03 22:20:25,195:INFO:Total runtime is 0.13367609977722167 minutes
2023-01-03 22:20:25,199:INFO:SubProcess create_model() called ==================================
2023-01-03 22:20:25,200:INFO:Initializing create_model()
2023-01-03 22:20:25,200:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001839D8C1670>, estimator=en, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000183A32FBFA0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:20:25,200:INFO:Checking exceptions
2023-01-03 22:20:25,200:INFO:Importing libraries
2023-01-03 22:20:25,200:INFO:Copying training dataset
2023-01-03 22:20:25,212:INFO:Defining folds
2023-01-03 22:20:25,212:INFO:Declaring metric variables
2023-01-03 22:20:25,217:INFO:Importing untrained model
2023-01-03 22:20:25,223:INFO:Elastic Net Imported successfully
2023-01-03 22:20:25,244:INFO:Starting cross validation
2023-01-03 22:20:25,245:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:20:25,385:INFO:Calculating mean and std
2023-01-03 22:20:25,387:INFO:Creating metrics dataframe
2023-01-03 22:20:25,390:INFO:Uploading results into container
2023-01-03 22:20:25,390:INFO:Uploading model into container now
2023-01-03 22:20:25,391:INFO:_master_model_container: 4
2023-01-03 22:20:25,391:INFO:_display_container: 2
2023-01-03 22:20:25,391:INFO:ElasticNet(random_state=123)
2023-01-03 22:20:25,392:INFO:create_model() successfully completed......................................
2023-01-03 22:20:25,498:INFO:SubProcess create_model() end ==================================
2023-01-03 22:20:25,498:INFO:Creating metrics dataframe
2023-01-03 22:20:25,510:INFO:Initializing Least Angle Regression
2023-01-03 22:20:25,511:INFO:Total runtime is 0.13894307613372803 minutes
2023-01-03 22:20:25,514:INFO:SubProcess create_model() called ==================================
2023-01-03 22:20:25,514:INFO:Initializing create_model()
2023-01-03 22:20:25,515:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001839D8C1670>, estimator=lar, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000183A32FBFA0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:20:25,515:INFO:Checking exceptions
2023-01-03 22:20:25,515:INFO:Importing libraries
2023-01-03 22:20:25,515:INFO:Copying training dataset
2023-01-03 22:20:25,526:INFO:Defining folds
2023-01-03 22:20:25,526:INFO:Declaring metric variables
2023-01-03 22:20:25,530:INFO:Importing untrained model
2023-01-03 22:20:25,535:INFO:Least Angle Regression Imported successfully
2023-01-03 22:20:25,543:INFO:Starting cross validation
2023-01-03 22:20:25,544:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:20:25,594:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 22:20:25,599:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 22:20:25,615:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 22:20:25,629:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 22:20:25,670:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 22:20:25,815:INFO:Calculating mean and std
2023-01-03 22:20:25,817:INFO:Creating metrics dataframe
2023-01-03 22:20:25,821:INFO:Uploading results into container
2023-01-03 22:20:25,822:INFO:Uploading model into container now
2023-01-03 22:20:25,823:INFO:_master_model_container: 5
2023-01-03 22:20:25,823:INFO:_display_container: 2
2023-01-03 22:20:25,823:INFO:Lars(random_state=123)
2023-01-03 22:20:25,823:INFO:create_model() successfully completed......................................
2023-01-03 22:20:25,930:INFO:SubProcess create_model() end ==================================
2023-01-03 22:20:25,930:INFO:Creating metrics dataframe
2023-01-03 22:20:25,940:INFO:Initializing Lasso Least Angle Regression
2023-01-03 22:20:25,941:INFO:Total runtime is 0.14609978199005128 minutes
2023-01-03 22:20:25,945:INFO:SubProcess create_model() called ==================================
2023-01-03 22:20:25,945:INFO:Initializing create_model()
2023-01-03 22:20:25,945:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001839D8C1670>, estimator=llar, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000183A32FBFA0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:20:25,945:INFO:Checking exceptions
2023-01-03 22:20:25,945:INFO:Importing libraries
2023-01-03 22:20:25,945:INFO:Copying training dataset
2023-01-03 22:20:25,955:INFO:Defining folds
2023-01-03 22:20:25,955:INFO:Declaring metric variables
2023-01-03 22:20:25,959:INFO:Importing untrained model
2023-01-03 22:20:25,963:INFO:Lasso Least Angle Regression Imported successfully
2023-01-03 22:20:25,972:INFO:Starting cross validation
2023-01-03 22:20:25,974:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:20:26,022:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-03 22:20:26,029:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-03 22:20:26,037:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-03 22:20:26,057:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-03 22:20:26,084:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-03 22:20:26,211:INFO:Calculating mean and std
2023-01-03 22:20:26,213:INFO:Creating metrics dataframe
2023-01-03 22:20:26,216:INFO:Uploading results into container
2023-01-03 22:20:26,217:INFO:Uploading model into container now
2023-01-03 22:20:26,217:INFO:_master_model_container: 6
2023-01-03 22:20:26,217:INFO:_display_container: 2
2023-01-03 22:20:26,218:INFO:LassoLars(random_state=123)
2023-01-03 22:20:26,218:INFO:create_model() successfully completed......................................
2023-01-03 22:20:26,357:INFO:SubProcess create_model() end ==================================
2023-01-03 22:20:26,357:INFO:Creating metrics dataframe
2023-01-03 22:20:26,372:INFO:Initializing Orthogonal Matching Pursuit
2023-01-03 22:20:26,372:INFO:Total runtime is 0.15328309138615925 minutes
2023-01-03 22:20:26,376:INFO:SubProcess create_model() called ==================================
2023-01-03 22:20:26,377:INFO:Initializing create_model()
2023-01-03 22:20:26,377:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001839D8C1670>, estimator=omp, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000183A32FBFA0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:20:26,377:INFO:Checking exceptions
2023-01-03 22:20:26,377:INFO:Importing libraries
2023-01-03 22:20:26,377:INFO:Copying training dataset
2023-01-03 22:20:26,388:INFO:Defining folds
2023-01-03 22:20:26,388:INFO:Declaring metric variables
2023-01-03 22:20:26,392:INFO:Importing untrained model
2023-01-03 22:20:26,397:INFO:Orthogonal Matching Pursuit Imported successfully
2023-01-03 22:20:26,409:INFO:Starting cross validation
2023-01-03 22:20:26,410:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:20:26,466:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 22:20:26,469:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 22:20:26,477:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 22:20:26,512:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 22:20:26,537:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 22:20:26,667:INFO:Calculating mean and std
2023-01-03 22:20:26,670:INFO:Creating metrics dataframe
2023-01-03 22:20:26,675:INFO:Uploading results into container
2023-01-03 22:20:26,676:INFO:Uploading model into container now
2023-01-03 22:20:26,676:INFO:_master_model_container: 7
2023-01-03 22:20:26,676:INFO:_display_container: 2
2023-01-03 22:20:26,676:INFO:OrthogonalMatchingPursuit()
2023-01-03 22:20:26,677:INFO:create_model() successfully completed......................................
2023-01-03 22:20:26,782:INFO:SubProcess create_model() end ==================================
2023-01-03 22:20:26,782:INFO:Creating metrics dataframe
2023-01-03 22:20:26,792:INFO:Initializing Bayesian Ridge
2023-01-03 22:20:26,792:INFO:Total runtime is 0.16028343041737875 minutes
2023-01-03 22:20:26,796:INFO:SubProcess create_model() called ==================================
2023-01-03 22:20:26,796:INFO:Initializing create_model()
2023-01-03 22:20:26,796:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001839D8C1670>, estimator=br, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000183A32FBFA0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:20:26,797:INFO:Checking exceptions
2023-01-03 22:20:26,797:INFO:Importing libraries
2023-01-03 22:20:26,797:INFO:Copying training dataset
2023-01-03 22:20:26,807:INFO:Defining folds
2023-01-03 22:20:26,807:INFO:Declaring metric variables
2023-01-03 22:20:26,812:INFO:Importing untrained model
2023-01-03 22:20:26,816:INFO:Bayesian Ridge Imported successfully
2023-01-03 22:20:26,825:INFO:Starting cross validation
2023-01-03 22:20:26,826:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:20:27,075:INFO:Calculating mean and std
2023-01-03 22:20:27,077:INFO:Creating metrics dataframe
2023-01-03 22:20:27,080:INFO:Uploading results into container
2023-01-03 22:20:27,080:INFO:Uploading model into container now
2023-01-03 22:20:27,080:INFO:_master_model_container: 8
2023-01-03 22:20:27,080:INFO:_display_container: 2
2023-01-03 22:20:27,081:INFO:BayesianRidge()
2023-01-03 22:20:27,081:INFO:create_model() successfully completed......................................
2023-01-03 22:20:27,180:INFO:SubProcess create_model() end ==================================
2023-01-03 22:20:27,180:INFO:Creating metrics dataframe
2023-01-03 22:20:27,192:INFO:Initializing Passive Aggressive Regressor
2023-01-03 22:20:27,192:INFO:Total runtime is 0.1669534206390381 minutes
2023-01-03 22:20:27,196:INFO:SubProcess create_model() called ==================================
2023-01-03 22:20:27,197:INFO:Initializing create_model()
2023-01-03 22:20:27,198:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001839D8C1670>, estimator=par, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000183A32FBFA0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:20:27,198:INFO:Checking exceptions
2023-01-03 22:20:27,198:INFO:Importing libraries
2023-01-03 22:20:27,198:INFO:Copying training dataset
2023-01-03 22:20:27,208:INFO:Defining folds
2023-01-03 22:20:27,209:INFO:Declaring metric variables
2023-01-03 22:20:27,212:INFO:Importing untrained model
2023-01-03 22:20:27,216:INFO:Passive Aggressive Regressor Imported successfully
2023-01-03 22:20:27,225:INFO:Starting cross validation
2023-01-03 22:20:27,226:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:20:27,469:INFO:Calculating mean and std
2023-01-03 22:20:27,471:INFO:Creating metrics dataframe
2023-01-03 22:20:27,474:INFO:Uploading results into container
2023-01-03 22:20:27,474:INFO:Uploading model into container now
2023-01-03 22:20:27,474:INFO:_master_model_container: 9
2023-01-03 22:20:27,474:INFO:_display_container: 2
2023-01-03 22:20:27,475:INFO:PassiveAggressiveRegressor(random_state=123)
2023-01-03 22:20:27,475:INFO:create_model() successfully completed......................................
2023-01-03 22:20:27,578:INFO:SubProcess create_model() end ==================================
2023-01-03 22:20:27,579:INFO:Creating metrics dataframe
2023-01-03 22:20:27,592:INFO:Initializing Huber Regressor
2023-01-03 22:20:27,592:INFO:Total runtime is 0.1736246705055237 minutes
2023-01-03 22:20:27,596:INFO:SubProcess create_model() called ==================================
2023-01-03 22:20:27,597:INFO:Initializing create_model()
2023-01-03 22:20:27,597:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001839D8C1670>, estimator=huber, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000183A32FBFA0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:20:27,597:INFO:Checking exceptions
2023-01-03 22:20:27,597:INFO:Importing libraries
2023-01-03 22:20:27,597:INFO:Copying training dataset
2023-01-03 22:20:27,607:INFO:Defining folds
2023-01-03 22:20:27,608:INFO:Declaring metric variables
2023-01-03 22:20:27,612:INFO:Importing untrained model
2023-01-03 22:20:27,616:INFO:Huber Regressor Imported successfully
2023-01-03 22:20:27,626:INFO:Starting cross validation
2023-01-03 22:20:27,627:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:20:27,742:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-03 22:20:27,817:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-03 22:20:27,901:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-03 22:20:28,072:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-03 22:20:28,176:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-03 22:20:28,296:INFO:Calculating mean and std
2023-01-03 22:20:28,298:INFO:Creating metrics dataframe
2023-01-03 22:20:28,302:INFO:Uploading results into container
2023-01-03 22:20:28,303:INFO:Uploading model into container now
2023-01-03 22:20:28,304:INFO:_master_model_container: 10
2023-01-03 22:20:28,304:INFO:_display_container: 2
2023-01-03 22:20:28,304:INFO:HuberRegressor()
2023-01-03 22:20:28,305:INFO:create_model() successfully completed......................................
2023-01-03 22:20:28,406:INFO:SubProcess create_model() end ==================================
2023-01-03 22:20:28,407:INFO:Creating metrics dataframe
2023-01-03 22:20:28,418:INFO:Initializing K Neighbors Regressor
2023-01-03 22:20:28,418:INFO:Total runtime is 0.18739424546559652 minutes
2023-01-03 22:20:28,423:INFO:SubProcess create_model() called ==================================
2023-01-03 22:20:28,423:INFO:Initializing create_model()
2023-01-03 22:20:28,423:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001839D8C1670>, estimator=knn, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000183A32FBFA0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:20:28,423:INFO:Checking exceptions
2023-01-03 22:20:28,423:INFO:Importing libraries
2023-01-03 22:20:28,424:INFO:Copying training dataset
2023-01-03 22:20:28,433:INFO:Defining folds
2023-01-03 22:20:28,433:INFO:Declaring metric variables
2023-01-03 22:20:28,438:INFO:Importing untrained model
2023-01-03 22:20:28,443:INFO:K Neighbors Regressor Imported successfully
2023-01-03 22:20:28,453:INFO:Starting cross validation
2023-01-03 22:20:28,454:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:20:29,125:INFO:Calculating mean and std
2023-01-03 22:20:29,127:INFO:Creating metrics dataframe
2023-01-03 22:20:29,130:INFO:Uploading results into container
2023-01-03 22:20:29,131:INFO:Uploading model into container now
2023-01-03 22:20:29,132:INFO:_master_model_container: 11
2023-01-03 22:20:29,132:INFO:_display_container: 2
2023-01-03 22:20:29,133:INFO:KNeighborsRegressor(n_jobs=-1)
2023-01-03 22:20:29,133:INFO:create_model() successfully completed......................................
2023-01-03 22:20:29,236:INFO:SubProcess create_model() end ==================================
2023-01-03 22:20:29,237:INFO:Creating metrics dataframe
2023-01-03 22:20:29,248:INFO:Initializing Decision Tree Regressor
2023-01-03 22:20:29,248:INFO:Total runtime is 0.20121222337086997 minutes
2023-01-03 22:20:29,252:INFO:SubProcess create_model() called ==================================
2023-01-03 22:20:29,253:INFO:Initializing create_model()
2023-01-03 22:20:29,253:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001839D8C1670>, estimator=dt, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000183A32FBFA0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:20:29,253:INFO:Checking exceptions
2023-01-03 22:20:29,253:INFO:Importing libraries
2023-01-03 22:20:29,253:INFO:Copying training dataset
2023-01-03 22:20:29,262:INFO:Defining folds
2023-01-03 22:20:29,262:INFO:Declaring metric variables
2023-01-03 22:20:29,267:INFO:Importing untrained model
2023-01-03 22:20:29,272:INFO:Decision Tree Regressor Imported successfully
2023-01-03 22:20:29,279:INFO:Starting cross validation
2023-01-03 22:20:29,281:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:20:29,747:INFO:Calculating mean and std
2023-01-03 22:20:29,749:INFO:Creating metrics dataframe
2023-01-03 22:20:29,752:INFO:Uploading results into container
2023-01-03 22:20:29,752:INFO:Uploading model into container now
2023-01-03 22:20:29,753:INFO:_master_model_container: 12
2023-01-03 22:20:29,753:INFO:_display_container: 2
2023-01-03 22:20:29,753:INFO:DecisionTreeRegressor(random_state=123)
2023-01-03 22:20:29,753:INFO:create_model() successfully completed......................................
2023-01-03 22:20:29,852:INFO:SubProcess create_model() end ==================================
2023-01-03 22:20:29,852:INFO:Creating metrics dataframe
2023-01-03 22:20:29,866:INFO:Initializing Random Forest Regressor
2023-01-03 22:20:29,866:INFO:Total runtime is 0.21152180830637615 minutes
2023-01-03 22:20:29,870:INFO:SubProcess create_model() called ==================================
2023-01-03 22:20:29,871:INFO:Initializing create_model()
2023-01-03 22:20:29,871:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001839D8C1670>, estimator=rf, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000183A32FBFA0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:20:29,871:INFO:Checking exceptions
2023-01-03 22:20:29,871:INFO:Importing libraries
2023-01-03 22:20:29,871:INFO:Copying training dataset
2023-01-03 22:20:29,880:INFO:Defining folds
2023-01-03 22:20:29,881:INFO:Declaring metric variables
2023-01-03 22:20:29,885:INFO:Importing untrained model
2023-01-03 22:20:29,890:INFO:Random Forest Regressor Imported successfully
2023-01-03 22:20:29,897:INFO:Starting cross validation
2023-01-03 22:20:29,898:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:20:39,803:INFO:Calculating mean and std
2023-01-03 22:20:39,805:INFO:Creating metrics dataframe
2023-01-03 22:20:39,808:INFO:Uploading results into container
2023-01-03 22:20:39,808:INFO:Uploading model into container now
2023-01-03 22:20:39,808:INFO:_master_model_container: 13
2023-01-03 22:20:39,809:INFO:_display_container: 2
2023-01-03 22:20:39,810:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-01-03 22:20:39,810:INFO:create_model() successfully completed......................................
2023-01-03 22:20:39,911:INFO:SubProcess create_model() end ==================================
2023-01-03 22:20:39,911:INFO:Creating metrics dataframe
2023-01-03 22:20:39,924:INFO:Initializing Extra Trees Regressor
2023-01-03 22:20:39,925:INFO:Total runtime is 0.37917501529057823 minutes
2023-01-03 22:20:39,929:INFO:SubProcess create_model() called ==================================
2023-01-03 22:20:39,930:INFO:Initializing create_model()
2023-01-03 22:20:39,930:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001839D8C1670>, estimator=et, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000183A32FBFA0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:20:39,930:INFO:Checking exceptions
2023-01-03 22:20:39,930:INFO:Importing libraries
2023-01-03 22:20:39,930:INFO:Copying training dataset
2023-01-03 22:20:39,941:INFO:Defining folds
2023-01-03 22:20:39,941:INFO:Declaring metric variables
2023-01-03 22:20:39,945:INFO:Importing untrained model
2023-01-03 22:20:39,949:INFO:Extra Trees Regressor Imported successfully
2023-01-03 22:20:39,958:INFO:Starting cross validation
2023-01-03 22:20:39,960:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:20:45,403:INFO:Calculating mean and std
2023-01-03 22:20:45,404:INFO:Creating metrics dataframe
2023-01-03 22:20:45,408:INFO:Uploading results into container
2023-01-03 22:20:45,408:INFO:Uploading model into container now
2023-01-03 22:20:45,409:INFO:_master_model_container: 14
2023-01-03 22:20:45,409:INFO:_display_container: 2
2023-01-03 22:20:45,410:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-01-03 22:20:45,410:INFO:create_model() successfully completed......................................
2023-01-03 22:20:45,527:INFO:SubProcess create_model() end ==================================
2023-01-03 22:20:45,527:INFO:Creating metrics dataframe
2023-01-03 22:20:45,540:INFO:Initializing AdaBoost Regressor
2023-01-03 22:20:45,540:INFO:Total runtime is 0.47275836865107224 minutes
2023-01-03 22:20:45,544:INFO:SubProcess create_model() called ==================================
2023-01-03 22:20:45,545:INFO:Initializing create_model()
2023-01-03 22:20:45,545:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001839D8C1670>, estimator=ada, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000183A32FBFA0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:20:45,545:INFO:Checking exceptions
2023-01-03 22:20:45,545:INFO:Importing libraries
2023-01-03 22:20:45,545:INFO:Copying training dataset
2023-01-03 22:20:45,555:INFO:Defining folds
2023-01-03 22:20:45,555:INFO:Declaring metric variables
2023-01-03 22:20:45,559:INFO:Importing untrained model
2023-01-03 22:20:45,563:INFO:AdaBoost Regressor Imported successfully
2023-01-03 22:20:45,570:INFO:Starting cross validation
2023-01-03 22:20:45,572:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:20:47,620:INFO:Calculating mean and std
2023-01-03 22:20:47,621:INFO:Creating metrics dataframe
2023-01-03 22:20:47,624:INFO:Uploading results into container
2023-01-03 22:20:47,624:INFO:Uploading model into container now
2023-01-03 22:20:47,625:INFO:_master_model_container: 15
2023-01-03 22:20:47,626:INFO:_display_container: 2
2023-01-03 22:20:47,626:INFO:AdaBoostRegressor(random_state=123)
2023-01-03 22:20:47,626:INFO:create_model() successfully completed......................................
2023-01-03 22:20:47,733:INFO:SubProcess create_model() end ==================================
2023-01-03 22:20:47,733:INFO:Creating metrics dataframe
2023-01-03 22:20:47,746:INFO:Initializing Gradient Boosting Regressor
2023-01-03 22:20:47,747:INFO:Total runtime is 0.5095126032829285 minutes
2023-01-03 22:20:47,750:INFO:SubProcess create_model() called ==================================
2023-01-03 22:20:47,751:INFO:Initializing create_model()
2023-01-03 22:20:47,751:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001839D8C1670>, estimator=gbr, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000183A32FBFA0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:20:47,751:INFO:Checking exceptions
2023-01-03 22:20:47,751:INFO:Importing libraries
2023-01-03 22:20:47,751:INFO:Copying training dataset
2023-01-03 22:20:47,761:INFO:Defining folds
2023-01-03 22:20:47,761:INFO:Declaring metric variables
2023-01-03 22:20:47,766:INFO:Importing untrained model
2023-01-03 22:20:47,770:INFO:Gradient Boosting Regressor Imported successfully
2023-01-03 22:20:47,779:INFO:Starting cross validation
2023-01-03 22:20:47,781:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:20:52,933:INFO:Calculating mean and std
2023-01-03 22:20:52,935:INFO:Creating metrics dataframe
2023-01-03 22:20:52,940:INFO:Uploading results into container
2023-01-03 22:20:52,941:INFO:Uploading model into container now
2023-01-03 22:20:52,941:INFO:_master_model_container: 16
2023-01-03 22:20:52,941:INFO:_display_container: 2
2023-01-03 22:20:52,942:INFO:GradientBoostingRegressor(random_state=123)
2023-01-03 22:20:52,942:INFO:create_model() successfully completed......................................
2023-01-03 22:20:53,061:INFO:SubProcess create_model() end ==================================
2023-01-03 22:20:53,061:INFO:Creating metrics dataframe
2023-01-03 22:20:53,075:INFO:Initializing Light Gradient Boosting Machine
2023-01-03 22:20:53,075:INFO:Total runtime is 0.5983423630396525 minutes
2023-01-03 22:20:53,078:INFO:SubProcess create_model() called ==================================
2023-01-03 22:20:53,079:INFO:Initializing create_model()
2023-01-03 22:20:53,079:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001839D8C1670>, estimator=lightgbm, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000183A32FBFA0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:20:53,079:INFO:Checking exceptions
2023-01-03 22:20:53,079:INFO:Importing libraries
2023-01-03 22:20:53,079:INFO:Copying training dataset
2023-01-03 22:20:53,090:INFO:Defining folds
2023-01-03 22:20:53,090:INFO:Declaring metric variables
2023-01-03 22:20:53,094:INFO:Importing untrained model
2023-01-03 22:20:53,098:INFO:Light Gradient Boosting Machine Imported successfully
2023-01-03 22:20:53,106:INFO:Starting cross validation
2023-01-03 22:20:53,107:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:20:55,413:INFO:Calculating mean and std
2023-01-03 22:20:55,415:INFO:Creating metrics dataframe
2023-01-03 22:20:55,419:INFO:Uploading results into container
2023-01-03 22:20:55,420:INFO:Uploading model into container now
2023-01-03 22:20:55,421:INFO:_master_model_container: 17
2023-01-03 22:20:55,421:INFO:_display_container: 2
2023-01-03 22:20:55,421:INFO:LGBMRegressor(random_state=123)
2023-01-03 22:20:55,421:INFO:create_model() successfully completed......................................
2023-01-03 22:20:55,544:INFO:SubProcess create_model() end ==================================
2023-01-03 22:20:55,544:INFO:Creating metrics dataframe
2023-01-03 22:20:55,557:INFO:Initializing Dummy Regressor
2023-01-03 22:20:55,558:INFO:Total runtime is 0.6397256970405578 minutes
2023-01-03 22:20:55,561:INFO:SubProcess create_model() called ==================================
2023-01-03 22:20:55,561:INFO:Initializing create_model()
2023-01-03 22:20:55,561:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001839D8C1670>, estimator=dummy, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000183A32FBFA0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:20:55,561:INFO:Checking exceptions
2023-01-03 22:20:55,561:INFO:Importing libraries
2023-01-03 22:20:55,562:INFO:Copying training dataset
2023-01-03 22:20:55,574:INFO:Defining folds
2023-01-03 22:20:55,574:INFO:Declaring metric variables
2023-01-03 22:20:55,578:INFO:Importing untrained model
2023-01-03 22:20:55,582:INFO:Dummy Regressor Imported successfully
2023-01-03 22:20:55,590:INFO:Starting cross validation
2023-01-03 22:20:55,591:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:20:55,810:INFO:Calculating mean and std
2023-01-03 22:20:55,812:INFO:Creating metrics dataframe
2023-01-03 22:20:55,815:INFO:Uploading results into container
2023-01-03 22:20:55,816:INFO:Uploading model into container now
2023-01-03 22:20:55,817:INFO:_master_model_container: 18
2023-01-03 22:20:55,817:INFO:_display_container: 2
2023-01-03 22:20:55,817:INFO:DummyRegressor()
2023-01-03 22:20:55,817:INFO:create_model() successfully completed......................................
2023-01-03 22:20:55,938:INFO:SubProcess create_model() end ==================================
2023-01-03 22:20:55,938:INFO:Creating metrics dataframe
2023-01-03 22:20:55,963:INFO:Initializing create_model()
2023-01-03 22:20:55,964:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001839D8C1670>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:20:55,964:INFO:Checking exceptions
2023-01-03 22:20:55,966:INFO:Importing libraries
2023-01-03 22:20:55,966:INFO:Copying training dataset
2023-01-03 22:20:55,975:INFO:Defining folds
2023-01-03 22:20:55,975:INFO:Declaring metric variables
2023-01-03 22:20:55,975:INFO:Importing untrained model
2023-01-03 22:20:55,975:INFO:Declaring custom model
2023-01-03 22:20:55,976:INFO:Extra Trees Regressor Imported successfully
2023-01-03 22:20:55,977:INFO:Cross validation set to False
2023-01-03 22:20:55,977:INFO:Fitting Model
2023-01-03 22:20:57,856:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-01-03 22:20:57,856:INFO:create_model() successfully completed......................................
2023-01-03 22:20:57,994:INFO:_master_model_container: 18
2023-01-03 22:20:57,995:INFO:_display_container: 2
2023-01-03 22:20:57,995:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-01-03 22:20:57,995:INFO:compare_models() successfully completed......................................
2023-01-03 22:20:57,995:INFO:Initializing tune_model()
2023-01-03 22:20:57,996:INFO:tune_model(estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=MAE, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001839D8C1670>)
2023-01-03 22:20:57,996:INFO:Checking exceptions
2023-01-03 22:20:58,033:INFO:Copying training dataset
2023-01-03 22:20:58,042:INFO:Checking base model
2023-01-03 22:20:58,043:INFO:Base model : Extra Trees Regressor
2023-01-03 22:20:58,047:INFO:Declaring metric variables
2023-01-03 22:20:58,052:INFO:Defining Hyperparameters
2023-01-03 22:20:58,235:INFO:Tuning with n_jobs=-1
2023-01-03 22:20:58,235:INFO:Initializing RandomizedSearchCV
2023-01-03 22:20:58,287:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:20:58,290:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:20:58,296:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:20:58,308:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:20:58,622:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:20:58,647:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:20:58,762:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:20:58,767:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:20:59,006:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:20:59,011:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:20:59,109:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:20:59,235:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:20:59,300:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:20:59,309:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:20:59,864:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:20:59,889:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:21:00,036:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:21:00,134:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:21:00,139:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:21:00,770:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:21:00,812:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:21:00,848:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:21:00,917:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:21:01,445:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 22:21:01,449:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:21:01,455:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:21:01,637:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 22:21:02,742:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 22:21:02,864:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 22:21:02,910:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 22:21:05,943:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:21:09,749:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:21:11,172:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:21:12,158:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:21:13,688:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:21:14,290:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:21:14,649:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:21:14,928:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:21:15,199:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:21:15,741:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:21:16,176:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 22:21:16,525:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 22:21:17,707:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 22:21:18,640:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 22:21:20,296:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 22:21:21,411:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:21:24,870:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:21:27,689:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:21:27,886:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:21:29,763:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:21:36,770:INFO:best_params: {'actual_estimator__n_estimators': 100, 'actual_estimator__min_samples_split': 7, 'actual_estimator__min_samples_leaf': 4, 'actual_estimator__min_impurity_decrease': 0.1, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 9, 'actual_estimator__criterion': 'mse', 'actual_estimator__bootstrap': True}
2023-01-03 22:21:36,772:INFO:Hyperparameter search completed
2023-01-03 22:21:36,772:INFO:SubProcess create_model() called ==================================
2023-01-03 22:21:36,773:INFO:Initializing create_model()
2023-01-03 22:21:36,773:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001839D8C1670>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000183A384EB80>, model_only=True, return_train_score=False, kwargs={'n_estimators': 100, 'min_samples_split': 7, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.1, 'max_features': 1.0, 'max_depth': 9, 'criterion': 'mse', 'bootstrap': True})
2023-01-03 22:21:36,773:INFO:Checking exceptions
2023-01-03 22:21:36,773:INFO:Importing libraries
2023-01-03 22:21:36,773:INFO:Copying training dataset
2023-01-03 22:21:36,783:INFO:Defining folds
2023-01-03 22:21:36,783:INFO:Declaring metric variables
2023-01-03 22:21:36,786:INFO:Importing untrained model
2023-01-03 22:21:36,786:INFO:Declaring custom model
2023-01-03 22:21:36,791:INFO:Extra Trees Regressor Imported successfully
2023-01-03 22:21:36,800:INFO:Starting cross validation
2023-01-03 22:21:36,801:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:21:36,851:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:21:36,853:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:21:36,865:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:21:36,892:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:21:37,342:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:21:37,784:INFO:Calculating mean and std
2023-01-03 22:21:37,786:INFO:Creating metrics dataframe
2023-01-03 22:21:37,791:INFO:Finalizing model
2023-01-03 22:21:38,125:INFO:Uploading results into container
2023-01-03 22:21:38,127:INFO:Uploading model into container now
2023-01-03 22:21:38,127:INFO:_master_model_container: 19
2023-01-03 22:21:38,127:INFO:_display_container: 3
2023-01-03 22:21:38,128:INFO:ExtraTreesRegressor(bootstrap=True, criterion='mse', max_depth=9,
                    max_features=1.0, min_impurity_decrease=0.1,
                    min_samples_leaf=4, min_samples_split=7, n_jobs=-1,
                    random_state=123)
2023-01-03 22:21:38,128:INFO:create_model() successfully completed......................................
2023-01-03 22:21:38,242:INFO:SubProcess create_model() end ==================================
2023-01-03 22:21:38,242:INFO:choose_better activated
2023-01-03 22:21:38,245:INFO:SubProcess create_model() called ==================================
2023-01-03 22:21:38,246:INFO:Initializing create_model()
2023-01-03 22:21:38,246:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001839D8C1670>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:21:38,246:INFO:Checking exceptions
2023-01-03 22:21:38,248:INFO:Importing libraries
2023-01-03 22:21:38,248:INFO:Copying training dataset
2023-01-03 22:21:38,257:INFO:Defining folds
2023-01-03 22:21:38,257:INFO:Declaring metric variables
2023-01-03 22:21:38,257:INFO:Importing untrained model
2023-01-03 22:21:38,257:INFO:Declaring custom model
2023-01-03 22:21:38,258:INFO:Extra Trees Regressor Imported successfully
2023-01-03 22:21:38,258:INFO:Starting cross validation
2023-01-03 22:21:38,259:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:21:42,254:INFO:Calculating mean and std
2023-01-03 22:21:42,256:INFO:Creating metrics dataframe
2023-01-03 22:21:42,258:INFO:Finalizing model
2023-01-03 22:21:43,859:INFO:Uploading results into container
2023-01-03 22:21:43,860:INFO:Uploading model into container now
2023-01-03 22:21:43,860:INFO:_master_model_container: 20
2023-01-03 22:21:43,860:INFO:_display_container: 4
2023-01-03 22:21:43,861:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-01-03 22:21:43,861:INFO:create_model() successfully completed......................................
2023-01-03 22:21:43,959:INFO:SubProcess create_model() end ==================================
2023-01-03 22:21:43,960:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123) result for MAE is 2.2409
2023-01-03 22:21:43,961:INFO:ExtraTreesRegressor(bootstrap=True, criterion='mse', max_depth=9,
                    max_features=1.0, min_impurity_decrease=0.1,
                    min_samples_leaf=4, min_samples_split=7, n_jobs=-1,
                    random_state=123) result for MAE is 2.9961
2023-01-03 22:21:43,961:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123) is best model
2023-01-03 22:21:43,961:INFO:choose_better completed
2023-01-03 22:21:43,961:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-01-03 22:21:43,970:INFO:_master_model_container: 20
2023-01-03 22:21:43,970:INFO:_display_container: 3
2023-01-03 22:21:43,971:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-01-03 22:21:43,971:INFO:tune_model() successfully completed......................................
2023-01-03 22:21:44,085:INFO:Initializing plot_model()
2023-01-03 22:21:44,085:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001839D8C1670>, system=True)
2023-01-03 22:21:44,085:INFO:Checking exceptions
2023-01-03 22:21:44,111:INFO:Preloading libraries
2023-01-03 22:21:44,248:INFO:Copying training dataset
2023-01-03 22:21:44,248:INFO:Plot type: error
2023-01-03 22:21:44,411:INFO:Fitting Model
2023-01-03 22:21:44,411:INFO:Scoring test/hold-out set
2023-01-03 22:21:44,880:INFO:Visual Rendered Successfully
2023-01-03 22:21:45,033:INFO:plot_model() successfully completed......................................
2023-01-03 22:21:45,045:INFO:Initializing predict_model()
2023-01-03 22:21:45,045:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001839D8C1670>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x00000183A703EEE0>)
2023-01-03 22:21:45,045:INFO:Checking exceptions
2023-01-03 22:21:45,045:INFO:Preloading libraries
2023-01-03 22:21:45,246:INFO:Initializing finalize_model()
2023-01-03 22:21:45,247:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001839D8C1670>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-01-03 22:21:45,247:INFO:Finalizing ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-01-03 22:21:45,256:INFO:Initializing create_model()
2023-01-03 22:21:45,256:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001839D8C1670>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-01-03 22:21:45,256:INFO:Checking exceptions
2023-01-03 22:21:45,258:INFO:Importing libraries
2023-01-03 22:21:45,258:INFO:Copying training dataset
2023-01-03 22:21:45,258:INFO:Defining folds
2023-01-03 22:21:45,258:INFO:Declaring metric variables
2023-01-03 22:21:45,259:INFO:Importing untrained model
2023-01-03 22:21:45,259:INFO:Declaring custom model
2023-01-03 22:21:45,259:INFO:Extra Trees Regressor Imported successfully
2023-01-03 22:21:45,260:INFO:Cross validation set to False
2023-01-03 22:21:45,260:INFO:Fitting Model
2023-01-03 22:21:48,286:INFO:Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))])
2023-01-03 22:21:48,286:INFO:create_model() successfully completed......................................
2023-01-03 22:21:48,385:INFO:_master_model_container: 20
2023-01-03 22:21:48,385:INFO:_display_container: 4
2023-01-03 22:21:48,392:INFO:Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))])
2023-01-03 22:21:48,392:INFO:finalize_model() successfully completed......................................
2023-01-03 22:21:48,496:INFO:Initializing predict_model()
2023-01-03 22:21:48,496:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001839D8C1670>, estimator=Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x00000183A6D5CC10>)
2023-01-03 22:21:48,497:INFO:Checking exceptions
2023-01-03 22:21:48,497:INFO:Preloading libraries
2023-01-03 22:21:48,499:INFO:Set up data.
2023-01-03 22:21:48,516:INFO:Set up index.
2023-01-03 22:21:49,000:INFO:Initializing save_model()
2023-01-03 22:21:49,000:INFO:save_model(model=Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))]), model_name=c:\Users\Kodotautas\Desktop\Data_science\7_TIME_SERIES_FORECAST_PYCARET/models/final_model.pkl, prep_pipe_=Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-01-03 22:21:49,001:INFO:Adding model into prep_pipe
2023-01-03 22:21:49,166:WARNING:Only Model saved as it was a pipeline.
2023-01-03 22:21:49,313:INFO:c:\Users\Kodotautas\Desktop\Data_science\7_TIME_SERIES_FORECAST_PYCARET/models/final_model.pkl.pkl saved in current working directory
2023-01-03 22:21:49,319:INFO:Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))])
2023-01-03 22:21:49,319:INFO:save_model() successfully completed......................................
2023-01-03 22:32:07,597:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-01-03 22:32:07,597:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-01-03 22:32:07,597:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-01-03 22:32:07,597:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-01-03 22:32:08,198:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-01-03 22:32:08,629:INFO:PyCaret RegressionExperiment
2023-01-03 22:32:08,629:INFO:Logging name: reg-default-name
2023-01-03 22:32:08,629:INFO:ML Usecase: MLUsecase.REGRESSION
2023-01-03 22:32:08,629:INFO:version 3.0.0.rc6
2023-01-03 22:32:08,629:INFO:Initializing setup()
2023-01-03 22:32:08,629:INFO:self.USI: e935
2023-01-03 22:32:08,629:INFO:self._variable_keys: {'_available_plots', 'gpu_param', 'pipeline', 'logging_param', 'exp_name_log', 'X_test', 'fold_generator', 'X_train', 'html_param', 'USI', 'target_param', 'fold_groups_param', 'idx', '_ml_usecase', 'log_plots_param', 'memory', 'y', 'y_train', 'gpu_n_jobs_param', 'n_jobs_param', 'X', 'data', 'seed', 'y_test', 'transform_target_param', 'fold_shuffle_param', 'exp_id'}
2023-01-03 22:32:08,630:INFO:Checking environment
2023-01-03 22:32:08,630:INFO:python_version: 3.9.13
2023-01-03 22:32:08,630:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-01-03 22:32:08,630:INFO:machine: AMD64
2023-01-03 22:32:08,630:INFO:platform: Windows-10-10.0.19044-SP0
2023-01-03 22:32:08,630:INFO:Memory: svmem(total=17114804224, available=10353119232, percent=39.5, used=6761684992, free=10353119232)
2023-01-03 22:32:08,630:INFO:Physical Core: 4
2023-01-03 22:32:08,630:INFO:Logical Core: 4
2023-01-03 22:32:08,630:INFO:Checking libraries
2023-01-03 22:32:08,630:INFO:System:
2023-01-03 22:32:08,630:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-01-03 22:32:08,630:INFO:executable: c:\Users\Kodotautas\anaconda3\python.exe
2023-01-03 22:32:08,630:INFO:   machine: Windows-10-10.0.19044-SP0
2023-01-03 22:32:08,630:INFO:PyCaret required dependencies:
2023-01-03 22:32:08,630:INFO:                 pip: 22.2.2
2023-01-03 22:32:08,630:INFO:          setuptools: 63.4.1
2023-01-03 22:32:08,630:INFO:             pycaret: 3.0.0rc6
2023-01-03 22:32:08,630:INFO:             IPython: 7.31.1
2023-01-03 22:32:08,630:INFO:          ipywidgets: 7.6.5
2023-01-03 22:32:08,630:INFO:                tqdm: 4.64.1
2023-01-03 22:32:08,630:INFO:               numpy: 1.21.5
2023-01-03 22:32:08,631:INFO:              pandas: 1.4.4
2023-01-03 22:32:08,631:INFO:              jinja2: 2.11.3
2023-01-03 22:32:08,631:INFO:               scipy: 1.9.1
2023-01-03 22:32:08,631:INFO:              joblib: 1.2.0
2023-01-03 22:32:08,631:INFO:             sklearn: 1.0.2
2023-01-03 22:32:08,631:INFO:                pyod: 1.0.7
2023-01-03 22:32:08,631:INFO:            imblearn: 0.10.1
2023-01-03 22:32:08,631:INFO:   category_encoders: 2.5.1.post0
2023-01-03 22:32:08,631:INFO:            lightgbm: 3.3.3
2023-01-03 22:32:08,631:INFO:               numba: 0.55.1
2023-01-03 22:32:08,631:INFO:            requests: 2.28.1
2023-01-03 22:32:08,631:INFO:          matplotlib: 3.5.2
2023-01-03 22:32:08,631:INFO:          scikitplot: 0.3.7
2023-01-03 22:32:08,631:INFO:         yellowbrick: 1.5
2023-01-03 22:32:08,631:INFO:              plotly: 5.9.0
2023-01-03 22:32:08,631:INFO:             kaleido: 0.2.1
2023-01-03 22:32:08,631:INFO:         statsmodels: 0.13.2
2023-01-03 22:32:08,631:INFO:              sktime: 0.14.1
2023-01-03 22:32:08,631:INFO:               tbats: 1.1.2
2023-01-03 22:32:08,631:INFO:            pmdarima: 2.0.2
2023-01-03 22:32:08,631:INFO:              psutil: 5.9.0
2023-01-03 22:32:08,631:INFO:PyCaret optional dependencies:
2023-01-03 22:32:08,905:INFO:                shap: 0.41.0
2023-01-03 22:32:08,905:INFO:           interpret: Not installed
2023-01-03 22:32:08,906:INFO:                umap: Not installed
2023-01-03 22:32:08,906:INFO:    pandas_profiling: Not installed
2023-01-03 22:32:08,906:INFO:  explainerdashboard: Not installed
2023-01-03 22:32:08,906:INFO:             autoviz: Not installed
2023-01-03 22:32:08,906:INFO:           fairlearn: Not installed
2023-01-03 22:32:08,906:INFO:             xgboost: Not installed
2023-01-03 22:32:08,906:INFO:            catboost: Not installed
2023-01-03 22:32:08,906:INFO:              kmodes: Not installed
2023-01-03 22:32:08,906:INFO:             mlxtend: Not installed
2023-01-03 22:32:08,906:INFO:       statsforecast: Not installed
2023-01-03 22:32:08,906:INFO:        tune_sklearn: 0.4.3
2023-01-03 22:32:08,906:INFO:                 ray: 2.0.0
2023-01-03 22:32:08,906:INFO:            hyperopt: 0.2.7
2023-01-03 22:32:08,906:INFO:              optuna: 3.0.1
2023-01-03 22:32:08,906:INFO:               skopt: 0.9.0
2023-01-03 22:32:08,906:INFO:              mlflow: Not installed
2023-01-03 22:32:08,906:INFO:              gradio: Not installed
2023-01-03 22:32:08,906:INFO:             fastapi: 0.88.0
2023-01-03 22:32:08,906:INFO:             uvicorn: 0.20.0
2023-01-03 22:32:08,906:INFO:              m2cgen: Not installed
2023-01-03 22:32:08,906:INFO:           evidently: Not installed
2023-01-03 22:32:08,906:INFO:                nltk: 3.7
2023-01-03 22:32:08,907:INFO:            pyLDAvis: Not installed
2023-01-03 22:32:08,907:INFO:              gensim: 4.1.2
2023-01-03 22:32:08,907:INFO:               spacy: 3.4.2
2023-01-03 22:32:08,907:INFO:           wordcloud: Not installed
2023-01-03 22:32:08,907:INFO:            textblob: Not installed
2023-01-03 22:32:08,907:INFO:               fugue: Not installed
2023-01-03 22:32:08,907:INFO:           streamlit: Not installed
2023-01-03 22:32:08,907:INFO:             prophet: Not installed
2023-01-03 22:32:08,907:INFO:None
2023-01-03 22:32:08,907:INFO:Set up data.
2023-01-03 22:32:09,028:INFO:Set up train/test split.
2023-01-03 22:32:09,041:INFO:Set up index.
2023-01-03 22:32:09,043:INFO:Set up folding strategy.
2023-01-03 22:32:09,043:INFO:Assigning column types.
2023-01-03 22:32:09,054:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-01-03 22:32:09,055:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-01-03 22:32:09,059:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-03 22:32:09,064:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 22:32:09,136:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 22:32:09,184:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 22:32:09,185:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:32:09,311:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:32:09,311:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-01-03 22:32:09,316:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-03 22:32:09,323:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 22:32:09,404:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 22:32:09,469:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 22:32:09,470:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:32:09,470:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:32:09,470:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-01-03 22:32:09,476:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-03 22:32:09,498:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 22:32:09,620:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 22:32:09,670:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 22:32:09,670:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:32:09,671:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:32:09,676:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-03 22:32:09,680:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 22:32:09,751:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 22:32:09,797:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 22:32:09,798:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:32:09,798:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:32:09,798:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-01-03 22:32:09,809:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 22:32:09,879:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 22:32:09,928:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 22:32:09,928:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:32:09,929:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:32:09,939:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 22:32:10,013:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 22:32:10,065:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 22:32:10,067:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:32:10,067:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:32:10,068:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-01-03 22:32:10,156:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 22:32:10,211:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 22:32:10,211:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:32:10,212:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:32:10,296:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 22:32:10,345:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 22:32:10,346:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:32:10,346:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:32:10,346:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-01-03 22:32:10,430:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 22:32:10,481:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:32:10,481:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:32:10,577:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 22:32:10,629:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:32:10,630:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:32:10,630:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-01-03 22:32:10,769:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:32:10,769:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:32:10,917:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:32:10,917:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:32:10,918:INFO:Preparing preprocessing pipeline...
2023-01-03 22:32:10,920:INFO:Set up simple imputation.
2023-01-03 22:32:10,920:INFO:Set up column transformation.
2023-01-03 22:32:10,921:INFO:Set up feature normalization.
2023-01-03 22:32:11,630:INFO:Finished creating preprocessing pipeline.
2023-01-03 22:32:11,637:INFO:Pipeline: Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2023-01-03 22:32:11,638:INFO:Creating final display dataframe.
2023-01-03 22:32:12,261:INFO:Setup _display_container:                Description             Value
0               Session id               123
1                   Target        b2b+b2c+vt
2              Target type        Regression
3               Data shape       (10506, 51)
4         Train data shape        (7354, 51)
5          Test data shape        (3152, 51)
6         Numeric features                 8
7               Preprocess              True
8          Imputation type            simple
9       Numeric imputation              mean
10  Categorical imputation              mode
11          Transformation              True
12   Transformation method       yeo-johnson
13               Normalize              True
14        Normalize method            zscore
15          Fold Generator   TimeSeriesSplit
16             Fold Number                 5
17                CPU Jobs                -1
18                 Use GPU             False
19          Log Experiment             False
20         Experiment Name  reg-default-name
21                     USI              e935
2023-01-03 22:32:12,408:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:32:12,408:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:32:12,541:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:32:12,542:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:32:12,543:INFO:setup() successfully completed in 3.92s...............
2023-01-03 22:32:12,543:INFO:Initializing compare_models()
2023-01-03 22:32:12,544:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4A8CB6E50>, include=None, fold=None, round=4, cross_validation=True, sort=MAE, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001B4A8CB6E50>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'MAE', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-01-03 22:32:12,544:INFO:Checking exceptions
2023-01-03 22:32:12,548:INFO:Preparing display monitor
2023-01-03 22:32:12,594:INFO:Initializing Linear Regression
2023-01-03 22:32:12,594:INFO:Total runtime is 0.0 minutes
2023-01-03 22:32:12,601:INFO:SubProcess create_model() called ==================================
2023-01-03 22:32:12,602:INFO:Initializing create_model()
2023-01-03 22:32:12,602:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4A8CB6E50>, estimator=lr, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B4B2816640>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:32:12,602:INFO:Checking exceptions
2023-01-03 22:32:12,602:INFO:Importing libraries
2023-01-03 22:32:12,602:INFO:Copying training dataset
2023-01-03 22:32:12,613:INFO:Defining folds
2023-01-03 22:32:12,613:INFO:Declaring metric variables
2023-01-03 22:32:12,618:INFO:Importing untrained model
2023-01-03 22:32:12,625:INFO:Linear Regression Imported successfully
2023-01-03 22:32:12,635:INFO:Starting cross validation
2023-01-03 22:32:12,642:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:32:20,231:INFO:Calculating mean and std
2023-01-03 22:32:20,233:INFO:Creating metrics dataframe
2023-01-03 22:32:20,239:INFO:Uploading results into container
2023-01-03 22:32:20,239:INFO:Uploading model into container now
2023-01-03 22:32:20,239:INFO:_master_model_container: 1
2023-01-03 22:32:20,240:INFO:_display_container: 2
2023-01-03 22:32:20,240:INFO:LinearRegression(n_jobs=-1)
2023-01-03 22:32:20,240:INFO:create_model() successfully completed......................................
2023-01-03 22:32:20,351:INFO:SubProcess create_model() end ==================================
2023-01-03 22:32:20,351:INFO:Creating metrics dataframe
2023-01-03 22:32:20,359:INFO:Initializing Lasso Regression
2023-01-03 22:32:20,359:INFO:Total runtime is 0.12941341797510783 minutes
2023-01-03 22:32:20,363:INFO:SubProcess create_model() called ==================================
2023-01-03 22:32:20,363:INFO:Initializing create_model()
2023-01-03 22:32:20,363:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4A8CB6E50>, estimator=lasso, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B4B2816640>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:32:20,363:INFO:Checking exceptions
2023-01-03 22:32:20,364:INFO:Importing libraries
2023-01-03 22:32:20,364:INFO:Copying training dataset
2023-01-03 22:32:20,373:INFO:Defining folds
2023-01-03 22:32:20,374:INFO:Declaring metric variables
2023-01-03 22:32:20,378:INFO:Importing untrained model
2023-01-03 22:32:20,382:INFO:Lasso Regression Imported successfully
2023-01-03 22:32:20,391:INFO:Starting cross validation
2023-01-03 22:32:20,393:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:32:20,737:INFO:Calculating mean and std
2023-01-03 22:32:20,738:INFO:Creating metrics dataframe
2023-01-03 22:32:20,741:INFO:Uploading results into container
2023-01-03 22:32:20,742:INFO:Uploading model into container now
2023-01-03 22:32:20,742:INFO:_master_model_container: 2
2023-01-03 22:32:20,742:INFO:_display_container: 2
2023-01-03 22:32:20,743:INFO:Lasso(random_state=123)
2023-01-03 22:32:20,743:INFO:create_model() successfully completed......................................
2023-01-03 22:32:20,841:INFO:SubProcess create_model() end ==================================
2023-01-03 22:32:20,841:INFO:Creating metrics dataframe
2023-01-03 22:32:20,854:INFO:Initializing Ridge Regression
2023-01-03 22:32:20,854:INFO:Total runtime is 0.13766295909881593 minutes
2023-01-03 22:32:20,858:INFO:SubProcess create_model() called ==================================
2023-01-03 22:32:20,859:INFO:Initializing create_model()
2023-01-03 22:32:20,859:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4A8CB6E50>, estimator=ridge, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B4B2816640>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:32:20,859:INFO:Checking exceptions
2023-01-03 22:32:20,859:INFO:Importing libraries
2023-01-03 22:32:20,859:INFO:Copying training dataset
2023-01-03 22:32:20,870:INFO:Defining folds
2023-01-03 22:32:20,870:INFO:Declaring metric variables
2023-01-03 22:32:20,874:INFO:Importing untrained model
2023-01-03 22:32:20,879:INFO:Ridge Regression Imported successfully
2023-01-03 22:32:20,887:INFO:Starting cross validation
2023-01-03 22:32:20,889:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:32:21,130:INFO:Calculating mean and std
2023-01-03 22:32:21,132:INFO:Creating metrics dataframe
2023-01-03 22:32:21,136:INFO:Uploading results into container
2023-01-03 22:32:21,137:INFO:Uploading model into container now
2023-01-03 22:32:21,138:INFO:_master_model_container: 3
2023-01-03 22:32:21,138:INFO:_display_container: 2
2023-01-03 22:32:21,139:INFO:Ridge(random_state=123)
2023-01-03 22:32:21,139:INFO:create_model() successfully completed......................................
2023-01-03 22:32:21,246:INFO:SubProcess create_model() end ==================================
2023-01-03 22:32:21,246:INFO:Creating metrics dataframe
2023-01-03 22:32:21,256:INFO:Initializing Elastic Net
2023-01-03 22:32:21,256:INFO:Total runtime is 0.14436291058858236 minutes
2023-01-03 22:32:21,260:INFO:SubProcess create_model() called ==================================
2023-01-03 22:32:21,260:INFO:Initializing create_model()
2023-01-03 22:32:21,260:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4A8CB6E50>, estimator=en, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B4B2816640>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:32:21,261:INFO:Checking exceptions
2023-01-03 22:32:21,261:INFO:Importing libraries
2023-01-03 22:32:21,261:INFO:Copying training dataset
2023-01-03 22:32:21,271:INFO:Defining folds
2023-01-03 22:32:21,271:INFO:Declaring metric variables
2023-01-03 22:32:21,275:INFO:Importing untrained model
2023-01-03 22:32:21,279:INFO:Elastic Net Imported successfully
2023-01-03 22:32:21,289:INFO:Starting cross validation
2023-01-03 22:32:21,290:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:32:21,537:INFO:Calculating mean and std
2023-01-03 22:32:21,539:INFO:Creating metrics dataframe
2023-01-03 22:32:21,542:INFO:Uploading results into container
2023-01-03 22:32:21,542:INFO:Uploading model into container now
2023-01-03 22:32:21,543:INFO:_master_model_container: 4
2023-01-03 22:32:21,543:INFO:_display_container: 2
2023-01-03 22:32:21,543:INFO:ElasticNet(random_state=123)
2023-01-03 22:32:21,543:INFO:create_model() successfully completed......................................
2023-01-03 22:32:21,647:INFO:SubProcess create_model() end ==================================
2023-01-03 22:32:21,648:INFO:Creating metrics dataframe
2023-01-03 22:32:21,659:INFO:Initializing Least Angle Regression
2023-01-03 22:32:21,659:INFO:Total runtime is 0.15108372767766318 minutes
2023-01-03 22:32:21,663:INFO:SubProcess create_model() called ==================================
2023-01-03 22:32:21,664:INFO:Initializing create_model()
2023-01-03 22:32:21,664:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4A8CB6E50>, estimator=lar, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B4B2816640>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:32:21,664:INFO:Checking exceptions
2023-01-03 22:32:21,664:INFO:Importing libraries
2023-01-03 22:32:21,664:INFO:Copying training dataset
2023-01-03 22:32:21,676:INFO:Defining folds
2023-01-03 22:32:21,676:INFO:Declaring metric variables
2023-01-03 22:32:21,680:INFO:Importing untrained model
2023-01-03 22:32:21,686:INFO:Least Angle Regression Imported successfully
2023-01-03 22:32:21,695:INFO:Starting cross validation
2023-01-03 22:32:21,696:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:32:21,777:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 22:32:21,784:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 22:32:21,785:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 22:32:21,821:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 22:32:21,900:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 22:32:22,044:INFO:Calculating mean and std
2023-01-03 22:32:22,046:INFO:Creating metrics dataframe
2023-01-03 22:32:22,049:INFO:Uploading results into container
2023-01-03 22:32:22,049:INFO:Uploading model into container now
2023-01-03 22:32:22,050:INFO:_master_model_container: 5
2023-01-03 22:32:22,050:INFO:_display_container: 2
2023-01-03 22:32:22,050:INFO:Lars(random_state=123)
2023-01-03 22:32:22,050:INFO:create_model() successfully completed......................................
2023-01-03 22:32:22,148:INFO:SubProcess create_model() end ==================================
2023-01-03 22:32:22,148:INFO:Creating metrics dataframe
2023-01-03 22:32:22,160:INFO:Initializing Lasso Least Angle Regression
2023-01-03 22:32:22,160:INFO:Total runtime is 0.15943931341171266 minutes
2023-01-03 22:32:22,163:INFO:SubProcess create_model() called ==================================
2023-01-03 22:32:22,164:INFO:Initializing create_model()
2023-01-03 22:32:22,164:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4A8CB6E50>, estimator=llar, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B4B2816640>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:32:22,164:INFO:Checking exceptions
2023-01-03 22:32:22,164:INFO:Importing libraries
2023-01-03 22:32:22,164:INFO:Copying training dataset
2023-01-03 22:32:22,175:INFO:Defining folds
2023-01-03 22:32:22,176:INFO:Declaring metric variables
2023-01-03 22:32:22,179:INFO:Importing untrained model
2023-01-03 22:32:22,184:INFO:Lasso Least Angle Regression Imported successfully
2023-01-03 22:32:22,192:INFO:Starting cross validation
2023-01-03 22:32:22,193:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:32:22,245:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-03 22:32:22,252:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-03 22:32:22,260:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-03 22:32:22,289:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-03 22:32:22,313:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-03 22:32:22,453:INFO:Calculating mean and std
2023-01-03 22:32:22,455:INFO:Creating metrics dataframe
2023-01-03 22:32:22,461:INFO:Uploading results into container
2023-01-03 22:32:22,463:INFO:Uploading model into container now
2023-01-03 22:32:22,464:INFO:_master_model_container: 6
2023-01-03 22:32:22,464:INFO:_display_container: 2
2023-01-03 22:32:22,464:INFO:LassoLars(random_state=123)
2023-01-03 22:32:22,464:INFO:create_model() successfully completed......................................
2023-01-03 22:32:22,569:INFO:SubProcess create_model() end ==================================
2023-01-03 22:32:22,569:INFO:Creating metrics dataframe
2023-01-03 22:32:22,579:INFO:Initializing Orthogonal Matching Pursuit
2023-01-03 22:32:22,579:INFO:Total runtime is 0.16642349561055503 minutes
2023-01-03 22:32:22,583:INFO:SubProcess create_model() called ==================================
2023-01-03 22:32:22,584:INFO:Initializing create_model()
2023-01-03 22:32:22,584:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4A8CB6E50>, estimator=omp, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B4B2816640>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:32:22,584:INFO:Checking exceptions
2023-01-03 22:32:22,584:INFO:Importing libraries
2023-01-03 22:32:22,584:INFO:Copying training dataset
2023-01-03 22:32:22,594:INFO:Defining folds
2023-01-03 22:32:22,595:INFO:Declaring metric variables
2023-01-03 22:32:22,600:INFO:Importing untrained model
2023-01-03 22:32:22,604:INFO:Orthogonal Matching Pursuit Imported successfully
2023-01-03 22:32:22,613:INFO:Starting cross validation
2023-01-03 22:32:22,615:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:32:22,663:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 22:32:22,669:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 22:32:22,692:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 22:32:22,702:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 22:32:22,725:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 22:32:22,866:INFO:Calculating mean and std
2023-01-03 22:32:22,868:INFO:Creating metrics dataframe
2023-01-03 22:32:22,873:INFO:Uploading results into container
2023-01-03 22:32:22,874:INFO:Uploading model into container now
2023-01-03 22:32:22,874:INFO:_master_model_container: 7
2023-01-03 22:32:22,874:INFO:_display_container: 2
2023-01-03 22:32:22,874:INFO:OrthogonalMatchingPursuit()
2023-01-03 22:32:22,874:INFO:create_model() successfully completed......................................
2023-01-03 22:32:22,975:INFO:SubProcess create_model() end ==================================
2023-01-03 22:32:22,976:INFO:Creating metrics dataframe
2023-01-03 22:32:22,989:INFO:Initializing Bayesian Ridge
2023-01-03 22:32:22,989:INFO:Total runtime is 0.1732462247212728 minutes
2023-01-03 22:32:22,992:INFO:SubProcess create_model() called ==================================
2023-01-03 22:32:22,993:INFO:Initializing create_model()
2023-01-03 22:32:22,993:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4A8CB6E50>, estimator=br, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B4B2816640>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:32:22,993:INFO:Checking exceptions
2023-01-03 22:32:22,993:INFO:Importing libraries
2023-01-03 22:32:22,993:INFO:Copying training dataset
2023-01-03 22:32:23,003:INFO:Defining folds
2023-01-03 22:32:23,004:INFO:Declaring metric variables
2023-01-03 22:32:23,009:INFO:Importing untrained model
2023-01-03 22:32:23,013:INFO:Bayesian Ridge Imported successfully
2023-01-03 22:32:23,022:INFO:Starting cross validation
2023-01-03 22:32:23,024:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:32:23,290:INFO:Calculating mean and std
2023-01-03 22:32:23,292:INFO:Creating metrics dataframe
2023-01-03 22:32:23,295:INFO:Uploading results into container
2023-01-03 22:32:23,295:INFO:Uploading model into container now
2023-01-03 22:32:23,295:INFO:_master_model_container: 8
2023-01-03 22:32:23,296:INFO:_display_container: 2
2023-01-03 22:32:23,296:INFO:BayesianRidge()
2023-01-03 22:32:23,296:INFO:create_model() successfully completed......................................
2023-01-03 22:32:23,397:INFO:SubProcess create_model() end ==================================
2023-01-03 22:32:23,398:INFO:Creating metrics dataframe
2023-01-03 22:32:23,411:INFO:Initializing Passive Aggressive Regressor
2023-01-03 22:32:23,412:INFO:Total runtime is 0.18030189673105876 minutes
2023-01-03 22:32:23,415:INFO:SubProcess create_model() called ==================================
2023-01-03 22:32:23,416:INFO:Initializing create_model()
2023-01-03 22:32:23,416:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4A8CB6E50>, estimator=par, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B4B2816640>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:32:23,416:INFO:Checking exceptions
2023-01-03 22:32:23,416:INFO:Importing libraries
2023-01-03 22:32:23,416:INFO:Copying training dataset
2023-01-03 22:32:23,427:INFO:Defining folds
2023-01-03 22:32:23,428:INFO:Declaring metric variables
2023-01-03 22:32:23,431:INFO:Importing untrained model
2023-01-03 22:32:23,436:INFO:Passive Aggressive Regressor Imported successfully
2023-01-03 22:32:23,444:INFO:Starting cross validation
2023-01-03 22:32:23,445:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:32:23,722:INFO:Calculating mean and std
2023-01-03 22:32:23,724:INFO:Creating metrics dataframe
2023-01-03 22:32:23,727:INFO:Uploading results into container
2023-01-03 22:32:23,728:INFO:Uploading model into container now
2023-01-03 22:32:23,728:INFO:_master_model_container: 9
2023-01-03 22:32:23,728:INFO:_display_container: 2
2023-01-03 22:32:23,728:INFO:PassiveAggressiveRegressor(random_state=123)
2023-01-03 22:32:23,728:INFO:create_model() successfully completed......................................
2023-01-03 22:32:23,834:INFO:SubProcess create_model() end ==================================
2023-01-03 22:32:23,834:INFO:Creating metrics dataframe
2023-01-03 22:32:23,848:INFO:Initializing Huber Regressor
2023-01-03 22:32:23,849:INFO:Total runtime is 0.1875847816467285 minutes
2023-01-03 22:32:23,855:INFO:SubProcess create_model() called ==================================
2023-01-03 22:32:23,856:INFO:Initializing create_model()
2023-01-03 22:32:23,856:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4A8CB6E50>, estimator=huber, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B4B2816640>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:32:23,856:INFO:Checking exceptions
2023-01-03 22:32:23,856:INFO:Importing libraries
2023-01-03 22:32:23,856:INFO:Copying training dataset
2023-01-03 22:32:23,867:INFO:Defining folds
2023-01-03 22:32:23,867:INFO:Declaring metric variables
2023-01-03 22:32:23,872:INFO:Importing untrained model
2023-01-03 22:32:23,876:INFO:Huber Regressor Imported successfully
2023-01-03 22:32:23,888:INFO:Starting cross validation
2023-01-03 22:32:23,890:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:32:24,070:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-03 22:32:24,152:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-03 22:32:24,201:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-03 22:32:24,339:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-03 22:32:24,542:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-03 22:32:24,672:INFO:Calculating mean and std
2023-01-03 22:32:24,674:INFO:Creating metrics dataframe
2023-01-03 22:32:24,677:INFO:Uploading results into container
2023-01-03 22:32:24,677:INFO:Uploading model into container now
2023-01-03 22:32:24,677:INFO:_master_model_container: 10
2023-01-03 22:32:24,677:INFO:_display_container: 2
2023-01-03 22:32:24,678:INFO:HuberRegressor()
2023-01-03 22:32:24,678:INFO:create_model() successfully completed......................................
2023-01-03 22:32:24,780:INFO:SubProcess create_model() end ==================================
2023-01-03 22:32:24,780:INFO:Creating metrics dataframe
2023-01-03 22:32:24,794:INFO:Initializing K Neighbors Regressor
2023-01-03 22:32:24,794:INFO:Total runtime is 0.20333683093388874 minutes
2023-01-03 22:32:24,798:INFO:SubProcess create_model() called ==================================
2023-01-03 22:32:24,799:INFO:Initializing create_model()
2023-01-03 22:32:24,799:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4A8CB6E50>, estimator=knn, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B4B2816640>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:32:24,799:INFO:Checking exceptions
2023-01-03 22:32:24,799:INFO:Importing libraries
2023-01-03 22:32:24,799:INFO:Copying training dataset
2023-01-03 22:32:24,810:INFO:Defining folds
2023-01-03 22:32:24,810:INFO:Declaring metric variables
2023-01-03 22:32:24,815:INFO:Importing untrained model
2023-01-03 22:32:24,820:INFO:K Neighbors Regressor Imported successfully
2023-01-03 22:32:24,827:INFO:Starting cross validation
2023-01-03 22:32:24,829:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:32:25,513:INFO:Calculating mean and std
2023-01-03 22:32:25,515:INFO:Creating metrics dataframe
2023-01-03 22:32:25,518:INFO:Uploading results into container
2023-01-03 22:32:25,519:INFO:Uploading model into container now
2023-01-03 22:32:25,520:INFO:_master_model_container: 11
2023-01-03 22:32:25,520:INFO:_display_container: 2
2023-01-03 22:32:25,521:INFO:KNeighborsRegressor(n_jobs=-1)
2023-01-03 22:32:25,521:INFO:create_model() successfully completed......................................
2023-01-03 22:32:25,621:INFO:SubProcess create_model() end ==================================
2023-01-03 22:32:25,622:INFO:Creating metrics dataframe
2023-01-03 22:32:25,632:INFO:Initializing Decision Tree Regressor
2023-01-03 22:32:25,633:INFO:Total runtime is 0.21730652650197346 minutes
2023-01-03 22:32:25,637:INFO:SubProcess create_model() called ==================================
2023-01-03 22:32:25,637:INFO:Initializing create_model()
2023-01-03 22:32:25,637:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4A8CB6E50>, estimator=dt, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B4B2816640>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:32:25,637:INFO:Checking exceptions
2023-01-03 22:32:25,638:INFO:Importing libraries
2023-01-03 22:32:25,638:INFO:Copying training dataset
2023-01-03 22:32:25,647:INFO:Defining folds
2023-01-03 22:32:25,647:INFO:Declaring metric variables
2023-01-03 22:32:25,653:INFO:Importing untrained model
2023-01-03 22:32:25,657:INFO:Decision Tree Regressor Imported successfully
2023-01-03 22:32:25,666:INFO:Starting cross validation
2023-01-03 22:32:25,668:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:32:26,181:INFO:Calculating mean and std
2023-01-03 22:32:26,183:INFO:Creating metrics dataframe
2023-01-03 22:32:26,186:INFO:Uploading results into container
2023-01-03 22:32:26,186:INFO:Uploading model into container now
2023-01-03 22:32:26,187:INFO:_master_model_container: 12
2023-01-03 22:32:26,187:INFO:_display_container: 2
2023-01-03 22:32:26,187:INFO:DecisionTreeRegressor(random_state=123)
2023-01-03 22:32:26,188:INFO:create_model() successfully completed......................................
2023-01-03 22:32:26,289:INFO:SubProcess create_model() end ==================================
2023-01-03 22:32:26,289:INFO:Creating metrics dataframe
2023-01-03 22:32:26,300:INFO:Initializing Random Forest Regressor
2023-01-03 22:32:26,300:INFO:Total runtime is 0.22842650810877482 minutes
2023-01-03 22:32:26,304:INFO:SubProcess create_model() called ==================================
2023-01-03 22:32:26,304:INFO:Initializing create_model()
2023-01-03 22:32:26,304:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4A8CB6E50>, estimator=rf, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B4B2816640>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:32:26,304:INFO:Checking exceptions
2023-01-03 22:32:26,305:INFO:Importing libraries
2023-01-03 22:32:26,305:INFO:Copying training dataset
2023-01-03 22:32:26,314:INFO:Defining folds
2023-01-03 22:32:26,314:INFO:Declaring metric variables
2023-01-03 22:32:26,319:INFO:Importing untrained model
2023-01-03 22:32:26,323:INFO:Random Forest Regressor Imported successfully
2023-01-03 22:32:26,331:INFO:Starting cross validation
2023-01-03 22:32:26,332:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:32:37,470:INFO:Calculating mean and std
2023-01-03 22:32:37,472:INFO:Creating metrics dataframe
2023-01-03 22:32:37,475:INFO:Uploading results into container
2023-01-03 22:32:37,475:INFO:Uploading model into container now
2023-01-03 22:32:37,475:INFO:_master_model_container: 13
2023-01-03 22:32:37,475:INFO:_display_container: 2
2023-01-03 22:32:37,476:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-01-03 22:32:37,476:INFO:create_model() successfully completed......................................
2023-01-03 22:32:37,580:INFO:SubProcess create_model() end ==================================
2023-01-03 22:32:37,581:INFO:Creating metrics dataframe
2023-01-03 22:32:37,595:INFO:Initializing Extra Trees Regressor
2023-01-03 22:32:37,595:INFO:Total runtime is 0.41668307383855185 minutes
2023-01-03 22:32:37,599:INFO:SubProcess create_model() called ==================================
2023-01-03 22:32:37,599:INFO:Initializing create_model()
2023-01-03 22:32:37,600:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4A8CB6E50>, estimator=et, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B4B2816640>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:32:37,600:INFO:Checking exceptions
2023-01-03 22:32:37,601:INFO:Importing libraries
2023-01-03 22:32:37,601:INFO:Copying training dataset
2023-01-03 22:32:37,612:INFO:Defining folds
2023-01-03 22:32:37,613:INFO:Declaring metric variables
2023-01-03 22:32:37,616:INFO:Importing untrained model
2023-01-03 22:32:37,621:INFO:Extra Trees Regressor Imported successfully
2023-01-03 22:32:37,630:INFO:Starting cross validation
2023-01-03 22:32:37,631:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:32:42,589:INFO:Calculating mean and std
2023-01-03 22:32:42,591:INFO:Creating metrics dataframe
2023-01-03 22:32:42,594:INFO:Uploading results into container
2023-01-03 22:32:42,594:INFO:Uploading model into container now
2023-01-03 22:32:42,595:INFO:_master_model_container: 14
2023-01-03 22:32:42,595:INFO:_display_container: 2
2023-01-03 22:32:42,596:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-01-03 22:32:42,596:INFO:create_model() successfully completed......................................
2023-01-03 22:32:42,697:INFO:SubProcess create_model() end ==================================
2023-01-03 22:32:42,698:INFO:Creating metrics dataframe
2023-01-03 22:32:42,709:INFO:Initializing AdaBoost Regressor
2023-01-03 22:32:42,709:INFO:Total runtime is 0.5019172430038452 minutes
2023-01-03 22:32:42,713:INFO:SubProcess create_model() called ==================================
2023-01-03 22:32:42,713:INFO:Initializing create_model()
2023-01-03 22:32:42,713:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4A8CB6E50>, estimator=ada, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B4B2816640>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:32:42,713:INFO:Checking exceptions
2023-01-03 22:32:42,713:INFO:Importing libraries
2023-01-03 22:32:42,713:INFO:Copying training dataset
2023-01-03 22:32:42,724:INFO:Defining folds
2023-01-03 22:32:42,724:INFO:Declaring metric variables
2023-01-03 22:32:42,727:INFO:Importing untrained model
2023-01-03 22:32:42,732:INFO:AdaBoost Regressor Imported successfully
2023-01-03 22:32:42,740:INFO:Starting cross validation
2023-01-03 22:32:42,741:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:32:45,314:INFO:Calculating mean and std
2023-01-03 22:32:45,316:INFO:Creating metrics dataframe
2023-01-03 22:32:45,319:INFO:Uploading results into container
2023-01-03 22:32:45,320:INFO:Uploading model into container now
2023-01-03 22:32:45,320:INFO:_master_model_container: 15
2023-01-03 22:32:45,321:INFO:_display_container: 2
2023-01-03 22:32:45,321:INFO:AdaBoostRegressor(random_state=123)
2023-01-03 22:32:45,321:INFO:create_model() successfully completed......................................
2023-01-03 22:32:45,420:INFO:SubProcess create_model() end ==================================
2023-01-03 22:32:45,420:INFO:Creating metrics dataframe
2023-01-03 22:32:45,435:INFO:Initializing Gradient Boosting Regressor
2023-01-03 22:32:45,435:INFO:Total runtime is 0.5473495483398437 minutes
2023-01-03 22:32:45,439:INFO:SubProcess create_model() called ==================================
2023-01-03 22:32:45,439:INFO:Initializing create_model()
2023-01-03 22:32:45,439:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4A8CB6E50>, estimator=gbr, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B4B2816640>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:32:45,439:INFO:Checking exceptions
2023-01-03 22:32:45,439:INFO:Importing libraries
2023-01-03 22:32:45,439:INFO:Copying training dataset
2023-01-03 22:32:45,449:INFO:Defining folds
2023-01-03 22:32:45,450:INFO:Declaring metric variables
2023-01-03 22:32:45,454:INFO:Importing untrained model
2023-01-03 22:32:45,459:INFO:Gradient Boosting Regressor Imported successfully
2023-01-03 22:32:45,466:INFO:Starting cross validation
2023-01-03 22:32:45,468:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:32:51,795:INFO:Calculating mean and std
2023-01-03 22:32:51,797:INFO:Creating metrics dataframe
2023-01-03 22:32:51,800:INFO:Uploading results into container
2023-01-03 22:32:51,800:INFO:Uploading model into container now
2023-01-03 22:32:51,800:INFO:_master_model_container: 16
2023-01-03 22:32:51,801:INFO:_display_container: 2
2023-01-03 22:32:51,801:INFO:GradientBoostingRegressor(random_state=123)
2023-01-03 22:32:51,801:INFO:create_model() successfully completed......................................
2023-01-03 22:32:51,898:INFO:SubProcess create_model() end ==================================
2023-01-03 22:32:51,898:INFO:Creating metrics dataframe
2023-01-03 22:32:51,914:INFO:Initializing Light Gradient Boosting Machine
2023-01-03 22:32:51,914:INFO:Total runtime is 0.6553352952003478 minutes
2023-01-03 22:32:51,919:INFO:SubProcess create_model() called ==================================
2023-01-03 22:32:51,920:INFO:Initializing create_model()
2023-01-03 22:32:51,920:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4A8CB6E50>, estimator=lightgbm, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B4B2816640>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:32:51,920:INFO:Checking exceptions
2023-01-03 22:32:51,920:INFO:Importing libraries
2023-01-03 22:32:51,920:INFO:Copying training dataset
2023-01-03 22:32:51,930:INFO:Defining folds
2023-01-03 22:32:51,930:INFO:Declaring metric variables
2023-01-03 22:32:51,936:INFO:Importing untrained model
2023-01-03 22:32:51,940:INFO:Light Gradient Boosting Machine Imported successfully
2023-01-03 22:32:51,948:INFO:Starting cross validation
2023-01-03 22:32:51,949:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:32:54,411:INFO:Calculating mean and std
2023-01-03 22:32:54,413:INFO:Creating metrics dataframe
2023-01-03 22:32:54,416:INFO:Uploading results into container
2023-01-03 22:32:54,416:INFO:Uploading model into container now
2023-01-03 22:32:54,416:INFO:_master_model_container: 17
2023-01-03 22:32:54,416:INFO:_display_container: 2
2023-01-03 22:32:54,417:INFO:LGBMRegressor(random_state=123)
2023-01-03 22:32:54,417:INFO:create_model() successfully completed......................................
2023-01-03 22:32:54,516:INFO:SubProcess create_model() end ==================================
2023-01-03 22:32:54,516:INFO:Creating metrics dataframe
2023-01-03 22:32:54,531:INFO:Initializing Dummy Regressor
2023-01-03 22:32:54,531:INFO:Total runtime is 0.6989501396814981 minutes
2023-01-03 22:32:54,536:INFO:SubProcess create_model() called ==================================
2023-01-03 22:32:54,536:INFO:Initializing create_model()
2023-01-03 22:32:54,537:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4A8CB6E50>, estimator=dummy, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B4B2816640>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:32:54,537:INFO:Checking exceptions
2023-01-03 22:32:54,537:INFO:Importing libraries
2023-01-03 22:32:54,537:INFO:Copying training dataset
2023-01-03 22:32:54,547:INFO:Defining folds
2023-01-03 22:32:54,547:INFO:Declaring metric variables
2023-01-03 22:32:54,551:INFO:Importing untrained model
2023-01-03 22:32:54,556:INFO:Dummy Regressor Imported successfully
2023-01-03 22:32:54,564:INFO:Starting cross validation
2023-01-03 22:32:54,566:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:32:54,804:INFO:Calculating mean and std
2023-01-03 22:32:54,806:INFO:Creating metrics dataframe
2023-01-03 22:32:54,809:INFO:Uploading results into container
2023-01-03 22:32:54,809:INFO:Uploading model into container now
2023-01-03 22:32:54,809:INFO:_master_model_container: 18
2023-01-03 22:32:54,809:INFO:_display_container: 2
2023-01-03 22:32:54,810:INFO:DummyRegressor()
2023-01-03 22:32:54,810:INFO:create_model() successfully completed......................................
2023-01-03 22:32:54,912:INFO:SubProcess create_model() end ==================================
2023-01-03 22:32:54,912:INFO:Creating metrics dataframe
2023-01-03 22:32:54,940:INFO:Initializing create_model()
2023-01-03 22:32:54,941:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4A8CB6E50>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:32:54,941:INFO:Checking exceptions
2023-01-03 22:32:54,943:INFO:Importing libraries
2023-01-03 22:32:54,943:INFO:Copying training dataset
2023-01-03 22:32:54,953:INFO:Defining folds
2023-01-03 22:32:54,953:INFO:Declaring metric variables
2023-01-03 22:32:54,953:INFO:Importing untrained model
2023-01-03 22:32:54,953:INFO:Declaring custom model
2023-01-03 22:32:54,954:INFO:Extra Trees Regressor Imported successfully
2023-01-03 22:32:54,955:INFO:Cross validation set to False
2023-01-03 22:32:54,955:INFO:Fitting Model
2023-01-03 22:32:57,213:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-01-03 22:32:57,213:INFO:create_model() successfully completed......................................
2023-01-03 22:32:57,392:INFO:_master_model_container: 18
2023-01-03 22:32:57,392:INFO:_display_container: 2
2023-01-03 22:32:57,393:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-01-03 22:32:57,393:INFO:compare_models() successfully completed......................................
2023-01-03 22:32:57,393:INFO:Initializing tune_model()
2023-01-03 22:32:57,394:INFO:tune_model(estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=MAE, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4A8CB6E50>)
2023-01-03 22:32:57,394:INFO:Checking exceptions
2023-01-03 22:32:57,443:INFO:Copying training dataset
2023-01-03 22:32:57,454:INFO:Checking base model
2023-01-03 22:32:57,454:INFO:Base model : Extra Trees Regressor
2023-01-03 22:32:57,458:INFO:Declaring metric variables
2023-01-03 22:32:57,463:INFO:Defining Hyperparameters
2023-01-03 22:32:57,597:INFO:Tuning with n_jobs=-1
2023-01-03 22:32:57,597:INFO:Initializing RandomizedSearchCV
2023-01-03 22:32:57,653:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:32:57,656:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:32:57,667:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:32:57,679:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:32:58,001:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:32:58,025:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:32:58,030:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:32:58,171:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:32:58,361:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:32:58,390:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:32:58,443:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:32:58,575:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:32:58,656:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:32:58,705:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:32:59,108:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:32:59,256:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:32:59,320:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:32:59,561:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:32:59,660:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:32:59,782:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:33:00,060:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:33:00,237:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:33:00,392:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:33:00,434:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:33:00,664:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:33:00,875:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 22:33:01,039:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 22:33:01,255:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 22:33:02,309:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 22:33:02,389:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 22:33:06,400:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:33:10,472:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:33:12,103:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:33:12,942:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:33:14,436:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:33:15,181:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:33:16,862:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:33:17,419:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:33:17,781:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:33:18,177:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:33:18,516:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 22:33:19,095:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 22:33:19,783:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 22:33:20,676:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 22:33:25,862:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 22:33:26,471:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:33:29,510:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:33:30,949:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:33:31,730:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:33:33,011:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:33:41,730:INFO:best_params: {'actual_estimator__n_estimators': 100, 'actual_estimator__min_samples_split': 7, 'actual_estimator__min_samples_leaf': 4, 'actual_estimator__min_impurity_decrease': 0.1, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 9, 'actual_estimator__criterion': 'mse', 'actual_estimator__bootstrap': True}
2023-01-03 22:33:41,732:INFO:Hyperparameter search completed
2023-01-03 22:33:41,732:INFO:SubProcess create_model() called ==================================
2023-01-03 22:33:41,733:INFO:Initializing create_model()
2023-01-03 22:33:41,733:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4A8CB6E50>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B4B1D7C820>, model_only=True, return_train_score=False, kwargs={'n_estimators': 100, 'min_samples_split': 7, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.1, 'max_features': 1.0, 'max_depth': 9, 'criterion': 'mse', 'bootstrap': True})
2023-01-03 22:33:41,733:INFO:Checking exceptions
2023-01-03 22:33:41,733:INFO:Importing libraries
2023-01-03 22:33:41,733:INFO:Copying training dataset
2023-01-03 22:33:41,744:INFO:Defining folds
2023-01-03 22:33:41,744:INFO:Declaring metric variables
2023-01-03 22:33:41,748:INFO:Importing untrained model
2023-01-03 22:33:41,748:INFO:Declaring custom model
2023-01-03 22:33:41,752:INFO:Extra Trees Regressor Imported successfully
2023-01-03 22:33:41,762:INFO:Starting cross validation
2023-01-03 22:33:41,763:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:33:41,817:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:33:41,821:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:33:41,834:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:33:41,862:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:33:42,239:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:33:42,692:INFO:Calculating mean and std
2023-01-03 22:33:42,694:INFO:Creating metrics dataframe
2023-01-03 22:33:42,701:INFO:Finalizing model
2023-01-03 22:33:43,043:INFO:Uploading results into container
2023-01-03 22:33:43,044:INFO:Uploading model into container now
2023-01-03 22:33:43,045:INFO:_master_model_container: 19
2023-01-03 22:33:43,045:INFO:_display_container: 3
2023-01-03 22:33:43,045:INFO:ExtraTreesRegressor(bootstrap=True, criterion='mse', max_depth=9,
                    max_features=1.0, min_impurity_decrease=0.1,
                    min_samples_leaf=4, min_samples_split=7, n_jobs=-1,
                    random_state=123)
2023-01-03 22:33:43,046:INFO:create_model() successfully completed......................................
2023-01-03 22:33:43,166:INFO:SubProcess create_model() end ==================================
2023-01-03 22:33:43,166:INFO:choose_better activated
2023-01-03 22:33:43,169:INFO:SubProcess create_model() called ==================================
2023-01-03 22:33:43,170:INFO:Initializing create_model()
2023-01-03 22:33:43,171:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4A8CB6E50>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:33:43,171:INFO:Checking exceptions
2023-01-03 22:33:43,173:INFO:Importing libraries
2023-01-03 22:33:43,173:INFO:Copying training dataset
2023-01-03 22:33:43,182:INFO:Defining folds
2023-01-03 22:33:43,182:INFO:Declaring metric variables
2023-01-03 22:33:43,182:INFO:Importing untrained model
2023-01-03 22:33:43,182:INFO:Declaring custom model
2023-01-03 22:33:43,183:INFO:Extra Trees Regressor Imported successfully
2023-01-03 22:33:43,183:INFO:Starting cross validation
2023-01-03 22:33:43,184:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:33:48,063:INFO:Calculating mean and std
2023-01-03 22:33:48,064:INFO:Creating metrics dataframe
2023-01-03 22:33:48,066:INFO:Finalizing model
2023-01-03 22:33:50,054:INFO:Uploading results into container
2023-01-03 22:33:50,055:INFO:Uploading model into container now
2023-01-03 22:33:50,055:INFO:_master_model_container: 20
2023-01-03 22:33:50,055:INFO:_display_container: 4
2023-01-03 22:33:50,055:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-01-03 22:33:50,055:INFO:create_model() successfully completed......................................
2023-01-03 22:33:50,160:INFO:SubProcess create_model() end ==================================
2023-01-03 22:33:50,161:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123) result for MAE is 0.1263
2023-01-03 22:33:50,162:INFO:ExtraTreesRegressor(bootstrap=True, criterion='mse', max_depth=9,
                    max_features=1.0, min_impurity_decrease=0.1,
                    min_samples_leaf=4, min_samples_split=7, n_jobs=-1,
                    random_state=123) result for MAE is 0.4665
2023-01-03 22:33:50,162:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123) is best model
2023-01-03 22:33:50,162:INFO:choose_better completed
2023-01-03 22:33:50,162:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-01-03 22:33:50,171:INFO:_master_model_container: 20
2023-01-03 22:33:50,171:INFO:_display_container: 3
2023-01-03 22:33:50,171:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-01-03 22:33:50,172:INFO:tune_model() successfully completed......................................
2023-01-03 22:33:50,293:INFO:Initializing plot_model()
2023-01-03 22:33:50,293:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4A8CB6E50>, system=True)
2023-01-03 22:33:50,293:INFO:Checking exceptions
2023-01-03 22:33:50,318:INFO:Preloading libraries
2023-01-03 22:33:50,468:INFO:Copying training dataset
2023-01-03 22:33:50,468:INFO:Plot type: error
2023-01-03 22:33:50,651:INFO:Fitting Model
2023-01-03 22:33:50,652:INFO:Scoring test/hold-out set
2023-01-03 22:33:51,110:INFO:Visual Rendered Successfully
2023-01-03 22:33:51,236:INFO:plot_model() successfully completed......................................
2023-01-03 22:33:51,247:INFO:Initializing predict_model()
2023-01-03 22:33:51,247:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4A8CB6E50>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001B4B240ACA0>)
2023-01-03 22:33:51,247:INFO:Checking exceptions
2023-01-03 22:33:51,248:INFO:Preloading libraries
2023-01-03 22:33:51,458:INFO:Initializing finalize_model()
2023-01-03 22:33:51,459:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4A8CB6E50>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-01-03 22:33:51,459:INFO:Finalizing ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-01-03 22:33:51,470:INFO:Initializing create_model()
2023-01-03 22:33:51,470:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4A8CB6E50>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-01-03 22:33:51,470:INFO:Checking exceptions
2023-01-03 22:33:51,472:INFO:Importing libraries
2023-01-03 22:33:51,472:INFO:Copying training dataset
2023-01-03 22:33:51,473:INFO:Defining folds
2023-01-03 22:33:51,473:INFO:Declaring metric variables
2023-01-03 22:33:51,473:INFO:Importing untrained model
2023-01-03 22:33:51,473:INFO:Declaring custom model
2023-01-03 22:33:51,474:INFO:Extra Trees Regressor Imported successfully
2023-01-03 22:33:51,475:INFO:Cross validation set to False
2023-01-03 22:33:51,475:INFO:Fitting Model
2023-01-03 22:33:55,144:INFO:Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))])
2023-01-03 22:33:55,144:INFO:create_model() successfully completed......................................
2023-01-03 22:33:55,256:INFO:_master_model_container: 20
2023-01-03 22:33:55,256:INFO:_display_container: 4
2023-01-03 22:33:55,263:INFO:Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))])
2023-01-03 22:33:55,263:INFO:finalize_model() successfully completed......................................
2023-01-03 22:33:55,373:INFO:Initializing predict_model()
2023-01-03 22:33:55,374:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4A8CB6E50>, estimator=Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001B4B286BE50>)
2023-01-03 22:33:55,374:INFO:Checking exceptions
2023-01-03 22:33:55,374:INFO:Preloading libraries
2023-01-03 22:33:55,376:INFO:Set up data.
2023-01-03 22:33:55,392:INFO:Set up index.
2023-01-03 22:33:55,862:INFO:Initializing save_model()
2023-01-03 22:33:55,862:INFO:save_model(model=Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))]), model_name=c:\Users\Kodotautas\Desktop\Data_science\7_TIME_SERIES_FORECAST_PYCARET/models/final_model.pkl, prep_pipe_=Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-01-03 22:33:55,862:INFO:Adding model into prep_pipe
2023-01-03 22:33:56,048:WARNING:Only Model saved as it was a pipeline.
2023-01-03 22:33:56,210:INFO:c:\Users\Kodotautas\Desktop\Data_science\7_TIME_SERIES_FORECAST_PYCARET/models/final_model.pkl.pkl saved in current working directory
2023-01-03 22:33:56,217:INFO:Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))])
2023-01-03 22:33:56,217:INFO:save_model() successfully completed......................................
2023-01-03 22:37:24,905:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-01-03 22:37:24,905:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-01-03 22:37:24,905:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-01-03 22:37:24,905:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-01-03 22:37:25,617:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-01-03 22:37:26,015:INFO:PyCaret RegressionExperiment
2023-01-03 22:37:26,015:INFO:Logging name: reg-default-name
2023-01-03 22:37:26,015:INFO:ML Usecase: MLUsecase.REGRESSION
2023-01-03 22:37:26,015:INFO:version 3.0.0.rc6
2023-01-03 22:37:26,015:INFO:Initializing setup()
2023-01-03 22:37:26,015:INFO:self.USI: 3e37
2023-01-03 22:37:26,015:INFO:self._variable_keys: {'exp_id', 'fold_shuffle_param', 'n_jobs_param', 'gpu_param', '_ml_usecase', 'gpu_n_jobs_param', 'y_train', 'X', 'y_test', 'log_plots_param', '_available_plots', 'logging_param', 'USI', 'exp_name_log', 'fold_groups_param', 'seed', 'idx', 'html_param', 'fold_generator', 'X_train', 'X_test', 'data', 'transform_target_param', 'target_param', 'memory', 'y', 'pipeline'}
2023-01-03 22:37:26,015:INFO:Checking environment
2023-01-03 22:37:26,015:INFO:python_version: 3.9.13
2023-01-03 22:37:26,015:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-01-03 22:37:26,015:INFO:machine: AMD64
2023-01-03 22:37:26,015:INFO:platform: Windows-10-10.0.19044-SP0
2023-01-03 22:37:26,015:INFO:Memory: svmem(total=17114804224, available=10357080064, percent=39.5, used=6757724160, free=10357080064)
2023-01-03 22:37:26,015:INFO:Physical Core: 4
2023-01-03 22:37:26,016:INFO:Logical Core: 4
2023-01-03 22:37:26,016:INFO:Checking libraries
2023-01-03 22:37:26,016:INFO:System:
2023-01-03 22:37:26,016:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-01-03 22:37:26,016:INFO:executable: c:\Users\Kodotautas\anaconda3\python.exe
2023-01-03 22:37:26,016:INFO:   machine: Windows-10-10.0.19044-SP0
2023-01-03 22:37:26,016:INFO:PyCaret required dependencies:
2023-01-03 22:37:26,016:INFO:                 pip: 22.2.2
2023-01-03 22:37:26,016:INFO:          setuptools: 63.4.1
2023-01-03 22:37:26,016:INFO:             pycaret: 3.0.0rc6
2023-01-03 22:37:26,016:INFO:             IPython: 7.31.1
2023-01-03 22:37:26,016:INFO:          ipywidgets: 7.6.5
2023-01-03 22:37:26,016:INFO:                tqdm: 4.64.1
2023-01-03 22:37:26,016:INFO:               numpy: 1.21.5
2023-01-03 22:37:26,016:INFO:              pandas: 1.4.4
2023-01-03 22:37:26,016:INFO:              jinja2: 2.11.3
2023-01-03 22:37:26,016:INFO:               scipy: 1.9.1
2023-01-03 22:37:26,016:INFO:              joblib: 1.2.0
2023-01-03 22:37:26,016:INFO:             sklearn: 1.0.2
2023-01-03 22:37:26,017:INFO:                pyod: 1.0.7
2023-01-03 22:37:26,017:INFO:            imblearn: 0.10.1
2023-01-03 22:37:26,017:INFO:   category_encoders: 2.5.1.post0
2023-01-03 22:37:26,017:INFO:            lightgbm: 3.3.3
2023-01-03 22:37:26,017:INFO:               numba: 0.55.1
2023-01-03 22:37:26,017:INFO:            requests: 2.28.1
2023-01-03 22:37:26,017:INFO:          matplotlib: 3.5.2
2023-01-03 22:37:26,017:INFO:          scikitplot: 0.3.7
2023-01-03 22:37:26,017:INFO:         yellowbrick: 1.5
2023-01-03 22:37:26,017:INFO:              plotly: 5.9.0
2023-01-03 22:37:26,017:INFO:             kaleido: 0.2.1
2023-01-03 22:37:26,017:INFO:         statsmodels: 0.13.2
2023-01-03 22:37:26,017:INFO:              sktime: 0.14.1
2023-01-03 22:37:26,017:INFO:               tbats: 1.1.2
2023-01-03 22:37:26,017:INFO:            pmdarima: 2.0.2
2023-01-03 22:37:26,017:INFO:              psutil: 5.9.0
2023-01-03 22:37:26,017:INFO:PyCaret optional dependencies:
2023-01-03 22:37:26,268:INFO:                shap: 0.41.0
2023-01-03 22:37:26,268:INFO:           interpret: Not installed
2023-01-03 22:37:26,269:INFO:                umap: Not installed
2023-01-03 22:37:26,269:INFO:    pandas_profiling: Not installed
2023-01-03 22:37:26,269:INFO:  explainerdashboard: Not installed
2023-01-03 22:37:26,269:INFO:             autoviz: Not installed
2023-01-03 22:37:26,269:INFO:           fairlearn: Not installed
2023-01-03 22:37:26,269:INFO:             xgboost: Not installed
2023-01-03 22:37:26,269:INFO:            catboost: Not installed
2023-01-03 22:37:26,269:INFO:              kmodes: Not installed
2023-01-03 22:37:26,269:INFO:             mlxtend: Not installed
2023-01-03 22:37:26,269:INFO:       statsforecast: Not installed
2023-01-03 22:37:26,269:INFO:        tune_sklearn: 0.4.3
2023-01-03 22:37:26,269:INFO:                 ray: 2.0.0
2023-01-03 22:37:26,269:INFO:            hyperopt: 0.2.7
2023-01-03 22:37:26,269:INFO:              optuna: 3.0.1
2023-01-03 22:37:26,269:INFO:               skopt: 0.9.0
2023-01-03 22:37:26,269:INFO:              mlflow: Not installed
2023-01-03 22:37:26,269:INFO:              gradio: Not installed
2023-01-03 22:37:26,269:INFO:             fastapi: 0.88.0
2023-01-03 22:37:26,269:INFO:             uvicorn: 0.20.0
2023-01-03 22:37:26,269:INFO:              m2cgen: Not installed
2023-01-03 22:37:26,269:INFO:           evidently: Not installed
2023-01-03 22:37:26,269:INFO:                nltk: 3.7
2023-01-03 22:37:26,270:INFO:            pyLDAvis: Not installed
2023-01-03 22:37:26,270:INFO:              gensim: 4.1.2
2023-01-03 22:37:26,270:INFO:               spacy: 3.4.2
2023-01-03 22:37:26,270:INFO:           wordcloud: Not installed
2023-01-03 22:37:26,270:INFO:            textblob: Not installed
2023-01-03 22:37:26,270:INFO:               fugue: Not installed
2023-01-03 22:37:26,270:INFO:           streamlit: Not installed
2023-01-03 22:37:26,270:INFO:             prophet: Not installed
2023-01-03 22:37:26,270:INFO:None
2023-01-03 22:37:26,270:INFO:Set up data.
2023-01-03 22:37:26,290:INFO:Set up train/test split.
2023-01-03 22:37:26,302:INFO:Set up index.
2023-01-03 22:37:26,304:INFO:Set up folding strategy.
2023-01-03 22:37:26,304:INFO:Assigning column types.
2023-01-03 22:37:26,314:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-01-03 22:37:26,315:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-01-03 22:37:26,319:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-03 22:37:26,324:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 22:37:26,391:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 22:37:26,438:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 22:37:26,438:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:37:26,570:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:37:26,570:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-01-03 22:37:26,575:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-03 22:37:26,579:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 22:37:26,644:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 22:37:26,691:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 22:37:26,692:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:37:26,692:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:37:26,692:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-01-03 22:37:26,698:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-03 22:37:26,703:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 22:37:26,774:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 22:37:26,821:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 22:37:26,821:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:37:26,822:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:37:26,826:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-03 22:37:26,831:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 22:37:26,897:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 22:37:26,944:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 22:37:26,945:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:37:26,945:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:37:26,945:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-01-03 22:37:26,956:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 22:37:27,025:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 22:37:27,072:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 22:37:27,072:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:37:27,073:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:37:27,083:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 22:37:27,148:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 22:37:27,195:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 22:37:27,195:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:37:27,195:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:37:27,196:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-01-03 22:37:27,274:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 22:37:27,322:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 22:37:27,322:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:37:27,322:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:37:27,400:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 22:37:27,446:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 22:37:27,447:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:37:27,448:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:37:27,448:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-01-03 22:37:27,527:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 22:37:27,573:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:37:27,573:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:37:27,648:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 22:37:27,695:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:37:27,696:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:37:27,696:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-01-03 22:37:27,824:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:37:27,824:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:37:27,945:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:37:27,946:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:37:27,947:INFO:Preparing preprocessing pipeline...
2023-01-03 22:37:27,949:INFO:Set up simple imputation.
2023-01-03 22:37:27,950:INFO:Set up column transformation.
2023-01-03 22:37:27,950:INFO:Set up feature normalization.
2023-01-03 22:37:28,555:INFO:Finished creating preprocessing pipeline.
2023-01-03 22:37:28,561:INFO:Pipeline: Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2023-01-03 22:37:28,561:INFO:Creating final display dataframe.
2023-01-03 22:37:29,109:INFO:Setup _display_container:                Description             Value
0               Session id               123
1                   Target        b2b+b2c+vt
2              Target type        Regression
3               Data shape       (10506, 48)
4         Train data shape        (7354, 48)
5          Test data shape        (3152, 48)
6         Numeric features                 8
7               Preprocess              True
8          Imputation type            simple
9       Numeric imputation              mean
10  Categorical imputation              mode
11          Transformation              True
12   Transformation method       yeo-johnson
13               Normalize              True
14        Normalize method            zscore
15          Fold Generator   TimeSeriesSplit
16             Fold Number                 5
17                CPU Jobs                -1
18                 Use GPU             False
19          Log Experiment             False
20         Experiment Name  reg-default-name
21                     USI              3e37
2023-01-03 22:37:29,251:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:37:29,252:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:37:29,376:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:37:29,376:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:37:29,377:INFO:setup() successfully completed in 3.36s...............
2023-01-03 22:37:29,377:INFO:Initializing compare_models()
2023-01-03 22:37:29,377:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018F9B1BA790>, include=None, fold=None, round=4, cross_validation=True, sort=MAE, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x0000018F9B1BA790>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'MAE', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-01-03 22:37:29,377:INFO:Checking exceptions
2023-01-03 22:37:29,383:INFO:Preparing display monitor
2023-01-03 22:37:29,425:INFO:Initializing Linear Regression
2023-01-03 22:37:29,425:INFO:Total runtime is 0.0 minutes
2023-01-03 22:37:29,428:INFO:SubProcess create_model() called ==================================
2023-01-03 22:37:29,429:INFO:Initializing create_model()
2023-01-03 22:37:29,429:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018F9B1BA790>, estimator=lr, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018FA3D88E20>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:37:29,429:INFO:Checking exceptions
2023-01-03 22:37:29,429:INFO:Importing libraries
2023-01-03 22:37:29,429:INFO:Copying training dataset
2023-01-03 22:37:29,439:INFO:Defining folds
2023-01-03 22:37:29,439:INFO:Declaring metric variables
2023-01-03 22:37:29,443:INFO:Importing untrained model
2023-01-03 22:37:29,447:INFO:Linear Regression Imported successfully
2023-01-03 22:37:29,455:INFO:Starting cross validation
2023-01-03 22:37:29,461:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:37:36,389:INFO:Calculating mean and std
2023-01-03 22:37:36,391:INFO:Creating metrics dataframe
2023-01-03 22:37:36,394:INFO:Uploading results into container
2023-01-03 22:37:36,394:INFO:Uploading model into container now
2023-01-03 22:37:36,394:INFO:_master_model_container: 1
2023-01-03 22:37:36,395:INFO:_display_container: 2
2023-01-03 22:37:36,395:INFO:LinearRegression(n_jobs=-1)
2023-01-03 22:37:36,395:INFO:create_model() successfully completed......................................
2023-01-03 22:37:36,495:INFO:SubProcess create_model() end ==================================
2023-01-03 22:37:36,495:INFO:Creating metrics dataframe
2023-01-03 22:37:36,507:INFO:Initializing Lasso Regression
2023-01-03 22:37:36,507:INFO:Total runtime is 0.11801844835281372 minutes
2023-01-03 22:37:36,511:INFO:SubProcess create_model() called ==================================
2023-01-03 22:37:36,511:INFO:Initializing create_model()
2023-01-03 22:37:36,512:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018F9B1BA790>, estimator=lasso, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018FA3D88E20>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:37:36,512:INFO:Checking exceptions
2023-01-03 22:37:36,512:INFO:Importing libraries
2023-01-03 22:37:36,512:INFO:Copying training dataset
2023-01-03 22:37:36,525:INFO:Defining folds
2023-01-03 22:37:36,526:INFO:Declaring metric variables
2023-01-03 22:37:36,530:INFO:Importing untrained model
2023-01-03 22:37:36,535:INFO:Lasso Regression Imported successfully
2023-01-03 22:37:36,544:INFO:Starting cross validation
2023-01-03 22:37:36,546:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:37:36,898:INFO:Calculating mean and std
2023-01-03 22:37:36,899:INFO:Creating metrics dataframe
2023-01-03 22:37:36,902:INFO:Uploading results into container
2023-01-03 22:37:36,903:INFO:Uploading model into container now
2023-01-03 22:37:36,903:INFO:_master_model_container: 2
2023-01-03 22:37:36,903:INFO:_display_container: 2
2023-01-03 22:37:36,903:INFO:Lasso(random_state=123)
2023-01-03 22:37:36,904:INFO:create_model() successfully completed......................................
2023-01-03 22:37:37,001:INFO:SubProcess create_model() end ==================================
2023-01-03 22:37:37,001:INFO:Creating metrics dataframe
2023-01-03 22:37:37,012:INFO:Initializing Ridge Regression
2023-01-03 22:37:37,012:INFO:Total runtime is 0.1264380137125651 minutes
2023-01-03 22:37:37,017:INFO:SubProcess create_model() called ==================================
2023-01-03 22:37:37,017:INFO:Initializing create_model()
2023-01-03 22:37:37,017:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018F9B1BA790>, estimator=ridge, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018FA3D88E20>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:37:37,017:INFO:Checking exceptions
2023-01-03 22:37:37,017:INFO:Importing libraries
2023-01-03 22:37:37,018:INFO:Copying training dataset
2023-01-03 22:37:37,030:INFO:Defining folds
2023-01-03 22:37:37,030:INFO:Declaring metric variables
2023-01-03 22:37:37,035:INFO:Importing untrained model
2023-01-03 22:37:37,040:INFO:Ridge Regression Imported successfully
2023-01-03 22:37:37,048:INFO:Starting cross validation
2023-01-03 22:37:37,050:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:37:37,289:INFO:Calculating mean and std
2023-01-03 22:37:37,291:INFO:Creating metrics dataframe
2023-01-03 22:37:37,294:INFO:Uploading results into container
2023-01-03 22:37:37,294:INFO:Uploading model into container now
2023-01-03 22:37:37,294:INFO:_master_model_container: 3
2023-01-03 22:37:37,295:INFO:_display_container: 2
2023-01-03 22:37:37,295:INFO:Ridge(random_state=123)
2023-01-03 22:37:37,295:INFO:create_model() successfully completed......................................
2023-01-03 22:37:37,394:INFO:SubProcess create_model() end ==================================
2023-01-03 22:37:37,395:INFO:Creating metrics dataframe
2023-01-03 22:37:37,406:INFO:Initializing Elastic Net
2023-01-03 22:37:37,406:INFO:Total runtime is 0.1330119291941325 minutes
2023-01-03 22:37:37,410:INFO:SubProcess create_model() called ==================================
2023-01-03 22:37:37,411:INFO:Initializing create_model()
2023-01-03 22:37:37,411:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018F9B1BA790>, estimator=en, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018FA3D88E20>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:37:37,411:INFO:Checking exceptions
2023-01-03 22:37:37,411:INFO:Importing libraries
2023-01-03 22:37:37,411:INFO:Copying training dataset
2023-01-03 22:37:37,422:INFO:Defining folds
2023-01-03 22:37:37,422:INFO:Declaring metric variables
2023-01-03 22:37:37,427:INFO:Importing untrained model
2023-01-03 22:37:37,431:INFO:Elastic Net Imported successfully
2023-01-03 22:37:37,440:INFO:Starting cross validation
2023-01-03 22:37:37,441:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:37:37,686:INFO:Calculating mean and std
2023-01-03 22:37:37,688:INFO:Creating metrics dataframe
2023-01-03 22:37:37,691:INFO:Uploading results into container
2023-01-03 22:37:37,691:INFO:Uploading model into container now
2023-01-03 22:37:37,691:INFO:_master_model_container: 4
2023-01-03 22:37:37,691:INFO:_display_container: 2
2023-01-03 22:37:37,692:INFO:ElasticNet(random_state=123)
2023-01-03 22:37:37,692:INFO:create_model() successfully completed......................................
2023-01-03 22:37:37,791:INFO:SubProcess create_model() end ==================================
2023-01-03 22:37:37,791:INFO:Creating metrics dataframe
2023-01-03 22:37:37,804:INFO:Initializing Least Angle Regression
2023-01-03 22:37:37,805:INFO:Total runtime is 0.13965147336324057 minutes
2023-01-03 22:37:37,808:INFO:SubProcess create_model() called ==================================
2023-01-03 22:37:37,808:INFO:Initializing create_model()
2023-01-03 22:37:37,809:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018F9B1BA790>, estimator=lar, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018FA3D88E20>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:37:37,809:INFO:Checking exceptions
2023-01-03 22:37:37,809:INFO:Importing libraries
2023-01-03 22:37:37,809:INFO:Copying training dataset
2023-01-03 22:37:37,820:INFO:Defining folds
2023-01-03 22:37:37,820:INFO:Declaring metric variables
2023-01-03 22:37:37,825:INFO:Importing untrained model
2023-01-03 22:37:37,828:INFO:Least Angle Regression Imported successfully
2023-01-03 22:37:37,838:INFO:Starting cross validation
2023-01-03 22:37:37,840:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:37:37,888:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 22:37:37,894:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 22:37:37,915:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 22:37:37,930:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 22:37:37,959:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 22:37:38,098:INFO:Calculating mean and std
2023-01-03 22:37:38,100:INFO:Creating metrics dataframe
2023-01-03 22:37:38,105:INFO:Uploading results into container
2023-01-03 22:37:38,106:INFO:Uploading model into container now
2023-01-03 22:37:38,106:INFO:_master_model_container: 5
2023-01-03 22:37:38,106:INFO:_display_container: 2
2023-01-03 22:37:38,106:INFO:Lars(random_state=123)
2023-01-03 22:37:38,106:INFO:create_model() successfully completed......................................
2023-01-03 22:37:38,205:INFO:SubProcess create_model() end ==================================
2023-01-03 22:37:38,205:INFO:Creating metrics dataframe
2023-01-03 22:37:38,214:INFO:Initializing Lasso Least Angle Regression
2023-01-03 22:37:38,215:INFO:Total runtime is 0.14649519522984825 minutes
2023-01-03 22:37:38,219:INFO:SubProcess create_model() called ==================================
2023-01-03 22:37:38,219:INFO:Initializing create_model()
2023-01-03 22:37:38,219:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018F9B1BA790>, estimator=llar, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018FA3D88E20>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:37:38,219:INFO:Checking exceptions
2023-01-03 22:37:38,219:INFO:Importing libraries
2023-01-03 22:37:38,220:INFO:Copying training dataset
2023-01-03 22:37:38,229:INFO:Defining folds
2023-01-03 22:37:38,229:INFO:Declaring metric variables
2023-01-03 22:37:38,234:INFO:Importing untrained model
2023-01-03 22:37:38,238:INFO:Lasso Least Angle Regression Imported successfully
2023-01-03 22:37:38,247:INFO:Starting cross validation
2023-01-03 22:37:38,249:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:37:38,328:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-03 22:37:38,378:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-03 22:37:38,383:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-03 22:37:38,390:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-03 22:37:38,435:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-03 22:37:38,574:INFO:Calculating mean and std
2023-01-03 22:37:38,576:INFO:Creating metrics dataframe
2023-01-03 22:37:38,578:INFO:Uploading results into container
2023-01-03 22:37:38,579:INFO:Uploading model into container now
2023-01-03 22:37:38,579:INFO:_master_model_container: 6
2023-01-03 22:37:38,579:INFO:_display_container: 2
2023-01-03 22:37:38,580:INFO:LassoLars(random_state=123)
2023-01-03 22:37:38,580:INFO:create_model() successfully completed......................................
2023-01-03 22:37:38,677:INFO:SubProcess create_model() end ==================================
2023-01-03 22:37:38,677:INFO:Creating metrics dataframe
2023-01-03 22:37:38,690:INFO:Initializing Orthogonal Matching Pursuit
2023-01-03 22:37:38,690:INFO:Total runtime is 0.1544037222862244 minutes
2023-01-03 22:37:38,694:INFO:SubProcess create_model() called ==================================
2023-01-03 22:37:38,694:INFO:Initializing create_model()
2023-01-03 22:37:38,694:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018F9B1BA790>, estimator=omp, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018FA3D88E20>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:37:38,695:INFO:Checking exceptions
2023-01-03 22:37:38,695:INFO:Importing libraries
2023-01-03 22:37:38,695:INFO:Copying training dataset
2023-01-03 22:37:38,706:INFO:Defining folds
2023-01-03 22:37:38,707:INFO:Declaring metric variables
2023-01-03 22:37:38,711:INFO:Importing untrained model
2023-01-03 22:37:38,716:INFO:Orthogonal Matching Pursuit Imported successfully
2023-01-03 22:37:38,725:INFO:Starting cross validation
2023-01-03 22:37:38,727:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:37:38,774:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 22:37:38,779:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 22:37:38,792:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 22:37:38,810:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 22:37:38,836:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 22:37:38,970:INFO:Calculating mean and std
2023-01-03 22:37:38,972:INFO:Creating metrics dataframe
2023-01-03 22:37:38,977:INFO:Uploading results into container
2023-01-03 22:37:38,978:INFO:Uploading model into container now
2023-01-03 22:37:38,978:INFO:_master_model_container: 7
2023-01-03 22:37:38,978:INFO:_display_container: 2
2023-01-03 22:37:38,979:INFO:OrthogonalMatchingPursuit()
2023-01-03 22:37:38,979:INFO:create_model() successfully completed......................................
2023-01-03 22:37:39,086:INFO:SubProcess create_model() end ==================================
2023-01-03 22:37:39,086:INFO:Creating metrics dataframe
2023-01-03 22:37:39,096:INFO:Initializing Bayesian Ridge
2023-01-03 22:37:39,096:INFO:Total runtime is 0.16117900212605799 minutes
2023-01-03 22:37:39,100:INFO:SubProcess create_model() called ==================================
2023-01-03 22:37:39,101:INFO:Initializing create_model()
2023-01-03 22:37:39,101:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018F9B1BA790>, estimator=br, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018FA3D88E20>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:37:39,101:INFO:Checking exceptions
2023-01-03 22:37:39,101:INFO:Importing libraries
2023-01-03 22:37:39,101:INFO:Copying training dataset
2023-01-03 22:37:39,110:INFO:Defining folds
2023-01-03 22:37:39,111:INFO:Declaring metric variables
2023-01-03 22:37:39,115:INFO:Importing untrained model
2023-01-03 22:37:39,119:INFO:Bayesian Ridge Imported successfully
2023-01-03 22:37:39,127:INFO:Starting cross validation
2023-01-03 22:37:39,128:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:37:39,377:INFO:Calculating mean and std
2023-01-03 22:37:39,379:INFO:Creating metrics dataframe
2023-01-03 22:37:39,382:INFO:Uploading results into container
2023-01-03 22:37:39,382:INFO:Uploading model into container now
2023-01-03 22:37:39,383:INFO:_master_model_container: 8
2023-01-03 22:37:39,383:INFO:_display_container: 2
2023-01-03 22:37:39,384:INFO:BayesianRidge()
2023-01-03 22:37:39,384:INFO:create_model() successfully completed......................................
2023-01-03 22:37:39,484:INFO:SubProcess create_model() end ==================================
2023-01-03 22:37:39,484:INFO:Creating metrics dataframe
2023-01-03 22:37:39,494:INFO:Initializing Passive Aggressive Regressor
2023-01-03 22:37:39,495:INFO:Total runtime is 0.16783288319905604 minutes
2023-01-03 22:37:39,499:INFO:SubProcess create_model() called ==================================
2023-01-03 22:37:39,499:INFO:Initializing create_model()
2023-01-03 22:37:39,500:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018F9B1BA790>, estimator=par, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018FA3D88E20>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:37:39,500:INFO:Checking exceptions
2023-01-03 22:37:39,500:INFO:Importing libraries
2023-01-03 22:37:39,500:INFO:Copying training dataset
2023-01-03 22:37:39,509:INFO:Defining folds
2023-01-03 22:37:39,509:INFO:Declaring metric variables
2023-01-03 22:37:39,514:INFO:Importing untrained model
2023-01-03 22:37:39,518:INFO:Passive Aggressive Regressor Imported successfully
2023-01-03 22:37:39,526:INFO:Starting cross validation
2023-01-03 22:37:39,528:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:37:39,773:INFO:Calculating mean and std
2023-01-03 22:37:39,775:INFO:Creating metrics dataframe
2023-01-03 22:37:39,777:INFO:Uploading results into container
2023-01-03 22:37:39,778:INFO:Uploading model into container now
2023-01-03 22:37:39,779:INFO:_master_model_container: 9
2023-01-03 22:37:39,779:INFO:_display_container: 2
2023-01-03 22:37:39,780:INFO:PassiveAggressiveRegressor(random_state=123)
2023-01-03 22:37:39,780:INFO:create_model() successfully completed......................................
2023-01-03 22:37:39,882:INFO:SubProcess create_model() end ==================================
2023-01-03 22:37:39,882:INFO:Creating metrics dataframe
2023-01-03 22:37:39,892:INFO:Initializing Huber Regressor
2023-01-03 22:37:39,893:INFO:Total runtime is 0.17446531057357792 minutes
2023-01-03 22:37:39,896:INFO:SubProcess create_model() called ==================================
2023-01-03 22:37:39,897:INFO:Initializing create_model()
2023-01-03 22:37:39,897:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018F9B1BA790>, estimator=huber, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018FA3D88E20>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:37:39,897:INFO:Checking exceptions
2023-01-03 22:37:39,898:INFO:Importing libraries
2023-01-03 22:37:39,898:INFO:Copying training dataset
2023-01-03 22:37:39,907:INFO:Defining folds
2023-01-03 22:37:39,907:INFO:Declaring metric variables
2023-01-03 22:37:39,912:INFO:Importing untrained model
2023-01-03 22:37:39,917:INFO:Huber Regressor Imported successfully
2023-01-03 22:37:39,925:INFO:Starting cross validation
2023-01-03 22:37:39,927:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:37:40,044:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-03 22:37:40,135:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-03 22:37:40,317:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-03 22:37:40,380:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-03 22:37:40,508:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-03 22:37:40,627:INFO:Calculating mean and std
2023-01-03 22:37:40,629:INFO:Creating metrics dataframe
2023-01-03 22:37:40,633:INFO:Uploading results into container
2023-01-03 22:37:40,634:INFO:Uploading model into container now
2023-01-03 22:37:40,635:INFO:_master_model_container: 10
2023-01-03 22:37:40,636:INFO:_display_container: 2
2023-01-03 22:37:40,636:INFO:HuberRegressor()
2023-01-03 22:37:40,636:INFO:create_model() successfully completed......................................
2023-01-03 22:37:40,738:INFO:SubProcess create_model() end ==================================
2023-01-03 22:37:40,738:INFO:Creating metrics dataframe
2023-01-03 22:37:40,749:INFO:Initializing K Neighbors Regressor
2023-01-03 22:37:40,749:INFO:Total runtime is 0.18871910572052006 minutes
2023-01-03 22:37:40,753:INFO:SubProcess create_model() called ==================================
2023-01-03 22:37:40,754:INFO:Initializing create_model()
2023-01-03 22:37:40,754:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018F9B1BA790>, estimator=knn, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018FA3D88E20>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:37:40,754:INFO:Checking exceptions
2023-01-03 22:37:40,754:INFO:Importing libraries
2023-01-03 22:37:40,754:INFO:Copying training dataset
2023-01-03 22:37:40,763:INFO:Defining folds
2023-01-03 22:37:40,763:INFO:Declaring metric variables
2023-01-03 22:37:40,769:INFO:Importing untrained model
2023-01-03 22:37:40,773:INFO:K Neighbors Regressor Imported successfully
2023-01-03 22:37:40,780:INFO:Starting cross validation
2023-01-03 22:37:40,783:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:37:41,462:INFO:Calculating mean and std
2023-01-03 22:37:41,464:INFO:Creating metrics dataframe
2023-01-03 22:37:41,467:INFO:Uploading results into container
2023-01-03 22:37:41,468:INFO:Uploading model into container now
2023-01-03 22:37:41,469:INFO:_master_model_container: 11
2023-01-03 22:37:41,469:INFO:_display_container: 2
2023-01-03 22:37:41,470:INFO:KNeighborsRegressor(n_jobs=-1)
2023-01-03 22:37:41,470:INFO:create_model() successfully completed......................................
2023-01-03 22:37:41,571:INFO:SubProcess create_model() end ==================================
2023-01-03 22:37:41,571:INFO:Creating metrics dataframe
2023-01-03 22:37:41,583:INFO:Initializing Decision Tree Regressor
2023-01-03 22:37:41,583:INFO:Total runtime is 0.20262320439020798 minutes
2023-01-03 22:37:41,587:INFO:SubProcess create_model() called ==================================
2023-01-03 22:37:41,588:INFO:Initializing create_model()
2023-01-03 22:37:41,588:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018F9B1BA790>, estimator=dt, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018FA3D88E20>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:37:41,588:INFO:Checking exceptions
2023-01-03 22:37:41,588:INFO:Importing libraries
2023-01-03 22:37:41,588:INFO:Copying training dataset
2023-01-03 22:37:41,597:INFO:Defining folds
2023-01-03 22:37:41,597:INFO:Declaring metric variables
2023-01-03 22:37:41,603:INFO:Importing untrained model
2023-01-03 22:37:41,607:INFO:Decision Tree Regressor Imported successfully
2023-01-03 22:37:41,615:INFO:Starting cross validation
2023-01-03 22:37:41,616:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:37:42,093:INFO:Calculating mean and std
2023-01-03 22:37:42,095:INFO:Creating metrics dataframe
2023-01-03 22:37:42,098:INFO:Uploading results into container
2023-01-03 22:37:42,098:INFO:Uploading model into container now
2023-01-03 22:37:42,099:INFO:_master_model_container: 12
2023-01-03 22:37:42,099:INFO:_display_container: 2
2023-01-03 22:37:42,099:INFO:DecisionTreeRegressor(random_state=123)
2023-01-03 22:37:42,099:INFO:create_model() successfully completed......................................
2023-01-03 22:37:42,198:INFO:SubProcess create_model() end ==================================
2023-01-03 22:37:42,199:INFO:Creating metrics dataframe
2023-01-03 22:37:42,212:INFO:Initializing Random Forest Regressor
2023-01-03 22:37:42,213:INFO:Total runtime is 0.21312489509582525 minutes
2023-01-03 22:37:42,218:INFO:SubProcess create_model() called ==================================
2023-01-03 22:37:42,218:INFO:Initializing create_model()
2023-01-03 22:37:42,219:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018F9B1BA790>, estimator=rf, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018FA3D88E20>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:37:42,219:INFO:Checking exceptions
2023-01-03 22:37:42,219:INFO:Importing libraries
2023-01-03 22:37:42,219:INFO:Copying training dataset
2023-01-03 22:37:42,228:INFO:Defining folds
2023-01-03 22:37:42,229:INFO:Declaring metric variables
2023-01-03 22:37:42,234:INFO:Importing untrained model
2023-01-03 22:37:42,238:INFO:Random Forest Regressor Imported successfully
2023-01-03 22:37:42,245:INFO:Starting cross validation
2023-01-03 22:37:42,247:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:37:52,106:INFO:Calculating mean and std
2023-01-03 22:37:52,108:INFO:Creating metrics dataframe
2023-01-03 22:37:52,111:INFO:Uploading results into container
2023-01-03 22:37:52,111:INFO:Uploading model into container now
2023-01-03 22:37:52,111:INFO:_master_model_container: 13
2023-01-03 22:37:52,112:INFO:_display_container: 2
2023-01-03 22:37:52,112:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-01-03 22:37:52,112:INFO:create_model() successfully completed......................................
2023-01-03 22:37:52,211:INFO:SubProcess create_model() end ==================================
2023-01-03 22:37:52,211:INFO:Creating metrics dataframe
2023-01-03 22:37:52,225:INFO:Initializing Extra Trees Regressor
2023-01-03 22:37:52,226:INFO:Total runtime is 0.3800123492876689 minutes
2023-01-03 22:37:52,230:INFO:SubProcess create_model() called ==================================
2023-01-03 22:37:52,230:INFO:Initializing create_model()
2023-01-03 22:37:52,231:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018F9B1BA790>, estimator=et, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018FA3D88E20>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:37:52,231:INFO:Checking exceptions
2023-01-03 22:37:52,231:INFO:Importing libraries
2023-01-03 22:37:52,231:INFO:Copying training dataset
2023-01-03 22:37:52,242:INFO:Defining folds
2023-01-03 22:37:52,242:INFO:Declaring metric variables
2023-01-03 22:37:52,247:INFO:Importing untrained model
2023-01-03 22:37:52,252:INFO:Extra Trees Regressor Imported successfully
2023-01-03 22:37:52,260:INFO:Starting cross validation
2023-01-03 22:37:52,261:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:37:56,642:INFO:Calculating mean and std
2023-01-03 22:37:56,644:INFO:Creating metrics dataframe
2023-01-03 22:37:56,648:INFO:Uploading results into container
2023-01-03 22:37:56,649:INFO:Uploading model into container now
2023-01-03 22:37:56,649:INFO:_master_model_container: 14
2023-01-03 22:37:56,650:INFO:_display_container: 2
2023-01-03 22:37:56,650:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-01-03 22:37:56,650:INFO:create_model() successfully completed......................................
2023-01-03 22:37:56,750:INFO:SubProcess create_model() end ==================================
2023-01-03 22:37:56,750:INFO:Creating metrics dataframe
2023-01-03 22:37:56,762:INFO:Initializing AdaBoost Regressor
2023-01-03 22:37:56,762:INFO:Total runtime is 0.45560825268427535 minutes
2023-01-03 22:37:56,765:INFO:SubProcess create_model() called ==================================
2023-01-03 22:37:56,766:INFO:Initializing create_model()
2023-01-03 22:37:56,766:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018F9B1BA790>, estimator=ada, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018FA3D88E20>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:37:56,766:INFO:Checking exceptions
2023-01-03 22:37:56,766:INFO:Importing libraries
2023-01-03 22:37:56,766:INFO:Copying training dataset
2023-01-03 22:37:56,775:INFO:Defining folds
2023-01-03 22:37:56,776:INFO:Declaring metric variables
2023-01-03 22:37:56,779:INFO:Importing untrained model
2023-01-03 22:37:56,784:INFO:AdaBoost Regressor Imported successfully
2023-01-03 22:37:56,791:INFO:Starting cross validation
2023-01-03 22:37:56,793:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:37:58,927:INFO:Calculating mean and std
2023-01-03 22:37:58,929:INFO:Creating metrics dataframe
2023-01-03 22:37:58,932:INFO:Uploading results into container
2023-01-03 22:37:58,933:INFO:Uploading model into container now
2023-01-03 22:37:58,933:INFO:_master_model_container: 15
2023-01-03 22:37:58,934:INFO:_display_container: 2
2023-01-03 22:37:58,934:INFO:AdaBoostRegressor(random_state=123)
2023-01-03 22:37:58,934:INFO:create_model() successfully completed......................................
2023-01-03 22:37:59,032:INFO:SubProcess create_model() end ==================================
2023-01-03 22:37:59,032:INFO:Creating metrics dataframe
2023-01-03 22:37:59,044:INFO:Initializing Gradient Boosting Regressor
2023-01-03 22:37:59,044:INFO:Total runtime is 0.4936376253763835 minutes
2023-01-03 22:37:59,048:INFO:SubProcess create_model() called ==================================
2023-01-03 22:37:59,048:INFO:Initializing create_model()
2023-01-03 22:37:59,049:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018F9B1BA790>, estimator=gbr, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018FA3D88E20>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:37:59,049:INFO:Checking exceptions
2023-01-03 22:37:59,049:INFO:Importing libraries
2023-01-03 22:37:59,049:INFO:Copying training dataset
2023-01-03 22:37:59,058:INFO:Defining folds
2023-01-03 22:37:59,059:INFO:Declaring metric variables
2023-01-03 22:37:59,062:INFO:Importing untrained model
2023-01-03 22:37:59,067:INFO:Gradient Boosting Regressor Imported successfully
2023-01-03 22:37:59,075:INFO:Starting cross validation
2023-01-03 22:37:59,076:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:38:04,335:INFO:Calculating mean and std
2023-01-03 22:38:04,337:INFO:Creating metrics dataframe
2023-01-03 22:38:04,340:INFO:Uploading results into container
2023-01-03 22:38:04,340:INFO:Uploading model into container now
2023-01-03 22:38:04,340:INFO:_master_model_container: 16
2023-01-03 22:38:04,340:INFO:_display_container: 2
2023-01-03 22:38:04,341:INFO:GradientBoostingRegressor(random_state=123)
2023-01-03 22:38:04,341:INFO:create_model() successfully completed......................................
2023-01-03 22:38:04,438:INFO:SubProcess create_model() end ==================================
2023-01-03 22:38:04,438:INFO:Creating metrics dataframe
2023-01-03 22:38:04,456:INFO:Initializing Light Gradient Boosting Machine
2023-01-03 22:38:04,456:INFO:Total runtime is 0.583837902545929 minutes
2023-01-03 22:38:04,461:INFO:SubProcess create_model() called ==================================
2023-01-03 22:38:04,462:INFO:Initializing create_model()
2023-01-03 22:38:04,462:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018F9B1BA790>, estimator=lightgbm, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018FA3D88E20>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:38:04,462:INFO:Checking exceptions
2023-01-03 22:38:04,462:INFO:Importing libraries
2023-01-03 22:38:04,462:INFO:Copying training dataset
2023-01-03 22:38:04,472:INFO:Defining folds
2023-01-03 22:38:04,473:INFO:Declaring metric variables
2023-01-03 22:38:04,476:INFO:Importing untrained model
2023-01-03 22:38:04,481:INFO:Light Gradient Boosting Machine Imported successfully
2023-01-03 22:38:04,489:INFO:Starting cross validation
2023-01-03 22:38:04,491:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:38:06,673:INFO:Calculating mean and std
2023-01-03 22:38:06,675:INFO:Creating metrics dataframe
2023-01-03 22:38:06,678:INFO:Uploading results into container
2023-01-03 22:38:06,678:INFO:Uploading model into container now
2023-01-03 22:38:06,679:INFO:_master_model_container: 17
2023-01-03 22:38:06,679:INFO:_display_container: 2
2023-01-03 22:38:06,680:INFO:LGBMRegressor(random_state=123)
2023-01-03 22:38:06,680:INFO:create_model() successfully completed......................................
2023-01-03 22:38:06,780:INFO:SubProcess create_model() end ==================================
2023-01-03 22:38:06,780:INFO:Creating metrics dataframe
2023-01-03 22:38:06,793:INFO:Initializing Dummy Regressor
2023-01-03 22:38:06,793:INFO:Total runtime is 0.6227930823961895 minutes
2023-01-03 22:38:06,797:INFO:SubProcess create_model() called ==================================
2023-01-03 22:38:06,797:INFO:Initializing create_model()
2023-01-03 22:38:06,797:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018F9B1BA790>, estimator=dummy, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018FA3D88E20>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:38:06,797:INFO:Checking exceptions
2023-01-03 22:38:06,798:INFO:Importing libraries
2023-01-03 22:38:06,798:INFO:Copying training dataset
2023-01-03 22:38:06,807:INFO:Defining folds
2023-01-03 22:38:06,807:INFO:Declaring metric variables
2023-01-03 22:38:06,812:INFO:Importing untrained model
2023-01-03 22:38:06,816:INFO:Dummy Regressor Imported successfully
2023-01-03 22:38:06,824:INFO:Starting cross validation
2023-01-03 22:38:06,825:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:38:07,069:INFO:Calculating mean and std
2023-01-03 22:38:07,071:INFO:Creating metrics dataframe
2023-01-03 22:38:07,074:INFO:Uploading results into container
2023-01-03 22:38:07,074:INFO:Uploading model into container now
2023-01-03 22:38:07,074:INFO:_master_model_container: 18
2023-01-03 22:38:07,074:INFO:_display_container: 2
2023-01-03 22:38:07,075:INFO:DummyRegressor()
2023-01-03 22:38:07,075:INFO:create_model() successfully completed......................................
2023-01-03 22:38:07,174:INFO:SubProcess create_model() end ==================================
2023-01-03 22:38:07,174:INFO:Creating metrics dataframe
2023-01-03 22:38:07,202:INFO:Initializing create_model()
2023-01-03 22:38:07,202:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018F9B1BA790>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:38:07,203:INFO:Checking exceptions
2023-01-03 22:38:07,205:INFO:Importing libraries
2023-01-03 22:38:07,206:INFO:Copying training dataset
2023-01-03 22:38:07,215:INFO:Defining folds
2023-01-03 22:38:07,216:INFO:Declaring metric variables
2023-01-03 22:38:07,216:INFO:Importing untrained model
2023-01-03 22:38:07,216:INFO:Declaring custom model
2023-01-03 22:38:07,217:INFO:Extra Trees Regressor Imported successfully
2023-01-03 22:38:07,218:INFO:Cross validation set to False
2023-01-03 22:38:07,218:INFO:Fitting Model
2023-01-03 22:38:09,057:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-01-03 22:38:09,057:INFO:create_model() successfully completed......................................
2023-01-03 22:38:09,196:INFO:_master_model_container: 18
2023-01-03 22:38:09,196:INFO:_display_container: 2
2023-01-03 22:38:09,197:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-01-03 22:38:09,197:INFO:compare_models() successfully completed......................................
2023-01-03 22:38:09,197:INFO:Initializing tune_model()
2023-01-03 22:38:09,198:INFO:tune_model(estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=MAE, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018F9B1BA790>)
2023-01-03 22:38:09,198:INFO:Checking exceptions
2023-01-03 22:38:09,236:INFO:Copying training dataset
2023-01-03 22:38:09,246:INFO:Checking base model
2023-01-03 22:38:09,246:INFO:Base model : Extra Trees Regressor
2023-01-03 22:38:09,251:INFO:Declaring metric variables
2023-01-03 22:38:09,256:INFO:Defining Hyperparameters
2023-01-03 22:38:09,380:INFO:Tuning with n_jobs=-1
2023-01-03 22:38:09,381:INFO:Initializing RandomizedSearchCV
2023-01-03 22:38:09,433:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:38:09,437:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:38:09,445:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:38:09,462:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:38:09,768:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:38:09,783:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:38:09,819:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:38:09,914:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:38:10,105:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:38:10,124:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:38:10,190:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:38:10,329:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:38:10,399:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:38:10,452:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:38:10,928:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:38:10,929:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:38:11,055:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:38:11,322:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:38:11,414:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:38:11,637:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:38:11,841:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:38:11,998:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:38:12,384:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:38:12,536:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:38:12,610:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 22:38:12,631:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:38:13,523:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 22:38:13,627:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 22:38:13,727:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 22:38:13,764:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 22:38:18,613:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:38:21,889:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:38:22,391:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:38:24,216:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:38:24,670:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:38:25,939:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:38:26,098:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:38:26,290:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:38:27,109:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:38:27,212:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:38:27,355:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 22:38:28,789:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 22:38:28,872:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 22:38:29,088:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 22:38:31,512:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:403: FutureWarning: Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='absolute_error'` which is equivalent.
  warn(

2023-01-03 22:38:34,396:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:38:37,811:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:38:39,195:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:38:39,988:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:38:41,285:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:38:48,249:INFO:best_params: {'actual_estimator__n_estimators': 100, 'actual_estimator__min_samples_split': 7, 'actual_estimator__min_samples_leaf': 4, 'actual_estimator__min_impurity_decrease': 0.1, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 9, 'actual_estimator__criterion': 'mse', 'actual_estimator__bootstrap': True}
2023-01-03 22:38:48,251:INFO:Hyperparameter search completed
2023-01-03 22:38:48,251:INFO:SubProcess create_model() called ==================================
2023-01-03 22:38:48,251:INFO:Initializing create_model()
2023-01-03 22:38:48,252:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018F9B1BA790>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018FA7779220>, model_only=True, return_train_score=False, kwargs={'n_estimators': 100, 'min_samples_split': 7, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.1, 'max_features': 1.0, 'max_depth': 9, 'criterion': 'mse', 'bootstrap': True})
2023-01-03 22:38:48,252:INFO:Checking exceptions
2023-01-03 22:38:48,252:INFO:Importing libraries
2023-01-03 22:38:48,252:INFO:Copying training dataset
2023-01-03 22:38:48,262:INFO:Defining folds
2023-01-03 22:38:48,262:INFO:Declaring metric variables
2023-01-03 22:38:48,265:INFO:Importing untrained model
2023-01-03 22:38:48,265:INFO:Declaring custom model
2023-01-03 22:38:48,270:INFO:Extra Trees Regressor Imported successfully
2023-01-03 22:38:48,278:INFO:Starting cross validation
2023-01-03 22:38:48,280:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:38:48,331:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:38:48,334:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:38:48,357:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:38:48,357:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:38:48,854:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.
  warn(

2023-01-03 22:38:49,320:INFO:Calculating mean and std
2023-01-03 22:38:49,322:INFO:Creating metrics dataframe
2023-01-03 22:38:49,327:INFO:Finalizing model
2023-01-03 22:38:49,677:INFO:Uploading results into container
2023-01-03 22:38:49,678:INFO:Uploading model into container now
2023-01-03 22:38:49,678:INFO:_master_model_container: 19
2023-01-03 22:38:49,678:INFO:_display_container: 3
2023-01-03 22:38:49,679:INFO:ExtraTreesRegressor(bootstrap=True, criterion='mse', max_depth=9,
                    max_features=1.0, min_impurity_decrease=0.1,
                    min_samples_leaf=4, min_samples_split=7, n_jobs=-1,
                    random_state=123)
2023-01-03 22:38:49,679:INFO:create_model() successfully completed......................................
2023-01-03 22:38:49,791:INFO:SubProcess create_model() end ==================================
2023-01-03 22:38:49,791:INFO:choose_better activated
2023-01-03 22:38:49,795:INFO:SubProcess create_model() called ==================================
2023-01-03 22:38:49,795:INFO:Initializing create_model()
2023-01-03 22:38:49,795:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018F9B1BA790>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:38:49,796:INFO:Checking exceptions
2023-01-03 22:38:49,798:INFO:Importing libraries
2023-01-03 22:38:49,798:INFO:Copying training dataset
2023-01-03 22:38:49,806:INFO:Defining folds
2023-01-03 22:38:49,807:INFO:Declaring metric variables
2023-01-03 22:38:49,807:INFO:Importing untrained model
2023-01-03 22:38:49,807:INFO:Declaring custom model
2023-01-03 22:38:49,807:INFO:Extra Trees Regressor Imported successfully
2023-01-03 22:38:49,808:INFO:Starting cross validation
2023-01-03 22:38:49,809:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:38:54,133:INFO:Calculating mean and std
2023-01-03 22:38:54,134:INFO:Creating metrics dataframe
2023-01-03 22:38:54,136:INFO:Finalizing model
2023-01-03 22:38:55,910:INFO:Uploading results into container
2023-01-03 22:38:55,911:INFO:Uploading model into container now
2023-01-03 22:38:55,911:INFO:_master_model_container: 20
2023-01-03 22:38:55,911:INFO:_display_container: 4
2023-01-03 22:38:55,912:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-01-03 22:38:55,912:INFO:create_model() successfully completed......................................
2023-01-03 22:38:56,012:INFO:SubProcess create_model() end ==================================
2023-01-03 22:38:56,013:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123) result for MAE is 2.2413
2023-01-03 22:38:56,013:INFO:ExtraTreesRegressor(bootstrap=True, criterion='mse', max_depth=9,
                    max_features=1.0, min_impurity_decrease=0.1,
                    min_samples_leaf=4, min_samples_split=7, n_jobs=-1,
                    random_state=123) result for MAE is 2.9589
2023-01-03 22:38:56,014:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123) is best model
2023-01-03 22:38:56,014:INFO:choose_better completed
2023-01-03 22:38:56,014:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-01-03 22:38:56,023:INFO:_master_model_container: 20
2023-01-03 22:38:56,023:INFO:_display_container: 3
2023-01-03 22:38:56,023:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-01-03 22:38:56,023:INFO:tune_model() successfully completed......................................
2023-01-03 22:38:56,134:INFO:Initializing plot_model()
2023-01-03 22:38:56,134:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018F9B1BA790>, system=True)
2023-01-03 22:38:56,135:INFO:Checking exceptions
2023-01-03 22:38:56,160:INFO:Preloading libraries
2023-01-03 22:38:56,311:INFO:Copying training dataset
2023-01-03 22:38:56,311:INFO:Plot type: error
2023-01-03 22:38:56,477:INFO:Fitting Model
2023-01-03 22:38:56,478:INFO:Scoring test/hold-out set
2023-01-03 22:38:56,931:INFO:Visual Rendered Successfully
2023-01-03 22:38:57,033:INFO:plot_model() successfully completed......................................
2023-01-03 22:38:57,044:INFO:Initializing predict_model()
2023-01-03 22:38:57,044:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018F9B1BA790>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x0000018FA776AEE0>)
2023-01-03 22:38:57,044:INFO:Checking exceptions
2023-01-03 22:38:57,044:INFO:Preloading libraries
2023-01-03 22:38:57,265:INFO:Initializing finalize_model()
2023-01-03 22:38:57,266:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018F9B1BA790>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-01-03 22:38:57,266:INFO:Finalizing ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-01-03 22:38:57,275:INFO:Initializing create_model()
2023-01-03 22:38:57,275:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018F9B1BA790>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-01-03 22:38:57,275:INFO:Checking exceptions
2023-01-03 22:38:57,277:INFO:Importing libraries
2023-01-03 22:38:57,277:INFO:Copying training dataset
2023-01-03 22:38:57,278:INFO:Defining folds
2023-01-03 22:38:57,278:INFO:Declaring metric variables
2023-01-03 22:38:57,278:INFO:Importing untrained model
2023-01-03 22:38:57,278:INFO:Declaring custom model
2023-01-03 22:38:57,279:INFO:Extra Trees Regressor Imported successfully
2023-01-03 22:38:57,280:INFO:Cross validation set to False
2023-01-03 22:38:57,280:INFO:Fitting Model
2023-01-03 22:39:00,611:INFO:Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))])
2023-01-03 22:39:00,611:INFO:create_model() successfully completed......................................
2023-01-03 22:39:00,709:INFO:_master_model_container: 20
2023-01-03 22:39:00,709:INFO:_display_container: 4
2023-01-03 22:39:00,716:INFO:Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))])
2023-01-03 22:39:00,716:INFO:finalize_model() successfully completed......................................
2023-01-03 22:39:00,822:INFO:Initializing predict_model()
2023-01-03 22:39:00,822:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018F9B1BA790>, estimator=Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x0000018FA7F70280>)
2023-01-03 22:39:00,822:INFO:Checking exceptions
2023-01-03 22:39:00,822:INFO:Preloading libraries
2023-01-03 22:39:00,824:INFO:Set up data.
2023-01-03 22:39:00,838:INFO:Set up index.
2023-01-03 22:39:01,310:INFO:Initializing save_model()
2023-01-03 22:39:01,310:INFO:save_model(model=Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))]), model_name=c:\Users\Kodotautas\Desktop\Data_science\7_TIME_SERIES_FORECAST_PYCARET/models/final_model.pkl, prep_pipe_=Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-01-03 22:39:01,310:INFO:Adding model into prep_pipe
2023-01-03 22:39:01,517:WARNING:Only Model saved as it was a pipeline.
2023-01-03 22:39:01,758:INFO:c:\Users\Kodotautas\Desktop\Data_science\7_TIME_SERIES_FORECAST_PYCARET/models/final_model.pkl.pkl saved in current working directory
2023-01-03 22:39:01,766:INFO:Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))])
2023-01-03 22:39:01,766:INFO:save_model() successfully completed......................................
2023-01-03 22:41:32,903:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-01-03 22:41:32,903:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-01-03 22:41:32,903:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-01-03 22:41:32,903:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-01-03 22:41:33,585:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-01-03 22:41:33,956:INFO:PyCaret RegressionExperiment
2023-01-03 22:41:33,957:INFO:Logging name: reg-default-name
2023-01-03 22:41:33,957:INFO:ML Usecase: MLUsecase.REGRESSION
2023-01-03 22:41:33,957:INFO:version 3.0.0.rc6
2023-01-03 22:41:33,957:INFO:Initializing setup()
2023-01-03 22:41:33,957:INFO:self.USI: 1db4
2023-01-03 22:41:33,957:INFO:self._variable_keys: {'seed', 'n_jobs_param', 'pipeline', 'target_param', 'fold_generator', 'y_train', 'X_test', 'memory', 'exp_name_log', 'html_param', 'fold_groups_param', 'transform_target_param', 'log_plots_param', 'y', 'gpu_n_jobs_param', 'data', 'X', 'gpu_param', '_available_plots', 'logging_param', 'X_train', 'y_test', 'exp_id', 'idx', 'USI', '_ml_usecase', 'fold_shuffle_param'}
2023-01-03 22:41:33,957:INFO:Checking environment
2023-01-03 22:41:33,957:INFO:python_version: 3.9.13
2023-01-03 22:41:33,957:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-01-03 22:41:33,957:INFO:machine: AMD64
2023-01-03 22:41:33,957:INFO:platform: Windows-10-10.0.19044-SP0
2023-01-03 22:41:33,957:INFO:Memory: svmem(total=17114804224, available=10228465664, percent=40.2, used=6886338560, free=10228465664)
2023-01-03 22:41:33,957:INFO:Physical Core: 4
2023-01-03 22:41:33,957:INFO:Logical Core: 4
2023-01-03 22:41:33,957:INFO:Checking libraries
2023-01-03 22:41:33,958:INFO:System:
2023-01-03 22:41:33,958:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-01-03 22:41:33,958:INFO:executable: c:\Users\Kodotautas\anaconda3\python.exe
2023-01-03 22:41:33,958:INFO:   machine: Windows-10-10.0.19044-SP0
2023-01-03 22:41:33,958:INFO:PyCaret required dependencies:
2023-01-03 22:41:33,958:INFO:                 pip: 22.2.2
2023-01-03 22:41:33,958:INFO:          setuptools: 63.4.1
2023-01-03 22:41:33,958:INFO:             pycaret: 3.0.0rc6
2023-01-03 22:41:33,958:INFO:             IPython: 7.31.1
2023-01-03 22:41:33,958:INFO:          ipywidgets: 7.6.5
2023-01-03 22:41:33,958:INFO:                tqdm: 4.64.1
2023-01-03 22:41:33,958:INFO:               numpy: 1.21.5
2023-01-03 22:41:33,959:INFO:              pandas: 1.4.4
2023-01-03 22:41:33,959:INFO:              jinja2: 2.11.3
2023-01-03 22:41:33,959:INFO:               scipy: 1.9.1
2023-01-03 22:41:33,959:INFO:              joblib: 1.2.0
2023-01-03 22:41:33,959:INFO:             sklearn: 1.0.2
2023-01-03 22:41:33,959:INFO:                pyod: 1.0.7
2023-01-03 22:41:33,959:INFO:            imblearn: 0.10.1
2023-01-03 22:41:33,959:INFO:   category_encoders: 2.5.1.post0
2023-01-03 22:41:33,959:INFO:            lightgbm: 3.3.3
2023-01-03 22:41:33,959:INFO:               numba: 0.55.1
2023-01-03 22:41:33,959:INFO:            requests: 2.28.1
2023-01-03 22:41:33,959:INFO:          matplotlib: 3.5.2
2023-01-03 22:41:33,959:INFO:          scikitplot: 0.3.7
2023-01-03 22:41:33,959:INFO:         yellowbrick: 1.5
2023-01-03 22:41:33,959:INFO:              plotly: 5.9.0
2023-01-03 22:41:33,959:INFO:             kaleido: 0.2.1
2023-01-03 22:41:33,959:INFO:         statsmodels: 0.13.2
2023-01-03 22:41:33,960:INFO:              sktime: 0.14.1
2023-01-03 22:41:33,960:INFO:               tbats: 1.1.2
2023-01-03 22:41:33,960:INFO:            pmdarima: 2.0.2
2023-01-03 22:41:33,960:INFO:              psutil: 5.9.0
2023-01-03 22:41:33,960:INFO:PyCaret optional dependencies:
2023-01-03 22:41:34,216:INFO:                shap: 0.41.0
2023-01-03 22:41:34,216:INFO:           interpret: Not installed
2023-01-03 22:41:34,216:INFO:                umap: Not installed
2023-01-03 22:41:34,216:INFO:    pandas_profiling: Not installed
2023-01-03 22:41:34,216:INFO:  explainerdashboard: Not installed
2023-01-03 22:41:34,216:INFO:             autoviz: Not installed
2023-01-03 22:41:34,217:INFO:           fairlearn: Not installed
2023-01-03 22:41:34,217:INFO:             xgboost: Not installed
2023-01-03 22:41:34,217:INFO:            catboost: Not installed
2023-01-03 22:41:34,217:INFO:              kmodes: Not installed
2023-01-03 22:41:34,217:INFO:             mlxtend: Not installed
2023-01-03 22:41:34,217:INFO:       statsforecast: Not installed
2023-01-03 22:41:34,217:INFO:        tune_sklearn: 0.4.3
2023-01-03 22:41:34,217:INFO:                 ray: 2.0.0
2023-01-03 22:41:34,217:INFO:            hyperopt: 0.2.7
2023-01-03 22:41:34,217:INFO:              optuna: 3.0.1
2023-01-03 22:41:34,217:INFO:               skopt: 0.9.0
2023-01-03 22:41:34,217:INFO:              mlflow: Not installed
2023-01-03 22:41:34,217:INFO:              gradio: Not installed
2023-01-03 22:41:34,217:INFO:             fastapi: 0.88.0
2023-01-03 22:41:34,217:INFO:             uvicorn: 0.20.0
2023-01-03 22:41:34,217:INFO:              m2cgen: Not installed
2023-01-03 22:41:34,217:INFO:           evidently: Not installed
2023-01-03 22:41:34,217:INFO:                nltk: 3.7
2023-01-03 22:41:34,217:INFO:            pyLDAvis: Not installed
2023-01-03 22:41:34,217:INFO:              gensim: 4.1.2
2023-01-03 22:41:34,217:INFO:               spacy: 3.4.2
2023-01-03 22:41:34,217:INFO:           wordcloud: Not installed
2023-01-03 22:41:34,217:INFO:            textblob: Not installed
2023-01-03 22:41:34,218:INFO:               fugue: Not installed
2023-01-03 22:41:34,218:INFO:           streamlit: Not installed
2023-01-03 22:41:34,218:INFO:             prophet: Not installed
2023-01-03 22:41:34,218:INFO:None
2023-01-03 22:41:34,218:INFO:Set up data.
2023-01-03 22:41:34,238:INFO:Set up train/test split.
2023-01-03 22:41:34,252:INFO:Set up index.
2023-01-03 22:41:34,254:INFO:Set up folding strategy.
2023-01-03 22:41:34,254:INFO:Assigning column types.
2023-01-03 22:41:34,265:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-01-03 22:41:34,265:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-01-03 22:41:34,270:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-03 22:41:34,276:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 22:41:34,344:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 22:41:34,389:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 22:41:34,390:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:41:34,527:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:41:34,527:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-01-03 22:41:34,532:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-03 22:41:34,536:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 22:41:34,602:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 22:41:34,648:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 22:41:34,649:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:41:34,649:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:41:34,650:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-01-03 22:41:34,655:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-03 22:41:34,661:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 22:41:34,729:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 22:41:34,777:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 22:41:34,778:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:41:34,778:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:41:34,783:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-03 22:41:34,788:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 22:41:34,853:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 22:41:34,900:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 22:41:34,900:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:41:34,901:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:41:34,901:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-01-03 22:41:34,911:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 22:41:34,978:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 22:41:35,027:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 22:41:35,028:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:41:35,028:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:41:35,038:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 22:41:35,104:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 22:41:35,151:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 22:41:35,151:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:41:35,151:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:41:35,152:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-01-03 22:41:35,228:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 22:41:35,277:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 22:41:35,277:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:41:35,277:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:41:35,354:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 22:41:35,401:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 22:41:35,401:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:41:35,401:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:41:35,402:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-01-03 22:41:35,482:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 22:41:35,533:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:41:35,533:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:41:35,609:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 22:41:35,657:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:41:35,657:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:41:35,658:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-01-03 22:41:35,785:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:41:35,785:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:41:35,909:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:41:35,910:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:41:35,911:INFO:Preparing preprocessing pipeline...
2023-01-03 22:41:35,913:INFO:Set up simple imputation.
2023-01-03 22:41:35,913:INFO:Set up column transformation.
2023-01-03 22:41:35,913:INFO:Set up feature normalization.
2023-01-03 22:41:36,516:INFO:Finished creating preprocessing pipeline.
2023-01-03 22:41:36,522:INFO:Pipeline: Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2023-01-03 22:41:36,522:INFO:Creating final display dataframe.
2023-01-03 22:41:37,058:INFO:Setup _display_container:                Description             Value
0               Session id               123
1                   Target        b2b+b2c+vt
2              Target type        Regression
3               Data shape       (10506, 48)
4         Train data shape        (7354, 48)
5          Test data shape        (3152, 48)
6         Numeric features                 8
7               Preprocess              True
8          Imputation type            simple
9       Numeric imputation              mean
10  Categorical imputation              mode
11          Transformation              True
12   Transformation method       yeo-johnson
13               Normalize              True
14        Normalize method            zscore
15          Fold Generator   TimeSeriesSplit
16             Fold Number                 5
17                CPU Jobs                -1
18                 Use GPU             False
19          Log Experiment             False
20         Experiment Name  reg-default-name
21                     USI              1db4
2023-01-03 22:41:37,199:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:41:37,199:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:41:37,344:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:41:37,344:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:41:37,345:INFO:setup() successfully completed in 3.39s...............
2023-01-03 22:41:37,345:INFO:Initializing compare_models()
2023-01-03 22:41:37,345:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F1D9C8C940>, include=None, fold=None, round=4, cross_validation=True, sort=MAE, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001F1D9C8C940>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'MAE', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-01-03 22:41:37,346:INFO:Checking exceptions
2023-01-03 22:41:37,351:INFO:Preparing display monitor
2023-01-03 22:41:37,432:INFO:Initializing Linear Regression
2023-01-03 22:41:37,432:INFO:Total runtime is 0.0 minutes
2023-01-03 22:41:37,436:INFO:SubProcess create_model() called ==================================
2023-01-03 22:41:37,437:INFO:Initializing create_model()
2023-01-03 22:41:37,437:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F1D9C8C940>, estimator=lr, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F1DF97AFD0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:41:37,438:INFO:Checking exceptions
2023-01-03 22:41:37,438:INFO:Importing libraries
2023-01-03 22:41:37,438:INFO:Copying training dataset
2023-01-03 22:41:37,459:INFO:Defining folds
2023-01-03 22:41:37,459:INFO:Declaring metric variables
2023-01-03 22:41:37,466:INFO:Importing untrained model
2023-01-03 22:41:37,471:INFO:Linear Regression Imported successfully
2023-01-03 22:41:37,480:INFO:Starting cross validation
2023-01-03 22:41:37,486:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:41:44,336:INFO:Calculating mean and std
2023-01-03 22:41:44,338:INFO:Creating metrics dataframe
2023-01-03 22:41:44,341:INFO:Uploading results into container
2023-01-03 22:41:44,342:INFO:Uploading model into container now
2023-01-03 22:41:44,343:INFO:_master_model_container: 1
2023-01-03 22:41:44,343:INFO:_display_container: 2
2023-01-03 22:41:44,343:INFO:LinearRegression(n_jobs=-1)
2023-01-03 22:41:44,343:INFO:create_model() successfully completed......................................
2023-01-03 22:41:44,453:INFO:SubProcess create_model() end ==================================
2023-01-03 22:41:44,453:INFO:Creating metrics dataframe
2023-01-03 22:41:44,461:INFO:Initializing Lasso Regression
2023-01-03 22:41:44,461:INFO:Total runtime is 0.11714999675750733 minutes
2023-01-03 22:41:44,465:INFO:SubProcess create_model() called ==================================
2023-01-03 22:41:44,466:INFO:Initializing create_model()
2023-01-03 22:41:44,466:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F1D9C8C940>, estimator=lasso, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F1DF97AFD0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:41:44,466:INFO:Checking exceptions
2023-01-03 22:41:44,466:INFO:Importing libraries
2023-01-03 22:41:44,466:INFO:Copying training dataset
2023-01-03 22:41:44,476:INFO:Defining folds
2023-01-03 22:41:44,476:INFO:Declaring metric variables
2023-01-03 22:41:44,480:INFO:Importing untrained model
2023-01-03 22:41:44,484:INFO:Lasso Regression Imported successfully
2023-01-03 22:41:44,493:INFO:Starting cross validation
2023-01-03 22:41:44,494:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:41:44,859:INFO:Calculating mean and std
2023-01-03 22:41:44,861:INFO:Creating metrics dataframe
2023-01-03 22:41:44,864:INFO:Uploading results into container
2023-01-03 22:41:44,865:INFO:Uploading model into container now
2023-01-03 22:41:44,865:INFO:_master_model_container: 2
2023-01-03 22:41:44,865:INFO:_display_container: 2
2023-01-03 22:41:44,866:INFO:Lasso(random_state=123)
2023-01-03 22:41:44,866:INFO:create_model() successfully completed......................................
2023-01-03 22:41:44,974:INFO:SubProcess create_model() end ==================================
2023-01-03 22:41:44,974:INFO:Creating metrics dataframe
2023-01-03 22:41:44,985:INFO:Initializing Ridge Regression
2023-01-03 22:41:44,985:INFO:Total runtime is 0.1258833408355713 minutes
2023-01-03 22:41:44,990:INFO:SubProcess create_model() called ==================================
2023-01-03 22:41:44,990:INFO:Initializing create_model()
2023-01-03 22:41:44,990:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F1D9C8C940>, estimator=ridge, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F1DF97AFD0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:41:44,990:INFO:Checking exceptions
2023-01-03 22:41:44,990:INFO:Importing libraries
2023-01-03 22:41:44,990:INFO:Copying training dataset
2023-01-03 22:41:45,001:INFO:Defining folds
2023-01-03 22:41:45,001:INFO:Declaring metric variables
2023-01-03 22:41:45,005:INFO:Importing untrained model
2023-01-03 22:41:45,010:INFO:Ridge Regression Imported successfully
2023-01-03 22:41:45,018:INFO:Starting cross validation
2023-01-03 22:41:45,020:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:41:45,290:INFO:Calculating mean and std
2023-01-03 22:41:45,293:INFO:Creating metrics dataframe
2023-01-03 22:41:45,297:INFO:Uploading results into container
2023-01-03 22:41:45,297:INFO:Uploading model into container now
2023-01-03 22:41:45,298:INFO:_master_model_container: 3
2023-01-03 22:41:45,298:INFO:_display_container: 2
2023-01-03 22:41:45,299:INFO:Ridge(random_state=123)
2023-01-03 22:41:45,299:INFO:create_model() successfully completed......................................
2023-01-03 22:41:45,408:INFO:SubProcess create_model() end ==================================
2023-01-03 22:41:45,408:INFO:Creating metrics dataframe
2023-01-03 22:41:45,418:INFO:Initializing Elastic Net
2023-01-03 22:41:45,418:INFO:Total runtime is 0.1331000010172526 minutes
2023-01-03 22:41:45,422:INFO:SubProcess create_model() called ==================================
2023-01-03 22:41:45,422:INFO:Initializing create_model()
2023-01-03 22:41:45,423:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F1D9C8C940>, estimator=en, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F1DF97AFD0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:41:45,423:INFO:Checking exceptions
2023-01-03 22:41:45,423:INFO:Importing libraries
2023-01-03 22:41:45,423:INFO:Copying training dataset
2023-01-03 22:41:45,434:INFO:Defining folds
2023-01-03 22:41:45,435:INFO:Declaring metric variables
2023-01-03 22:41:45,438:INFO:Importing untrained model
2023-01-03 22:41:45,443:INFO:Elastic Net Imported successfully
2023-01-03 22:41:45,452:INFO:Starting cross validation
2023-01-03 22:41:45,454:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:41:45,716:INFO:Calculating mean and std
2023-01-03 22:41:45,718:INFO:Creating metrics dataframe
2023-01-03 22:41:45,721:INFO:Uploading results into container
2023-01-03 22:41:45,721:INFO:Uploading model into container now
2023-01-03 22:41:45,722:INFO:_master_model_container: 4
2023-01-03 22:41:45,722:INFO:_display_container: 2
2023-01-03 22:41:45,722:INFO:ElasticNet(random_state=123)
2023-01-03 22:41:45,722:INFO:create_model() successfully completed......................................
2023-01-03 22:41:45,821:INFO:SubProcess create_model() end ==================================
2023-01-03 22:41:45,821:INFO:Creating metrics dataframe
2023-01-03 22:41:45,834:INFO:Initializing Least Angle Regression
2023-01-03 22:41:45,834:INFO:Total runtime is 0.14003641208012899 minutes
2023-01-03 22:41:45,838:INFO:SubProcess create_model() called ==================================
2023-01-03 22:41:45,838:INFO:Initializing create_model()
2023-01-03 22:41:45,839:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F1D9C8C940>, estimator=lar, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F1DF97AFD0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:41:45,839:INFO:Checking exceptions
2023-01-03 22:41:45,839:INFO:Importing libraries
2023-01-03 22:41:45,839:INFO:Copying training dataset
2023-01-03 22:41:45,849:INFO:Defining folds
2023-01-03 22:41:45,850:INFO:Declaring metric variables
2023-01-03 22:41:45,854:INFO:Importing untrained model
2023-01-03 22:41:45,858:INFO:Least Angle Regression Imported successfully
2023-01-03 22:41:45,867:INFO:Starting cross validation
2023-01-03 22:41:45,868:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:41:45,973:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 22:41:46,003:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 22:41:46,010:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 22:41:46,027:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 22:41:46,075:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 22:41:46,206:INFO:Calculating mean and std
2023-01-03 22:41:46,208:INFO:Creating metrics dataframe
2023-01-03 22:41:46,211:INFO:Uploading results into container
2023-01-03 22:41:46,211:INFO:Uploading model into container now
2023-01-03 22:41:46,212:INFO:_master_model_container: 5
2023-01-03 22:41:46,212:INFO:_display_container: 2
2023-01-03 22:41:46,212:INFO:Lars(random_state=123)
2023-01-03 22:41:46,212:INFO:create_model() successfully completed......................................
2023-01-03 22:41:46,308:INFO:SubProcess create_model() end ==================================
2023-01-03 22:41:46,309:INFO:Creating metrics dataframe
2023-01-03 22:41:46,323:INFO:Initializing Lasso Least Angle Regression
2023-01-03 22:41:46,323:INFO:Total runtime is 0.14818716843922933 minutes
2023-01-03 22:41:46,328:INFO:SubProcess create_model() called ==================================
2023-01-03 22:41:46,328:INFO:Initializing create_model()
2023-01-03 22:41:46,328:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F1D9C8C940>, estimator=llar, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F1DF97AFD0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:41:46,328:INFO:Checking exceptions
2023-01-03 22:41:46,328:INFO:Importing libraries
2023-01-03 22:41:46,328:INFO:Copying training dataset
2023-01-03 22:41:46,339:INFO:Defining folds
2023-01-03 22:41:46,339:INFO:Declaring metric variables
2023-01-03 22:41:46,344:INFO:Importing untrained model
2023-01-03 22:41:46,348:INFO:Lasso Least Angle Regression Imported successfully
2023-01-03 22:41:46,357:INFO:Starting cross validation
2023-01-03 22:41:46,358:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:41:46,429:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-03 22:41:46,432:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-03 22:41:46,434:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-03 22:41:46,455:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-03 22:41:46,494:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-03 22:41:46,619:INFO:Calculating mean and std
2023-01-03 22:41:46,621:INFO:Creating metrics dataframe
2023-01-03 22:41:46,624:INFO:Uploading results into container
2023-01-03 22:41:46,624:INFO:Uploading model into container now
2023-01-03 22:41:46,625:INFO:_master_model_container: 6
2023-01-03 22:41:46,625:INFO:_display_container: 2
2023-01-03 22:41:46,625:INFO:LassoLars(random_state=123)
2023-01-03 22:41:46,626:INFO:create_model() successfully completed......................................
2023-01-03 22:41:46,726:INFO:SubProcess create_model() end ==================================
2023-01-03 22:41:46,726:INFO:Creating metrics dataframe
2023-01-03 22:41:46,736:INFO:Initializing Orthogonal Matching Pursuit
2023-01-03 22:41:46,736:INFO:Total runtime is 0.1550678292910258 minutes
2023-01-03 22:41:46,740:INFO:SubProcess create_model() called ==================================
2023-01-03 22:41:46,740:INFO:Initializing create_model()
2023-01-03 22:41:46,740:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F1D9C8C940>, estimator=omp, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F1DF97AFD0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:41:46,741:INFO:Checking exceptions
2023-01-03 22:41:46,741:INFO:Importing libraries
2023-01-03 22:41:46,741:INFO:Copying training dataset
2023-01-03 22:41:46,750:INFO:Defining folds
2023-01-03 22:41:46,751:INFO:Declaring metric variables
2023-01-03 22:41:46,755:INFO:Importing untrained model
2023-01-03 22:41:46,760:INFO:Orthogonal Matching Pursuit Imported successfully
2023-01-03 22:41:46,769:INFO:Starting cross validation
2023-01-03 22:41:46,771:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:41:46,845:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 22:41:46,846:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 22:41:46,850:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 22:41:46,852:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 22:41:46,902:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 22:41:47,031:INFO:Calculating mean and std
2023-01-03 22:41:47,033:INFO:Creating metrics dataframe
2023-01-03 22:41:47,036:INFO:Uploading results into container
2023-01-03 22:41:47,037:INFO:Uploading model into container now
2023-01-03 22:41:47,038:INFO:_master_model_container: 7
2023-01-03 22:41:47,038:INFO:_display_container: 2
2023-01-03 22:41:47,038:INFO:OrthogonalMatchingPursuit()
2023-01-03 22:41:47,038:INFO:create_model() successfully completed......................................
2023-01-03 22:41:47,142:INFO:SubProcess create_model() end ==================================
2023-01-03 22:41:47,142:INFO:Creating metrics dataframe
2023-01-03 22:41:47,153:INFO:Initializing Bayesian Ridge
2023-01-03 22:41:47,153:INFO:Total runtime is 0.16201194922129314 minutes
2023-01-03 22:41:47,156:INFO:SubProcess create_model() called ==================================
2023-01-03 22:41:47,157:INFO:Initializing create_model()
2023-01-03 22:41:47,157:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F1D9C8C940>, estimator=br, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F1DF97AFD0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:41:47,157:INFO:Checking exceptions
2023-01-03 22:41:47,157:INFO:Importing libraries
2023-01-03 22:41:47,157:INFO:Copying training dataset
2023-01-03 22:41:47,167:INFO:Defining folds
2023-01-03 22:41:47,167:INFO:Declaring metric variables
2023-01-03 22:41:47,170:INFO:Importing untrained model
2023-01-03 22:41:47,175:INFO:Bayesian Ridge Imported successfully
2023-01-03 22:41:47,183:INFO:Starting cross validation
2023-01-03 22:41:47,184:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:41:47,463:INFO:Calculating mean and std
2023-01-03 22:41:47,465:INFO:Creating metrics dataframe
2023-01-03 22:41:47,468:INFO:Uploading results into container
2023-01-03 22:41:47,469:INFO:Uploading model into container now
2023-01-03 22:41:47,470:INFO:_master_model_container: 8
2023-01-03 22:41:47,470:INFO:_display_container: 2
2023-01-03 22:41:47,470:INFO:BayesianRidge()
2023-01-03 22:41:47,471:INFO:create_model() successfully completed......................................
2023-01-03 22:41:47,569:INFO:SubProcess create_model() end ==================================
2023-01-03 22:41:47,569:INFO:Creating metrics dataframe
2023-01-03 22:41:47,582:INFO:Initializing Passive Aggressive Regressor
2023-01-03 22:41:47,582:INFO:Total runtime is 0.16916686296463013 minutes
2023-01-03 22:41:47,586:INFO:SubProcess create_model() called ==================================
2023-01-03 22:41:47,587:INFO:Initializing create_model()
2023-01-03 22:41:47,587:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F1D9C8C940>, estimator=par, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F1DF97AFD0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:41:47,587:INFO:Checking exceptions
2023-01-03 22:41:47,587:INFO:Importing libraries
2023-01-03 22:41:47,587:INFO:Copying training dataset
2023-01-03 22:41:47,597:INFO:Defining folds
2023-01-03 22:41:47,597:INFO:Declaring metric variables
2023-01-03 22:41:47,602:INFO:Importing untrained model
2023-01-03 22:41:47,606:INFO:Passive Aggressive Regressor Imported successfully
2023-01-03 22:41:47,614:INFO:Starting cross validation
2023-01-03 22:41:47,616:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:41:47,905:INFO:Calculating mean and std
2023-01-03 22:41:47,907:INFO:Creating metrics dataframe
2023-01-03 22:41:47,910:INFO:Uploading results into container
2023-01-03 22:41:47,911:INFO:Uploading model into container now
2023-01-03 22:41:47,912:INFO:_master_model_container: 9
2023-01-03 22:41:47,912:INFO:_display_container: 2
2023-01-03 22:41:47,912:INFO:PassiveAggressiveRegressor(random_state=123)
2023-01-03 22:41:47,913:INFO:create_model() successfully completed......................................
2023-01-03 22:41:48,011:INFO:SubProcess create_model() end ==================================
2023-01-03 22:41:48,011:INFO:Creating metrics dataframe
2023-01-03 22:41:48,022:INFO:Initializing Huber Regressor
2023-01-03 22:41:48,022:INFO:Total runtime is 0.17650126616160075 minutes
2023-01-03 22:41:48,027:INFO:SubProcess create_model() called ==================================
2023-01-03 22:41:48,027:INFO:Initializing create_model()
2023-01-03 22:41:48,027:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F1D9C8C940>, estimator=huber, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F1DF97AFD0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:41:48,027:INFO:Checking exceptions
2023-01-03 22:41:48,027:INFO:Importing libraries
2023-01-03 22:41:48,027:INFO:Copying training dataset
2023-01-03 22:41:48,038:INFO:Defining folds
2023-01-03 22:41:48,038:INFO:Declaring metric variables
2023-01-03 22:41:48,043:INFO:Importing untrained model
2023-01-03 22:41:48,047:INFO:Huber Regressor Imported successfully
2023-01-03 22:41:48,054:INFO:Starting cross validation
2023-01-03 22:41:48,056:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:41:48,225:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-03 22:41:48,363:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-03 22:41:48,377:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-03 22:41:48,509:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-03 22:41:48,679:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-03 22:41:48,810:INFO:Calculating mean and std
2023-01-03 22:41:48,812:INFO:Creating metrics dataframe
2023-01-03 22:41:48,815:INFO:Uploading results into container
2023-01-03 22:41:48,815:INFO:Uploading model into container now
2023-01-03 22:41:48,815:INFO:_master_model_container: 10
2023-01-03 22:41:48,815:INFO:_display_container: 2
2023-01-03 22:41:48,816:INFO:HuberRegressor()
2023-01-03 22:41:48,816:INFO:create_model() successfully completed......................................
2023-01-03 22:41:48,917:INFO:SubProcess create_model() end ==================================
2023-01-03 22:41:48,917:INFO:Creating metrics dataframe
2023-01-03 22:41:48,931:INFO:Initializing K Neighbors Regressor
2023-01-03 22:41:48,931:INFO:Total runtime is 0.19165708223978678 minutes
2023-01-03 22:41:48,935:INFO:SubProcess create_model() called ==================================
2023-01-03 22:41:48,936:INFO:Initializing create_model()
2023-01-03 22:41:48,936:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F1D9C8C940>, estimator=knn, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F1DF97AFD0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:41:48,936:INFO:Checking exceptions
2023-01-03 22:41:48,936:INFO:Importing libraries
2023-01-03 22:41:48,936:INFO:Copying training dataset
2023-01-03 22:41:48,947:INFO:Defining folds
2023-01-03 22:41:48,947:INFO:Declaring metric variables
2023-01-03 22:41:48,950:INFO:Importing untrained model
2023-01-03 22:41:48,955:INFO:K Neighbors Regressor Imported successfully
2023-01-03 22:41:48,963:INFO:Starting cross validation
2023-01-03 22:41:48,964:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:41:49,631:INFO:Calculating mean and std
2023-01-03 22:41:49,633:INFO:Creating metrics dataframe
2023-01-03 22:41:49,637:INFO:Uploading results into container
2023-01-03 22:41:49,637:INFO:Uploading model into container now
2023-01-03 22:41:49,638:INFO:_master_model_container: 11
2023-01-03 22:41:49,638:INFO:_display_container: 2
2023-01-03 22:41:49,638:INFO:KNeighborsRegressor(n_jobs=-1)
2023-01-03 22:41:49,638:INFO:create_model() successfully completed......................................
2023-01-03 22:41:49,740:INFO:SubProcess create_model() end ==================================
2023-01-03 22:41:49,740:INFO:Creating metrics dataframe
2023-01-03 22:41:49,752:INFO:Initializing Decision Tree Regressor
2023-01-03 22:41:49,752:INFO:Total runtime is 0.20534354448318481 minutes
2023-01-03 22:41:49,756:INFO:SubProcess create_model() called ==================================
2023-01-03 22:41:49,757:INFO:Initializing create_model()
2023-01-03 22:41:49,757:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F1D9C8C940>, estimator=dt, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F1DF97AFD0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:41:49,757:INFO:Checking exceptions
2023-01-03 22:41:49,757:INFO:Importing libraries
2023-01-03 22:41:49,757:INFO:Copying training dataset
2023-01-03 22:41:49,767:INFO:Defining folds
2023-01-03 22:41:49,768:INFO:Declaring metric variables
2023-01-03 22:41:49,772:INFO:Importing untrained model
2023-01-03 22:41:49,777:INFO:Decision Tree Regressor Imported successfully
2023-01-03 22:41:49,784:INFO:Starting cross validation
2023-01-03 22:41:49,786:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:41:50,282:INFO:Calculating mean and std
2023-01-03 22:41:50,284:INFO:Creating metrics dataframe
2023-01-03 22:41:50,287:INFO:Uploading results into container
2023-01-03 22:41:50,287:INFO:Uploading model into container now
2023-01-03 22:41:50,287:INFO:_master_model_container: 12
2023-01-03 22:41:50,287:INFO:_display_container: 2
2023-01-03 22:41:50,288:INFO:DecisionTreeRegressor(random_state=123)
2023-01-03 22:41:50,288:INFO:create_model() successfully completed......................................
2023-01-03 22:41:50,386:INFO:SubProcess create_model() end ==================================
2023-01-03 22:41:50,387:INFO:Creating metrics dataframe
2023-01-03 22:41:50,401:INFO:Initializing Random Forest Regressor
2023-01-03 22:41:50,401:INFO:Total runtime is 0.21615725358327229 minutes
2023-01-03 22:41:50,405:INFO:SubProcess create_model() called ==================================
2023-01-03 22:41:50,406:INFO:Initializing create_model()
2023-01-03 22:41:50,406:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F1D9C8C940>, estimator=rf, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F1DF97AFD0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:41:50,406:INFO:Checking exceptions
2023-01-03 22:41:50,406:INFO:Importing libraries
2023-01-03 22:41:50,406:INFO:Copying training dataset
2023-01-03 22:41:50,416:INFO:Defining folds
2023-01-03 22:41:50,416:INFO:Declaring metric variables
2023-01-03 22:41:50,421:INFO:Importing untrained model
2023-01-03 22:41:50,425:INFO:Random Forest Regressor Imported successfully
2023-01-03 22:41:50,433:INFO:Starting cross validation
2023-01-03 22:41:50,434:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:42:00,310:INFO:Calculating mean and std
2023-01-03 22:42:00,312:INFO:Creating metrics dataframe
2023-01-03 22:42:00,315:INFO:Uploading results into container
2023-01-03 22:42:00,315:INFO:Uploading model into container now
2023-01-03 22:42:00,315:INFO:_master_model_container: 13
2023-01-03 22:42:00,315:INFO:_display_container: 2
2023-01-03 22:42:00,316:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-01-03 22:42:00,316:INFO:create_model() successfully completed......................................
2023-01-03 22:42:00,413:INFO:SubProcess create_model() end ==================================
2023-01-03 22:42:00,414:INFO:Creating metrics dataframe
2023-01-03 22:42:00,431:INFO:Initializing Extra Trees Regressor
2023-01-03 22:42:00,431:INFO:Total runtime is 0.38332665761311846 minutes
2023-01-03 22:42:00,435:INFO:SubProcess create_model() called ==================================
2023-01-03 22:42:00,436:INFO:Initializing create_model()
2023-01-03 22:42:00,436:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F1D9C8C940>, estimator=et, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F1DF97AFD0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:42:00,436:INFO:Checking exceptions
2023-01-03 22:42:00,436:INFO:Importing libraries
2023-01-03 22:42:00,436:INFO:Copying training dataset
2023-01-03 22:42:00,447:INFO:Defining folds
2023-01-03 22:42:00,447:INFO:Declaring metric variables
2023-01-03 22:42:00,452:INFO:Importing untrained model
2023-01-03 22:42:00,456:INFO:Extra Trees Regressor Imported successfully
2023-01-03 22:42:00,463:INFO:Starting cross validation
2023-01-03 22:42:00,464:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:42:04,875:INFO:Calculating mean and std
2023-01-03 22:42:04,877:INFO:Creating metrics dataframe
2023-01-03 22:42:04,881:INFO:Uploading results into container
2023-01-03 22:42:04,882:INFO:Uploading model into container now
2023-01-03 22:42:04,882:INFO:_master_model_container: 14
2023-01-03 22:42:04,883:INFO:_display_container: 2
2023-01-03 22:42:04,883:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-01-03 22:42:04,883:INFO:create_model() successfully completed......................................
2023-01-03 22:42:04,994:INFO:SubProcess create_model() end ==================================
2023-01-03 22:42:04,994:INFO:Creating metrics dataframe
2023-01-03 22:42:05,006:INFO:Initializing AdaBoost Regressor
2023-01-03 22:42:05,006:INFO:Total runtime is 0.4595763405164083 minutes
2023-01-03 22:42:05,010:INFO:SubProcess create_model() called ==================================
2023-01-03 22:42:05,011:INFO:Initializing create_model()
2023-01-03 22:42:05,011:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F1D9C8C940>, estimator=ada, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F1DF97AFD0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:42:05,011:INFO:Checking exceptions
2023-01-03 22:42:05,011:INFO:Importing libraries
2023-01-03 22:42:05,011:INFO:Copying training dataset
2023-01-03 22:42:05,020:INFO:Defining folds
2023-01-03 22:42:05,020:INFO:Declaring metric variables
2023-01-03 22:42:05,025:INFO:Importing untrained model
2023-01-03 22:42:05,029:INFO:AdaBoost Regressor Imported successfully
2023-01-03 22:42:05,036:INFO:Starting cross validation
2023-01-03 22:42:05,037:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:42:06,903:INFO:Calculating mean and std
2023-01-03 22:42:06,905:INFO:Creating metrics dataframe
2023-01-03 22:42:06,908:INFO:Uploading results into container
2023-01-03 22:42:06,908:INFO:Uploading model into container now
2023-01-03 22:42:06,909:INFO:_master_model_container: 15
2023-01-03 22:42:06,910:INFO:_display_container: 2
2023-01-03 22:42:06,910:INFO:AdaBoostRegressor(random_state=123)
2023-01-03 22:42:06,910:INFO:create_model() successfully completed......................................
2023-01-03 22:42:07,010:INFO:SubProcess create_model() end ==================================
2023-01-03 22:42:07,010:INFO:Creating metrics dataframe
2023-01-03 22:42:07,022:INFO:Initializing Gradient Boosting Regressor
2023-01-03 22:42:07,022:INFO:Total runtime is 0.4931659897168477 minutes
2023-01-03 22:42:07,027:INFO:SubProcess create_model() called ==================================
2023-01-03 22:42:07,027:INFO:Initializing create_model()
2023-01-03 22:42:07,027:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F1D9C8C940>, estimator=gbr, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F1DF97AFD0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:42:07,027:INFO:Checking exceptions
2023-01-03 22:42:07,027:INFO:Importing libraries
2023-01-03 22:42:07,027:INFO:Copying training dataset
2023-01-03 22:42:07,036:INFO:Defining folds
2023-01-03 22:42:07,037:INFO:Declaring metric variables
2023-01-03 22:42:07,041:INFO:Importing untrained model
2023-01-03 22:42:07,046:INFO:Gradient Boosting Regressor Imported successfully
2023-01-03 22:42:07,053:INFO:Starting cross validation
2023-01-03 22:42:07,054:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:42:12,413:INFO:Calculating mean and std
2023-01-03 22:42:12,415:INFO:Creating metrics dataframe
2023-01-03 22:42:12,417:INFO:Uploading results into container
2023-01-03 22:42:12,418:INFO:Uploading model into container now
2023-01-03 22:42:12,418:INFO:_master_model_container: 16
2023-01-03 22:42:12,418:INFO:_display_container: 2
2023-01-03 22:42:12,419:INFO:GradientBoostingRegressor(random_state=123)
2023-01-03 22:42:12,419:INFO:create_model() successfully completed......................................
2023-01-03 22:42:12,517:INFO:SubProcess create_model() end ==================================
2023-01-03 22:42:12,517:INFO:Creating metrics dataframe
2023-01-03 22:42:12,534:INFO:Initializing Light Gradient Boosting Machine
2023-01-03 22:42:12,534:INFO:Total runtime is 0.5850420236587525 minutes
2023-01-03 22:42:12,538:INFO:SubProcess create_model() called ==================================
2023-01-03 22:42:12,538:INFO:Initializing create_model()
2023-01-03 22:42:12,539:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F1D9C8C940>, estimator=lightgbm, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F1DF97AFD0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:42:12,539:INFO:Checking exceptions
2023-01-03 22:42:12,539:INFO:Importing libraries
2023-01-03 22:42:12,539:INFO:Copying training dataset
2023-01-03 22:42:12,549:INFO:Defining folds
2023-01-03 22:42:12,549:INFO:Declaring metric variables
2023-01-03 22:42:12,552:INFO:Importing untrained model
2023-01-03 22:42:12,557:INFO:Light Gradient Boosting Machine Imported successfully
2023-01-03 22:42:12,565:INFO:Starting cross validation
2023-01-03 22:42:12,566:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:42:14,988:INFO:Calculating mean and std
2023-01-03 22:42:14,990:INFO:Creating metrics dataframe
2023-01-03 22:42:14,993:INFO:Uploading results into container
2023-01-03 22:42:14,994:INFO:Uploading model into container now
2023-01-03 22:42:14,995:INFO:_master_model_container: 17
2023-01-03 22:42:14,995:INFO:_display_container: 2
2023-01-03 22:42:14,996:INFO:LGBMRegressor(random_state=123)
2023-01-03 22:42:14,996:INFO:create_model() successfully completed......................................
2023-01-03 22:42:15,100:INFO:SubProcess create_model() end ==================================
2023-01-03 22:42:15,100:INFO:Creating metrics dataframe
2023-01-03 22:42:15,113:INFO:Initializing Dummy Regressor
2023-01-03 22:42:15,114:INFO:Total runtime is 0.6280420541763306 minutes
2023-01-03 22:42:15,118:INFO:SubProcess create_model() called ==================================
2023-01-03 22:42:15,118:INFO:Initializing create_model()
2023-01-03 22:42:15,118:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F1D9C8C940>, estimator=dummy, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F1DF97AFD0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:42:15,118:INFO:Checking exceptions
2023-01-03 22:42:15,118:INFO:Importing libraries
2023-01-03 22:42:15,118:INFO:Copying training dataset
2023-01-03 22:42:15,128:INFO:Defining folds
2023-01-03 22:42:15,128:INFO:Declaring metric variables
2023-01-03 22:42:15,133:INFO:Importing untrained model
2023-01-03 22:42:15,137:INFO:Dummy Regressor Imported successfully
2023-01-03 22:42:15,145:INFO:Starting cross validation
2023-01-03 22:42:15,146:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:42:15,412:INFO:Calculating mean and std
2023-01-03 22:42:15,414:INFO:Creating metrics dataframe
2023-01-03 22:42:15,417:INFO:Uploading results into container
2023-01-03 22:42:15,417:INFO:Uploading model into container now
2023-01-03 22:42:15,417:INFO:_master_model_container: 18
2023-01-03 22:42:15,417:INFO:_display_container: 2
2023-01-03 22:42:15,418:INFO:DummyRegressor()
2023-01-03 22:42:15,418:INFO:create_model() successfully completed......................................
2023-01-03 22:42:15,517:INFO:SubProcess create_model() end ==================================
2023-01-03 22:42:15,517:INFO:Creating metrics dataframe
2023-01-03 22:42:15,544:INFO:Initializing create_model()
2023-01-03 22:42:15,545:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F1D9C8C940>, estimator=LGBMRegressor(random_state=123), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:42:15,545:INFO:Checking exceptions
2023-01-03 22:42:15,547:INFO:Importing libraries
2023-01-03 22:42:15,547:INFO:Copying training dataset
2023-01-03 22:42:15,557:INFO:Defining folds
2023-01-03 22:42:15,557:INFO:Declaring metric variables
2023-01-03 22:42:15,557:INFO:Importing untrained model
2023-01-03 22:42:15,557:INFO:Declaring custom model
2023-01-03 22:42:15,558:INFO:Light Gradient Boosting Machine Imported successfully
2023-01-03 22:42:15,559:INFO:Cross validation set to False
2023-01-03 22:42:15,559:INFO:Fitting Model
2023-01-03 22:42:15,876:INFO:LGBMRegressor(random_state=123)
2023-01-03 22:42:15,876:INFO:create_model() successfully completed......................................
2023-01-03 22:42:16,016:INFO:_master_model_container: 18
2023-01-03 22:42:16,017:INFO:_display_container: 2
2023-01-03 22:42:16,017:INFO:LGBMRegressor(random_state=123)
2023-01-03 22:42:16,017:INFO:compare_models() successfully completed......................................
2023-01-03 22:42:16,018:INFO:Initializing tune_model()
2023-01-03 22:42:16,018:INFO:tune_model(estimator=LGBMRegressor(random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=MAE, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F1D9C8C940>)
2023-01-03 22:42:16,018:INFO:Checking exceptions
2023-01-03 22:42:16,052:INFO:Copying training dataset
2023-01-03 22:42:16,062:INFO:Checking base model
2023-01-03 22:42:16,062:INFO:Base model : Light Gradient Boosting Machine
2023-01-03 22:42:16,067:INFO:Declaring metric variables
2023-01-03 22:42:16,072:INFO:Defining Hyperparameters
2023-01-03 22:42:16,196:INFO:Tuning with n_jobs=-1
2023-01-03 22:42:16,197:INFO:Initializing RandomizedSearchCV
2023-01-03 22:42:22,729:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2023-01-03 22:42:22,730:INFO:Hyperparameter search completed
2023-01-03 22:42:22,730:INFO:SubProcess create_model() called ==================================
2023-01-03 22:42:22,731:INFO:Initializing create_model()
2023-01-03 22:42:22,731:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F1D9C8C940>, estimator=LGBMRegressor(random_state=123), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F1DD40A8B0>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2023-01-03 22:42:22,731:INFO:Checking exceptions
2023-01-03 22:42:22,731:INFO:Importing libraries
2023-01-03 22:42:22,731:INFO:Copying training dataset
2023-01-03 22:42:22,742:INFO:Defining folds
2023-01-03 22:42:22,742:INFO:Declaring metric variables
2023-01-03 22:42:22,746:INFO:Importing untrained model
2023-01-03 22:42:22,747:INFO:Declaring custom model
2023-01-03 22:42:22,752:INFO:Light Gradient Boosting Machine Imported successfully
2023-01-03 22:42:22,759:INFO:Starting cross validation
2023-01-03 22:42:22,762:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:42:24,327:INFO:Calculating mean and std
2023-01-03 22:42:24,329:INFO:Creating metrics dataframe
2023-01-03 22:42:24,334:INFO:Finalizing model
2023-01-03 22:42:24,917:INFO:Uploading results into container
2023-01-03 22:42:24,918:INFO:Uploading model into container now
2023-01-03 22:42:24,919:INFO:_master_model_container: 19
2023-01-03 22:42:24,919:INFO:_display_container: 3
2023-01-03 22:42:24,920:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              num_leaves=70, random_state=123, reg_alpha=2, reg_lambda=3)
2023-01-03 22:42:24,920:INFO:create_model() successfully completed......................................
2023-01-03 22:42:25,028:INFO:SubProcess create_model() end ==================================
2023-01-03 22:42:25,028:INFO:choose_better activated
2023-01-03 22:42:25,031:INFO:SubProcess create_model() called ==================================
2023-01-03 22:42:25,032:INFO:Initializing create_model()
2023-01-03 22:42:25,032:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F1D9C8C940>, estimator=LGBMRegressor(random_state=123), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:42:25,032:INFO:Checking exceptions
2023-01-03 22:42:25,034:INFO:Importing libraries
2023-01-03 22:42:25,034:INFO:Copying training dataset
2023-01-03 22:42:25,042:INFO:Defining folds
2023-01-03 22:42:25,042:INFO:Declaring metric variables
2023-01-03 22:42:25,042:INFO:Importing untrained model
2023-01-03 22:42:25,043:INFO:Declaring custom model
2023-01-03 22:42:25,044:INFO:Light Gradient Boosting Machine Imported successfully
2023-01-03 22:42:25,045:INFO:Starting cross validation
2023-01-03 22:42:25,046:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:42:26,372:INFO:Calculating mean and std
2023-01-03 22:42:26,373:INFO:Creating metrics dataframe
2023-01-03 22:42:26,375:INFO:Finalizing model
2023-01-03 22:42:26,666:INFO:Uploading results into container
2023-01-03 22:42:26,666:INFO:Uploading model into container now
2023-01-03 22:42:26,667:INFO:_master_model_container: 20
2023-01-03 22:42:26,667:INFO:_display_container: 4
2023-01-03 22:42:26,667:INFO:LGBMRegressor(random_state=123)
2023-01-03 22:42:26,667:INFO:create_model() successfully completed......................................
2023-01-03 22:42:26,772:INFO:SubProcess create_model() end ==================================
2023-01-03 22:42:26,773:INFO:LGBMRegressor(random_state=123) result for MAE is 2.2482
2023-01-03 22:42:26,773:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              num_leaves=70, random_state=123, reg_alpha=2, reg_lambda=3) result for MAE is 2.737
2023-01-03 22:42:26,774:INFO:LGBMRegressor(random_state=123) is best model
2023-01-03 22:42:26,774:INFO:choose_better completed
2023-01-03 22:42:26,774:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-01-03 22:42:26,783:INFO:_master_model_container: 20
2023-01-03 22:42:26,783:INFO:_display_container: 3
2023-01-03 22:42:26,784:INFO:LGBMRegressor(random_state=123)
2023-01-03 22:42:26,784:INFO:tune_model() successfully completed......................................
2023-01-03 22:42:26,901:INFO:Initializing plot_model()
2023-01-03 22:42:26,901:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LGBMRegressor(random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F1D9C8C940>, system=True)
2023-01-03 22:42:26,901:INFO:Checking exceptions
2023-01-03 22:42:26,908:INFO:Preloading libraries
2023-01-03 22:42:26,915:INFO:Copying training dataset
2023-01-03 22:42:26,915:INFO:Plot type: error
2023-01-03 22:42:27,169:INFO:Fitting Model
2023-01-03 22:42:27,169:INFO:Scoring test/hold-out set
2023-01-03 22:42:27,634:INFO:Visual Rendered Successfully
2023-01-03 22:42:27,751:INFO:plot_model() successfully completed......................................
2023-01-03 22:42:27,752:INFO:Initializing predict_model()
2023-01-03 22:42:27,753:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F1D9C8C940>, estimator=LGBMRegressor(random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001F1E37A5310>)
2023-01-03 22:42:27,753:INFO:Checking exceptions
2023-01-03 22:42:27,753:INFO:Preloading libraries
2023-01-03 22:42:27,937:INFO:Initializing finalize_model()
2023-01-03 22:42:27,937:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F1D9C8C940>, estimator=LGBMRegressor(random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-01-03 22:42:27,938:INFO:Finalizing LGBMRegressor(random_state=123)
2023-01-03 22:42:27,946:INFO:Initializing create_model()
2023-01-03 22:42:27,946:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F1D9C8C940>, estimator=LGBMRegressor(random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-01-03 22:42:27,946:INFO:Checking exceptions
2023-01-03 22:42:27,948:INFO:Importing libraries
2023-01-03 22:42:27,948:INFO:Copying training dataset
2023-01-03 22:42:27,949:INFO:Defining folds
2023-01-03 22:42:27,949:INFO:Declaring metric variables
2023-01-03 22:42:27,949:INFO:Importing untrained model
2023-01-03 22:42:27,949:INFO:Declaring custom model
2023-01-03 22:42:27,950:INFO:Light Gradient Boosting Machine Imported successfully
2023-01-03 22:42:27,951:INFO:Cross validation set to False
2023-01-03 22:42:27,951:INFO:Fitting Model
2023-01-03 22:42:29,038:INFO:Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator', LGBMRegressor(random_state=123))])
2023-01-03 22:42:29,039:INFO:create_model() successfully completed......................................
2023-01-03 22:42:29,146:INFO:_master_model_container: 20
2023-01-03 22:42:29,146:INFO:_display_container: 4
2023-01-03 22:42:29,153:INFO:Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator', LGBMRegressor(random_state=123))])
2023-01-03 22:42:29,153:INFO:finalize_model() successfully completed......................................
2023-01-03 22:42:29,262:INFO:Initializing predict_model()
2023-01-03 22:42:29,262:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F1D9C8C940>, estimator=Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator', LGBMRegressor(random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001F1E119CA60>)
2023-01-03 22:42:29,262:INFO:Checking exceptions
2023-01-03 22:42:29,263:INFO:Preloading libraries
2023-01-03 22:42:29,265:INFO:Set up data.
2023-01-03 22:42:29,280:INFO:Set up index.
2023-01-03 22:42:29,795:INFO:Initializing save_model()
2023-01-03 22:42:29,795:INFO:save_model(model=Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator', LGBMRegressor(random_state=123))]), model_name=c:\Users\Kodotautas\Desktop\Data_science\7_TIME_SERIES_FORECAST_PYCARET/models/final_model.pkl, prep_pipe_=Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-01-03 22:42:29,796:INFO:Adding model into prep_pipe
2023-01-03 22:42:29,805:WARNING:Only Model saved as it was a pipeline.
2023-01-03 22:42:29,825:INFO:c:\Users\Kodotautas\Desktop\Data_science\7_TIME_SERIES_FORECAST_PYCARET/models/final_model.pkl.pkl saved in current working directory
2023-01-03 22:42:29,836:INFO:Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator', LGBMRegressor(random_state=123))])
2023-01-03 22:42:29,836:INFO:save_model() successfully completed......................................
2023-01-03 22:46:54,325:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-01-03 22:46:54,325:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-01-03 22:46:54,325:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-01-03 22:46:54,325:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-01-03 22:46:55,435:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-01-03 22:46:56,227:INFO:PyCaret RegressionExperiment
2023-01-03 22:46:56,227:INFO:Logging name: reg-default-name
2023-01-03 22:46:56,227:INFO:ML Usecase: MLUsecase.REGRESSION
2023-01-03 22:46:56,227:INFO:version 3.0.0.rc6
2023-01-03 22:46:56,227:INFO:Initializing setup()
2023-01-03 22:46:56,227:INFO:self.USI: f822
2023-01-03 22:46:56,227:INFO:self._variable_keys: {'idx', 'pipeline', 'gpu_param', 'memory', 'X', 'data', 'gpu_n_jobs_param', 'y_test', 'exp_id', 'seed', 'html_param', 'fold_shuffle_param', 'logging_param', 'X_test', 'target_param', 'USI', 'exp_name_log', 'fold_generator', 'y_train', 'fold_groups_param', 'transform_target_param', 'n_jobs_param', 'y', '_ml_usecase', '_available_plots', 'X_train', 'log_plots_param'}
2023-01-03 22:46:56,227:INFO:Checking environment
2023-01-03 22:46:56,227:INFO:python_version: 3.9.13
2023-01-03 22:46:56,227:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-01-03 22:46:56,227:INFO:machine: AMD64
2023-01-03 22:46:56,228:INFO:platform: Windows-10-10.0.19044-SP0
2023-01-03 22:46:56,228:INFO:Memory: svmem(total=17114804224, available=9928044544, percent=42.0, used=7186759680, free=9928044544)
2023-01-03 22:46:56,228:INFO:Physical Core: 4
2023-01-03 22:46:56,228:INFO:Logical Core: 4
2023-01-03 22:46:56,228:INFO:Checking libraries
2023-01-03 22:46:56,228:INFO:System:
2023-01-03 22:46:56,228:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-01-03 22:46:56,228:INFO:executable: c:\Users\Kodotautas\anaconda3\python.exe
2023-01-03 22:46:56,228:INFO:   machine: Windows-10-10.0.19044-SP0
2023-01-03 22:46:56,228:INFO:PyCaret required dependencies:
2023-01-03 22:46:56,228:INFO:                 pip: 22.2.2
2023-01-03 22:46:56,228:INFO:          setuptools: 63.4.1
2023-01-03 22:46:56,228:INFO:             pycaret: 3.0.0rc6
2023-01-03 22:46:56,228:INFO:             IPython: 7.31.1
2023-01-03 22:46:56,228:INFO:          ipywidgets: 7.6.5
2023-01-03 22:46:56,228:INFO:                tqdm: 4.64.1
2023-01-03 22:46:56,228:INFO:               numpy: 1.21.5
2023-01-03 22:46:56,228:INFO:              pandas: 1.4.4
2023-01-03 22:46:56,228:INFO:              jinja2: 2.11.3
2023-01-03 22:46:56,229:INFO:               scipy: 1.9.1
2023-01-03 22:46:56,229:INFO:              joblib: 1.2.0
2023-01-03 22:46:56,229:INFO:             sklearn: 1.0.2
2023-01-03 22:46:56,229:INFO:                pyod: 1.0.7
2023-01-03 22:46:56,229:INFO:            imblearn: 0.10.1
2023-01-03 22:46:56,229:INFO:   category_encoders: 2.5.1.post0
2023-01-03 22:46:56,229:INFO:            lightgbm: 3.3.3
2023-01-03 22:46:56,229:INFO:               numba: 0.55.1
2023-01-03 22:46:56,229:INFO:            requests: 2.28.1
2023-01-03 22:46:56,229:INFO:          matplotlib: 3.5.2
2023-01-03 22:46:56,229:INFO:          scikitplot: 0.3.7
2023-01-03 22:46:56,229:INFO:         yellowbrick: 1.5
2023-01-03 22:46:56,229:INFO:              plotly: 5.9.0
2023-01-03 22:46:56,229:INFO:             kaleido: 0.2.1
2023-01-03 22:46:56,229:INFO:         statsmodels: 0.13.2
2023-01-03 22:46:56,229:INFO:              sktime: 0.14.1
2023-01-03 22:46:56,229:INFO:               tbats: 1.1.2
2023-01-03 22:46:56,229:INFO:            pmdarima: 2.0.2
2023-01-03 22:46:56,229:INFO:              psutil: 5.9.0
2023-01-03 22:46:56,229:INFO:PyCaret optional dependencies:
2023-01-03 22:46:56,665:INFO:                shap: 0.41.0
2023-01-03 22:46:56,665:INFO:           interpret: Not installed
2023-01-03 22:46:56,665:INFO:                umap: Not installed
2023-01-03 22:46:56,665:INFO:    pandas_profiling: Not installed
2023-01-03 22:46:56,665:INFO:  explainerdashboard: Not installed
2023-01-03 22:46:56,665:INFO:             autoviz: Not installed
2023-01-03 22:46:56,665:INFO:           fairlearn: Not installed
2023-01-03 22:46:56,665:INFO:             xgboost: Not installed
2023-01-03 22:46:56,665:INFO:            catboost: Not installed
2023-01-03 22:46:56,665:INFO:              kmodes: Not installed
2023-01-03 22:46:56,665:INFO:             mlxtend: Not installed
2023-01-03 22:46:56,665:INFO:       statsforecast: Not installed
2023-01-03 22:46:56,666:INFO:        tune_sklearn: 0.4.3
2023-01-03 22:46:56,666:INFO:                 ray: 2.0.0
2023-01-03 22:46:56,666:INFO:            hyperopt: 0.2.7
2023-01-03 22:46:56,666:INFO:              optuna: 3.0.1
2023-01-03 22:46:56,666:INFO:               skopt: 0.9.0
2023-01-03 22:46:56,666:INFO:              mlflow: Not installed
2023-01-03 22:46:56,666:INFO:              gradio: Not installed
2023-01-03 22:46:56,666:INFO:             fastapi: 0.88.0
2023-01-03 22:46:56,666:INFO:             uvicorn: 0.20.0
2023-01-03 22:46:56,666:INFO:              m2cgen: Not installed
2023-01-03 22:46:56,666:INFO:           evidently: Not installed
2023-01-03 22:46:56,666:INFO:                nltk: 3.7
2023-01-03 22:46:56,666:INFO:            pyLDAvis: Not installed
2023-01-03 22:46:56,666:INFO:              gensim: 4.1.2
2023-01-03 22:46:56,666:INFO:               spacy: 3.4.2
2023-01-03 22:46:56,666:INFO:           wordcloud: Not installed
2023-01-03 22:46:56,666:INFO:            textblob: Not installed
2023-01-03 22:46:56,666:INFO:               fugue: Not installed
2023-01-03 22:46:56,666:INFO:           streamlit: Not installed
2023-01-03 22:46:56,666:INFO:             prophet: Not installed
2023-01-03 22:46:56,666:INFO:None
2023-01-03 22:46:56,666:INFO:Set up data.
2023-01-03 22:46:56,695:INFO:Set up train/test split.
2023-01-03 22:46:56,710:INFO:Set up index.
2023-01-03 22:46:56,712:INFO:Set up folding strategy.
2023-01-03 22:46:56,712:INFO:Assigning column types.
2023-01-03 22:46:56,726:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-01-03 22:46:56,726:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-01-03 22:46:56,731:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-03 22:46:56,737:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 22:46:56,815:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 22:46:56,867:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 22:46:56,868:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:46:57,034:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:46:57,035:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-01-03 22:46:57,040:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-03 22:46:57,045:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 22:46:57,119:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 22:46:57,172:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 22:46:57,173:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:46:57,174:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:46:57,174:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-01-03 22:46:57,179:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-03 22:46:57,184:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 22:46:57,258:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 22:46:57,309:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 22:46:57,310:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:46:57,310:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:46:57,315:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-03 22:46:57,320:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 22:46:57,391:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 22:46:57,441:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 22:46:57,441:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:46:57,442:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:46:57,442:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-01-03 22:46:57,452:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 22:46:57,525:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 22:46:57,576:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 22:46:57,576:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:46:57,577:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:46:57,587:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 22:46:57,660:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 22:46:57,709:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 22:46:57,710:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:46:57,710:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:46:57,711:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-01-03 22:46:57,794:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 22:46:57,845:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 22:46:57,846:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:46:57,846:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:46:57,927:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 22:46:57,977:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 22:46:57,977:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:46:57,977:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:46:57,978:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-01-03 22:46:58,060:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 22:46:58,110:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:46:58,110:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:46:58,192:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 22:46:58,242:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:46:58,242:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:46:58,242:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-01-03 22:46:58,377:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:46:58,378:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:46:58,519:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:46:58,519:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:46:58,520:INFO:Preparing preprocessing pipeline...
2023-01-03 22:46:58,522:INFO:Set up simple imputation.
2023-01-03 22:46:58,522:INFO:Set up column transformation.
2023-01-03 22:46:58,522:INFO:Set up feature normalization.
2023-01-03 22:46:59,185:INFO:Finished creating preprocessing pipeline.
2023-01-03 22:46:59,192:INFO:Pipeline: Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2023-01-03 22:46:59,192:INFO:Creating final display dataframe.
2023-01-03 22:46:59,766:INFO:Setup _display_container:                Description             Value
0               Session id               123
1                   Target        b2b+b2c+vt
2              Target type        Regression
3               Data shape       (10506, 48)
4         Train data shape        (7354, 48)
5          Test data shape        (3152, 48)
6         Numeric features                 8
7               Preprocess              True
8          Imputation type            simple
9       Numeric imputation              mean
10  Categorical imputation              mode
11          Transformation              True
12   Transformation method       yeo-johnson
13               Normalize              True
14        Normalize method            zscore
15          Fold Generator   TimeSeriesSplit
16             Fold Number                 5
17                CPU Jobs                -1
18                 Use GPU             False
19          Log Experiment             False
20         Experiment Name  reg-default-name
21                     USI              f822
2023-01-03 22:46:59,915:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:46:59,916:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:47:00,046:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:47:00,047:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 22:47:00,048:INFO:setup() successfully completed in 3.82s...............
2023-01-03 22:47:00,048:INFO:Initializing compare_models()
2023-01-03 22:47:00,048:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024C56CFB970>, include=None, fold=None, round=4, cross_validation=True, sort=MAE, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x0000024C56CFB970>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'MAE', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-01-03 22:47:00,048:INFO:Checking exceptions
2023-01-03 22:47:00,053:INFO:Preparing display monitor
2023-01-03 22:47:00,095:INFO:Initializing Linear Regression
2023-01-03 22:47:00,096:INFO:Total runtime is 1.6705195109049478e-05 minutes
2023-01-03 22:47:00,100:INFO:SubProcess create_model() called ==================================
2023-01-03 22:47:00,100:INFO:Initializing create_model()
2023-01-03 22:47:00,100:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024C56CFB970>, estimator=lr, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024C62A6DFD0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:47:00,100:INFO:Checking exceptions
2023-01-03 22:47:00,100:INFO:Importing libraries
2023-01-03 22:47:00,100:INFO:Copying training dataset
2023-01-03 22:47:00,111:INFO:Defining folds
2023-01-03 22:47:00,111:INFO:Declaring metric variables
2023-01-03 22:47:00,115:INFO:Importing untrained model
2023-01-03 22:47:00,131:INFO:Linear Regression Imported successfully
2023-01-03 22:47:00,141:INFO:Starting cross validation
2023-01-03 22:47:00,148:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:47:07,998:INFO:Calculating mean and std
2023-01-03 22:47:08,000:INFO:Creating metrics dataframe
2023-01-03 22:47:08,004:INFO:Uploading results into container
2023-01-03 22:47:08,005:INFO:Uploading model into container now
2023-01-03 22:47:08,005:INFO:_master_model_container: 1
2023-01-03 22:47:08,005:INFO:_display_container: 2
2023-01-03 22:47:08,006:INFO:LinearRegression(n_jobs=-1)
2023-01-03 22:47:08,006:INFO:create_model() successfully completed......................................
2023-01-03 22:47:08,109:INFO:SubProcess create_model() end ==================================
2023-01-03 22:47:08,109:INFO:Creating metrics dataframe
2023-01-03 22:47:08,119:INFO:Initializing Lasso Regression
2023-01-03 22:47:08,119:INFO:Total runtime is 0.13373339573542276 minutes
2023-01-03 22:47:08,123:INFO:SubProcess create_model() called ==================================
2023-01-03 22:47:08,124:INFO:Initializing create_model()
2023-01-03 22:47:08,124:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024C56CFB970>, estimator=lasso, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024C62A6DFD0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:47:08,124:INFO:Checking exceptions
2023-01-03 22:47:08,124:INFO:Importing libraries
2023-01-03 22:47:08,124:INFO:Copying training dataset
2023-01-03 22:47:08,133:INFO:Defining folds
2023-01-03 22:47:08,134:INFO:Declaring metric variables
2023-01-03 22:47:08,138:INFO:Importing untrained model
2023-01-03 22:47:08,143:INFO:Lasso Regression Imported successfully
2023-01-03 22:47:08,152:INFO:Starting cross validation
2023-01-03 22:47:08,154:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:47:08,596:INFO:Calculating mean and std
2023-01-03 22:47:08,597:INFO:Creating metrics dataframe
2023-01-03 22:47:08,601:INFO:Uploading results into container
2023-01-03 22:47:08,601:INFO:Uploading model into container now
2023-01-03 22:47:08,602:INFO:_master_model_container: 2
2023-01-03 22:47:08,602:INFO:_display_container: 2
2023-01-03 22:47:08,603:INFO:Lasso(random_state=123)
2023-01-03 22:47:08,603:INFO:create_model() successfully completed......................................
2023-01-03 22:47:08,706:INFO:SubProcess create_model() end ==================================
2023-01-03 22:47:08,706:INFO:Creating metrics dataframe
2023-01-03 22:47:08,716:INFO:Initializing Ridge Regression
2023-01-03 22:47:08,716:INFO:Total runtime is 0.14369483391443888 minutes
2023-01-03 22:47:08,719:INFO:SubProcess create_model() called ==================================
2023-01-03 22:47:08,720:INFO:Initializing create_model()
2023-01-03 22:47:08,720:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024C56CFB970>, estimator=ridge, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024C62A6DFD0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:47:08,720:INFO:Checking exceptions
2023-01-03 22:47:08,720:INFO:Importing libraries
2023-01-03 22:47:08,720:INFO:Copying training dataset
2023-01-03 22:47:08,730:INFO:Defining folds
2023-01-03 22:47:08,730:INFO:Declaring metric variables
2023-01-03 22:47:08,734:INFO:Importing untrained model
2023-01-03 22:47:08,738:INFO:Ridge Regression Imported successfully
2023-01-03 22:47:08,746:INFO:Starting cross validation
2023-01-03 22:47:08,749:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:47:08,990:INFO:Calculating mean and std
2023-01-03 22:47:08,991:INFO:Creating metrics dataframe
2023-01-03 22:47:08,995:INFO:Uploading results into container
2023-01-03 22:47:08,996:INFO:Uploading model into container now
2023-01-03 22:47:08,996:INFO:_master_model_container: 3
2023-01-03 22:47:08,996:INFO:_display_container: 2
2023-01-03 22:47:08,997:INFO:Ridge(random_state=123)
2023-01-03 22:47:08,997:INFO:create_model() successfully completed......................................
2023-01-03 22:47:09,095:INFO:SubProcess create_model() end ==================================
2023-01-03 22:47:09,095:INFO:Creating metrics dataframe
2023-01-03 22:47:09,105:INFO:Initializing Elastic Net
2023-01-03 22:47:09,105:INFO:Total runtime is 0.15016526381174722 minutes
2023-01-03 22:47:09,108:INFO:SubProcess create_model() called ==================================
2023-01-03 22:47:09,110:INFO:Initializing create_model()
2023-01-03 22:47:09,110:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024C56CFB970>, estimator=en, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024C62A6DFD0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:47:09,110:INFO:Checking exceptions
2023-01-03 22:47:09,110:INFO:Importing libraries
2023-01-03 22:47:09,110:INFO:Copying training dataset
2023-01-03 22:47:09,120:INFO:Defining folds
2023-01-03 22:47:09,121:INFO:Declaring metric variables
2023-01-03 22:47:09,126:INFO:Importing untrained model
2023-01-03 22:47:09,130:INFO:Elastic Net Imported successfully
2023-01-03 22:47:09,139:INFO:Starting cross validation
2023-01-03 22:47:09,141:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:47:09,387:INFO:Calculating mean and std
2023-01-03 22:47:09,389:INFO:Creating metrics dataframe
2023-01-03 22:47:09,394:INFO:Uploading results into container
2023-01-03 22:47:09,396:INFO:Uploading model into container now
2023-01-03 22:47:09,396:INFO:_master_model_container: 4
2023-01-03 22:47:09,397:INFO:_display_container: 2
2023-01-03 22:47:09,397:INFO:ElasticNet(random_state=123)
2023-01-03 22:47:09,397:INFO:create_model() successfully completed......................................
2023-01-03 22:47:09,492:INFO:SubProcess create_model() end ==================================
2023-01-03 22:47:09,493:INFO:Creating metrics dataframe
2023-01-03 22:47:09,502:INFO:Initializing Least Angle Regression
2023-01-03 22:47:09,502:INFO:Total runtime is 0.15679274002710977 minutes
2023-01-03 22:47:09,506:INFO:SubProcess create_model() called ==================================
2023-01-03 22:47:09,507:INFO:Initializing create_model()
2023-01-03 22:47:09,507:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024C56CFB970>, estimator=lar, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024C62A6DFD0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:47:09,507:INFO:Checking exceptions
2023-01-03 22:47:09,507:INFO:Importing libraries
2023-01-03 22:47:09,507:INFO:Copying training dataset
2023-01-03 22:47:09,517:INFO:Defining folds
2023-01-03 22:47:09,517:INFO:Declaring metric variables
2023-01-03 22:47:09,522:INFO:Importing untrained model
2023-01-03 22:47:09,526:INFO:Least Angle Regression Imported successfully
2023-01-03 22:47:09,535:INFO:Starting cross validation
2023-01-03 22:47:09,536:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:47:09,585:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 22:47:09,590:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 22:47:09,605:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 22:47:09,630:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 22:47:09,660:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 22:47:09,799:INFO:Calculating mean and std
2023-01-03 22:47:09,801:INFO:Creating metrics dataframe
2023-01-03 22:47:09,804:INFO:Uploading results into container
2023-01-03 22:47:09,805:INFO:Uploading model into container now
2023-01-03 22:47:09,805:INFO:_master_model_container: 5
2023-01-03 22:47:09,805:INFO:_display_container: 2
2023-01-03 22:47:09,805:INFO:Lars(random_state=123)
2023-01-03 22:47:09,805:INFO:create_model() successfully completed......................................
2023-01-03 22:47:09,910:INFO:SubProcess create_model() end ==================================
2023-01-03 22:47:09,911:INFO:Creating metrics dataframe
2023-01-03 22:47:09,924:INFO:Initializing Lasso Least Angle Regression
2023-01-03 22:47:09,925:INFO:Total runtime is 0.16384196678797402 minutes
2023-01-03 22:47:09,929:INFO:SubProcess create_model() called ==================================
2023-01-03 22:47:09,930:INFO:Initializing create_model()
2023-01-03 22:47:09,930:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024C56CFB970>, estimator=llar, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024C62A6DFD0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:47:09,930:INFO:Checking exceptions
2023-01-03 22:47:09,930:INFO:Importing libraries
2023-01-03 22:47:09,930:INFO:Copying training dataset
2023-01-03 22:47:09,940:INFO:Defining folds
2023-01-03 22:47:09,941:INFO:Declaring metric variables
2023-01-03 22:47:09,945:INFO:Importing untrained model
2023-01-03 22:47:09,950:INFO:Lasso Least Angle Regression Imported successfully
2023-01-03 22:47:09,960:INFO:Starting cross validation
2023-01-03 22:47:09,962:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:47:10,019:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-03 22:47:10,024:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-03 22:47:10,033:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-03 22:47:10,061:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-03 22:47:10,085:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-03 22:47:10,225:INFO:Calculating mean and std
2023-01-03 22:47:10,226:INFO:Creating metrics dataframe
2023-01-03 22:47:10,229:INFO:Uploading results into container
2023-01-03 22:47:10,230:INFO:Uploading model into container now
2023-01-03 22:47:10,230:INFO:_master_model_container: 6
2023-01-03 22:47:10,230:INFO:_display_container: 2
2023-01-03 22:47:10,231:INFO:LassoLars(random_state=123)
2023-01-03 22:47:10,231:INFO:create_model() successfully completed......................................
2023-01-03 22:47:10,346:INFO:SubProcess create_model() end ==================================
2023-01-03 22:47:10,346:INFO:Creating metrics dataframe
2023-01-03 22:47:10,359:INFO:Initializing Orthogonal Matching Pursuit
2023-01-03 22:47:10,359:INFO:Total runtime is 0.17107261419296263 minutes
2023-01-03 22:47:10,364:INFO:SubProcess create_model() called ==================================
2023-01-03 22:47:10,364:INFO:Initializing create_model()
2023-01-03 22:47:10,364:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024C56CFB970>, estimator=omp, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024C62A6DFD0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:47:10,364:INFO:Checking exceptions
2023-01-03 22:47:10,365:INFO:Importing libraries
2023-01-03 22:47:10,365:INFO:Copying training dataset
2023-01-03 22:47:10,377:INFO:Defining folds
2023-01-03 22:47:10,377:INFO:Declaring metric variables
2023-01-03 22:47:10,382:INFO:Importing untrained model
2023-01-03 22:47:10,386:INFO:Orthogonal Matching Pursuit Imported successfully
2023-01-03 22:47:10,396:INFO:Starting cross validation
2023-01-03 22:47:10,398:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:47:10,448:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 22:47:10,453:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 22:47:10,486:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 22:47:10,487:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 22:47:10,516:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 22:47:10,646:INFO:Calculating mean and std
2023-01-03 22:47:10,648:INFO:Creating metrics dataframe
2023-01-03 22:47:10,651:INFO:Uploading results into container
2023-01-03 22:47:10,652:INFO:Uploading model into container now
2023-01-03 22:47:10,652:INFO:_master_model_container: 7
2023-01-03 22:47:10,653:INFO:_display_container: 2
2023-01-03 22:47:10,653:INFO:OrthogonalMatchingPursuit()
2023-01-03 22:47:10,653:INFO:create_model() successfully completed......................................
2023-01-03 22:47:10,762:INFO:SubProcess create_model() end ==================================
2023-01-03 22:47:10,762:INFO:Creating metrics dataframe
2023-01-03 22:47:10,774:INFO:Initializing Bayesian Ridge
2023-01-03 22:47:10,774:INFO:Total runtime is 0.17799206574757892 minutes
2023-01-03 22:47:10,778:INFO:SubProcess create_model() called ==================================
2023-01-03 22:47:10,779:INFO:Initializing create_model()
2023-01-03 22:47:10,779:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024C56CFB970>, estimator=br, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024C62A6DFD0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:47:10,779:INFO:Checking exceptions
2023-01-03 22:47:10,779:INFO:Importing libraries
2023-01-03 22:47:10,779:INFO:Copying training dataset
2023-01-03 22:47:10,788:INFO:Defining folds
2023-01-03 22:47:10,789:INFO:Declaring metric variables
2023-01-03 22:47:10,793:INFO:Importing untrained model
2023-01-03 22:47:10,798:INFO:Bayesian Ridge Imported successfully
2023-01-03 22:47:10,805:INFO:Starting cross validation
2023-01-03 22:47:10,807:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:47:11,086:INFO:Calculating mean and std
2023-01-03 22:47:11,088:INFO:Creating metrics dataframe
2023-01-03 22:47:11,092:INFO:Uploading results into container
2023-01-03 22:47:11,093:INFO:Uploading model into container now
2023-01-03 22:47:11,093:INFO:_master_model_container: 8
2023-01-03 22:47:11,093:INFO:_display_container: 2
2023-01-03 22:47:11,094:INFO:BayesianRidge()
2023-01-03 22:47:11,094:INFO:create_model() successfully completed......................................
2023-01-03 22:47:11,205:INFO:SubProcess create_model() end ==================================
2023-01-03 22:47:11,205:INFO:Creating metrics dataframe
2023-01-03 22:47:11,217:INFO:Initializing Passive Aggressive Regressor
2023-01-03 22:47:11,218:INFO:Total runtime is 0.18539201021194457 minutes
2023-01-03 22:47:11,222:INFO:SubProcess create_model() called ==================================
2023-01-03 22:47:11,223:INFO:Initializing create_model()
2023-01-03 22:47:11,223:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024C56CFB970>, estimator=par, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024C62A6DFD0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:47:11,223:INFO:Checking exceptions
2023-01-03 22:47:11,224:INFO:Importing libraries
2023-01-03 22:47:11,224:INFO:Copying training dataset
2023-01-03 22:47:11,236:INFO:Defining folds
2023-01-03 22:47:11,236:INFO:Declaring metric variables
2023-01-03 22:47:11,241:INFO:Importing untrained model
2023-01-03 22:47:11,246:INFO:Passive Aggressive Regressor Imported successfully
2023-01-03 22:47:11,254:INFO:Starting cross validation
2023-01-03 22:47:11,256:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:47:11,559:INFO:Calculating mean and std
2023-01-03 22:47:11,562:INFO:Creating metrics dataframe
2023-01-03 22:47:11,567:INFO:Uploading results into container
2023-01-03 22:47:11,567:INFO:Uploading model into container now
2023-01-03 22:47:11,568:INFO:_master_model_container: 9
2023-01-03 22:47:11,568:INFO:_display_container: 2
2023-01-03 22:47:11,568:INFO:PassiveAggressiveRegressor(random_state=123)
2023-01-03 22:47:11,568:INFO:create_model() successfully completed......................................
2023-01-03 22:47:11,678:INFO:SubProcess create_model() end ==================================
2023-01-03 22:47:11,678:INFO:Creating metrics dataframe
2023-01-03 22:47:11,690:INFO:Initializing Huber Regressor
2023-01-03 22:47:11,690:INFO:Total runtime is 0.19326204856236776 minutes
2023-01-03 22:47:11,695:INFO:SubProcess create_model() called ==================================
2023-01-03 22:47:11,696:INFO:Initializing create_model()
2023-01-03 22:47:11,696:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024C56CFB970>, estimator=huber, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024C62A6DFD0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:47:11,696:INFO:Checking exceptions
2023-01-03 22:47:11,696:INFO:Importing libraries
2023-01-03 22:47:11,696:INFO:Copying training dataset
2023-01-03 22:47:11,708:INFO:Defining folds
2023-01-03 22:47:11,708:INFO:Declaring metric variables
2023-01-03 22:47:11,713:INFO:Importing untrained model
2023-01-03 22:47:11,717:INFO:Huber Regressor Imported successfully
2023-01-03 22:47:11,727:INFO:Starting cross validation
2023-01-03 22:47:11,728:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:47:11,863:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-03 22:47:11,977:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-03 22:47:12,061:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-03 22:47:12,160:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-03 22:47:12,367:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-03 22:47:12,499:INFO:Calculating mean and std
2023-01-03 22:47:12,501:INFO:Creating metrics dataframe
2023-01-03 22:47:12,504:INFO:Uploading results into container
2023-01-03 22:47:12,505:INFO:Uploading model into container now
2023-01-03 22:47:12,507:INFO:_master_model_container: 10
2023-01-03 22:47:12,507:INFO:_display_container: 2
2023-01-03 22:47:12,508:INFO:HuberRegressor()
2023-01-03 22:47:12,508:INFO:create_model() successfully completed......................................
2023-01-03 22:47:12,617:INFO:SubProcess create_model() end ==================================
2023-01-03 22:47:12,617:INFO:Creating metrics dataframe
2023-01-03 22:47:12,631:INFO:Initializing K Neighbors Regressor
2023-01-03 22:47:12,632:INFO:Total runtime is 0.20895671447118122 minutes
2023-01-03 22:47:12,636:INFO:SubProcess create_model() called ==================================
2023-01-03 22:47:12,636:INFO:Initializing create_model()
2023-01-03 22:47:12,636:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024C56CFB970>, estimator=knn, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024C62A6DFD0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:47:12,637:INFO:Checking exceptions
2023-01-03 22:47:12,637:INFO:Importing libraries
2023-01-03 22:47:12,637:INFO:Copying training dataset
2023-01-03 22:47:12,651:INFO:Defining folds
2023-01-03 22:47:12,652:INFO:Declaring metric variables
2023-01-03 22:47:12,655:INFO:Importing untrained model
2023-01-03 22:47:12,661:INFO:K Neighbors Regressor Imported successfully
2023-01-03 22:47:12,668:INFO:Starting cross validation
2023-01-03 22:47:12,670:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:47:13,545:INFO:Calculating mean and std
2023-01-03 22:47:13,548:INFO:Creating metrics dataframe
2023-01-03 22:47:13,551:INFO:Uploading results into container
2023-01-03 22:47:13,552:INFO:Uploading model into container now
2023-01-03 22:47:13,552:INFO:_master_model_container: 11
2023-01-03 22:47:13,552:INFO:_display_container: 2
2023-01-03 22:47:13,553:INFO:KNeighborsRegressor(n_jobs=-1)
2023-01-03 22:47:13,553:INFO:create_model() successfully completed......................................
2023-01-03 22:47:13,692:INFO:SubProcess create_model() end ==================================
2023-01-03 22:47:13,692:INFO:Creating metrics dataframe
2023-01-03 22:47:13,707:INFO:Initializing Decision Tree Regressor
2023-01-03 22:47:13,708:INFO:Total runtime is 0.22688976526260374 minutes
2023-01-03 22:47:13,713:INFO:SubProcess create_model() called ==================================
2023-01-03 22:47:13,713:INFO:Initializing create_model()
2023-01-03 22:47:13,713:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024C56CFB970>, estimator=dt, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024C62A6DFD0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:47:13,714:INFO:Checking exceptions
2023-01-03 22:47:13,714:INFO:Importing libraries
2023-01-03 22:47:13,714:INFO:Copying training dataset
2023-01-03 22:47:13,725:INFO:Defining folds
2023-01-03 22:47:13,726:INFO:Declaring metric variables
2023-01-03 22:47:13,731:INFO:Importing untrained model
2023-01-03 22:47:13,735:INFO:Decision Tree Regressor Imported successfully
2023-01-03 22:47:13,743:INFO:Starting cross validation
2023-01-03 22:47:13,745:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:47:14,339:INFO:Calculating mean and std
2023-01-03 22:47:14,341:INFO:Creating metrics dataframe
2023-01-03 22:47:14,345:INFO:Uploading results into container
2023-01-03 22:47:14,345:INFO:Uploading model into container now
2023-01-03 22:47:14,346:INFO:_master_model_container: 12
2023-01-03 22:47:14,346:INFO:_display_container: 2
2023-01-03 22:47:14,346:INFO:DecisionTreeRegressor(random_state=123)
2023-01-03 22:47:14,347:INFO:create_model() successfully completed......................................
2023-01-03 22:47:14,450:INFO:SubProcess create_model() end ==================================
2023-01-03 22:47:14,450:INFO:Creating metrics dataframe
2023-01-03 22:47:14,462:INFO:Initializing Random Forest Regressor
2023-01-03 22:47:14,463:INFO:Total runtime is 0.23947304089864094 minutes
2023-01-03 22:47:14,466:INFO:SubProcess create_model() called ==================================
2023-01-03 22:47:14,466:INFO:Initializing create_model()
2023-01-03 22:47:14,467:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024C56CFB970>, estimator=rf, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024C62A6DFD0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:47:14,467:INFO:Checking exceptions
2023-01-03 22:47:14,467:INFO:Importing libraries
2023-01-03 22:47:14,467:INFO:Copying training dataset
2023-01-03 22:47:14,477:INFO:Defining folds
2023-01-03 22:47:14,477:INFO:Declaring metric variables
2023-01-03 22:47:14,482:INFO:Importing untrained model
2023-01-03 22:47:14,485:INFO:Random Forest Regressor Imported successfully
2023-01-03 22:47:14,493:INFO:Starting cross validation
2023-01-03 22:47:14,495:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:47:29,170:INFO:Calculating mean and std
2023-01-03 22:47:29,172:INFO:Creating metrics dataframe
2023-01-03 22:47:29,176:INFO:Uploading results into container
2023-01-03 22:47:29,177:INFO:Uploading model into container now
2023-01-03 22:47:29,177:INFO:_master_model_container: 13
2023-01-03 22:47:29,177:INFO:_display_container: 2
2023-01-03 22:47:29,178:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-01-03 22:47:29,178:INFO:create_model() successfully completed......................................
2023-01-03 22:47:29,281:INFO:SubProcess create_model() end ==================================
2023-01-03 22:47:29,281:INFO:Creating metrics dataframe
2023-01-03 22:47:29,297:INFO:Initializing Extra Trees Regressor
2023-01-03 22:47:29,297:INFO:Total runtime is 0.48670665423075354 minutes
2023-01-03 22:47:29,301:INFO:SubProcess create_model() called ==================================
2023-01-03 22:47:29,301:INFO:Initializing create_model()
2023-01-03 22:47:29,302:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024C56CFB970>, estimator=et, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024C62A6DFD0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:47:29,302:INFO:Checking exceptions
2023-01-03 22:47:29,302:INFO:Importing libraries
2023-01-03 22:47:29,302:INFO:Copying training dataset
2023-01-03 22:47:29,311:INFO:Defining folds
2023-01-03 22:47:29,311:INFO:Declaring metric variables
2023-01-03 22:47:29,316:INFO:Importing untrained model
2023-01-03 22:47:29,321:INFO:Extra Trees Regressor Imported successfully
2023-01-03 22:47:29,328:INFO:Starting cross validation
2023-01-03 22:47:29,330:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:47:34,420:INFO:Calculating mean and std
2023-01-03 22:47:34,423:INFO:Creating metrics dataframe
2023-01-03 22:47:34,428:INFO:Uploading results into container
2023-01-03 22:47:34,428:INFO:Uploading model into container now
2023-01-03 22:47:34,429:INFO:_master_model_container: 14
2023-01-03 22:47:34,429:INFO:_display_container: 2
2023-01-03 22:47:34,429:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-01-03 22:47:34,429:INFO:create_model() successfully completed......................................
2023-01-03 22:47:34,540:INFO:SubProcess create_model() end ==================================
2023-01-03 22:47:34,540:INFO:Creating metrics dataframe
2023-01-03 22:47:34,552:INFO:Initializing AdaBoost Regressor
2023-01-03 22:47:34,553:INFO:Total runtime is 0.5743063728014628 minutes
2023-01-03 22:47:34,556:INFO:SubProcess create_model() called ==================================
2023-01-03 22:47:34,557:INFO:Initializing create_model()
2023-01-03 22:47:34,557:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024C56CFB970>, estimator=ada, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024C62A6DFD0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:47:34,557:INFO:Checking exceptions
2023-01-03 22:47:34,557:INFO:Importing libraries
2023-01-03 22:47:34,558:INFO:Copying training dataset
2023-01-03 22:47:34,567:INFO:Defining folds
2023-01-03 22:47:34,568:INFO:Declaring metric variables
2023-01-03 22:47:34,572:INFO:Importing untrained model
2023-01-03 22:47:34,577:INFO:AdaBoost Regressor Imported successfully
2023-01-03 22:47:34,584:INFO:Starting cross validation
2023-01-03 22:47:34,586:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:47:36,486:INFO:Calculating mean and std
2023-01-03 22:47:36,488:INFO:Creating metrics dataframe
2023-01-03 22:47:36,491:INFO:Uploading results into container
2023-01-03 22:47:36,492:INFO:Uploading model into container now
2023-01-03 22:47:36,492:INFO:_master_model_container: 15
2023-01-03 22:47:36,493:INFO:_display_container: 2
2023-01-03 22:47:36,493:INFO:AdaBoostRegressor(random_state=123)
2023-01-03 22:47:36,493:INFO:create_model() successfully completed......................................
2023-01-03 22:47:36,587:INFO:SubProcess create_model() end ==================================
2023-01-03 22:47:36,587:INFO:Creating metrics dataframe
2023-01-03 22:47:36,599:INFO:Initializing Gradient Boosting Regressor
2023-01-03 22:47:36,599:INFO:Total runtime is 0.6084016601244608 minutes
2023-01-03 22:47:36,603:INFO:SubProcess create_model() called ==================================
2023-01-03 22:47:36,604:INFO:Initializing create_model()
2023-01-03 22:47:36,604:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024C56CFB970>, estimator=gbr, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024C62A6DFD0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:47:36,604:INFO:Checking exceptions
2023-01-03 22:47:36,604:INFO:Importing libraries
2023-01-03 22:47:36,604:INFO:Copying training dataset
2023-01-03 22:47:36,616:INFO:Defining folds
2023-01-03 22:47:36,616:INFO:Declaring metric variables
2023-01-03 22:47:36,621:INFO:Importing untrained model
2023-01-03 22:47:36,625:INFO:Gradient Boosting Regressor Imported successfully
2023-01-03 22:47:36,632:INFO:Starting cross validation
2023-01-03 22:47:36,634:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:47:42,217:INFO:Calculating mean and std
2023-01-03 22:47:42,219:INFO:Creating metrics dataframe
2023-01-03 22:47:42,223:INFO:Uploading results into container
2023-01-03 22:47:42,223:INFO:Uploading model into container now
2023-01-03 22:47:42,224:INFO:_master_model_container: 16
2023-01-03 22:47:42,224:INFO:_display_container: 2
2023-01-03 22:47:42,225:INFO:GradientBoostingRegressor(random_state=123)
2023-01-03 22:47:42,225:INFO:create_model() successfully completed......................................
2023-01-03 22:47:42,336:INFO:SubProcess create_model() end ==================================
2023-01-03 22:47:42,337:INFO:Creating metrics dataframe
2023-01-03 22:47:42,351:INFO:Initializing Light Gradient Boosting Machine
2023-01-03 22:47:42,351:INFO:Total runtime is 0.704268209139506 minutes
2023-01-03 22:47:42,355:INFO:SubProcess create_model() called ==================================
2023-01-03 22:47:42,356:INFO:Initializing create_model()
2023-01-03 22:47:42,356:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024C56CFB970>, estimator=lightgbm, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024C62A6DFD0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:47:42,356:INFO:Checking exceptions
2023-01-03 22:47:42,356:INFO:Importing libraries
2023-01-03 22:47:42,356:INFO:Copying training dataset
2023-01-03 22:47:42,368:INFO:Defining folds
2023-01-03 22:47:42,368:INFO:Declaring metric variables
2023-01-03 22:47:42,372:INFO:Importing untrained model
2023-01-03 22:47:42,378:INFO:Light Gradient Boosting Machine Imported successfully
2023-01-03 22:47:42,386:INFO:Starting cross validation
2023-01-03 22:47:42,387:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:47:44,536:INFO:Calculating mean and std
2023-01-03 22:47:44,538:INFO:Creating metrics dataframe
2023-01-03 22:47:44,542:INFO:Uploading results into container
2023-01-03 22:47:44,542:INFO:Uploading model into container now
2023-01-03 22:47:44,543:INFO:_master_model_container: 17
2023-01-03 22:47:44,543:INFO:_display_container: 2
2023-01-03 22:47:44,544:INFO:LGBMRegressor(random_state=123)
2023-01-03 22:47:44,544:INFO:create_model() successfully completed......................................
2023-01-03 22:47:44,644:INFO:SubProcess create_model() end ==================================
2023-01-03 22:47:44,644:INFO:Creating metrics dataframe
2023-01-03 22:47:44,657:INFO:Initializing Dummy Regressor
2023-01-03 22:47:44,658:INFO:Total runtime is 0.742718493938446 minutes
2023-01-03 22:47:44,663:INFO:SubProcess create_model() called ==================================
2023-01-03 22:47:44,663:INFO:Initializing create_model()
2023-01-03 22:47:44,663:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024C56CFB970>, estimator=dummy, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024C62A6DFD0>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:47:44,663:INFO:Checking exceptions
2023-01-03 22:47:44,664:INFO:Importing libraries
2023-01-03 22:47:44,664:INFO:Copying training dataset
2023-01-03 22:47:44,674:INFO:Defining folds
2023-01-03 22:47:44,674:INFO:Declaring metric variables
2023-01-03 22:47:44,678:INFO:Importing untrained model
2023-01-03 22:47:44,682:INFO:Dummy Regressor Imported successfully
2023-01-03 22:47:44,689:INFO:Starting cross validation
2023-01-03 22:47:44,691:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:47:44,930:INFO:Calculating mean and std
2023-01-03 22:47:44,932:INFO:Creating metrics dataframe
2023-01-03 22:47:44,936:INFO:Uploading results into container
2023-01-03 22:47:44,936:INFO:Uploading model into container now
2023-01-03 22:47:44,937:INFO:_master_model_container: 18
2023-01-03 22:47:44,937:INFO:_display_container: 2
2023-01-03 22:47:44,937:INFO:DummyRegressor()
2023-01-03 22:47:44,937:INFO:create_model() successfully completed......................................
2023-01-03 22:47:45,055:INFO:SubProcess create_model() end ==================================
2023-01-03 22:47:45,055:INFO:Creating metrics dataframe
2023-01-03 22:47:45,083:INFO:Initializing create_model()
2023-01-03 22:47:45,083:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024C56CFB970>, estimator=LGBMRegressor(random_state=123), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:47:45,083:INFO:Checking exceptions
2023-01-03 22:47:45,085:INFO:Importing libraries
2023-01-03 22:47:45,085:INFO:Copying training dataset
2023-01-03 22:47:45,095:INFO:Defining folds
2023-01-03 22:47:45,095:INFO:Declaring metric variables
2023-01-03 22:47:45,095:INFO:Importing untrained model
2023-01-03 22:47:45,095:INFO:Declaring custom model
2023-01-03 22:47:45,096:INFO:Light Gradient Boosting Machine Imported successfully
2023-01-03 22:47:45,097:INFO:Cross validation set to False
2023-01-03 22:47:45,097:INFO:Fitting Model
2023-01-03 22:47:45,857:INFO:LGBMRegressor(random_state=123)
2023-01-03 22:47:45,857:INFO:create_model() successfully completed......................................
2023-01-03 22:47:46,011:INFO:_master_model_container: 18
2023-01-03 22:47:46,011:INFO:_display_container: 2
2023-01-03 22:47:46,011:INFO:LGBMRegressor(random_state=123)
2023-01-03 22:47:46,012:INFO:compare_models() successfully completed......................................
2023-01-03 22:47:46,012:INFO:Initializing tune_model()
2023-01-03 22:47:46,013:INFO:tune_model(estimator=LGBMRegressor(random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=MAE, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024C56CFB970>)
2023-01-03 22:47:46,013:INFO:Checking exceptions
2023-01-03 22:47:46,047:INFO:Copying training dataset
2023-01-03 22:47:46,059:INFO:Checking base model
2023-01-03 22:47:46,060:INFO:Base model : Light Gradient Boosting Machine
2023-01-03 22:47:46,065:INFO:Declaring metric variables
2023-01-03 22:47:46,069:INFO:Defining Hyperparameters
2023-01-03 22:47:46,193:INFO:Tuning with n_jobs=-1
2023-01-03 22:47:46,194:INFO:Initializing RandomizedSearchCV
2023-01-03 22:47:53,599:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2023-01-03 22:47:53,601:INFO:Hyperparameter search completed
2023-01-03 22:47:53,601:INFO:SubProcess create_model() called ==================================
2023-01-03 22:47:53,601:INFO:Initializing create_model()
2023-01-03 22:47:53,602:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024C56CFB970>, estimator=LGBMRegressor(random_state=123), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024C621F88E0>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2023-01-03 22:47:53,602:INFO:Checking exceptions
2023-01-03 22:47:53,602:INFO:Importing libraries
2023-01-03 22:47:53,602:INFO:Copying training dataset
2023-01-03 22:47:53,611:INFO:Defining folds
2023-01-03 22:47:53,611:INFO:Declaring metric variables
2023-01-03 22:47:53,614:INFO:Importing untrained model
2023-01-03 22:47:53,615:INFO:Declaring custom model
2023-01-03 22:47:53,619:INFO:Light Gradient Boosting Machine Imported successfully
2023-01-03 22:47:53,626:INFO:Starting cross validation
2023-01-03 22:47:53,628:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:47:55,021:INFO:Calculating mean and std
2023-01-03 22:47:55,023:INFO:Creating metrics dataframe
2023-01-03 22:47:55,029:INFO:Finalizing model
2023-01-03 22:47:55,581:INFO:Uploading results into container
2023-01-03 22:47:55,581:INFO:Uploading model into container now
2023-01-03 22:47:55,582:INFO:_master_model_container: 19
2023-01-03 22:47:55,583:INFO:_display_container: 3
2023-01-03 22:47:55,583:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              num_leaves=70, random_state=123, reg_alpha=2, reg_lambda=3)
2023-01-03 22:47:55,583:INFO:create_model() successfully completed......................................
2023-01-03 22:47:55,681:INFO:SubProcess create_model() end ==================================
2023-01-03 22:47:55,681:INFO:choose_better activated
2023-01-03 22:47:55,685:INFO:SubProcess create_model() called ==================================
2023-01-03 22:47:55,685:INFO:Initializing create_model()
2023-01-03 22:47:55,685:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024C56CFB970>, estimator=LGBMRegressor(random_state=123), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-01-03 22:47:55,685:INFO:Checking exceptions
2023-01-03 22:47:55,687:INFO:Importing libraries
2023-01-03 22:47:55,687:INFO:Copying training dataset
2023-01-03 22:47:55,695:INFO:Defining folds
2023-01-03 22:47:55,696:INFO:Declaring metric variables
2023-01-03 22:47:55,696:INFO:Importing untrained model
2023-01-03 22:47:55,696:INFO:Declaring custom model
2023-01-03 22:47:55,697:INFO:Light Gradient Boosting Machine Imported successfully
2023-01-03 22:47:55,697:INFO:Starting cross validation
2023-01-03 22:47:55,698:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 22:47:56,939:INFO:Calculating mean and std
2023-01-03 22:47:56,940:INFO:Creating metrics dataframe
2023-01-03 22:47:56,942:INFO:Finalizing model
2023-01-03 22:47:57,201:INFO:Uploading results into container
2023-01-03 22:47:57,202:INFO:Uploading model into container now
2023-01-03 22:47:57,202:INFO:_master_model_container: 20
2023-01-03 22:47:57,202:INFO:_display_container: 4
2023-01-03 22:47:57,203:INFO:LGBMRegressor(random_state=123)
2023-01-03 22:47:57,203:INFO:create_model() successfully completed......................................
2023-01-03 22:47:57,300:INFO:SubProcess create_model() end ==================================
2023-01-03 22:47:57,301:INFO:LGBMRegressor(random_state=123) result for MAE is 2.1328
2023-01-03 22:47:57,302:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              num_leaves=70, random_state=123, reg_alpha=2, reg_lambda=3) result for MAE is 2.4065
2023-01-03 22:47:57,302:INFO:LGBMRegressor(random_state=123) is best model
2023-01-03 22:47:57,302:INFO:choose_better completed
2023-01-03 22:47:57,302:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-01-03 22:47:57,311:INFO:_master_model_container: 20
2023-01-03 22:47:57,311:INFO:_display_container: 3
2023-01-03 22:47:57,312:INFO:LGBMRegressor(random_state=123)
2023-01-03 22:47:57,312:INFO:tune_model() successfully completed......................................
2023-01-03 22:47:57,411:INFO:Initializing plot_model()
2023-01-03 22:47:57,411:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LGBMRegressor(random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024C56CFB970>, system=True)
2023-01-03 22:47:57,411:INFO:Checking exceptions
2023-01-03 22:47:57,418:INFO:Preloading libraries
2023-01-03 22:47:57,425:INFO:Copying training dataset
2023-01-03 22:47:57,425:INFO:Plot type: error
2023-01-03 22:47:57,592:INFO:Fitting Model
2023-01-03 22:47:57,592:INFO:Scoring test/hold-out set
2023-01-03 22:47:58,002:INFO:Visual Rendered Successfully
2023-01-03 22:47:58,102:INFO:plot_model() successfully completed......................................
2023-01-03 22:47:58,103:INFO:Initializing predict_model()
2023-01-03 22:47:58,103:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024C56CFB970>, estimator=LGBMRegressor(random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x0000024C62A64D30>)
2023-01-03 22:47:58,103:INFO:Checking exceptions
2023-01-03 22:47:58,103:INFO:Preloading libraries
2023-01-03 22:47:58,255:INFO:Initializing finalize_model()
2023-01-03 22:47:58,256:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024C56CFB970>, estimator=LGBMRegressor(random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-01-03 22:47:58,256:INFO:Finalizing LGBMRegressor(random_state=123)
2023-01-03 22:47:58,264:INFO:Initializing create_model()
2023-01-03 22:47:58,264:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024C56CFB970>, estimator=LGBMRegressor(random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-01-03 22:47:58,264:INFO:Checking exceptions
2023-01-03 22:47:58,266:INFO:Importing libraries
2023-01-03 22:47:58,266:INFO:Copying training dataset
2023-01-03 22:47:58,267:INFO:Defining folds
2023-01-03 22:47:58,268:INFO:Declaring metric variables
2023-01-03 22:47:58,268:INFO:Importing untrained model
2023-01-03 22:47:58,268:INFO:Declaring custom model
2023-01-03 22:47:58,269:INFO:Light Gradient Boosting Machine Imported successfully
2023-01-03 22:47:58,270:INFO:Cross validation set to False
2023-01-03 22:47:58,270:INFO:Fitting Model
2023-01-03 22:47:59,369:INFO:Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator', LGBMRegressor(random_state=123))])
2023-01-03 22:47:59,369:INFO:create_model() successfully completed......................................
2023-01-03 22:47:59,468:INFO:_master_model_container: 20
2023-01-03 22:47:59,468:INFO:_display_container: 4
2023-01-03 22:47:59,475:INFO:Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator', LGBMRegressor(random_state=123))])
2023-01-03 22:47:59,475:INFO:finalize_model() successfully completed......................................
2023-01-03 22:47:59,580:INFO:Initializing predict_model()
2023-01-03 22:47:59,581:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024C56CFB970>, estimator=Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator', LGBMRegressor(random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x0000024C62A64280>)
2023-01-03 22:47:59,581:INFO:Checking exceptions
2023-01-03 22:47:59,581:INFO:Preloading libraries
2023-01-03 22:47:59,582:INFO:Set up data.
2023-01-03 22:47:59,597:INFO:Set up index.
2023-01-03 22:48:00,043:INFO:Initializing save_model()
2023-01-03 22:48:00,043:INFO:save_model(model=Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator', LGBMRegressor(random_state=123))]), model_name=c:\Users\Kodotautas\Desktop\Data_science\7_TIME_SERIES_FORECAST_PYCARET/models/final_model.pkl, prep_pipe_=Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-01-03 22:48:00,043:INFO:Adding model into prep_pipe
2023-01-03 22:48:00,055:WARNING:Only Model saved as it was a pipeline.
2023-01-03 22:48:00,067:INFO:c:\Users\Kodotautas\Desktop\Data_science\7_TIME_SERIES_FORECAST_PYCARET/models/final_model.pkl.pkl saved in current working directory
2023-01-03 22:48:00,074:INFO:Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator', LGBMRegressor(random_state=123))])
2023-01-03 22:48:00,074:INFO:save_model() successfully completed......................................
2023-01-03 23:03:10,432:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-01-03 23:03:10,432:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-01-03 23:03:10,436:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-01-03 23:03:10,436:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-01-03 23:03:11,754:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-01-03 23:03:12,767:INFO:PyCaret RegressionExperiment
2023-01-03 23:03:12,767:INFO:Logging name: reg-default-name
2023-01-03 23:03:12,767:INFO:ML Usecase: MLUsecase.REGRESSION
2023-01-03 23:03:12,767:INFO:version 3.0.0.rc6
2023-01-03 23:03:12,767:INFO:Initializing setup()
2023-01-03 23:03:12,767:INFO:self.USI: 5190
2023-01-03 23:03:12,767:INFO:self._variable_keys: {'target_param', 'idx', 'y', 'fold_shuffle_param', 'exp_name_log', 'exp_id', 'y_test', 'n_jobs_param', 'X_train', 'transform_target_param', 'gpu_param', 'fold_groups_param', 'gpu_n_jobs_param', 'X', '_ml_usecase', 'pipeline', '_available_plots', 'USI', 'html_param', 'seed', 'logging_param', 'X_test', 'memory', 'fold_generator', 'y_train', 'log_plots_param', 'data'}
2023-01-03 23:03:12,767:INFO:Checking environment
2023-01-03 23:03:12,767:INFO:python_version: 3.9.13
2023-01-03 23:03:12,767:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-01-03 23:03:12,767:INFO:machine: AMD64
2023-01-03 23:03:12,767:INFO:platform: Windows-10-10.0.19044-SP0
2023-01-03 23:03:12,767:INFO:Memory: svmem(total=17114804224, available=9800839168, percent=42.7, used=7313965056, free=9800839168)
2023-01-03 23:03:12,767:INFO:Physical Core: 4
2023-01-03 23:03:12,767:INFO:Logical Core: 4
2023-01-03 23:03:12,768:INFO:Checking libraries
2023-01-03 23:03:12,768:INFO:System:
2023-01-03 23:03:12,768:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-01-03 23:03:12,768:INFO:executable: c:\Users\Kodotautas\anaconda3\python.exe
2023-01-03 23:03:12,768:INFO:   machine: Windows-10-10.0.19044-SP0
2023-01-03 23:03:12,768:INFO:PyCaret required dependencies:
2023-01-03 23:03:12,768:INFO:                 pip: 22.2.2
2023-01-03 23:03:12,768:INFO:          setuptools: 63.4.1
2023-01-03 23:03:12,768:INFO:             pycaret: 3.0.0rc6
2023-01-03 23:03:12,768:INFO:             IPython: 7.31.1
2023-01-03 23:03:12,768:INFO:          ipywidgets: 7.6.5
2023-01-03 23:03:12,768:INFO:                tqdm: 4.64.1
2023-01-03 23:03:12,768:INFO:               numpy: 1.21.5
2023-01-03 23:03:12,768:INFO:              pandas: 1.4.4
2023-01-03 23:03:12,768:INFO:              jinja2: 2.11.3
2023-01-03 23:03:12,768:INFO:               scipy: 1.9.1
2023-01-03 23:03:12,768:INFO:              joblib: 1.2.0
2023-01-03 23:03:12,769:INFO:             sklearn: 1.0.2
2023-01-03 23:03:12,769:INFO:                pyod: 1.0.7
2023-01-03 23:03:12,769:INFO:            imblearn: 0.10.1
2023-01-03 23:03:12,769:INFO:   category_encoders: 2.5.1.post0
2023-01-03 23:03:12,769:INFO:            lightgbm: 3.3.3
2023-01-03 23:03:12,769:INFO:               numba: 0.55.1
2023-01-03 23:03:12,769:INFO:            requests: 2.28.1
2023-01-03 23:03:12,769:INFO:          matplotlib: 3.5.2
2023-01-03 23:03:12,769:INFO:          scikitplot: 0.3.7
2023-01-03 23:03:12,769:INFO:         yellowbrick: 1.5
2023-01-03 23:03:12,769:INFO:              plotly: 5.9.0
2023-01-03 23:03:12,769:INFO:             kaleido: 0.2.1
2023-01-03 23:03:12,769:INFO:         statsmodels: 0.13.2
2023-01-03 23:03:12,769:INFO:              sktime: 0.14.1
2023-01-03 23:03:12,769:INFO:               tbats: 1.1.2
2023-01-03 23:03:12,769:INFO:            pmdarima: 2.0.2
2023-01-03 23:03:12,769:INFO:              psutil: 5.9.0
2023-01-03 23:03:12,769:INFO:PyCaret optional dependencies:
2023-01-03 23:03:13,189:INFO:                shap: 0.41.0
2023-01-03 23:03:13,189:INFO:           interpret: Not installed
2023-01-03 23:03:13,189:INFO:                umap: Not installed
2023-01-03 23:03:13,189:INFO:    pandas_profiling: Not installed
2023-01-03 23:03:13,189:INFO:  explainerdashboard: Not installed
2023-01-03 23:03:13,189:INFO:             autoviz: Not installed
2023-01-03 23:03:13,190:INFO:           fairlearn: Not installed
2023-01-03 23:03:13,190:INFO:             xgboost: Not installed
2023-01-03 23:03:13,190:INFO:            catboost: Not installed
2023-01-03 23:03:13,190:INFO:              kmodes: Not installed
2023-01-03 23:03:13,190:INFO:             mlxtend: Not installed
2023-01-03 23:03:13,190:INFO:       statsforecast: Not installed
2023-01-03 23:03:13,190:INFO:        tune_sklearn: 0.4.3
2023-01-03 23:03:13,190:INFO:                 ray: 2.0.0
2023-01-03 23:03:13,190:INFO:            hyperopt: 0.2.7
2023-01-03 23:03:13,190:INFO:              optuna: 3.0.1
2023-01-03 23:03:13,190:INFO:               skopt: 0.9.0
2023-01-03 23:03:13,190:INFO:              mlflow: Not installed
2023-01-03 23:03:13,190:INFO:              gradio: Not installed
2023-01-03 23:03:13,190:INFO:             fastapi: 0.88.0
2023-01-03 23:03:13,191:INFO:             uvicorn: 0.20.0
2023-01-03 23:03:13,191:INFO:              m2cgen: Not installed
2023-01-03 23:03:13,191:INFO:           evidently: Not installed
2023-01-03 23:03:13,191:INFO:                nltk: 3.7
2023-01-03 23:03:13,191:INFO:            pyLDAvis: Not installed
2023-01-03 23:03:13,191:INFO:              gensim: 4.1.2
2023-01-03 23:03:13,191:INFO:               spacy: 3.4.2
2023-01-03 23:03:13,191:INFO:           wordcloud: Not installed
2023-01-03 23:03:13,191:INFO:            textblob: Not installed
2023-01-03 23:03:13,191:INFO:               fugue: Not installed
2023-01-03 23:03:13,191:INFO:           streamlit: Not installed
2023-01-03 23:03:13,191:INFO:             prophet: Not installed
2023-01-03 23:03:13,191:INFO:None
2023-01-03 23:03:13,191:INFO:Set up data.
2023-01-03 23:03:13,227:INFO:Set up train/test split.
2023-01-03 23:03:13,241:INFO:Set up index.
2023-01-03 23:03:13,244:INFO:Set up folding strategy.
2023-01-03 23:03:13,244:INFO:Assigning column types.
2023-01-03 23:03:13,259:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-01-03 23:03:13,259:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-01-03 23:03:13,265:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-03 23:03:13,271:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 23:03:13,351:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 23:03:13,410:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 23:03:13,411:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 23:03:13,607:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 23:03:13,607:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-01-03 23:03:13,613:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-03 23:03:13,623:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 23:03:13,764:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 23:03:13,878:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 23:03:13,879:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 23:03:13,881:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 23:03:13,881:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-01-03 23:03:13,916:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-03 23:03:13,922:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 23:03:14,031:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 23:03:14,088:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 23:03:14,089:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 23:03:14,089:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 23:03:14,094:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-03 23:03:14,104:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 23:03:14,191:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 23:03:14,241:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 23:03:14,242:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 23:03:14,242:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 23:03:14,243:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-01-03 23:03:14,253:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 23:03:14,325:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 23:03:14,375:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 23:03:14,376:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 23:03:14,376:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 23:03:14,387:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-03 23:03:14,460:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 23:03:14,519:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 23:03:14,519:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 23:03:14,520:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 23:03:14,520:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-01-03 23:03:14,609:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 23:03:14,659:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 23:03:14,660:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 23:03:14,660:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 23:03:14,742:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 23:03:14,795:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-03 23:03:14,796:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 23:03:14,796:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 23:03:14,796:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-01-03 23:03:14,881:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 23:03:14,931:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 23:03:14,931:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 23:03:15,013:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-03 23:03:15,064:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 23:03:15,064:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 23:03:15,065:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-01-03 23:03:15,221:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 23:03:15,221:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 23:03:15,386:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 23:03:15,387:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 23:03:15,388:INFO:Preparing preprocessing pipeline...
2023-01-03 23:03:15,390:INFO:Set up simple imputation.
2023-01-03 23:03:15,391:INFO:Set up column transformation.
2023-01-03 23:03:15,391:INFO:Set up feature normalization.
2023-01-03 23:03:16,037:INFO:Finished creating preprocessing pipeline.
2023-01-03 23:03:16,043:INFO:Pipeline: Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2023-01-03 23:03:16,043:INFO:Creating final display dataframe.
2023-01-03 23:03:16,618:INFO:Setup _display_container:                Description             Value
0               Session id               123
1                   Target        b2b+b2c+vt
2              Target type        Regression
3               Data shape       (10487, 48)
4         Train data shape        (7340, 48)
5          Test data shape        (3147, 48)
6         Numeric features                 8
7               Preprocess              True
8          Imputation type            simple
9       Numeric imputation              mean
10  Categorical imputation              mode
11          Transformation              True
12   Transformation method       yeo-johnson
13               Normalize              True
14        Normalize method            zscore
15          Fold Generator   TimeSeriesSplit
16             Fold Number                 5
17                CPU Jobs                -1
18                 Use GPU             False
19          Log Experiment             False
20         Experiment Name  reg-default-name
21                     USI              5190
2023-01-03 23:03:16,759:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 23:03:16,760:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 23:03:16,886:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 23:03:16,887:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-03 23:03:16,887:INFO:setup() successfully completed in 4.12s...............
2023-01-03 23:03:16,888:INFO:Initializing compare_models()
2023-01-03 23:03:16,888:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209971BB610>, include=None, fold=None, round=4, cross_validation=True, sort=MAE, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000209971BB610>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'MAE', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-01-03 23:03:16,888:INFO:Checking exceptions
2023-01-03 23:03:16,893:INFO:Preparing display monitor
2023-01-03 23:03:16,935:INFO:Initializing Linear Regression
2023-01-03 23:03:16,935:INFO:Total runtime is 0.0 minutes
2023-01-03 23:03:16,940:INFO:SubProcess create_model() called ==================================
2023-01-03 23:03:16,940:INFO:Initializing create_model()
2023-01-03 23:03:16,941:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209971BB610>, estimator=lr, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002099719F100>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 23:03:16,941:INFO:Checking exceptions
2023-01-03 23:03:16,941:INFO:Importing libraries
2023-01-03 23:03:16,941:INFO:Copying training dataset
2023-01-03 23:03:16,951:INFO:Defining folds
2023-01-03 23:03:16,951:INFO:Declaring metric variables
2023-01-03 23:03:16,956:INFO:Importing untrained model
2023-01-03 23:03:16,962:INFO:Linear Regression Imported successfully
2023-01-03 23:03:16,971:INFO:Starting cross validation
2023-01-03 23:03:16,977:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 23:03:23,859:INFO:Calculating mean and std
2023-01-03 23:03:23,861:INFO:Creating metrics dataframe
2023-01-03 23:03:23,865:INFO:Uploading results into container
2023-01-03 23:03:23,865:INFO:Uploading model into container now
2023-01-03 23:03:23,866:INFO:_master_model_container: 1
2023-01-03 23:03:23,866:INFO:_display_container: 2
2023-01-03 23:03:23,866:INFO:LinearRegression(n_jobs=-1)
2023-01-03 23:03:23,866:INFO:create_model() successfully completed......................................
2023-01-03 23:03:23,991:INFO:SubProcess create_model() end ==================================
2023-01-03 23:03:23,991:INFO:Creating metrics dataframe
2023-01-03 23:03:23,999:INFO:Initializing Lasso Regression
2023-01-03 23:03:24,000:INFO:Total runtime is 0.11774997711181641 minutes
2023-01-03 23:03:24,003:INFO:SubProcess create_model() called ==================================
2023-01-03 23:03:24,003:INFO:Initializing create_model()
2023-01-03 23:03:24,004:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209971BB610>, estimator=lasso, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002099719F100>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 23:03:24,004:INFO:Checking exceptions
2023-01-03 23:03:24,004:INFO:Importing libraries
2023-01-03 23:03:24,004:INFO:Copying training dataset
2023-01-03 23:03:24,013:INFO:Defining folds
2023-01-03 23:03:24,013:INFO:Declaring metric variables
2023-01-03 23:03:24,018:INFO:Importing untrained model
2023-01-03 23:03:24,023:INFO:Lasso Regression Imported successfully
2023-01-03 23:03:24,030:INFO:Starting cross validation
2023-01-03 23:03:24,031:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 23:03:24,454:INFO:Calculating mean and std
2023-01-03 23:03:24,455:INFO:Creating metrics dataframe
2023-01-03 23:03:24,462:INFO:Uploading results into container
2023-01-03 23:03:24,462:INFO:Uploading model into container now
2023-01-03 23:03:24,463:INFO:_master_model_container: 2
2023-01-03 23:03:24,463:INFO:_display_container: 2
2023-01-03 23:03:24,463:INFO:Lasso(random_state=123)
2023-01-03 23:03:24,463:INFO:create_model() successfully completed......................................
2023-01-03 23:03:24,652:INFO:SubProcess create_model() end ==================================
2023-01-03 23:03:24,652:INFO:Creating metrics dataframe
2023-01-03 23:03:24,661:INFO:Initializing Ridge Regression
2023-01-03 23:03:24,661:INFO:Total runtime is 0.1287727435429891 minutes
2023-01-03 23:03:24,665:INFO:SubProcess create_model() called ==================================
2023-01-03 23:03:24,665:INFO:Initializing create_model()
2023-01-03 23:03:24,666:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209971BB610>, estimator=ridge, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002099719F100>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 23:03:24,666:INFO:Checking exceptions
2023-01-03 23:03:24,666:INFO:Importing libraries
2023-01-03 23:03:24,666:INFO:Copying training dataset
2023-01-03 23:03:24,675:INFO:Defining folds
2023-01-03 23:03:24,676:INFO:Declaring metric variables
2023-01-03 23:03:24,679:INFO:Importing untrained model
2023-01-03 23:03:24,685:INFO:Ridge Regression Imported successfully
2023-01-03 23:03:24,693:INFO:Starting cross validation
2023-01-03 23:03:24,695:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 23:03:24,951:INFO:Calculating mean and std
2023-01-03 23:03:24,955:INFO:Creating metrics dataframe
2023-01-03 23:03:24,959:INFO:Uploading results into container
2023-01-03 23:03:24,960:INFO:Uploading model into container now
2023-01-03 23:03:24,960:INFO:_master_model_container: 3
2023-01-03 23:03:24,960:INFO:_display_container: 2
2023-01-03 23:03:24,960:INFO:Ridge(random_state=123)
2023-01-03 23:03:24,960:INFO:create_model() successfully completed......................................
2023-01-03 23:03:25,059:INFO:SubProcess create_model() end ==================================
2023-01-03 23:03:25,059:INFO:Creating metrics dataframe
2023-01-03 23:03:25,068:INFO:Initializing Elastic Net
2023-01-03 23:03:25,069:INFO:Total runtime is 0.1355800231297811 minutes
2023-01-03 23:03:25,072:INFO:SubProcess create_model() called ==================================
2023-01-03 23:03:25,072:INFO:Initializing create_model()
2023-01-03 23:03:25,073:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209971BB610>, estimator=en, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002099719F100>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 23:03:25,073:INFO:Checking exceptions
2023-01-03 23:03:25,073:INFO:Importing libraries
2023-01-03 23:03:25,073:INFO:Copying training dataset
2023-01-03 23:03:25,082:INFO:Defining folds
2023-01-03 23:03:25,083:INFO:Declaring metric variables
2023-01-03 23:03:25,088:INFO:Importing untrained model
2023-01-03 23:03:25,092:INFO:Elastic Net Imported successfully
2023-01-03 23:03:25,109:INFO:Starting cross validation
2023-01-03 23:03:25,110:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 23:03:25,441:INFO:Calculating mean and std
2023-01-03 23:03:25,443:INFO:Creating metrics dataframe
2023-01-03 23:03:25,446:INFO:Uploading results into container
2023-01-03 23:03:25,446:INFO:Uploading model into container now
2023-01-03 23:03:25,447:INFO:_master_model_container: 4
2023-01-03 23:03:25,447:INFO:_display_container: 2
2023-01-03 23:03:25,447:INFO:ElasticNet(random_state=123)
2023-01-03 23:03:25,447:INFO:create_model() successfully completed......................................
2023-01-03 23:03:25,543:INFO:SubProcess create_model() end ==================================
2023-01-03 23:03:25,544:INFO:Creating metrics dataframe
2023-01-03 23:03:25,556:INFO:Initializing Least Angle Regression
2023-01-03 23:03:25,557:INFO:Total runtime is 0.14371310869852702 minutes
2023-01-03 23:03:25,560:INFO:SubProcess create_model() called ==================================
2023-01-03 23:03:25,561:INFO:Initializing create_model()
2023-01-03 23:03:25,561:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209971BB610>, estimator=lar, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002099719F100>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 23:03:25,561:INFO:Checking exceptions
2023-01-03 23:03:25,561:INFO:Importing libraries
2023-01-03 23:03:25,561:INFO:Copying training dataset
2023-01-03 23:03:25,571:INFO:Defining folds
2023-01-03 23:03:25,571:INFO:Declaring metric variables
2023-01-03 23:03:25,575:INFO:Importing untrained model
2023-01-03 23:03:25,580:INFO:Least Angle Regression Imported successfully
2023-01-03 23:03:25,589:INFO:Starting cross validation
2023-01-03 23:03:25,590:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 23:03:25,661:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 23:03:25,664:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 23:03:25,668:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 23:03:25,722:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 23:03:25,748:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 23:03:25,883:INFO:Calculating mean and std
2023-01-03 23:03:25,885:INFO:Creating metrics dataframe
2023-01-03 23:03:25,889:INFO:Uploading results into container
2023-01-03 23:03:25,890:INFO:Uploading model into container now
2023-01-03 23:03:25,890:INFO:_master_model_container: 5
2023-01-03 23:03:25,891:INFO:_display_container: 2
2023-01-03 23:03:25,891:INFO:Lars(random_state=123)
2023-01-03 23:03:25,891:INFO:create_model() successfully completed......................................
2023-01-03 23:03:25,988:INFO:SubProcess create_model() end ==================================
2023-01-03 23:03:25,988:INFO:Creating metrics dataframe
2023-01-03 23:03:25,998:INFO:Initializing Lasso Least Angle Regression
2023-01-03 23:03:25,998:INFO:Total runtime is 0.15106186072031658 minutes
2023-01-03 23:03:26,001:INFO:SubProcess create_model() called ==================================
2023-01-03 23:03:26,002:INFO:Initializing create_model()
2023-01-03 23:03:26,002:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209971BB610>, estimator=llar, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002099719F100>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 23:03:26,002:INFO:Checking exceptions
2023-01-03 23:03:26,002:INFO:Importing libraries
2023-01-03 23:03:26,002:INFO:Copying training dataset
2023-01-03 23:03:26,012:INFO:Defining folds
2023-01-03 23:03:26,012:INFO:Declaring metric variables
2023-01-03 23:03:26,016:INFO:Importing untrained model
2023-01-03 23:03:26,020:INFO:Lasso Least Angle Regression Imported successfully
2023-01-03 23:03:26,029:INFO:Starting cross validation
2023-01-03 23:03:26,031:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 23:03:26,103:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-03 23:03:26,104:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-03 23:03:26,106:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-03 23:03:26,108:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-03 23:03:26,163:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-03 23:03:26,292:INFO:Calculating mean and std
2023-01-03 23:03:26,294:INFO:Creating metrics dataframe
2023-01-03 23:03:26,297:INFO:Uploading results into container
2023-01-03 23:03:26,297:INFO:Uploading model into container now
2023-01-03 23:03:26,298:INFO:_master_model_container: 6
2023-01-03 23:03:26,298:INFO:_display_container: 2
2023-01-03 23:03:26,298:INFO:LassoLars(random_state=123)
2023-01-03 23:03:26,298:INFO:create_model() successfully completed......................................
2023-01-03 23:03:26,424:INFO:SubProcess create_model() end ==================================
2023-01-03 23:03:26,424:INFO:Creating metrics dataframe
2023-01-03 23:03:26,436:INFO:Initializing Orthogonal Matching Pursuit
2023-01-03 23:03:26,436:INFO:Total runtime is 0.15835237503051758 minutes
2023-01-03 23:03:26,441:INFO:SubProcess create_model() called ==================================
2023-01-03 23:03:26,441:INFO:Initializing create_model()
2023-01-03 23:03:26,442:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209971BB610>, estimator=omp, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002099719F100>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 23:03:26,442:INFO:Checking exceptions
2023-01-03 23:03:26,442:INFO:Importing libraries
2023-01-03 23:03:26,442:INFO:Copying training dataset
2023-01-03 23:03:26,453:INFO:Defining folds
2023-01-03 23:03:26,453:INFO:Declaring metric variables
2023-01-03 23:03:26,457:INFO:Importing untrained model
2023-01-03 23:03:26,461:INFO:Orthogonal Matching Pursuit Imported successfully
2023-01-03 23:03:26,471:INFO:Starting cross validation
2023-01-03 23:03:26,473:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 23:03:26,539:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 23:03:26,542:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 23:03:26,547:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 23:03:26,548:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 23:03:26,594:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-03 23:03:26,723:INFO:Calculating mean and std
2023-01-03 23:03:26,725:INFO:Creating metrics dataframe
2023-01-03 23:03:26,728:INFO:Uploading results into container
2023-01-03 23:03:26,728:INFO:Uploading model into container now
2023-01-03 23:03:26,728:INFO:_master_model_container: 7
2023-01-03 23:03:26,729:INFO:_display_container: 2
2023-01-03 23:03:26,729:INFO:OrthogonalMatchingPursuit()
2023-01-03 23:03:26,729:INFO:create_model() successfully completed......................................
2023-01-03 23:03:26,829:INFO:SubProcess create_model() end ==================================
2023-01-03 23:03:26,830:INFO:Creating metrics dataframe
2023-01-03 23:03:26,843:INFO:Initializing Bayesian Ridge
2023-01-03 23:03:26,843:INFO:Total runtime is 0.16513621012369792 minutes
2023-01-03 23:03:26,847:INFO:SubProcess create_model() called ==================================
2023-01-03 23:03:26,848:INFO:Initializing create_model()
2023-01-03 23:03:26,848:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209971BB610>, estimator=br, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002099719F100>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 23:03:26,848:INFO:Checking exceptions
2023-01-03 23:03:26,848:INFO:Importing libraries
2023-01-03 23:03:26,848:INFO:Copying training dataset
2023-01-03 23:03:26,858:INFO:Defining folds
2023-01-03 23:03:26,858:INFO:Declaring metric variables
2023-01-03 23:03:26,861:INFO:Importing untrained model
2023-01-03 23:03:26,868:INFO:Bayesian Ridge Imported successfully
2023-01-03 23:03:26,877:INFO:Starting cross validation
2023-01-03 23:03:26,878:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 23:03:27,170:INFO:Calculating mean and std
2023-01-03 23:03:27,172:INFO:Creating metrics dataframe
2023-01-03 23:03:27,175:INFO:Uploading results into container
2023-01-03 23:03:27,175:INFO:Uploading model into container now
2023-01-03 23:03:27,175:INFO:_master_model_container: 8
2023-01-03 23:03:27,175:INFO:_display_container: 2
2023-01-03 23:03:27,176:INFO:BayesianRidge()
2023-01-03 23:03:27,176:INFO:create_model() successfully completed......................................
2023-01-03 23:03:27,273:INFO:SubProcess create_model() end ==================================
2023-01-03 23:03:27,273:INFO:Creating metrics dataframe
2023-01-03 23:03:27,288:INFO:Initializing Passive Aggressive Regressor
2023-01-03 23:03:27,288:INFO:Total runtime is 0.17255518039067586 minutes
2023-01-03 23:03:27,292:INFO:SubProcess create_model() called ==================================
2023-01-03 23:03:27,292:INFO:Initializing create_model()
2023-01-03 23:03:27,293:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209971BB610>, estimator=par, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002099719F100>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 23:03:27,293:INFO:Checking exceptions
2023-01-03 23:03:27,293:INFO:Importing libraries
2023-01-03 23:03:27,293:INFO:Copying training dataset
2023-01-03 23:03:27,303:INFO:Defining folds
2023-01-03 23:03:27,303:INFO:Declaring metric variables
2023-01-03 23:03:27,308:INFO:Importing untrained model
2023-01-03 23:03:27,312:INFO:Passive Aggressive Regressor Imported successfully
2023-01-03 23:03:27,323:INFO:Starting cross validation
2023-01-03 23:03:27,324:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 23:03:27,598:INFO:Calculating mean and std
2023-01-03 23:03:27,600:INFO:Creating metrics dataframe
2023-01-03 23:03:27,605:INFO:Uploading results into container
2023-01-03 23:03:27,606:INFO:Uploading model into container now
2023-01-03 23:03:27,607:INFO:_master_model_container: 9
2023-01-03 23:03:27,607:INFO:_display_container: 2
2023-01-03 23:03:27,607:INFO:PassiveAggressiveRegressor(random_state=123)
2023-01-03 23:03:27,607:INFO:create_model() successfully completed......................................
2023-01-03 23:03:27,709:INFO:SubProcess create_model() end ==================================
2023-01-03 23:03:27,710:INFO:Creating metrics dataframe
2023-01-03 23:03:27,720:INFO:Initializing Huber Regressor
2023-01-03 23:03:27,720:INFO:Total runtime is 0.1797536015510559 minutes
2023-01-03 23:03:27,724:INFO:SubProcess create_model() called ==================================
2023-01-03 23:03:27,724:INFO:Initializing create_model()
2023-01-03 23:03:27,724:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209971BB610>, estimator=huber, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002099719F100>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 23:03:27,724:INFO:Checking exceptions
2023-01-03 23:03:27,724:INFO:Importing libraries
2023-01-03 23:03:27,724:INFO:Copying training dataset
2023-01-03 23:03:27,734:INFO:Defining folds
2023-01-03 23:03:27,734:INFO:Declaring metric variables
2023-01-03 23:03:27,739:INFO:Importing untrained model
2023-01-03 23:03:27,743:INFO:Huber Regressor Imported successfully
2023-01-03 23:03:27,752:INFO:Starting cross validation
2023-01-03 23:03:27,754:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 23:03:27,923:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-03 23:03:27,990:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-03 23:03:28,051:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-03 23:03:28,213:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-03 23:03:28,358:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-03 23:03:28,483:INFO:Calculating mean and std
2023-01-03 23:03:28,485:INFO:Creating metrics dataframe
2023-01-03 23:03:28,488:INFO:Uploading results into container
2023-01-03 23:03:28,488:INFO:Uploading model into container now
2023-01-03 23:03:28,489:INFO:_master_model_container: 10
2023-01-03 23:03:28,489:INFO:_display_container: 2
2023-01-03 23:03:28,489:INFO:HuberRegressor()
2023-01-03 23:03:28,489:INFO:create_model() successfully completed......................................
2023-01-03 23:03:28,586:INFO:SubProcess create_model() end ==================================
2023-01-03 23:03:28,586:INFO:Creating metrics dataframe
2023-01-03 23:03:28,598:INFO:Initializing K Neighbors Regressor
2023-01-03 23:03:28,598:INFO:Total runtime is 0.19439328114191692 minutes
2023-01-03 23:03:28,603:INFO:SubProcess create_model() called ==================================
2023-01-03 23:03:28,604:INFO:Initializing create_model()
2023-01-03 23:03:28,604:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209971BB610>, estimator=knn, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002099719F100>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 23:03:28,604:INFO:Checking exceptions
2023-01-03 23:03:28,604:INFO:Importing libraries
2023-01-03 23:03:28,604:INFO:Copying training dataset
2023-01-03 23:03:28,615:INFO:Defining folds
2023-01-03 23:03:28,615:INFO:Declaring metric variables
2023-01-03 23:03:28,620:INFO:Importing untrained model
2023-01-03 23:03:28,624:INFO:K Neighbors Regressor Imported successfully
2023-01-03 23:03:28,642:INFO:Starting cross validation
2023-01-03 23:03:28,644:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 23:03:29,344:INFO:Calculating mean and std
2023-01-03 23:03:29,346:INFO:Creating metrics dataframe
2023-01-03 23:03:29,349:INFO:Uploading results into container
2023-01-03 23:03:29,349:INFO:Uploading model into container now
2023-01-03 23:03:29,349:INFO:_master_model_container: 11
2023-01-03 23:03:29,350:INFO:_display_container: 2
2023-01-03 23:03:29,350:INFO:KNeighborsRegressor(n_jobs=-1)
2023-01-03 23:03:29,350:INFO:create_model() successfully completed......................................
2023-01-03 23:03:29,448:INFO:SubProcess create_model() end ==================================
2023-01-03 23:03:29,448:INFO:Creating metrics dataframe
2023-01-03 23:03:29,462:INFO:Initializing Decision Tree Regressor
2023-01-03 23:03:29,462:INFO:Total runtime is 0.20878407955169678 minutes
2023-01-03 23:03:29,466:INFO:SubProcess create_model() called ==================================
2023-01-03 23:03:29,467:INFO:Initializing create_model()
2023-01-03 23:03:29,467:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209971BB610>, estimator=dt, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002099719F100>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 23:03:29,468:INFO:Checking exceptions
2023-01-03 23:03:29,468:INFO:Importing libraries
2023-01-03 23:03:29,468:INFO:Copying training dataset
2023-01-03 23:03:29,477:INFO:Defining folds
2023-01-03 23:03:29,478:INFO:Declaring metric variables
2023-01-03 23:03:29,492:INFO:Importing untrained model
2023-01-03 23:03:29,496:INFO:Decision Tree Regressor Imported successfully
2023-01-03 23:03:29,520:INFO:Starting cross validation
2023-01-03 23:03:29,521:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 23:03:30,071:INFO:Calculating mean and std
2023-01-03 23:03:30,073:INFO:Creating metrics dataframe
2023-01-03 23:03:30,076:INFO:Uploading results into container
2023-01-03 23:03:30,076:INFO:Uploading model into container now
2023-01-03 23:03:30,076:INFO:_master_model_container: 12
2023-01-03 23:03:30,076:INFO:_display_container: 2
2023-01-03 23:03:30,077:INFO:DecisionTreeRegressor(random_state=123)
2023-01-03 23:03:30,077:INFO:create_model() successfully completed......................................
2023-01-03 23:03:30,176:INFO:SubProcess create_model() end ==================================
2023-01-03 23:03:30,177:INFO:Creating metrics dataframe
2023-01-03 23:03:30,191:INFO:Initializing Random Forest Regressor
2023-01-03 23:03:30,192:INFO:Total runtime is 0.22095826466878254 minutes
2023-01-03 23:03:30,196:INFO:SubProcess create_model() called ==================================
2023-01-03 23:03:30,196:INFO:Initializing create_model()
2023-01-03 23:03:30,196:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209971BB610>, estimator=rf, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002099719F100>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 23:03:30,196:INFO:Checking exceptions
2023-01-03 23:03:30,197:INFO:Importing libraries
2023-01-03 23:03:30,197:INFO:Copying training dataset
2023-01-03 23:03:30,206:INFO:Defining folds
2023-01-03 23:03:30,207:INFO:Declaring metric variables
2023-01-03 23:03:30,211:INFO:Importing untrained model
2023-01-03 23:03:30,216:INFO:Random Forest Regressor Imported successfully
2023-01-03 23:03:30,225:INFO:Starting cross validation
2023-01-03 23:03:30,227:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 23:03:41,429:INFO:Calculating mean and std
2023-01-03 23:03:41,431:INFO:Creating metrics dataframe
2023-01-03 23:03:41,436:INFO:Uploading results into container
2023-01-03 23:03:41,438:INFO:Uploading model into container now
2023-01-03 23:03:41,438:INFO:_master_model_container: 13
2023-01-03 23:03:41,438:INFO:_display_container: 2
2023-01-03 23:03:41,439:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-01-03 23:03:41,439:INFO:create_model() successfully completed......................................
2023-01-03 23:03:41,540:INFO:SubProcess create_model() end ==================================
2023-01-03 23:03:41,541:INFO:Creating metrics dataframe
2023-01-03 23:03:41,553:INFO:Initializing Extra Trees Regressor
2023-01-03 23:03:41,553:INFO:Total runtime is 0.41029844284057615 minutes
2023-01-03 23:03:41,557:INFO:SubProcess create_model() called ==================================
2023-01-03 23:03:41,557:INFO:Initializing create_model()
2023-01-03 23:03:41,557:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209971BB610>, estimator=et, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002099719F100>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 23:03:41,558:INFO:Checking exceptions
2023-01-03 23:03:41,558:INFO:Importing libraries
2023-01-03 23:03:41,558:INFO:Copying training dataset
2023-01-03 23:03:41,567:INFO:Defining folds
2023-01-03 23:03:41,567:INFO:Declaring metric variables
2023-01-03 23:03:41,572:INFO:Importing untrained model
2023-01-03 23:03:41,576:INFO:Extra Trees Regressor Imported successfully
2023-01-03 23:03:41,585:INFO:Starting cross validation
2023-01-03 23:03:41,587:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 23:03:46,222:INFO:Calculating mean and std
2023-01-03 23:03:46,224:INFO:Creating metrics dataframe
2023-01-03 23:03:46,227:INFO:Uploading results into container
2023-01-03 23:03:46,228:INFO:Uploading model into container now
2023-01-03 23:03:46,228:INFO:_master_model_container: 14
2023-01-03 23:03:46,228:INFO:_display_container: 2
2023-01-03 23:03:46,229:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-01-03 23:03:46,229:INFO:create_model() successfully completed......................................
2023-01-03 23:03:46,331:INFO:SubProcess create_model() end ==================================
2023-01-03 23:03:46,331:INFO:Creating metrics dataframe
2023-01-03 23:03:46,346:INFO:Initializing AdaBoost Regressor
2023-01-03 23:03:46,346:INFO:Total runtime is 0.4901817798614502 minutes
2023-01-03 23:03:46,350:INFO:SubProcess create_model() called ==================================
2023-01-03 23:03:46,351:INFO:Initializing create_model()
2023-01-03 23:03:46,351:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209971BB610>, estimator=ada, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002099719F100>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 23:03:46,351:INFO:Checking exceptions
2023-01-03 23:03:46,351:INFO:Importing libraries
2023-01-03 23:03:46,351:INFO:Copying training dataset
2023-01-03 23:03:46,361:INFO:Defining folds
2023-01-03 23:03:46,361:INFO:Declaring metric variables
2023-01-03 23:03:46,365:INFO:Importing untrained model
2023-01-03 23:03:46,370:INFO:AdaBoost Regressor Imported successfully
2023-01-03 23:03:46,378:INFO:Starting cross validation
2023-01-03 23:03:46,380:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 23:03:49,309:INFO:Calculating mean and std
2023-01-03 23:03:49,310:INFO:Creating metrics dataframe
2023-01-03 23:03:49,314:INFO:Uploading results into container
2023-01-03 23:03:49,314:INFO:Uploading model into container now
2023-01-03 23:03:49,315:INFO:_master_model_container: 15
2023-01-03 23:03:49,315:INFO:_display_container: 2
2023-01-03 23:03:49,316:INFO:AdaBoostRegressor(random_state=123)
2023-01-03 23:03:49,316:INFO:create_model() successfully completed......................................
2023-01-03 23:03:49,434:INFO:SubProcess create_model() end ==================================
2023-01-03 23:03:49,434:INFO:Creating metrics dataframe
2023-01-03 23:03:49,447:INFO:Initializing Gradient Boosting Regressor
2023-01-03 23:03:49,447:INFO:Total runtime is 0.5418647686640421 minutes
2023-01-03 23:03:49,450:INFO:SubProcess create_model() called ==================================
2023-01-03 23:03:49,451:INFO:Initializing create_model()
2023-01-03 23:03:49,451:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209971BB610>, estimator=gbr, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002099719F100>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 23:03:49,451:INFO:Checking exceptions
2023-01-03 23:03:49,451:INFO:Importing libraries
2023-01-03 23:03:49,451:INFO:Copying training dataset
2023-01-03 23:03:49,461:INFO:Defining folds
2023-01-03 23:03:49,461:INFO:Declaring metric variables
2023-01-03 23:03:49,465:INFO:Importing untrained model
2023-01-03 23:03:49,469:INFO:Gradient Boosting Regressor Imported successfully
2023-01-03 23:03:49,476:INFO:Starting cross validation
2023-01-03 23:03:49,477:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 23:03:54,905:INFO:Calculating mean and std
2023-01-03 23:03:54,907:INFO:Creating metrics dataframe
2023-01-03 23:03:54,913:INFO:Uploading results into container
2023-01-03 23:03:54,914:INFO:Uploading model into container now
2023-01-03 23:03:54,914:INFO:_master_model_container: 16
2023-01-03 23:03:54,914:INFO:_display_container: 2
2023-01-03 23:03:54,914:INFO:GradientBoostingRegressor(random_state=123)
2023-01-03 23:03:54,914:INFO:create_model() successfully completed......................................
2023-01-03 23:03:55,027:INFO:SubProcess create_model() end ==================================
2023-01-03 23:03:55,027:INFO:Creating metrics dataframe
2023-01-03 23:03:55,041:INFO:Initializing Light Gradient Boosting Machine
2023-01-03 23:03:55,041:INFO:Total runtime is 0.6351101915041605 minutes
2023-01-03 23:03:55,045:INFO:SubProcess create_model() called ==================================
2023-01-03 23:03:55,046:INFO:Initializing create_model()
2023-01-03 23:03:55,046:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209971BB610>, estimator=lightgbm, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002099719F100>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 23:03:55,046:INFO:Checking exceptions
2023-01-03 23:03:55,046:INFO:Importing libraries
2023-01-03 23:03:55,046:INFO:Copying training dataset
2023-01-03 23:03:55,056:INFO:Defining folds
2023-01-03 23:03:55,056:INFO:Declaring metric variables
2023-01-03 23:03:55,061:INFO:Importing untrained model
2023-01-03 23:03:55,065:INFO:Light Gradient Boosting Machine Imported successfully
2023-01-03 23:03:55,075:INFO:Starting cross validation
2023-01-03 23:03:55,077:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 23:03:57,407:INFO:Calculating mean and std
2023-01-03 23:03:57,409:INFO:Creating metrics dataframe
2023-01-03 23:03:57,413:INFO:Uploading results into container
2023-01-03 23:03:57,414:INFO:Uploading model into container now
2023-01-03 23:03:57,415:INFO:_master_model_container: 17
2023-01-03 23:03:57,415:INFO:_display_container: 2
2023-01-03 23:03:57,415:INFO:LGBMRegressor(random_state=123)
2023-01-03 23:03:57,415:INFO:create_model() successfully completed......................................
2023-01-03 23:03:57,515:INFO:SubProcess create_model() end ==================================
2023-01-03 23:03:57,515:INFO:Creating metrics dataframe
2023-01-03 23:03:57,531:INFO:Initializing Dummy Regressor
2023-01-03 23:03:57,531:INFO:Total runtime is 0.6766034245491027 minutes
2023-01-03 23:03:57,536:INFO:SubProcess create_model() called ==================================
2023-01-03 23:03:57,537:INFO:Initializing create_model()
2023-01-03 23:03:57,537:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209971BB610>, estimator=dummy, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002099719F100>, model_only=True, return_train_score=False, kwargs={})
2023-01-03 23:03:57,537:INFO:Checking exceptions
2023-01-03 23:03:57,537:INFO:Importing libraries
2023-01-03 23:03:57,537:INFO:Copying training dataset
2023-01-03 23:03:57,547:INFO:Defining folds
2023-01-03 23:03:57,547:INFO:Declaring metric variables
2023-01-03 23:03:57,552:INFO:Importing untrained model
2023-01-03 23:03:57,556:INFO:Dummy Regressor Imported successfully
2023-01-03 23:03:57,564:INFO:Starting cross validation
2023-01-03 23:03:57,566:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 23:03:57,818:INFO:Calculating mean and std
2023-01-03 23:03:57,820:INFO:Creating metrics dataframe
2023-01-03 23:03:57,826:INFO:Uploading results into container
2023-01-03 23:03:57,827:INFO:Uploading model into container now
2023-01-03 23:03:57,827:INFO:_master_model_container: 18
2023-01-03 23:03:57,827:INFO:_display_container: 2
2023-01-03 23:03:57,828:INFO:DummyRegressor()
2023-01-03 23:03:57,828:INFO:create_model() successfully completed......................................
2023-01-03 23:03:57,934:INFO:SubProcess create_model() end ==================================
2023-01-03 23:03:57,934:INFO:Creating metrics dataframe
2023-01-03 23:03:57,962:INFO:Initializing create_model()
2023-01-03 23:03:57,963:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209971BB610>, estimator=LGBMRegressor(random_state=123), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-01-03 23:03:57,963:INFO:Checking exceptions
2023-01-03 23:03:57,965:INFO:Importing libraries
2023-01-03 23:03:57,965:INFO:Copying training dataset
2023-01-03 23:03:57,974:INFO:Defining folds
2023-01-03 23:03:57,974:INFO:Declaring metric variables
2023-01-03 23:03:57,975:INFO:Importing untrained model
2023-01-03 23:03:57,975:INFO:Declaring custom model
2023-01-03 23:03:57,975:INFO:Light Gradient Boosting Machine Imported successfully
2023-01-03 23:03:57,976:INFO:Cross validation set to False
2023-01-03 23:03:57,976:INFO:Fitting Model
2023-01-03 23:03:58,337:INFO:LGBMRegressor(random_state=123)
2023-01-03 23:03:58,337:INFO:create_model() successfully completed......................................
2023-01-03 23:03:58,498:INFO:_master_model_container: 18
2023-01-03 23:03:58,498:INFO:_display_container: 2
2023-01-03 23:03:58,498:INFO:LGBMRegressor(random_state=123)
2023-01-03 23:03:58,498:INFO:compare_models() successfully completed......................................
2023-01-03 23:03:58,499:INFO:Initializing tune_model()
2023-01-03 23:03:58,499:INFO:tune_model(estimator=LGBMRegressor(random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=MAE, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209971BB610>)
2023-01-03 23:03:58,500:INFO:Checking exceptions
2023-01-03 23:03:58,542:INFO:Copying training dataset
2023-01-03 23:03:58,554:INFO:Checking base model
2023-01-03 23:03:58,554:INFO:Base model : Light Gradient Boosting Machine
2023-01-03 23:03:58,560:INFO:Declaring metric variables
2023-01-03 23:03:58,563:INFO:Defining Hyperparameters
2023-01-03 23:03:58,690:INFO:Tuning with n_jobs=-1
2023-01-03 23:03:58,690:INFO:Initializing RandomizedSearchCV
2023-01-03 23:04:05,898:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2023-01-03 23:04:05,906:INFO:Hyperparameter search completed
2023-01-03 23:04:05,907:INFO:SubProcess create_model() called ==================================
2023-01-03 23:04:05,907:INFO:Initializing create_model()
2023-01-03 23:04:05,907:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209971BB610>, estimator=LGBMRegressor(random_state=123), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209A42B6A00>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2023-01-03 23:04:05,907:INFO:Checking exceptions
2023-01-03 23:04:05,908:INFO:Importing libraries
2023-01-03 23:04:05,908:INFO:Copying training dataset
2023-01-03 23:04:05,916:INFO:Defining folds
2023-01-03 23:04:05,917:INFO:Declaring metric variables
2023-01-03 23:04:05,922:INFO:Importing untrained model
2023-01-03 23:04:05,922:INFO:Declaring custom model
2023-01-03 23:04:05,926:INFO:Light Gradient Boosting Machine Imported successfully
2023-01-03 23:04:05,933:INFO:Starting cross validation
2023-01-03 23:04:05,934:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 23:04:07,470:INFO:Calculating mean and std
2023-01-03 23:04:07,472:INFO:Creating metrics dataframe
2023-01-03 23:04:07,477:INFO:Finalizing model
2023-01-03 23:04:08,108:INFO:Uploading results into container
2023-01-03 23:04:08,110:INFO:Uploading model into container now
2023-01-03 23:04:08,111:INFO:_master_model_container: 19
2023-01-03 23:04:08,111:INFO:_display_container: 3
2023-01-03 23:04:08,112:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              num_leaves=70, random_state=123, reg_alpha=2, reg_lambda=3)
2023-01-03 23:04:08,112:INFO:create_model() successfully completed......................................
2023-01-03 23:04:08,227:INFO:SubProcess create_model() end ==================================
2023-01-03 23:04:08,227:INFO:choose_better activated
2023-01-03 23:04:08,231:INFO:SubProcess create_model() called ==================================
2023-01-03 23:04:08,231:INFO:Initializing create_model()
2023-01-03 23:04:08,231:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209971BB610>, estimator=LGBMRegressor(random_state=123), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-01-03 23:04:08,232:INFO:Checking exceptions
2023-01-03 23:04:08,234:INFO:Importing libraries
2023-01-03 23:04:08,234:INFO:Copying training dataset
2023-01-03 23:04:08,242:INFO:Defining folds
2023-01-03 23:04:08,242:INFO:Declaring metric variables
2023-01-03 23:04:08,243:INFO:Importing untrained model
2023-01-03 23:04:08,243:INFO:Declaring custom model
2023-01-03 23:04:08,243:INFO:Light Gradient Boosting Machine Imported successfully
2023-01-03 23:04:08,244:INFO:Starting cross validation
2023-01-03 23:04:08,245:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-03 23:04:09,619:INFO:Calculating mean and std
2023-01-03 23:04:09,619:INFO:Creating metrics dataframe
2023-01-03 23:04:09,621:INFO:Finalizing model
2023-01-03 23:04:10,254:INFO:Uploading results into container
2023-01-03 23:04:10,255:INFO:Uploading model into container now
2023-01-03 23:04:10,255:INFO:_master_model_container: 20
2023-01-03 23:04:10,255:INFO:_display_container: 4
2023-01-03 23:04:10,255:INFO:LGBMRegressor(random_state=123)
2023-01-03 23:04:10,255:INFO:create_model() successfully completed......................................
2023-01-03 23:04:10,364:INFO:SubProcess create_model() end ==================================
2023-01-03 23:04:10,365:INFO:LGBMRegressor(random_state=123) result for MAE is 2.1036
2023-01-03 23:04:10,365:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              num_leaves=70, random_state=123, reg_alpha=2, reg_lambda=3) result for MAE is 2.3306
2023-01-03 23:04:10,366:INFO:LGBMRegressor(random_state=123) is best model
2023-01-03 23:04:10,366:INFO:choose_better completed
2023-01-03 23:04:10,366:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-01-03 23:04:10,375:INFO:_master_model_container: 20
2023-01-03 23:04:10,375:INFO:_display_container: 3
2023-01-03 23:04:10,375:INFO:LGBMRegressor(random_state=123)
2023-01-03 23:04:10,375:INFO:tune_model() successfully completed......................................
2023-01-03 23:04:10,484:INFO:Initializing plot_model()
2023-01-03 23:04:10,484:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LGBMRegressor(random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209971BB610>, system=True)
2023-01-03 23:04:10,485:INFO:Checking exceptions
2023-01-03 23:04:10,492:INFO:Preloading libraries
2023-01-03 23:04:10,498:INFO:Copying training dataset
2023-01-03 23:04:10,498:INFO:Plot type: error
2023-01-03 23:04:10,776:INFO:Fitting Model
2023-01-03 23:04:10,776:INFO:Scoring test/hold-out set
2023-01-03 23:04:11,239:INFO:Visual Rendered Successfully
2023-01-03 23:04:11,358:INFO:plot_model() successfully completed......................................
2023-01-03 23:04:11,359:INFO:Initializing predict_model()
2023-01-03 23:04:11,360:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209971BB610>, estimator=LGBMRegressor(random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x00000209A43FBDC0>)
2023-01-03 23:04:11,360:INFO:Checking exceptions
2023-01-03 23:04:11,360:INFO:Preloading libraries
2023-01-03 23:04:11,525:INFO:Initializing finalize_model()
2023-01-03 23:04:11,525:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209971BB610>, estimator=LGBMRegressor(random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-01-03 23:04:11,526:INFO:Finalizing LGBMRegressor(random_state=123)
2023-01-03 23:04:11,534:INFO:Initializing create_model()
2023-01-03 23:04:11,534:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209971BB610>, estimator=LGBMRegressor(random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-01-03 23:04:11,534:INFO:Checking exceptions
2023-01-03 23:04:11,536:INFO:Importing libraries
2023-01-03 23:04:11,536:INFO:Copying training dataset
2023-01-03 23:04:11,537:INFO:Defining folds
2023-01-03 23:04:11,537:INFO:Declaring metric variables
2023-01-03 23:04:11,537:INFO:Importing untrained model
2023-01-03 23:04:11,537:INFO:Declaring custom model
2023-01-03 23:04:11,538:INFO:Light Gradient Boosting Machine Imported successfully
2023-01-03 23:04:11,538:INFO:Cross validation set to False
2023-01-03 23:04:11,539:INFO:Fitting Model
2023-01-03 23:04:12,600:INFO:Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator', LGBMRegressor(random_state=123))])
2023-01-03 23:04:12,600:INFO:create_model() successfully completed......................................
2023-01-03 23:04:12,706:INFO:_master_model_container: 20
2023-01-03 23:04:12,706:INFO:_display_container: 4
2023-01-03 23:04:12,713:INFO:Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator', LGBMRegressor(random_state=123))])
2023-01-03 23:04:12,713:INFO:finalize_model() successfully completed......................................
2023-01-03 23:04:12,823:INFO:Initializing predict_model()
2023-01-03 23:04:12,823:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000209971BB610>, estimator=Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator', LGBMRegressor(random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x00000209A43FBC10>)
2023-01-03 23:04:12,823:INFO:Checking exceptions
2023-01-03 23:04:12,823:INFO:Preloading libraries
2023-01-03 23:04:12,825:INFO:Set up data.
2023-01-03 23:04:12,841:INFO:Set up index.
2023-01-03 23:04:13,288:INFO:Initializing save_model()
2023-01-03 23:04:13,288:INFO:save_model(model=Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator', LGBMRegressor(random_state=123))]), model_name=c:\Users\Kodotautas\Desktop\Data_science\7_TIME_SERIES_FORECAST_PYCARET/models/final_model.pkl, prep_pipe_=Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-01-03 23:04:13,288:INFO:Adding model into prep_pipe
2023-01-03 23:04:13,298:WARNING:Only Model saved as it was a pipeline.
2023-01-03 23:04:13,306:INFO:c:\Users\Kodotautas\Desktop\Data_science\7_TIME_SERIES_FORECAST_PYCARET/models/final_model.pkl.pkl saved in current working directory
2023-01-03 23:04:13,313:INFO:Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator', LGBMRegressor(random_state=123))])
2023-01-03 23:04:13,313:INFO:save_model() successfully completed......................................
2023-01-05 20:26:44,807:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-01-05 20:26:44,807:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-01-05 20:26:44,807:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-01-05 20:26:44,807:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-01-05 20:26:45,846:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-01-05 20:26:46,293:INFO:PyCaret RegressionExperiment
2023-01-05 20:26:46,294:INFO:Logging name: reg-default-name
2023-01-05 20:26:46,294:INFO:ML Usecase: MLUsecase.REGRESSION
2023-01-05 20:26:46,294:INFO:version 3.0.0.rc6
2023-01-05 20:26:46,294:INFO:Initializing setup()
2023-01-05 20:26:46,294:INFO:self.USI: 32d7
2023-01-05 20:26:46,294:INFO:self._variable_keys: {'X_test', 'fold_groups_param', 'y', 'data', 'seed', '_ml_usecase', 'pipeline', 'memory', 'USI', 'fold_shuffle_param', 'target_param', 'X_train', 'X', 'transform_target_param', 'html_param', '_available_plots', 'exp_name_log', 'fold_generator', 'logging_param', 'n_jobs_param', 'exp_id', 'y_train', 'gpu_param', 'log_plots_param', 'idx', 'gpu_n_jobs_param', 'y_test'}
2023-01-05 20:26:46,294:INFO:Checking environment
2023-01-05 20:26:46,294:INFO:python_version: 3.9.13
2023-01-05 20:26:46,294:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-01-05 20:26:46,294:INFO:machine: AMD64
2023-01-05 20:26:46,294:INFO:platform: Windows-10-10.0.19044-SP0
2023-01-05 20:26:46,294:INFO:Memory: svmem(total=17114804224, available=9706188800, percent=43.3, used=7408615424, free=9706188800)
2023-01-05 20:26:46,294:INFO:Physical Core: 4
2023-01-05 20:26:46,294:INFO:Logical Core: 4
2023-01-05 20:26:46,294:INFO:Checking libraries
2023-01-05 20:26:46,294:INFO:System:
2023-01-05 20:26:46,294:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-01-05 20:26:46,294:INFO:executable: c:\Users\Kodotautas\anaconda3\python.exe
2023-01-05 20:26:46,294:INFO:   machine: Windows-10-10.0.19044-SP0
2023-01-05 20:26:46,294:INFO:PyCaret required dependencies:
2023-01-05 20:26:46,295:INFO:                 pip: 22.2.2
2023-01-05 20:26:46,295:INFO:          setuptools: 63.4.1
2023-01-05 20:26:46,295:INFO:             pycaret: 3.0.0rc6
2023-01-05 20:26:46,295:INFO:             IPython: 7.31.1
2023-01-05 20:26:46,295:INFO:          ipywidgets: 7.6.5
2023-01-05 20:26:46,295:INFO:                tqdm: 4.64.1
2023-01-05 20:26:46,295:INFO:               numpy: 1.21.5
2023-01-05 20:26:46,295:INFO:              pandas: 1.4.4
2023-01-05 20:26:46,295:INFO:              jinja2: 2.11.3
2023-01-05 20:26:46,295:INFO:               scipy: 1.9.1
2023-01-05 20:26:46,295:INFO:              joblib: 1.2.0
2023-01-05 20:26:46,295:INFO:             sklearn: 1.0.2
2023-01-05 20:26:46,295:INFO:                pyod: 1.0.7
2023-01-05 20:26:46,295:INFO:            imblearn: 0.10.1
2023-01-05 20:26:46,295:INFO:   category_encoders: 2.5.1.post0
2023-01-05 20:26:46,295:INFO:            lightgbm: 3.3.3
2023-01-05 20:26:46,295:INFO:               numba: 0.55.1
2023-01-05 20:26:46,295:INFO:            requests: 2.28.1
2023-01-05 20:26:46,295:INFO:          matplotlib: 3.5.2
2023-01-05 20:26:46,295:INFO:          scikitplot: 0.3.7
2023-01-05 20:26:46,296:INFO:         yellowbrick: 1.5
2023-01-05 20:26:46,296:INFO:              plotly: 5.9.0
2023-01-05 20:26:46,296:INFO:             kaleido: 0.2.1
2023-01-05 20:26:46,296:INFO:         statsmodels: 0.13.2
2023-01-05 20:26:46,296:INFO:              sktime: 0.14.1
2023-01-05 20:26:46,296:INFO:               tbats: 1.1.2
2023-01-05 20:26:46,296:INFO:            pmdarima: 2.0.2
2023-01-05 20:26:46,296:INFO:              psutil: 5.9.0
2023-01-05 20:26:46,296:INFO:PyCaret optional dependencies:
2023-01-05 20:26:46,730:INFO:                shap: 0.41.0
2023-01-05 20:26:46,730:INFO:           interpret: Not installed
2023-01-05 20:26:46,730:INFO:                umap: Not installed
2023-01-05 20:26:46,730:INFO:    pandas_profiling: Not installed
2023-01-05 20:26:46,730:INFO:  explainerdashboard: Not installed
2023-01-05 20:26:46,730:INFO:             autoviz: Not installed
2023-01-05 20:26:46,730:INFO:           fairlearn: Not installed
2023-01-05 20:26:46,730:INFO:             xgboost: Not installed
2023-01-05 20:26:46,730:INFO:            catboost: Not installed
2023-01-05 20:26:46,730:INFO:              kmodes: Not installed
2023-01-05 20:26:46,730:INFO:             mlxtend: Not installed
2023-01-05 20:26:46,730:INFO:       statsforecast: Not installed
2023-01-05 20:26:46,730:INFO:        tune_sklearn: 0.4.3
2023-01-05 20:26:46,730:INFO:                 ray: 2.0.0
2023-01-05 20:26:46,730:INFO:            hyperopt: 0.2.7
2023-01-05 20:26:46,730:INFO:              optuna: 3.0.1
2023-01-05 20:26:46,730:INFO:               skopt: 0.9.0
2023-01-05 20:26:46,730:INFO:              mlflow: Not installed
2023-01-05 20:26:46,730:INFO:              gradio: Not installed
2023-01-05 20:26:46,731:INFO:             fastapi: 0.88.0
2023-01-05 20:26:46,731:INFO:             uvicorn: 0.20.0
2023-01-05 20:26:46,731:INFO:              m2cgen: Not installed
2023-01-05 20:26:46,731:INFO:           evidently: Not installed
2023-01-05 20:26:46,731:INFO:                nltk: 3.7
2023-01-05 20:26:46,731:INFO:            pyLDAvis: Not installed
2023-01-05 20:26:46,731:INFO:              gensim: 4.1.2
2023-01-05 20:26:46,731:INFO:               spacy: 3.4.2
2023-01-05 20:26:46,731:INFO:           wordcloud: Not installed
2023-01-05 20:26:46,731:INFO:            textblob: Not installed
2023-01-05 20:26:46,731:INFO:               fugue: Not installed
2023-01-05 20:26:46,731:INFO:           streamlit: Not installed
2023-01-05 20:26:46,731:INFO:             prophet: Not installed
2023-01-05 20:26:46,731:INFO:None
2023-01-05 20:26:46,731:INFO:Set up data.
2023-01-05 20:26:46,751:INFO:Set up train/test split.
2023-01-05 20:26:46,764:INFO:Set up index.
2023-01-05 20:26:46,766:INFO:Set up folding strategy.
2023-01-05 20:26:46,766:INFO:Assigning column types.
2023-01-05 20:26:46,776:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-01-05 20:26:46,777:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-01-05 20:26:46,781:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-05 20:26:46,786:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-05 20:26:46,853:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-05 20:26:46,901:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-05 20:26:46,903:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:26:47,073:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:26:47,074:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-01-05 20:26:47,078:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-05 20:26:47,083:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-05 20:26:47,149:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-05 20:26:47,197:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-05 20:26:47,198:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:26:47,198:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:26:47,199:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-01-05 20:26:47,204:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-05 20:26:47,209:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-05 20:26:47,279:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-05 20:26:47,327:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-05 20:26:47,327:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:26:47,328:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:26:47,333:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-05 20:26:47,338:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-05 20:26:47,405:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-05 20:26:47,451:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-05 20:26:47,452:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:26:47,452:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:26:47,453:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-01-05 20:26:47,462:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-05 20:26:47,531:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-05 20:26:47,582:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-05 20:26:47,582:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:26:47,583:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:26:47,594:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-05 20:26:47,672:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-05 20:26:47,718:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-05 20:26:47,718:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:26:47,719:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:26:47,719:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-01-05 20:26:47,791:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-05 20:26:47,836:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-05 20:26:47,837:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:26:47,837:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:26:47,908:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-05 20:26:47,953:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-05 20:26:47,954:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:26:47,954:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:26:47,954:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-01-05 20:26:48,030:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-05 20:26:48,077:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:26:48,078:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:26:48,152:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-05 20:26:48,197:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:26:48,198:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:26:48,198:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-01-05 20:26:48,318:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:26:48,319:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:26:48,436:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:26:48,436:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:26:48,437:INFO:Preparing preprocessing pipeline...
2023-01-05 20:26:48,439:INFO:Set up simple imputation.
2023-01-05 20:26:48,439:INFO:Set up column transformation.
2023-01-05 20:26:48,439:INFO:Set up feature normalization.
2023-01-05 20:26:48,992:INFO:Finished creating preprocessing pipeline.
2023-01-05 20:26:48,998:INFO:Pipeline: Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2023-01-05 20:26:48,998:INFO:Creating final display dataframe.
2023-01-05 20:26:49,545:INFO:Setup _display_container:                Description             Value
0               Session id               123
1                   Target        b2b+b2c+vt
2              Target type        Regression
3               Data shape        (9930, 48)
4         Train data shape        (6951, 48)
5          Test data shape        (2979, 48)
6         Numeric features                 8
7               Preprocess              True
8          Imputation type            simple
9       Numeric imputation              mean
10  Categorical imputation              mode
11          Transformation              True
12   Transformation method       yeo-johnson
13               Normalize              True
14        Normalize method            zscore
15          Fold Generator   TimeSeriesSplit
16             Fold Number                 5
17                CPU Jobs                -1
18                 Use GPU             False
19          Log Experiment             False
20         Experiment Name  reg-default-name
21                     USI              32d7
2023-01-05 20:26:49,672:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:26:49,672:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:26:49,789:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:26:49,789:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:26:49,790:INFO:setup() successfully completed in 3.5s...............
2023-01-05 20:26:49,790:INFO:Initializing compare_models()
2023-01-05 20:26:49,790:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014FEFE5ADF0>, include=None, fold=None, round=4, cross_validation=True, sort=MAE, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x0000014FEFE5ADF0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'MAE', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-01-05 20:26:49,790:INFO:Checking exceptions
2023-01-05 20:26:49,795:INFO:Preparing display monitor
2023-01-05 20:26:49,835:INFO:Initializing Linear Regression
2023-01-05 20:26:49,836:INFO:Total runtime is 1.6677379608154298e-05 minutes
2023-01-05 20:26:49,840:INFO:SubProcess create_model() called ==================================
2023-01-05 20:26:49,840:INFO:Initializing create_model()
2023-01-05 20:26:49,840:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014FEFE5ADF0>, estimator=lr, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014FF9978F70>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:26:49,841:INFO:Checking exceptions
2023-01-05 20:26:49,841:INFO:Importing libraries
2023-01-05 20:26:49,841:INFO:Copying training dataset
2023-01-05 20:26:49,851:INFO:Defining folds
2023-01-05 20:26:49,851:INFO:Declaring metric variables
2023-01-05 20:26:49,855:INFO:Importing untrained model
2023-01-05 20:26:49,860:INFO:Linear Regression Imported successfully
2023-01-05 20:26:49,870:INFO:Starting cross validation
2023-01-05 20:26:49,878:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:26:56,702:INFO:Calculating mean and std
2023-01-05 20:26:56,704:INFO:Creating metrics dataframe
2023-01-05 20:26:56,708:INFO:Uploading results into container
2023-01-05 20:26:56,708:INFO:Uploading model into container now
2023-01-05 20:26:56,708:INFO:_master_model_container: 1
2023-01-05 20:26:56,709:INFO:_display_container: 2
2023-01-05 20:26:56,709:INFO:LinearRegression(n_jobs=-1)
2023-01-05 20:26:56,710:INFO:create_model() successfully completed......................................
2023-01-05 20:26:56,811:INFO:SubProcess create_model() end ==================================
2023-01-05 20:26:56,811:INFO:Creating metrics dataframe
2023-01-05 20:26:56,820:INFO:Initializing Lasso Regression
2023-01-05 20:26:56,820:INFO:Total runtime is 0.1164198637008667 minutes
2023-01-05 20:26:56,824:INFO:SubProcess create_model() called ==================================
2023-01-05 20:26:56,824:INFO:Initializing create_model()
2023-01-05 20:26:56,824:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014FEFE5ADF0>, estimator=lasso, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014FF9978F70>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:26:56,824:INFO:Checking exceptions
2023-01-05 20:26:56,824:INFO:Importing libraries
2023-01-05 20:26:56,825:INFO:Copying training dataset
2023-01-05 20:26:56,834:INFO:Defining folds
2023-01-05 20:26:56,834:INFO:Declaring metric variables
2023-01-05 20:26:56,838:INFO:Importing untrained model
2023-01-05 20:26:56,844:INFO:Lasso Regression Imported successfully
2023-01-05 20:26:56,854:INFO:Starting cross validation
2023-01-05 20:26:56,855:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:26:57,249:INFO:Calculating mean and std
2023-01-05 20:26:57,251:INFO:Creating metrics dataframe
2023-01-05 20:26:57,255:INFO:Uploading results into container
2023-01-05 20:26:57,256:INFO:Uploading model into container now
2023-01-05 20:26:57,256:INFO:_master_model_container: 2
2023-01-05 20:26:57,258:INFO:_display_container: 2
2023-01-05 20:26:57,258:INFO:Lasso(random_state=123)
2023-01-05 20:26:57,258:INFO:create_model() successfully completed......................................
2023-01-05 20:26:57,355:INFO:SubProcess create_model() end ==================================
2023-01-05 20:26:57,355:INFO:Creating metrics dataframe
2023-01-05 20:26:57,364:INFO:Initializing Ridge Regression
2023-01-05 20:26:57,364:INFO:Total runtime is 0.12548449834187825 minutes
2023-01-05 20:26:57,369:INFO:SubProcess create_model() called ==================================
2023-01-05 20:26:57,370:INFO:Initializing create_model()
2023-01-05 20:26:57,370:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014FEFE5ADF0>, estimator=ridge, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014FF9978F70>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:26:57,370:INFO:Checking exceptions
2023-01-05 20:26:57,370:INFO:Importing libraries
2023-01-05 20:26:57,370:INFO:Copying training dataset
2023-01-05 20:26:57,380:INFO:Defining folds
2023-01-05 20:26:57,380:INFO:Declaring metric variables
2023-01-05 20:26:57,386:INFO:Importing untrained model
2023-01-05 20:26:57,392:INFO:Ridge Regression Imported successfully
2023-01-05 20:26:57,402:INFO:Starting cross validation
2023-01-05 20:26:57,404:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:26:57,656:INFO:Calculating mean and std
2023-01-05 20:26:57,658:INFO:Creating metrics dataframe
2023-01-05 20:26:57,661:INFO:Uploading results into container
2023-01-05 20:26:57,662:INFO:Uploading model into container now
2023-01-05 20:26:57,662:INFO:_master_model_container: 3
2023-01-05 20:26:57,662:INFO:_display_container: 2
2023-01-05 20:26:57,662:INFO:Ridge(random_state=123)
2023-01-05 20:26:57,662:INFO:create_model() successfully completed......................................
2023-01-05 20:26:57,757:INFO:SubProcess create_model() end ==================================
2023-01-05 20:26:57,757:INFO:Creating metrics dataframe
2023-01-05 20:26:57,768:INFO:Initializing Elastic Net
2023-01-05 20:26:57,768:INFO:Total runtime is 0.1322192390759786 minutes
2023-01-05 20:26:57,774:INFO:SubProcess create_model() called ==================================
2023-01-05 20:26:57,774:INFO:Initializing create_model()
2023-01-05 20:26:57,775:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014FEFE5ADF0>, estimator=en, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014FF9978F70>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:26:57,775:INFO:Checking exceptions
2023-01-05 20:26:57,775:INFO:Importing libraries
2023-01-05 20:26:57,775:INFO:Copying training dataset
2023-01-05 20:26:57,784:INFO:Defining folds
2023-01-05 20:26:57,784:INFO:Declaring metric variables
2023-01-05 20:26:57,790:INFO:Importing untrained model
2023-01-05 20:26:57,795:INFO:Elastic Net Imported successfully
2023-01-05 20:26:57,804:INFO:Starting cross validation
2023-01-05 20:26:57,805:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:26:57,960:INFO:Calculating mean and std
2023-01-05 20:26:57,962:INFO:Creating metrics dataframe
2023-01-05 20:26:57,966:INFO:Uploading results into container
2023-01-05 20:26:57,967:INFO:Uploading model into container now
2023-01-05 20:26:57,967:INFO:_master_model_container: 4
2023-01-05 20:26:57,968:INFO:_display_container: 2
2023-01-05 20:26:57,968:INFO:ElasticNet(random_state=123)
2023-01-05 20:26:57,968:INFO:create_model() successfully completed......................................
2023-01-05 20:26:58,063:INFO:SubProcess create_model() end ==================================
2023-01-05 20:26:58,063:INFO:Creating metrics dataframe
2023-01-05 20:26:58,081:INFO:Initializing Least Angle Regression
2023-01-05 20:26:58,081:INFO:Total runtime is 0.1374272386233012 minutes
2023-01-05 20:26:58,084:INFO:SubProcess create_model() called ==================================
2023-01-05 20:26:58,085:INFO:Initializing create_model()
2023-01-05 20:26:58,085:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014FEFE5ADF0>, estimator=lar, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014FF9978F70>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:26:58,085:INFO:Checking exceptions
2023-01-05 20:26:58,086:INFO:Importing libraries
2023-01-05 20:26:58,086:INFO:Copying training dataset
2023-01-05 20:26:58,099:INFO:Defining folds
2023-01-05 20:26:58,100:INFO:Declaring metric variables
2023-01-05 20:26:58,104:INFO:Importing untrained model
2023-01-05 20:26:58,109:INFO:Least Angle Regression Imported successfully
2023-01-05 20:26:58,117:INFO:Starting cross validation
2023-01-05 20:26:58,118:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:26:58,184:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-05 20:26:58,185:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-05 20:26:58,189:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-05 20:26:58,191:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-05 20:26:58,250:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-05 20:26:58,392:INFO:Calculating mean and std
2023-01-05 20:26:58,395:INFO:Creating metrics dataframe
2023-01-05 20:26:58,398:INFO:Uploading results into container
2023-01-05 20:26:58,399:INFO:Uploading model into container now
2023-01-05 20:26:58,400:INFO:_master_model_container: 5
2023-01-05 20:26:58,400:INFO:_display_container: 2
2023-01-05 20:26:58,400:INFO:Lars(random_state=123)
2023-01-05 20:26:58,401:INFO:create_model() successfully completed......................................
2023-01-05 20:26:58,492:INFO:SubProcess create_model() end ==================================
2023-01-05 20:26:58,492:INFO:Creating metrics dataframe
2023-01-05 20:26:58,502:INFO:Initializing Lasso Least Angle Regression
2023-01-05 20:26:58,502:INFO:Total runtime is 0.14445383151372274 minutes
2023-01-05 20:26:58,506:INFO:SubProcess create_model() called ==================================
2023-01-05 20:26:58,507:INFO:Initializing create_model()
2023-01-05 20:26:58,507:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014FEFE5ADF0>, estimator=llar, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014FF9978F70>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:26:58,507:INFO:Checking exceptions
2023-01-05 20:26:58,507:INFO:Importing libraries
2023-01-05 20:26:58,507:INFO:Copying training dataset
2023-01-05 20:26:58,516:INFO:Defining folds
2023-01-05 20:26:58,516:INFO:Declaring metric variables
2023-01-05 20:26:58,521:INFO:Importing untrained model
2023-01-05 20:26:58,525:INFO:Lasso Least Angle Regression Imported successfully
2023-01-05 20:26:58,533:INFO:Starting cross validation
2023-01-05 20:26:58,534:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:26:58,599:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-05 20:26:58,603:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-05 20:26:58,605:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-05 20:26:58,606:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-05 20:26:58,653:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-05 20:26:58,782:INFO:Calculating mean and std
2023-01-05 20:26:58,784:INFO:Creating metrics dataframe
2023-01-05 20:26:58,788:INFO:Uploading results into container
2023-01-05 20:26:58,789:INFO:Uploading model into container now
2023-01-05 20:26:58,789:INFO:_master_model_container: 6
2023-01-05 20:26:58,789:INFO:_display_container: 2
2023-01-05 20:26:58,789:INFO:LassoLars(random_state=123)
2023-01-05 20:26:58,790:INFO:create_model() successfully completed......................................
2023-01-05 20:26:58,881:INFO:SubProcess create_model() end ==================================
2023-01-05 20:26:58,882:INFO:Creating metrics dataframe
2023-01-05 20:26:58,892:INFO:Initializing Orthogonal Matching Pursuit
2023-01-05 20:26:58,892:INFO:Total runtime is 0.15095181862513224 minutes
2023-01-05 20:26:58,896:INFO:SubProcess create_model() called ==================================
2023-01-05 20:26:58,897:INFO:Initializing create_model()
2023-01-05 20:26:58,897:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014FEFE5ADF0>, estimator=omp, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014FF9978F70>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:26:58,897:INFO:Checking exceptions
2023-01-05 20:26:58,897:INFO:Importing libraries
2023-01-05 20:26:58,897:INFO:Copying training dataset
2023-01-05 20:26:58,906:INFO:Defining folds
2023-01-05 20:26:58,907:INFO:Declaring metric variables
2023-01-05 20:26:58,911:INFO:Importing untrained model
2023-01-05 20:26:58,915:INFO:Orthogonal Matching Pursuit Imported successfully
2023-01-05 20:26:58,923:INFO:Starting cross validation
2023-01-05 20:26:58,924:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:26:58,985:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-05 20:26:58,989:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-05 20:26:58,990:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-05 20:26:58,993:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-05 20:26:59,040:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-05 20:26:59,172:INFO:Calculating mean and std
2023-01-05 20:26:59,174:INFO:Creating metrics dataframe
2023-01-05 20:26:59,177:INFO:Uploading results into container
2023-01-05 20:26:59,177:INFO:Uploading model into container now
2023-01-05 20:26:59,178:INFO:_master_model_container: 7
2023-01-05 20:26:59,178:INFO:_display_container: 2
2023-01-05 20:26:59,178:INFO:OrthogonalMatchingPursuit()
2023-01-05 20:26:59,178:INFO:create_model() successfully completed......................................
2023-01-05 20:26:59,274:INFO:SubProcess create_model() end ==================================
2023-01-05 20:26:59,274:INFO:Creating metrics dataframe
2023-01-05 20:26:59,287:INFO:Initializing Bayesian Ridge
2023-01-05 20:26:59,287:INFO:Total runtime is 0.15753674109776813 minutes
2023-01-05 20:26:59,291:INFO:SubProcess create_model() called ==================================
2023-01-05 20:26:59,292:INFO:Initializing create_model()
2023-01-05 20:26:59,292:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014FEFE5ADF0>, estimator=br, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014FF9978F70>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:26:59,292:INFO:Checking exceptions
2023-01-05 20:26:59,292:INFO:Importing libraries
2023-01-05 20:26:59,292:INFO:Copying training dataset
2023-01-05 20:26:59,301:INFO:Defining folds
2023-01-05 20:26:59,302:INFO:Declaring metric variables
2023-01-05 20:26:59,306:INFO:Importing untrained model
2023-01-05 20:26:59,310:INFO:Bayesian Ridge Imported successfully
2023-01-05 20:26:59,318:INFO:Starting cross validation
2023-01-05 20:26:59,319:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:26:59,622:INFO:Calculating mean and std
2023-01-05 20:26:59,624:INFO:Creating metrics dataframe
2023-01-05 20:26:59,627:INFO:Uploading results into container
2023-01-05 20:26:59,628:INFO:Uploading model into container now
2023-01-05 20:26:59,628:INFO:_master_model_container: 8
2023-01-05 20:26:59,628:INFO:_display_container: 2
2023-01-05 20:26:59,629:INFO:BayesianRidge()
2023-01-05 20:26:59,629:INFO:create_model() successfully completed......................................
2023-01-05 20:26:59,737:INFO:SubProcess create_model() end ==================================
2023-01-05 20:26:59,738:INFO:Creating metrics dataframe
2023-01-05 20:26:59,749:INFO:Initializing Passive Aggressive Regressor
2023-01-05 20:26:59,749:INFO:Total runtime is 0.16523675123850504 minutes
2023-01-05 20:26:59,753:INFO:SubProcess create_model() called ==================================
2023-01-05 20:26:59,753:INFO:Initializing create_model()
2023-01-05 20:26:59,754:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014FEFE5ADF0>, estimator=par, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014FF9978F70>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:26:59,754:INFO:Checking exceptions
2023-01-05 20:26:59,754:INFO:Importing libraries
2023-01-05 20:26:59,754:INFO:Copying training dataset
2023-01-05 20:26:59,764:INFO:Defining folds
2023-01-05 20:26:59,764:INFO:Declaring metric variables
2023-01-05 20:26:59,768:INFO:Importing untrained model
2023-01-05 20:26:59,772:INFO:Passive Aggressive Regressor Imported successfully
2023-01-05 20:26:59,780:INFO:Starting cross validation
2023-01-05 20:26:59,782:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:27:00,044:INFO:Calculating mean and std
2023-01-05 20:27:00,046:INFO:Creating metrics dataframe
2023-01-05 20:27:00,049:INFO:Uploading results into container
2023-01-05 20:27:00,049:INFO:Uploading model into container now
2023-01-05 20:27:00,049:INFO:_master_model_container: 9
2023-01-05 20:27:00,050:INFO:_display_container: 2
2023-01-05 20:27:00,050:INFO:PassiveAggressiveRegressor(random_state=123)
2023-01-05 20:27:00,050:INFO:create_model() successfully completed......................................
2023-01-05 20:27:00,215:INFO:SubProcess create_model() end ==================================
2023-01-05 20:27:00,215:INFO:Creating metrics dataframe
2023-01-05 20:27:00,245:INFO:Initializing Huber Regressor
2023-01-05 20:27:00,246:INFO:Total runtime is 0.17352012793223062 minutes
2023-01-05 20:27:00,249:INFO:SubProcess create_model() called ==================================
2023-01-05 20:27:00,250:INFO:Initializing create_model()
2023-01-05 20:27:00,250:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014FEFE5ADF0>, estimator=huber, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014FF9978F70>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:27:00,250:INFO:Checking exceptions
2023-01-05 20:27:00,250:INFO:Importing libraries
2023-01-05 20:27:00,250:INFO:Copying training dataset
2023-01-05 20:27:00,260:INFO:Defining folds
2023-01-05 20:27:00,260:INFO:Declaring metric variables
2023-01-05 20:27:00,264:INFO:Importing untrained model
2023-01-05 20:27:00,268:INFO:Huber Regressor Imported successfully
2023-01-05 20:27:00,275:INFO:Starting cross validation
2023-01-05 20:27:00,277:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:27:00,421:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-05 20:27:00,493:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-05 20:27:00,561:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-05 20:27:00,635:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-05 20:27:00,810:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-05 20:27:00,935:INFO:Calculating mean and std
2023-01-05 20:27:00,937:INFO:Creating metrics dataframe
2023-01-05 20:27:00,940:INFO:Uploading results into container
2023-01-05 20:27:00,941:INFO:Uploading model into container now
2023-01-05 20:27:00,941:INFO:_master_model_container: 10
2023-01-05 20:27:00,941:INFO:_display_container: 2
2023-01-05 20:27:00,942:INFO:HuberRegressor()
2023-01-05 20:27:00,942:INFO:create_model() successfully completed......................................
2023-01-05 20:27:01,036:INFO:SubProcess create_model() end ==================================
2023-01-05 20:27:01,037:INFO:Creating metrics dataframe
2023-01-05 20:27:01,049:INFO:Initializing K Neighbors Regressor
2023-01-05 20:27:01,049:INFO:Total runtime is 0.18690341313680012 minutes
2023-01-05 20:27:01,053:INFO:SubProcess create_model() called ==================================
2023-01-05 20:27:01,054:INFO:Initializing create_model()
2023-01-05 20:27:01,054:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014FEFE5ADF0>, estimator=knn, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014FF9978F70>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:27:01,054:INFO:Checking exceptions
2023-01-05 20:27:01,054:INFO:Importing libraries
2023-01-05 20:27:01,054:INFO:Copying training dataset
2023-01-05 20:27:01,063:INFO:Defining folds
2023-01-05 20:27:01,063:INFO:Declaring metric variables
2023-01-05 20:27:01,067:INFO:Importing untrained model
2023-01-05 20:27:01,072:INFO:K Neighbors Regressor Imported successfully
2023-01-05 20:27:01,079:INFO:Starting cross validation
2023-01-05 20:27:01,081:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:27:01,734:INFO:Calculating mean and std
2023-01-05 20:27:01,736:INFO:Creating metrics dataframe
2023-01-05 20:27:01,740:INFO:Uploading results into container
2023-01-05 20:27:01,741:INFO:Uploading model into container now
2023-01-05 20:27:01,742:INFO:_master_model_container: 11
2023-01-05 20:27:01,742:INFO:_display_container: 2
2023-01-05 20:27:01,742:INFO:KNeighborsRegressor(n_jobs=-1)
2023-01-05 20:27:01,742:INFO:create_model() successfully completed......................................
2023-01-05 20:27:01,846:INFO:SubProcess create_model() end ==================================
2023-01-05 20:27:01,847:INFO:Creating metrics dataframe
2023-01-05 20:27:01,858:INFO:Initializing Decision Tree Regressor
2023-01-05 20:27:01,858:INFO:Total runtime is 0.20037829081217445 minutes
2023-01-05 20:27:01,862:INFO:SubProcess create_model() called ==================================
2023-01-05 20:27:01,862:INFO:Initializing create_model()
2023-01-05 20:27:01,863:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014FEFE5ADF0>, estimator=dt, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014FF9978F70>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:27:01,863:INFO:Checking exceptions
2023-01-05 20:27:01,863:INFO:Importing libraries
2023-01-05 20:27:01,863:INFO:Copying training dataset
2023-01-05 20:27:01,872:INFO:Defining folds
2023-01-05 20:27:01,873:INFO:Declaring metric variables
2023-01-05 20:27:01,877:INFO:Importing untrained model
2023-01-05 20:27:01,881:INFO:Decision Tree Regressor Imported successfully
2023-01-05 20:27:01,888:INFO:Starting cross validation
2023-01-05 20:27:01,890:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:27:02,365:INFO:Calculating mean and std
2023-01-05 20:27:02,367:INFO:Creating metrics dataframe
2023-01-05 20:27:02,370:INFO:Uploading results into container
2023-01-05 20:27:02,371:INFO:Uploading model into container now
2023-01-05 20:27:02,371:INFO:_master_model_container: 12
2023-01-05 20:27:02,372:INFO:_display_container: 2
2023-01-05 20:27:02,372:INFO:DecisionTreeRegressor(random_state=123)
2023-01-05 20:27:02,372:INFO:create_model() successfully completed......................................
2023-01-05 20:27:02,467:INFO:SubProcess create_model() end ==================================
2023-01-05 20:27:02,467:INFO:Creating metrics dataframe
2023-01-05 20:27:02,480:INFO:Initializing Random Forest Regressor
2023-01-05 20:27:02,480:INFO:Total runtime is 0.2107529600461324 minutes
2023-01-05 20:27:02,484:INFO:SubProcess create_model() called ==================================
2023-01-05 20:27:02,485:INFO:Initializing create_model()
2023-01-05 20:27:02,485:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014FEFE5ADF0>, estimator=rf, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014FF9978F70>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:27:02,485:INFO:Checking exceptions
2023-01-05 20:27:02,485:INFO:Importing libraries
2023-01-05 20:27:02,485:INFO:Copying training dataset
2023-01-05 20:27:02,495:INFO:Defining folds
2023-01-05 20:27:02,495:INFO:Declaring metric variables
2023-01-05 20:27:02,499:INFO:Importing untrained model
2023-01-05 20:27:02,504:INFO:Random Forest Regressor Imported successfully
2023-01-05 20:27:02,512:INFO:Starting cross validation
2023-01-05 20:27:02,513:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:27:13,156:INFO:Calculating mean and std
2023-01-05 20:27:13,158:INFO:Creating metrics dataframe
2023-01-05 20:27:13,161:INFO:Uploading results into container
2023-01-05 20:27:13,161:INFO:Uploading model into container now
2023-01-05 20:27:13,162:INFO:_master_model_container: 13
2023-01-05 20:27:13,162:INFO:_display_container: 2
2023-01-05 20:27:13,162:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-01-05 20:27:13,162:INFO:create_model() successfully completed......................................
2023-01-05 20:27:13,252:INFO:SubProcess create_model() end ==================================
2023-01-05 20:27:13,252:INFO:Creating metrics dataframe
2023-01-05 20:27:13,263:INFO:Initializing Extra Trees Regressor
2023-01-05 20:27:13,264:INFO:Total runtime is 0.39047534863154093 minutes
2023-01-05 20:27:13,268:INFO:SubProcess create_model() called ==================================
2023-01-05 20:27:13,268:INFO:Initializing create_model()
2023-01-05 20:27:13,269:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014FEFE5ADF0>, estimator=et, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014FF9978F70>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:27:13,269:INFO:Checking exceptions
2023-01-05 20:27:13,269:INFO:Importing libraries
2023-01-05 20:27:13,269:INFO:Copying training dataset
2023-01-05 20:27:13,278:INFO:Defining folds
2023-01-05 20:27:13,278:INFO:Declaring metric variables
2023-01-05 20:27:13,281:INFO:Importing untrained model
2023-01-05 20:27:13,286:INFO:Extra Trees Regressor Imported successfully
2023-01-05 20:27:13,293:INFO:Starting cross validation
2023-01-05 20:27:13,295:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:27:17,581:INFO:Calculating mean and std
2023-01-05 20:27:17,583:INFO:Creating metrics dataframe
2023-01-05 20:27:17,586:INFO:Uploading results into container
2023-01-05 20:27:17,586:INFO:Uploading model into container now
2023-01-05 20:27:17,587:INFO:_master_model_container: 14
2023-01-05 20:27:17,587:INFO:_display_container: 2
2023-01-05 20:27:17,587:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-01-05 20:27:17,587:INFO:create_model() successfully completed......................................
2023-01-05 20:27:17,676:INFO:SubProcess create_model() end ==================================
2023-01-05 20:27:17,676:INFO:Creating metrics dataframe
2023-01-05 20:27:17,689:INFO:Initializing AdaBoost Regressor
2023-01-05 20:27:17,689:INFO:Total runtime is 0.46423364082972207 minutes
2023-01-05 20:27:17,693:INFO:SubProcess create_model() called ==================================
2023-01-05 20:27:17,694:INFO:Initializing create_model()
2023-01-05 20:27:17,694:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014FEFE5ADF0>, estimator=ada, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014FF9978F70>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:27:17,694:INFO:Checking exceptions
2023-01-05 20:27:17,694:INFO:Importing libraries
2023-01-05 20:27:17,694:INFO:Copying training dataset
2023-01-05 20:27:17,705:INFO:Defining folds
2023-01-05 20:27:17,705:INFO:Declaring metric variables
2023-01-05 20:27:17,709:INFO:Importing untrained model
2023-01-05 20:27:17,713:INFO:AdaBoost Regressor Imported successfully
2023-01-05 20:27:17,721:INFO:Starting cross validation
2023-01-05 20:27:17,722:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:27:19,744:INFO:Calculating mean and std
2023-01-05 20:27:19,746:INFO:Creating metrics dataframe
2023-01-05 20:27:19,750:INFO:Uploading results into container
2023-01-05 20:27:19,751:INFO:Uploading model into container now
2023-01-05 20:27:19,751:INFO:_master_model_container: 15
2023-01-05 20:27:19,751:INFO:_display_container: 2
2023-01-05 20:27:19,752:INFO:AdaBoostRegressor(random_state=123)
2023-01-05 20:27:19,752:INFO:create_model() successfully completed......................................
2023-01-05 20:27:19,892:INFO:SubProcess create_model() end ==================================
2023-01-05 20:27:19,892:INFO:Creating metrics dataframe
2023-01-05 20:27:19,912:INFO:Initializing Gradient Boosting Regressor
2023-01-05 20:27:19,912:INFO:Total runtime is 0.5012835303942362 minutes
2023-01-05 20:27:19,917:INFO:SubProcess create_model() called ==================================
2023-01-05 20:27:19,917:INFO:Initializing create_model()
2023-01-05 20:27:19,918:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014FEFE5ADF0>, estimator=gbr, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014FF9978F70>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:27:19,918:INFO:Checking exceptions
2023-01-05 20:27:19,918:INFO:Importing libraries
2023-01-05 20:27:19,918:INFO:Copying training dataset
2023-01-05 20:27:19,930:INFO:Defining folds
2023-01-05 20:27:19,930:INFO:Declaring metric variables
2023-01-05 20:27:19,935:INFO:Importing untrained model
2023-01-05 20:27:19,951:INFO:Gradient Boosting Regressor Imported successfully
2023-01-05 20:27:19,967:INFO:Starting cross validation
2023-01-05 20:27:19,968:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:27:27,155:INFO:Calculating mean and std
2023-01-05 20:27:27,159:INFO:Creating metrics dataframe
2023-01-05 20:27:27,162:INFO:Uploading results into container
2023-01-05 20:27:27,163:INFO:Uploading model into container now
2023-01-05 20:27:27,163:INFO:_master_model_container: 16
2023-01-05 20:27:27,163:INFO:_display_container: 2
2023-01-05 20:27:27,164:INFO:GradientBoostingRegressor(random_state=123)
2023-01-05 20:27:27,164:INFO:create_model() successfully completed......................................
2023-01-05 20:27:27,270:INFO:SubProcess create_model() end ==================================
2023-01-05 20:27:27,270:INFO:Creating metrics dataframe
2023-01-05 20:27:27,284:INFO:Initializing Light Gradient Boosting Machine
2023-01-05 20:27:27,284:INFO:Total runtime is 0.6241501728693644 minutes
2023-01-05 20:27:27,288:INFO:SubProcess create_model() called ==================================
2023-01-05 20:27:27,288:INFO:Initializing create_model()
2023-01-05 20:27:27,288:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014FEFE5ADF0>, estimator=lightgbm, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014FF9978F70>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:27:27,288:INFO:Checking exceptions
2023-01-05 20:27:27,288:INFO:Importing libraries
2023-01-05 20:27:27,288:INFO:Copying training dataset
2023-01-05 20:27:27,308:INFO:Defining folds
2023-01-05 20:27:27,308:INFO:Declaring metric variables
2023-01-05 20:27:27,312:INFO:Importing untrained model
2023-01-05 20:27:27,315:INFO:Light Gradient Boosting Machine Imported successfully
2023-01-05 20:27:27,322:INFO:Starting cross validation
2023-01-05 20:27:27,324:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:27:31,257:INFO:Calculating mean and std
2023-01-05 20:27:31,258:INFO:Creating metrics dataframe
2023-01-05 20:27:31,262:INFO:Uploading results into container
2023-01-05 20:27:31,263:INFO:Uploading model into container now
2023-01-05 20:27:31,263:INFO:_master_model_container: 17
2023-01-05 20:27:31,263:INFO:_display_container: 2
2023-01-05 20:27:31,264:INFO:LGBMRegressor(random_state=123)
2023-01-05 20:27:31,264:INFO:create_model() successfully completed......................................
2023-01-05 20:27:31,392:INFO:SubProcess create_model() end ==================================
2023-01-05 20:27:31,392:INFO:Creating metrics dataframe
2023-01-05 20:27:31,409:INFO:Initializing Dummy Regressor
2023-01-05 20:27:31,409:INFO:Total runtime is 0.6929001808166504 minutes
2023-01-05 20:27:31,413:INFO:SubProcess create_model() called ==================================
2023-01-05 20:27:31,414:INFO:Initializing create_model()
2023-01-05 20:27:31,414:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014FEFE5ADF0>, estimator=dummy, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014FF9978F70>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:27:31,414:INFO:Checking exceptions
2023-01-05 20:27:31,414:INFO:Importing libraries
2023-01-05 20:27:31,414:INFO:Copying training dataset
2023-01-05 20:27:31,425:INFO:Defining folds
2023-01-05 20:27:31,426:INFO:Declaring metric variables
2023-01-05 20:27:31,430:INFO:Importing untrained model
2023-01-05 20:27:31,434:INFO:Dummy Regressor Imported successfully
2023-01-05 20:27:31,443:INFO:Starting cross validation
2023-01-05 20:27:31,444:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:27:31,703:INFO:Calculating mean and std
2023-01-05 20:27:31,719:INFO:Creating metrics dataframe
2023-01-05 20:27:31,726:INFO:Uploading results into container
2023-01-05 20:27:31,726:INFO:Uploading model into container now
2023-01-05 20:27:31,726:INFO:_master_model_container: 18
2023-01-05 20:27:31,726:INFO:_display_container: 2
2023-01-05 20:27:31,727:INFO:DummyRegressor()
2023-01-05 20:27:31,727:INFO:create_model() successfully completed......................................
2023-01-05 20:27:31,956:INFO:SubProcess create_model() end ==================================
2023-01-05 20:27:31,956:INFO:Creating metrics dataframe
2023-01-05 20:27:32,000:INFO:Initializing create_model()
2023-01-05 20:27:32,000:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014FEFE5ADF0>, estimator=LGBMRegressor(random_state=123), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:27:32,000:INFO:Checking exceptions
2023-01-05 20:27:32,003:INFO:Importing libraries
2023-01-05 20:27:32,003:INFO:Copying training dataset
2023-01-05 20:27:32,012:INFO:Defining folds
2023-01-05 20:27:32,012:INFO:Declaring metric variables
2023-01-05 20:27:32,012:INFO:Importing untrained model
2023-01-05 20:27:32,012:INFO:Declaring custom model
2023-01-05 20:27:32,013:INFO:Light Gradient Boosting Machine Imported successfully
2023-01-05 20:27:32,035:INFO:Cross validation set to False
2023-01-05 20:27:32,035:INFO:Fitting Model
2023-01-05 20:27:33,465:INFO:LGBMRegressor(random_state=123)
2023-01-05 20:27:33,465:INFO:create_model() successfully completed......................................
2023-01-05 20:27:33,606:INFO:_master_model_container: 18
2023-01-05 20:27:33,606:INFO:_display_container: 2
2023-01-05 20:27:33,607:INFO:LGBMRegressor(random_state=123)
2023-01-05 20:27:33,607:INFO:compare_models() successfully completed......................................
2023-01-05 20:27:33,607:INFO:Initializing tune_model()
2023-01-05 20:27:33,608:INFO:tune_model(estimator=LGBMRegressor(random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=MAE, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014FEFE5ADF0>)
2023-01-05 20:27:33,608:INFO:Checking exceptions
2023-01-05 20:27:33,638:INFO:Copying training dataset
2023-01-05 20:27:33,647:INFO:Checking base model
2023-01-05 20:27:33,647:INFO:Base model : Light Gradient Boosting Machine
2023-01-05 20:27:33,651:INFO:Declaring metric variables
2023-01-05 20:27:33,655:INFO:Defining Hyperparameters
2023-01-05 20:27:33,767:INFO:Tuning with n_jobs=-1
2023-01-05 20:27:33,768:INFO:Initializing RandomizedSearchCV
2023-01-05 20:27:40,138:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2023-01-05 20:27:40,140:INFO:Hyperparameter search completed
2023-01-05 20:27:40,140:INFO:SubProcess create_model() called ==================================
2023-01-05 20:27:40,141:INFO:Initializing create_model()
2023-01-05 20:27:40,141:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014FEFE5ADF0>, estimator=LGBMRegressor(random_state=123), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014FFA38AA30>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2023-01-05 20:27:40,141:INFO:Checking exceptions
2023-01-05 20:27:40,141:INFO:Importing libraries
2023-01-05 20:27:40,141:INFO:Copying training dataset
2023-01-05 20:27:40,150:INFO:Defining folds
2023-01-05 20:27:40,150:INFO:Declaring metric variables
2023-01-05 20:27:40,153:INFO:Importing untrained model
2023-01-05 20:27:40,153:INFO:Declaring custom model
2023-01-05 20:27:40,158:INFO:Light Gradient Boosting Machine Imported successfully
2023-01-05 20:27:40,164:INFO:Starting cross validation
2023-01-05 20:27:40,165:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:27:41,544:INFO:Calculating mean and std
2023-01-05 20:27:41,546:INFO:Creating metrics dataframe
2023-01-05 20:27:41,550:INFO:Finalizing model
2023-01-05 20:27:42,057:INFO:Uploading results into container
2023-01-05 20:27:42,057:INFO:Uploading model into container now
2023-01-05 20:27:42,058:INFO:_master_model_container: 19
2023-01-05 20:27:42,058:INFO:_display_container: 3
2023-01-05 20:27:42,059:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              num_leaves=70, random_state=123, reg_alpha=2, reg_lambda=3)
2023-01-05 20:27:42,059:INFO:create_model() successfully completed......................................
2023-01-05 20:27:42,154:INFO:SubProcess create_model() end ==================================
2023-01-05 20:27:42,154:INFO:choose_better activated
2023-01-05 20:27:42,157:INFO:SubProcess create_model() called ==================================
2023-01-05 20:27:42,158:INFO:Initializing create_model()
2023-01-05 20:27:42,158:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014FEFE5ADF0>, estimator=LGBMRegressor(random_state=123), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:27:42,158:INFO:Checking exceptions
2023-01-05 20:27:42,160:INFO:Importing libraries
2023-01-05 20:27:42,160:INFO:Copying training dataset
2023-01-05 20:27:42,168:INFO:Defining folds
2023-01-05 20:27:42,168:INFO:Declaring metric variables
2023-01-05 20:27:42,168:INFO:Importing untrained model
2023-01-05 20:27:42,168:INFO:Declaring custom model
2023-01-05 20:27:42,169:INFO:Light Gradient Boosting Machine Imported successfully
2023-01-05 20:27:42,169:INFO:Starting cross validation
2023-01-05 20:27:42,170:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:27:43,332:INFO:Calculating mean and std
2023-01-05 20:27:43,333:INFO:Creating metrics dataframe
2023-01-05 20:27:43,335:INFO:Finalizing model
2023-01-05 20:27:43,563:INFO:Uploading results into container
2023-01-05 20:27:43,564:INFO:Uploading model into container now
2023-01-05 20:27:43,564:INFO:_master_model_container: 20
2023-01-05 20:27:43,564:INFO:_display_container: 4
2023-01-05 20:27:43,565:INFO:LGBMRegressor(random_state=123)
2023-01-05 20:27:43,565:INFO:create_model() successfully completed......................................
2023-01-05 20:27:43,659:INFO:SubProcess create_model() end ==================================
2023-01-05 20:27:43,660:INFO:LGBMRegressor(random_state=123) result for MAE is 2.1529
2023-01-05 20:27:43,660:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              num_leaves=70, random_state=123, reg_alpha=2, reg_lambda=3) result for MAE is 2.422
2023-01-05 20:27:43,661:INFO:LGBMRegressor(random_state=123) is best model
2023-01-05 20:27:43,661:INFO:choose_better completed
2023-01-05 20:27:43,661:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-01-05 20:27:43,669:INFO:_master_model_container: 20
2023-01-05 20:27:43,669:INFO:_display_container: 3
2023-01-05 20:27:43,670:INFO:LGBMRegressor(random_state=123)
2023-01-05 20:27:43,670:INFO:tune_model() successfully completed......................................
2023-01-05 20:27:43,767:INFO:Initializing plot_model()
2023-01-05 20:27:43,767:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LGBMRegressor(random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014FEFE5ADF0>, system=True)
2023-01-05 20:27:43,767:INFO:Checking exceptions
2023-01-05 20:27:43,773:INFO:Preloading libraries
2023-01-05 20:27:43,779:INFO:Copying training dataset
2023-01-05 20:27:43,779:INFO:Plot type: error
2023-01-05 20:27:43,944:INFO:Fitting Model
2023-01-05 20:27:43,944:INFO:Scoring test/hold-out set
2023-01-05 20:27:44,370:INFO:Visual Rendered Successfully
2023-01-05 20:27:44,466:INFO:plot_model() successfully completed......................................
2023-01-05 20:27:44,467:INFO:Initializing predict_model()
2023-01-05 20:27:44,467:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014FEFE5ADF0>, estimator=LGBMRegressor(random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x0000014FFABA4D30>)
2023-01-05 20:27:44,467:INFO:Checking exceptions
2023-01-05 20:27:44,467:INFO:Preloading libraries
2023-01-05 20:27:44,631:INFO:Initializing finalize_model()
2023-01-05 20:27:44,631:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014FEFE5ADF0>, estimator=LGBMRegressor(random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-01-05 20:27:44,631:INFO:Finalizing LGBMRegressor(random_state=123)
2023-01-05 20:27:44,640:INFO:Initializing create_model()
2023-01-05 20:27:44,640:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014FEFE5ADF0>, estimator=LGBMRegressor(random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-01-05 20:27:44,640:INFO:Checking exceptions
2023-01-05 20:27:44,642:INFO:Importing libraries
2023-01-05 20:27:44,642:INFO:Copying training dataset
2023-01-05 20:27:44,643:INFO:Defining folds
2023-01-05 20:27:44,643:INFO:Declaring metric variables
2023-01-05 20:27:44,643:INFO:Importing untrained model
2023-01-05 20:27:44,643:INFO:Declaring custom model
2023-01-05 20:27:44,644:INFO:Light Gradient Boosting Machine Imported successfully
2023-01-05 20:27:44,645:INFO:Cross validation set to False
2023-01-05 20:27:44,645:INFO:Fitting Model
2023-01-05 20:27:45,638:INFO:Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator', LGBMRegressor(random_state=123))])
2023-01-05 20:27:45,638:INFO:create_model() successfully completed......................................
2023-01-05 20:27:45,737:INFO:_master_model_container: 20
2023-01-05 20:27:45,737:INFO:_display_container: 4
2023-01-05 20:27:45,744:INFO:Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator', LGBMRegressor(random_state=123))])
2023-01-05 20:27:45,744:INFO:finalize_model() successfully completed......................................
2023-01-05 20:27:45,847:INFO:Initializing predict_model()
2023-01-05 20:27:45,847:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014FEFE5ADF0>, estimator=Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator', LGBMRegressor(random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x0000014FFABA4CA0>)
2023-01-05 20:27:45,847:INFO:Checking exceptions
2023-01-05 20:27:45,848:INFO:Preloading libraries
2023-01-05 20:27:45,849:INFO:Set up data.
2023-01-05 20:27:45,864:INFO:Set up index.
2023-01-05 20:27:46,406:INFO:Initializing save_model()
2023-01-05 20:27:46,407:INFO:save_model(model=Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator', LGBMRegressor(random_state=123))]), model_name=c:\Users\Kodotautas\Desktop\Data_science\7_TIME_SERIES_FORECAST_AUTOML/models/final_model.pkl, prep_pipe_=Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-01-05 20:27:46,407:INFO:Adding model into prep_pipe
2023-01-05 20:27:46,418:WARNING:Only Model saved as it was a pipeline.
2023-01-05 20:27:46,431:INFO:c:\Users\Kodotautas\Desktop\Data_science\7_TIME_SERIES_FORECAST_AUTOML/models/final_model.pkl.pkl saved in current working directory
2023-01-05 20:27:46,439:INFO:Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator', LGBMRegressor(random_state=123))])
2023-01-05 20:27:46,439:INFO:save_model() successfully completed......................................
2023-01-05 20:32:40,745:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-01-05 20:32:40,745:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-01-05 20:32:40,745:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-01-05 20:32:40,745:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-01-05 20:32:41,490:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-01-05 20:32:41,859:INFO:PyCaret RegressionExperiment
2023-01-05 20:32:41,859:INFO:Logging name: reg-default-name
2023-01-05 20:32:41,859:INFO:ML Usecase: MLUsecase.REGRESSION
2023-01-05 20:32:41,859:INFO:version 3.0.0.rc6
2023-01-05 20:32:41,859:INFO:Initializing setup()
2023-01-05 20:32:41,859:INFO:self.USI: 7576
2023-01-05 20:32:41,859:INFO:self._variable_keys: {'y_train', 'data', 'gpu_n_jobs_param', 'fold_shuffle_param', 'n_jobs_param', 'exp_name_log', 'fold_generator', 'seed', 'gpu_param', 'USI', 'exp_id', 'logging_param', 'html_param', 'transform_target_param', 'y_test', 'target_param', 'X', 'X_test', 'log_plots_param', 'pipeline', '_available_plots', 'idx', 'fold_groups_param', 'X_train', '_ml_usecase', 'y', 'memory'}
2023-01-05 20:32:41,859:INFO:Checking environment
2023-01-05 20:32:41,859:INFO:python_version: 3.9.13
2023-01-05 20:32:41,860:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-01-05 20:32:41,860:INFO:machine: AMD64
2023-01-05 20:32:41,860:INFO:platform: Windows-10-10.0.19044-SP0
2023-01-05 20:32:41,860:INFO:Memory: svmem(total=17114804224, available=9420337152, percent=45.0, used=7694467072, free=9420337152)
2023-01-05 20:32:41,860:INFO:Physical Core: 4
2023-01-05 20:32:41,860:INFO:Logical Core: 4
2023-01-05 20:32:41,860:INFO:Checking libraries
2023-01-05 20:32:41,860:INFO:System:
2023-01-05 20:32:41,860:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-01-05 20:32:41,860:INFO:executable: c:\Users\Kodotautas\anaconda3\python.exe
2023-01-05 20:32:41,860:INFO:   machine: Windows-10-10.0.19044-SP0
2023-01-05 20:32:41,860:INFO:PyCaret required dependencies:
2023-01-05 20:32:41,860:INFO:                 pip: 22.2.2
2023-01-05 20:32:41,860:INFO:          setuptools: 63.4.1
2023-01-05 20:32:41,860:INFO:             pycaret: 3.0.0rc6
2023-01-05 20:32:41,860:INFO:             IPython: 7.31.1
2023-01-05 20:32:41,860:INFO:          ipywidgets: 7.6.5
2023-01-05 20:32:41,861:INFO:                tqdm: 4.64.1
2023-01-05 20:32:41,861:INFO:               numpy: 1.21.5
2023-01-05 20:32:41,861:INFO:              pandas: 1.4.4
2023-01-05 20:32:41,861:INFO:              jinja2: 2.11.3
2023-01-05 20:32:41,861:INFO:               scipy: 1.9.1
2023-01-05 20:32:41,861:INFO:              joblib: 1.2.0
2023-01-05 20:32:41,861:INFO:             sklearn: 1.0.2
2023-01-05 20:32:41,861:INFO:                pyod: 1.0.7
2023-01-05 20:32:41,861:INFO:            imblearn: 0.10.1
2023-01-05 20:32:41,861:INFO:   category_encoders: 2.5.1.post0
2023-01-05 20:32:41,861:INFO:            lightgbm: 3.3.3
2023-01-05 20:32:41,861:INFO:               numba: 0.55.1
2023-01-05 20:32:41,861:INFO:            requests: 2.28.1
2023-01-05 20:32:41,861:INFO:          matplotlib: 3.5.2
2023-01-05 20:32:41,861:INFO:          scikitplot: 0.3.7
2023-01-05 20:32:41,861:INFO:         yellowbrick: 1.5
2023-01-05 20:32:41,861:INFO:              plotly: 5.9.0
2023-01-05 20:32:41,861:INFO:             kaleido: 0.2.1
2023-01-05 20:32:41,861:INFO:         statsmodels: 0.13.2
2023-01-05 20:32:41,861:INFO:              sktime: 0.14.1
2023-01-05 20:32:41,861:INFO:               tbats: 1.1.2
2023-01-05 20:32:41,861:INFO:            pmdarima: 2.0.2
2023-01-05 20:32:41,861:INFO:              psutil: 5.9.0
2023-01-05 20:32:41,861:INFO:PyCaret optional dependencies:
2023-01-05 20:32:42,136:INFO:                shap: 0.41.0
2023-01-05 20:32:42,136:INFO:           interpret: Not installed
2023-01-05 20:32:42,136:INFO:                umap: Not installed
2023-01-05 20:32:42,136:INFO:    pandas_profiling: Not installed
2023-01-05 20:32:42,136:INFO:  explainerdashboard: Not installed
2023-01-05 20:32:42,136:INFO:             autoviz: Not installed
2023-01-05 20:32:42,136:INFO:           fairlearn: Not installed
2023-01-05 20:32:42,136:INFO:             xgboost: Not installed
2023-01-05 20:32:42,137:INFO:            catboost: Not installed
2023-01-05 20:32:42,137:INFO:              kmodes: Not installed
2023-01-05 20:32:42,137:INFO:             mlxtend: Not installed
2023-01-05 20:32:42,137:INFO:       statsforecast: Not installed
2023-01-05 20:32:42,137:INFO:        tune_sklearn: 0.4.3
2023-01-05 20:32:42,137:INFO:                 ray: 2.0.0
2023-01-05 20:32:42,137:INFO:            hyperopt: 0.2.7
2023-01-05 20:32:42,137:INFO:              optuna: 3.0.1
2023-01-05 20:32:42,137:INFO:               skopt: 0.9.0
2023-01-05 20:32:42,137:INFO:              mlflow: Not installed
2023-01-05 20:32:42,137:INFO:              gradio: Not installed
2023-01-05 20:32:42,137:INFO:             fastapi: 0.88.0
2023-01-05 20:32:42,137:INFO:             uvicorn: 0.20.0
2023-01-05 20:32:42,137:INFO:              m2cgen: Not installed
2023-01-05 20:32:42,137:INFO:           evidently: Not installed
2023-01-05 20:32:42,137:INFO:                nltk: 3.7
2023-01-05 20:32:42,137:INFO:            pyLDAvis: Not installed
2023-01-05 20:32:42,137:INFO:              gensim: 4.1.2
2023-01-05 20:32:42,137:INFO:               spacy: 3.4.2
2023-01-05 20:32:42,137:INFO:           wordcloud: Not installed
2023-01-05 20:32:42,137:INFO:            textblob: Not installed
2023-01-05 20:32:42,137:INFO:               fugue: Not installed
2023-01-05 20:32:42,137:INFO:           streamlit: Not installed
2023-01-05 20:32:42,138:INFO:             prophet: Not installed
2023-01-05 20:32:42,138:INFO:None
2023-01-05 20:32:42,138:INFO:Set up data.
2023-01-05 20:32:42,157:INFO:Set up train/test split.
2023-01-05 20:32:42,170:INFO:Set up index.
2023-01-05 20:32:42,172:INFO:Set up folding strategy.
2023-01-05 20:32:42,172:INFO:Assigning column types.
2023-01-05 20:32:42,182:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-01-05 20:32:42,182:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-01-05 20:32:42,188:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-05 20:32:42,193:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-05 20:32:42,262:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-05 20:32:42,310:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-05 20:32:42,311:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:32:42,475:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:32:42,476:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-01-05 20:32:42,480:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-05 20:32:42,486:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-05 20:32:42,553:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-05 20:32:42,601:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-05 20:32:42,602:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:32:42,602:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:32:42,603:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-01-05 20:32:42,608:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-05 20:32:42,612:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-05 20:32:42,678:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-05 20:32:42,726:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-05 20:32:42,726:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:32:42,727:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:32:42,732:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-05 20:32:42,737:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-05 20:32:42,809:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-05 20:32:42,858:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-05 20:32:42,858:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:32:42,859:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:32:42,859:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-01-05 20:32:42,869:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-05 20:32:42,938:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-05 20:32:42,984:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-05 20:32:42,985:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:32:42,985:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:32:42,995:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-05 20:32:43,061:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-05 20:32:43,109:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-05 20:32:43,110:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:32:43,110:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:32:43,110:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-01-05 20:32:43,188:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-05 20:32:43,239:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-05 20:32:43,240:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:32:43,240:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:32:43,319:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-05 20:32:43,367:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-05 20:32:43,368:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:32:43,368:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:32:43,369:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-01-05 20:32:43,446:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-05 20:32:43,493:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:32:43,493:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:32:43,574:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-05 20:32:43,624:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:32:43,624:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:32:43,625:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-01-05 20:32:43,756:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:32:43,757:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:32:43,884:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:32:43,884:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:32:43,886:INFO:Preparing preprocessing pipeline...
2023-01-05 20:32:43,888:INFO:Set up simple imputation.
2023-01-05 20:32:43,889:INFO:Set up column transformation.
2023-01-05 20:32:43,889:INFO:Set up feature normalization.
2023-01-05 20:32:44,555:INFO:Finished creating preprocessing pipeline.
2023-01-05 20:32:44,562:INFO:Pipeline: Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2023-01-05 20:32:44,562:INFO:Creating final display dataframe.
2023-01-05 20:32:45,144:INFO:Setup _display_container:                Description             Value
0               Session id               123
1                   Target        b2b+b2c+vt
2              Target type        Regression
3               Data shape        (9930, 48)
4         Train data shape        (6951, 48)
5          Test data shape        (2979, 48)
6         Numeric features                 8
7               Preprocess              True
8          Imputation type            simple
9       Numeric imputation              mean
10  Categorical imputation              mode
11          Transformation              True
12   Transformation method       yeo-johnson
13               Normalize              True
14        Normalize method            zscore
15          Fold Generator   TimeSeriesSplit
16             Fold Number                 5
17                CPU Jobs                -1
18                 Use GPU             False
19          Log Experiment             False
20         Experiment Name  reg-default-name
21                     USI              7576
2023-01-05 20:32:45,288:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:32:45,289:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:32:45,419:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:32:45,419:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:32:45,420:INFO:setup() successfully completed in 3.56s...............
2023-01-05 20:32:45,420:INFO:Initializing compare_models()
2023-01-05 20:32:45,420:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A81F3E7220>, include=None, fold=None, round=4, cross_validation=True, sort=MAE, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001A81F3E7220>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'MAE', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-01-05 20:32:45,421:INFO:Checking exceptions
2023-01-05 20:32:45,426:INFO:Preparing display monitor
2023-01-05 20:32:45,471:INFO:Initializing Linear Regression
2023-01-05 20:32:45,472:INFO:Total runtime is 0.0 minutes
2023-01-05 20:32:45,475:INFO:SubProcess create_model() called ==================================
2023-01-05 20:32:45,476:INFO:Initializing create_model()
2023-01-05 20:32:45,476:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A81F3E7220>, estimator=lr, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A82BF9FF70>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:32:45,476:INFO:Checking exceptions
2023-01-05 20:32:45,476:INFO:Importing libraries
2023-01-05 20:32:45,476:INFO:Copying training dataset
2023-01-05 20:32:45,490:INFO:Defining folds
2023-01-05 20:32:45,491:INFO:Declaring metric variables
2023-01-05 20:32:45,497:INFO:Importing untrained model
2023-01-05 20:32:45,501:INFO:Linear Regression Imported successfully
2023-01-05 20:32:45,513:INFO:Starting cross validation
2023-01-05 20:32:45,519:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:32:54,291:INFO:Calculating mean and std
2023-01-05 20:32:54,293:INFO:Creating metrics dataframe
2023-01-05 20:32:54,296:INFO:Uploading results into container
2023-01-05 20:32:54,297:INFO:Uploading model into container now
2023-01-05 20:32:54,298:INFO:_master_model_container: 1
2023-01-05 20:32:54,298:INFO:_display_container: 2
2023-01-05 20:32:54,299:INFO:LinearRegression(n_jobs=-1)
2023-01-05 20:32:54,299:INFO:create_model() successfully completed......................................
2023-01-05 20:32:54,404:INFO:SubProcess create_model() end ==================================
2023-01-05 20:32:54,404:INFO:Creating metrics dataframe
2023-01-05 20:32:54,412:INFO:Initializing Lasso Regression
2023-01-05 20:32:54,412:INFO:Total runtime is 0.14901118278503417 minutes
2023-01-05 20:32:54,416:INFO:SubProcess create_model() called ==================================
2023-01-05 20:32:54,417:INFO:Initializing create_model()
2023-01-05 20:32:54,417:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A81F3E7220>, estimator=lasso, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A82BF9FF70>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:32:54,417:INFO:Checking exceptions
2023-01-05 20:32:54,417:INFO:Importing libraries
2023-01-05 20:32:54,417:INFO:Copying training dataset
2023-01-05 20:32:54,427:INFO:Defining folds
2023-01-05 20:32:54,427:INFO:Declaring metric variables
2023-01-05 20:32:54,432:INFO:Importing untrained model
2023-01-05 20:32:54,437:INFO:Lasso Regression Imported successfully
2023-01-05 20:32:54,446:INFO:Starting cross validation
2023-01-05 20:32:54,448:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:32:54,873:INFO:Calculating mean and std
2023-01-05 20:32:54,875:INFO:Creating metrics dataframe
2023-01-05 20:32:54,878:INFO:Uploading results into container
2023-01-05 20:32:54,878:INFO:Uploading model into container now
2023-01-05 20:32:54,878:INFO:_master_model_container: 2
2023-01-05 20:32:54,878:INFO:_display_container: 2
2023-01-05 20:32:54,879:INFO:Lasso(random_state=123)
2023-01-05 20:32:54,879:INFO:create_model() successfully completed......................................
2023-01-05 20:32:55,002:INFO:SubProcess create_model() end ==================================
2023-01-05 20:32:55,002:INFO:Creating metrics dataframe
2023-01-05 20:32:55,015:INFO:Initializing Ridge Regression
2023-01-05 20:32:55,015:INFO:Total runtime is 0.15906579891840616 minutes
2023-01-05 20:32:55,020:INFO:SubProcess create_model() called ==================================
2023-01-05 20:32:55,021:INFO:Initializing create_model()
2023-01-05 20:32:55,021:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A81F3E7220>, estimator=ridge, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A82BF9FF70>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:32:55,021:INFO:Checking exceptions
2023-01-05 20:32:55,021:INFO:Importing libraries
2023-01-05 20:32:55,021:INFO:Copying training dataset
2023-01-05 20:32:55,042:INFO:Defining folds
2023-01-05 20:32:55,043:INFO:Declaring metric variables
2023-01-05 20:32:55,047:INFO:Importing untrained model
2023-01-05 20:32:55,052:INFO:Ridge Regression Imported successfully
2023-01-05 20:32:55,062:INFO:Starting cross validation
2023-01-05 20:32:55,064:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:32:55,548:INFO:Calculating mean and std
2023-01-05 20:32:55,550:INFO:Creating metrics dataframe
2023-01-05 20:32:55,556:INFO:Uploading results into container
2023-01-05 20:32:55,557:INFO:Uploading model into container now
2023-01-05 20:32:55,558:INFO:_master_model_container: 3
2023-01-05 20:32:55,558:INFO:_display_container: 2
2023-01-05 20:32:55,558:INFO:Ridge(random_state=123)
2023-01-05 20:32:55,558:INFO:create_model() successfully completed......................................
2023-01-05 20:32:55,670:INFO:SubProcess create_model() end ==================================
2023-01-05 20:32:55,670:INFO:Creating metrics dataframe
2023-01-05 20:32:55,680:INFO:Initializing Elastic Net
2023-01-05 20:32:55,680:INFO:Total runtime is 0.17014159758885702 minutes
2023-01-05 20:32:55,684:INFO:SubProcess create_model() called ==================================
2023-01-05 20:32:55,685:INFO:Initializing create_model()
2023-01-05 20:32:55,685:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A81F3E7220>, estimator=en, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A82BF9FF70>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:32:55,685:INFO:Checking exceptions
2023-01-05 20:32:55,685:INFO:Importing libraries
2023-01-05 20:32:55,685:INFO:Copying training dataset
2023-01-05 20:32:55,695:INFO:Defining folds
2023-01-05 20:32:55,695:INFO:Declaring metric variables
2023-01-05 20:32:55,699:INFO:Importing untrained model
2023-01-05 20:32:55,704:INFO:Elastic Net Imported successfully
2023-01-05 20:32:55,713:INFO:Starting cross validation
2023-01-05 20:32:55,714:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:32:55,990:INFO:Calculating mean and std
2023-01-05 20:32:55,992:INFO:Creating metrics dataframe
2023-01-05 20:32:55,996:INFO:Uploading results into container
2023-01-05 20:32:55,996:INFO:Uploading model into container now
2023-01-05 20:32:55,997:INFO:_master_model_container: 4
2023-01-05 20:32:55,997:INFO:_display_container: 2
2023-01-05 20:32:55,998:INFO:ElasticNet(random_state=123)
2023-01-05 20:32:55,998:INFO:create_model() successfully completed......................................
2023-01-05 20:32:56,100:INFO:SubProcess create_model() end ==================================
2023-01-05 20:32:56,100:INFO:Creating metrics dataframe
2023-01-05 20:32:56,111:INFO:Initializing Least Angle Regression
2023-01-05 20:32:56,111:INFO:Total runtime is 0.17732801040013632 minutes
2023-01-05 20:32:56,116:INFO:SubProcess create_model() called ==================================
2023-01-05 20:32:56,116:INFO:Initializing create_model()
2023-01-05 20:32:56,116:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A81F3E7220>, estimator=lar, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A82BF9FF70>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:32:56,116:INFO:Checking exceptions
2023-01-05 20:32:56,116:INFO:Importing libraries
2023-01-05 20:32:56,116:INFO:Copying training dataset
2023-01-05 20:32:56,127:INFO:Defining folds
2023-01-05 20:32:56,127:INFO:Declaring metric variables
2023-01-05 20:32:56,132:INFO:Importing untrained model
2023-01-05 20:32:56,137:INFO:Least Angle Regression Imported successfully
2023-01-05 20:32:56,145:INFO:Starting cross validation
2023-01-05 20:32:56,146:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:32:56,224:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-05 20:32:56,225:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-05 20:32:56,227:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-05 20:32:56,261:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-05 20:32:56,314:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-05 20:32:56,584:INFO:Calculating mean and std
2023-01-05 20:32:56,586:INFO:Creating metrics dataframe
2023-01-05 20:32:56,589:INFO:Uploading results into container
2023-01-05 20:32:56,589:INFO:Uploading model into container now
2023-01-05 20:32:56,590:INFO:_master_model_container: 5
2023-01-05 20:32:56,590:INFO:_display_container: 2
2023-01-05 20:32:56,590:INFO:Lars(random_state=123)
2023-01-05 20:32:56,590:INFO:create_model() successfully completed......................................
2023-01-05 20:32:56,688:INFO:SubProcess create_model() end ==================================
2023-01-05 20:32:56,689:INFO:Creating metrics dataframe
2023-01-05 20:32:56,700:INFO:Initializing Lasso Least Angle Regression
2023-01-05 20:32:56,700:INFO:Total runtime is 0.18715298175811768 minutes
2023-01-05 20:32:56,704:INFO:SubProcess create_model() called ==================================
2023-01-05 20:32:56,705:INFO:Initializing create_model()
2023-01-05 20:32:56,705:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A81F3E7220>, estimator=llar, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A82BF9FF70>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:32:56,706:INFO:Checking exceptions
2023-01-05 20:32:56,706:INFO:Importing libraries
2023-01-05 20:32:56,706:INFO:Copying training dataset
2023-01-05 20:32:56,716:INFO:Defining folds
2023-01-05 20:32:56,716:INFO:Declaring metric variables
2023-01-05 20:32:56,720:INFO:Importing untrained model
2023-01-05 20:32:56,726:INFO:Lasso Least Angle Regression Imported successfully
2023-01-05 20:32:56,735:INFO:Starting cross validation
2023-01-05 20:32:56,736:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:32:56,811:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-05 20:32:56,814:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-05 20:32:56,815:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-05 20:32:56,828:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-05 20:32:56,877:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-05 20:32:57,012:INFO:Calculating mean and std
2023-01-05 20:32:57,014:INFO:Creating metrics dataframe
2023-01-05 20:32:57,017:INFO:Uploading results into container
2023-01-05 20:32:57,018:INFO:Uploading model into container now
2023-01-05 20:32:57,019:INFO:_master_model_container: 6
2023-01-05 20:32:57,019:INFO:_display_container: 2
2023-01-05 20:32:57,020:INFO:LassoLars(random_state=123)
2023-01-05 20:32:57,020:INFO:create_model() successfully completed......................................
2023-01-05 20:32:57,128:INFO:SubProcess create_model() end ==================================
2023-01-05 20:32:57,128:INFO:Creating metrics dataframe
2023-01-05 20:32:57,139:INFO:Initializing Orthogonal Matching Pursuit
2023-01-05 20:32:57,140:INFO:Total runtime is 0.1944800853729248 minutes
2023-01-05 20:32:57,143:INFO:SubProcess create_model() called ==================================
2023-01-05 20:32:57,143:INFO:Initializing create_model()
2023-01-05 20:32:57,144:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A81F3E7220>, estimator=omp, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A82BF9FF70>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:32:57,144:INFO:Checking exceptions
2023-01-05 20:32:57,144:INFO:Importing libraries
2023-01-05 20:32:57,144:INFO:Copying training dataset
2023-01-05 20:32:57,153:INFO:Defining folds
2023-01-05 20:32:57,154:INFO:Declaring metric variables
2023-01-05 20:32:57,158:INFO:Importing untrained model
2023-01-05 20:32:57,163:INFO:Orthogonal Matching Pursuit Imported successfully
2023-01-05 20:32:57,174:INFO:Starting cross validation
2023-01-05 20:32:57,175:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:32:57,249:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-05 20:32:57,251:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-05 20:32:57,254:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-05 20:32:57,282:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-05 20:32:57,315:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-05 20:32:57,455:INFO:Calculating mean and std
2023-01-05 20:32:57,457:INFO:Creating metrics dataframe
2023-01-05 20:32:57,460:INFO:Uploading results into container
2023-01-05 20:32:57,460:INFO:Uploading model into container now
2023-01-05 20:32:57,460:INFO:_master_model_container: 7
2023-01-05 20:32:57,461:INFO:_display_container: 2
2023-01-05 20:32:57,461:INFO:OrthogonalMatchingPursuit()
2023-01-05 20:32:57,461:INFO:create_model() successfully completed......................................
2023-01-05 20:32:57,565:INFO:SubProcess create_model() end ==================================
2023-01-05 20:32:57,565:INFO:Creating metrics dataframe
2023-01-05 20:32:57,576:INFO:Initializing Bayesian Ridge
2023-01-05 20:32:57,577:INFO:Total runtime is 0.20175784826278687 minutes
2023-01-05 20:32:57,581:INFO:SubProcess create_model() called ==================================
2023-01-05 20:32:57,582:INFO:Initializing create_model()
2023-01-05 20:32:57,582:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A81F3E7220>, estimator=br, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A82BF9FF70>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:32:57,582:INFO:Checking exceptions
2023-01-05 20:32:57,582:INFO:Importing libraries
2023-01-05 20:32:57,582:INFO:Copying training dataset
2023-01-05 20:32:57,593:INFO:Defining folds
2023-01-05 20:32:57,594:INFO:Declaring metric variables
2023-01-05 20:32:57,598:INFO:Importing untrained model
2023-01-05 20:32:57,604:INFO:Bayesian Ridge Imported successfully
2023-01-05 20:32:57,613:INFO:Starting cross validation
2023-01-05 20:32:57,614:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:32:57,880:INFO:Calculating mean and std
2023-01-05 20:32:57,882:INFO:Creating metrics dataframe
2023-01-05 20:32:57,885:INFO:Uploading results into container
2023-01-05 20:32:57,886:INFO:Uploading model into container now
2023-01-05 20:32:57,887:INFO:_master_model_container: 8
2023-01-05 20:32:57,887:INFO:_display_container: 2
2023-01-05 20:32:57,888:INFO:BayesianRidge()
2023-01-05 20:32:57,888:INFO:create_model() successfully completed......................................
2023-01-05 20:32:57,987:INFO:SubProcess create_model() end ==================================
2023-01-05 20:32:57,987:INFO:Creating metrics dataframe
2023-01-05 20:32:57,997:INFO:Initializing Passive Aggressive Regressor
2023-01-05 20:32:57,997:INFO:Total runtime is 0.20875698725382488 minutes
2023-01-05 20:32:58,001:INFO:SubProcess create_model() called ==================================
2023-01-05 20:32:58,002:INFO:Initializing create_model()
2023-01-05 20:32:58,002:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A81F3E7220>, estimator=par, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A82BF9FF70>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:32:58,002:INFO:Checking exceptions
2023-01-05 20:32:58,002:INFO:Importing libraries
2023-01-05 20:32:58,002:INFO:Copying training dataset
2023-01-05 20:32:58,011:INFO:Defining folds
2023-01-05 20:32:58,011:INFO:Declaring metric variables
2023-01-05 20:32:58,016:INFO:Importing untrained model
2023-01-05 20:32:58,020:INFO:Passive Aggressive Regressor Imported successfully
2023-01-05 20:32:58,030:INFO:Starting cross validation
2023-01-05 20:32:58,031:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:32:58,302:INFO:Calculating mean and std
2023-01-05 20:32:58,304:INFO:Creating metrics dataframe
2023-01-05 20:32:58,307:INFO:Uploading results into container
2023-01-05 20:32:58,307:INFO:Uploading model into container now
2023-01-05 20:32:58,307:INFO:_master_model_container: 9
2023-01-05 20:32:58,308:INFO:_display_container: 2
2023-01-05 20:32:58,308:INFO:PassiveAggressiveRegressor(random_state=123)
2023-01-05 20:32:58,308:INFO:create_model() successfully completed......................................
2023-01-05 20:32:58,408:INFO:SubProcess create_model() end ==================================
2023-01-05 20:32:58,408:INFO:Creating metrics dataframe
2023-01-05 20:32:58,421:INFO:Initializing Huber Regressor
2023-01-05 20:32:58,421:INFO:Total runtime is 0.215829340616862 minutes
2023-01-05 20:32:58,426:INFO:SubProcess create_model() called ==================================
2023-01-05 20:32:58,426:INFO:Initializing create_model()
2023-01-05 20:32:58,426:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A81F3E7220>, estimator=huber, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A82BF9FF70>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:32:58,426:INFO:Checking exceptions
2023-01-05 20:32:58,427:INFO:Importing libraries
2023-01-05 20:32:58,427:INFO:Copying training dataset
2023-01-05 20:32:58,437:INFO:Defining folds
2023-01-05 20:32:58,437:INFO:Declaring metric variables
2023-01-05 20:32:58,441:INFO:Importing untrained model
2023-01-05 20:32:58,445:INFO:Huber Regressor Imported successfully
2023-01-05 20:32:58,454:INFO:Starting cross validation
2023-01-05 20:32:58,456:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:32:58,599:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-05 20:32:58,684:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-05 20:32:58,772:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-05 20:32:58,799:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-05 20:32:58,982:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-05 20:32:59,113:INFO:Calculating mean and std
2023-01-05 20:32:59,115:INFO:Creating metrics dataframe
2023-01-05 20:32:59,118:INFO:Uploading results into container
2023-01-05 20:32:59,118:INFO:Uploading model into container now
2023-01-05 20:32:59,119:INFO:_master_model_container: 10
2023-01-05 20:32:59,119:INFO:_display_container: 2
2023-01-05 20:32:59,119:INFO:HuberRegressor()
2023-01-05 20:32:59,119:INFO:create_model() successfully completed......................................
2023-01-05 20:32:59,214:INFO:SubProcess create_model() end ==================================
2023-01-05 20:32:59,215:INFO:Creating metrics dataframe
2023-01-05 20:32:59,229:INFO:Initializing K Neighbors Regressor
2023-01-05 20:32:59,229:INFO:Total runtime is 0.22928900321324666 minutes
2023-01-05 20:32:59,233:INFO:SubProcess create_model() called ==================================
2023-01-05 20:32:59,233:INFO:Initializing create_model()
2023-01-05 20:32:59,234:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A81F3E7220>, estimator=knn, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A82BF9FF70>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:32:59,234:INFO:Checking exceptions
2023-01-05 20:32:59,234:INFO:Importing libraries
2023-01-05 20:32:59,234:INFO:Copying training dataset
2023-01-05 20:32:59,244:INFO:Defining folds
2023-01-05 20:32:59,245:INFO:Declaring metric variables
2023-01-05 20:32:59,249:INFO:Importing untrained model
2023-01-05 20:32:59,255:INFO:K Neighbors Regressor Imported successfully
2023-01-05 20:32:59,265:INFO:Starting cross validation
2023-01-05 20:32:59,266:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:32:59,896:INFO:Calculating mean and std
2023-01-05 20:32:59,898:INFO:Creating metrics dataframe
2023-01-05 20:32:59,901:INFO:Uploading results into container
2023-01-05 20:32:59,902:INFO:Uploading model into container now
2023-01-05 20:32:59,903:INFO:_master_model_container: 11
2023-01-05 20:32:59,903:INFO:_display_container: 2
2023-01-05 20:32:59,904:INFO:KNeighborsRegressor(n_jobs=-1)
2023-01-05 20:32:59,904:INFO:create_model() successfully completed......................................
2023-01-05 20:33:00,035:INFO:SubProcess create_model() end ==================================
2023-01-05 20:33:00,036:INFO:Creating metrics dataframe
2023-01-05 20:33:00,055:INFO:Initializing Decision Tree Regressor
2023-01-05 20:33:00,055:INFO:Total runtime is 0.2430668552716573 minutes
2023-01-05 20:33:00,059:INFO:SubProcess create_model() called ==================================
2023-01-05 20:33:00,059:INFO:Initializing create_model()
2023-01-05 20:33:00,059:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A81F3E7220>, estimator=dt, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A82BF9FF70>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:33:00,060:INFO:Checking exceptions
2023-01-05 20:33:00,060:INFO:Importing libraries
2023-01-05 20:33:00,060:INFO:Copying training dataset
2023-01-05 20:33:00,069:INFO:Defining folds
2023-01-05 20:33:00,070:INFO:Declaring metric variables
2023-01-05 20:33:00,074:INFO:Importing untrained model
2023-01-05 20:33:00,077:INFO:Decision Tree Regressor Imported successfully
2023-01-05 20:33:00,086:INFO:Starting cross validation
2023-01-05 20:33:00,087:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:33:00,570:INFO:Calculating mean and std
2023-01-05 20:33:00,572:INFO:Creating metrics dataframe
2023-01-05 20:33:00,576:INFO:Uploading results into container
2023-01-05 20:33:00,577:INFO:Uploading model into container now
2023-01-05 20:33:00,577:INFO:_master_model_container: 12
2023-01-05 20:33:00,578:INFO:_display_container: 2
2023-01-05 20:33:00,578:INFO:DecisionTreeRegressor(random_state=123)
2023-01-05 20:33:00,578:INFO:create_model() successfully completed......................................
2023-01-05 20:33:00,689:INFO:SubProcess create_model() end ==================================
2023-01-05 20:33:00,689:INFO:Creating metrics dataframe
2023-01-05 20:33:00,700:INFO:Initializing Random Forest Regressor
2023-01-05 20:33:00,701:INFO:Total runtime is 0.253828505674998 minutes
2023-01-05 20:33:00,706:INFO:SubProcess create_model() called ==================================
2023-01-05 20:33:00,707:INFO:Initializing create_model()
2023-01-05 20:33:00,707:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A81F3E7220>, estimator=rf, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A82BF9FF70>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:33:00,707:INFO:Checking exceptions
2023-01-05 20:33:00,707:INFO:Importing libraries
2023-01-05 20:33:00,707:INFO:Copying training dataset
2023-01-05 20:33:00,716:INFO:Defining folds
2023-01-05 20:33:00,716:INFO:Declaring metric variables
2023-01-05 20:33:00,721:INFO:Importing untrained model
2023-01-05 20:33:00,726:INFO:Random Forest Regressor Imported successfully
2023-01-05 20:33:00,734:INFO:Starting cross validation
2023-01-05 20:33:00,736:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:33:11,367:INFO:Calculating mean and std
2023-01-05 20:33:11,369:INFO:Creating metrics dataframe
2023-01-05 20:33:11,372:INFO:Uploading results into container
2023-01-05 20:33:11,373:INFO:Uploading model into container now
2023-01-05 20:33:11,373:INFO:_master_model_container: 13
2023-01-05 20:33:11,373:INFO:_display_container: 2
2023-01-05 20:33:11,373:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-01-05 20:33:11,373:INFO:create_model() successfully completed......................................
2023-01-05 20:33:11,469:INFO:SubProcess create_model() end ==================================
2023-01-05 20:33:11,469:INFO:Creating metrics dataframe
2023-01-05 20:33:11,484:INFO:Initializing Extra Trees Regressor
2023-01-05 20:33:11,485:INFO:Total runtime is 0.4335615356763204 minutes
2023-01-05 20:33:11,490:INFO:SubProcess create_model() called ==================================
2023-01-05 20:33:11,491:INFO:Initializing create_model()
2023-01-05 20:33:11,491:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A81F3E7220>, estimator=et, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A82BF9FF70>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:33:11,491:INFO:Checking exceptions
2023-01-05 20:33:11,491:INFO:Importing libraries
2023-01-05 20:33:11,491:INFO:Copying training dataset
2023-01-05 20:33:11,500:INFO:Defining folds
2023-01-05 20:33:11,500:INFO:Declaring metric variables
2023-01-05 20:33:11,505:INFO:Importing untrained model
2023-01-05 20:33:11,510:INFO:Extra Trees Regressor Imported successfully
2023-01-05 20:33:11,518:INFO:Starting cross validation
2023-01-05 20:33:11,519:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:33:16,217:INFO:Calculating mean and std
2023-01-05 20:33:16,219:INFO:Creating metrics dataframe
2023-01-05 20:33:16,224:INFO:Uploading results into container
2023-01-05 20:33:16,225:INFO:Uploading model into container now
2023-01-05 20:33:16,225:INFO:_master_model_container: 14
2023-01-05 20:33:16,225:INFO:_display_container: 2
2023-01-05 20:33:16,226:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-01-05 20:33:16,226:INFO:create_model() successfully completed......................................
2023-01-05 20:33:16,324:INFO:SubProcess create_model() end ==================================
2023-01-05 20:33:16,324:INFO:Creating metrics dataframe
2023-01-05 20:33:16,340:INFO:Initializing AdaBoost Regressor
2023-01-05 20:33:16,340:INFO:Total runtime is 0.5144772211710612 minutes
2023-01-05 20:33:16,344:INFO:SubProcess create_model() called ==================================
2023-01-05 20:33:16,345:INFO:Initializing create_model()
2023-01-05 20:33:16,345:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A81F3E7220>, estimator=ada, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A82BF9FF70>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:33:16,345:INFO:Checking exceptions
2023-01-05 20:33:16,345:INFO:Importing libraries
2023-01-05 20:33:16,345:INFO:Copying training dataset
2023-01-05 20:33:16,355:INFO:Defining folds
2023-01-05 20:33:16,355:INFO:Declaring metric variables
2023-01-05 20:33:16,360:INFO:Importing untrained model
2023-01-05 20:33:16,364:INFO:AdaBoost Regressor Imported successfully
2023-01-05 20:33:16,373:INFO:Starting cross validation
2023-01-05 20:33:16,374:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:33:18,365:INFO:Calculating mean and std
2023-01-05 20:33:18,367:INFO:Creating metrics dataframe
2023-01-05 20:33:18,371:INFO:Uploading results into container
2023-01-05 20:33:18,371:INFO:Uploading model into container now
2023-01-05 20:33:18,372:INFO:_master_model_container: 15
2023-01-05 20:33:18,372:INFO:_display_container: 2
2023-01-05 20:33:18,373:INFO:AdaBoostRegressor(random_state=123)
2023-01-05 20:33:18,373:INFO:create_model() successfully completed......................................
2023-01-05 20:33:18,497:INFO:SubProcess create_model() end ==================================
2023-01-05 20:33:18,498:INFO:Creating metrics dataframe
2023-01-05 20:33:18,512:INFO:Initializing Gradient Boosting Regressor
2023-01-05 20:33:18,512:INFO:Total runtime is 0.5506749709447225 minutes
2023-01-05 20:33:18,515:INFO:SubProcess create_model() called ==================================
2023-01-05 20:33:18,515:INFO:Initializing create_model()
2023-01-05 20:33:18,515:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A81F3E7220>, estimator=gbr, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A82BF9FF70>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:33:18,515:INFO:Checking exceptions
2023-01-05 20:33:18,516:INFO:Importing libraries
2023-01-05 20:33:18,516:INFO:Copying training dataset
2023-01-05 20:33:18,526:INFO:Defining folds
2023-01-05 20:33:18,526:INFO:Declaring metric variables
2023-01-05 20:33:18,529:INFO:Importing untrained model
2023-01-05 20:33:18,534:INFO:Gradient Boosting Regressor Imported successfully
2023-01-05 20:33:18,541:INFO:Starting cross validation
2023-01-05 20:33:18,542:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:33:24,287:INFO:Calculating mean and std
2023-01-05 20:33:24,289:INFO:Creating metrics dataframe
2023-01-05 20:33:24,292:INFO:Uploading results into container
2023-01-05 20:33:24,293:INFO:Uploading model into container now
2023-01-05 20:33:24,293:INFO:_master_model_container: 16
2023-01-05 20:33:24,293:INFO:_display_container: 2
2023-01-05 20:33:24,294:INFO:GradientBoostingRegressor(random_state=123)
2023-01-05 20:33:24,294:INFO:create_model() successfully completed......................................
2023-01-05 20:33:24,448:INFO:SubProcess create_model() end ==================================
2023-01-05 20:33:24,448:INFO:Creating metrics dataframe
2023-01-05 20:33:24,464:INFO:Initializing Light Gradient Boosting Machine
2023-01-05 20:33:24,464:INFO:Total runtime is 0.6498747746149699 minutes
2023-01-05 20:33:24,468:INFO:SubProcess create_model() called ==================================
2023-01-05 20:33:24,469:INFO:Initializing create_model()
2023-01-05 20:33:24,469:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A81F3E7220>, estimator=lightgbm, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A82BF9FF70>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:33:24,469:INFO:Checking exceptions
2023-01-05 20:33:24,469:INFO:Importing libraries
2023-01-05 20:33:24,469:INFO:Copying training dataset
2023-01-05 20:33:24,480:INFO:Defining folds
2023-01-05 20:33:24,480:INFO:Declaring metric variables
2023-01-05 20:33:24,484:INFO:Importing untrained model
2023-01-05 20:33:24,489:INFO:Light Gradient Boosting Machine Imported successfully
2023-01-05 20:33:24,509:INFO:Starting cross validation
2023-01-05 20:33:24,511:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:33:27,563:INFO:Calculating mean and std
2023-01-05 20:33:27,565:INFO:Creating metrics dataframe
2023-01-05 20:33:27,569:INFO:Uploading results into container
2023-01-05 20:33:27,569:INFO:Uploading model into container now
2023-01-05 20:33:27,570:INFO:_master_model_container: 17
2023-01-05 20:33:27,570:INFO:_display_container: 2
2023-01-05 20:33:27,570:INFO:LGBMRegressor(random_state=123)
2023-01-05 20:33:27,571:INFO:create_model() successfully completed......................................
2023-01-05 20:33:27,681:INFO:SubProcess create_model() end ==================================
2023-01-05 20:33:27,681:INFO:Creating metrics dataframe
2023-01-05 20:33:27,694:INFO:Initializing Dummy Regressor
2023-01-05 20:33:27,695:INFO:Total runtime is 0.703724745909373 minutes
2023-01-05 20:33:27,698:INFO:SubProcess create_model() called ==================================
2023-01-05 20:33:27,698:INFO:Initializing create_model()
2023-01-05 20:33:27,699:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A81F3E7220>, estimator=dummy, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A82BF9FF70>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:33:27,699:INFO:Checking exceptions
2023-01-05 20:33:27,699:INFO:Importing libraries
2023-01-05 20:33:27,699:INFO:Copying training dataset
2023-01-05 20:33:27,708:INFO:Defining folds
2023-01-05 20:33:27,709:INFO:Declaring metric variables
2023-01-05 20:33:27,713:INFO:Importing untrained model
2023-01-05 20:33:27,717:INFO:Dummy Regressor Imported successfully
2023-01-05 20:33:27,724:INFO:Starting cross validation
2023-01-05 20:33:27,725:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:33:27,966:INFO:Calculating mean and std
2023-01-05 20:33:27,968:INFO:Creating metrics dataframe
2023-01-05 20:33:27,972:INFO:Uploading results into container
2023-01-05 20:33:27,972:INFO:Uploading model into container now
2023-01-05 20:33:27,973:INFO:_master_model_container: 18
2023-01-05 20:33:27,973:INFO:_display_container: 2
2023-01-05 20:33:27,973:INFO:DummyRegressor()
2023-01-05 20:33:27,973:INFO:create_model() successfully completed......................................
2023-01-05 20:33:28,080:INFO:SubProcess create_model() end ==================================
2023-01-05 20:33:28,080:INFO:Creating metrics dataframe
2023-01-05 20:33:28,105:INFO:Initializing create_model()
2023-01-05 20:33:28,106:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A81F3E7220>, estimator=LGBMRegressor(random_state=123), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:33:28,106:INFO:Checking exceptions
2023-01-05 20:33:28,108:INFO:Importing libraries
2023-01-05 20:33:28,108:INFO:Copying training dataset
2023-01-05 20:33:28,115:INFO:Defining folds
2023-01-05 20:33:28,115:INFO:Declaring metric variables
2023-01-05 20:33:28,116:INFO:Importing untrained model
2023-01-05 20:33:28,116:INFO:Declaring custom model
2023-01-05 20:33:28,116:INFO:Light Gradient Boosting Machine Imported successfully
2023-01-05 20:33:28,117:INFO:Cross validation set to False
2023-01-05 20:33:28,117:INFO:Fitting Model
2023-01-05 20:33:28,523:INFO:LGBMRegressor(random_state=123)
2023-01-05 20:33:28,523:INFO:create_model() successfully completed......................................
2023-01-05 20:33:28,663:INFO:_master_model_container: 18
2023-01-05 20:33:28,663:INFO:_display_container: 2
2023-01-05 20:33:28,663:INFO:LGBMRegressor(random_state=123)
2023-01-05 20:33:28,664:INFO:compare_models() successfully completed......................................
2023-01-05 20:33:28,664:INFO:Initializing tune_model()
2023-01-05 20:33:28,664:INFO:tune_model(estimator=LGBMRegressor(random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=MAE, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A81F3E7220>)
2023-01-05 20:33:28,665:INFO:Checking exceptions
2023-01-05 20:33:28,696:INFO:Copying training dataset
2023-01-05 20:33:28,705:INFO:Checking base model
2023-01-05 20:33:28,705:INFO:Base model : Light Gradient Boosting Machine
2023-01-05 20:33:28,709:INFO:Declaring metric variables
2023-01-05 20:33:28,713:INFO:Defining Hyperparameters
2023-01-05 20:33:28,827:INFO:Tuning with n_jobs=-1
2023-01-05 20:33:28,827:INFO:Initializing RandomizedSearchCV
2023-01-05 20:33:34,247:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2023-01-05 20:33:34,249:INFO:Hyperparameter search completed
2023-01-05 20:33:34,249:INFO:SubProcess create_model() called ==================================
2023-01-05 20:33:34,249:INFO:Initializing create_model()
2023-01-05 20:33:34,249:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A81F3E7220>, estimator=LGBMRegressor(random_state=123), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A82BB07C40>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2023-01-05 20:33:34,249:INFO:Checking exceptions
2023-01-05 20:33:34,249:INFO:Importing libraries
2023-01-05 20:33:34,249:INFO:Copying training dataset
2023-01-05 20:33:34,258:INFO:Defining folds
2023-01-05 20:33:34,258:INFO:Declaring metric variables
2023-01-05 20:33:34,261:INFO:Importing untrained model
2023-01-05 20:33:34,261:INFO:Declaring custom model
2023-01-05 20:33:34,265:INFO:Light Gradient Boosting Machine Imported successfully
2023-01-05 20:33:34,273:INFO:Starting cross validation
2023-01-05 20:33:34,274:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:33:35,589:INFO:Calculating mean and std
2023-01-05 20:33:35,591:INFO:Creating metrics dataframe
2023-01-05 20:33:35,596:INFO:Finalizing model
2023-01-05 20:33:36,055:INFO:Uploading results into container
2023-01-05 20:33:36,056:INFO:Uploading model into container now
2023-01-05 20:33:36,056:INFO:_master_model_container: 19
2023-01-05 20:33:36,056:INFO:_display_container: 3
2023-01-05 20:33:36,057:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              num_leaves=70, random_state=123, reg_alpha=2, reg_lambda=3)
2023-01-05 20:33:36,057:INFO:create_model() successfully completed......................................
2023-01-05 20:33:36,158:INFO:SubProcess create_model() end ==================================
2023-01-05 20:33:36,159:INFO:choose_better activated
2023-01-05 20:33:36,162:INFO:SubProcess create_model() called ==================================
2023-01-05 20:33:36,162:INFO:Initializing create_model()
2023-01-05 20:33:36,163:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A81F3E7220>, estimator=LGBMRegressor(random_state=123), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:33:36,163:INFO:Checking exceptions
2023-01-05 20:33:36,164:INFO:Importing libraries
2023-01-05 20:33:36,165:INFO:Copying training dataset
2023-01-05 20:33:36,172:INFO:Defining folds
2023-01-05 20:33:36,172:INFO:Declaring metric variables
2023-01-05 20:33:36,172:INFO:Importing untrained model
2023-01-05 20:33:36,173:INFO:Declaring custom model
2023-01-05 20:33:36,173:INFO:Light Gradient Boosting Machine Imported successfully
2023-01-05 20:33:36,173:INFO:Starting cross validation
2023-01-05 20:33:36,174:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:33:37,283:INFO:Calculating mean and std
2023-01-05 20:33:37,284:INFO:Creating metrics dataframe
2023-01-05 20:33:37,286:INFO:Finalizing model
2023-01-05 20:33:37,495:INFO:Uploading results into container
2023-01-05 20:33:37,496:INFO:Uploading model into container now
2023-01-05 20:33:37,496:INFO:_master_model_container: 20
2023-01-05 20:33:37,496:INFO:_display_container: 4
2023-01-05 20:33:37,497:INFO:LGBMRegressor(random_state=123)
2023-01-05 20:33:37,497:INFO:create_model() successfully completed......................................
2023-01-05 20:33:37,599:INFO:SubProcess create_model() end ==================================
2023-01-05 20:33:37,599:INFO:LGBMRegressor(random_state=123) result for MAE is 2.201
2023-01-05 20:33:37,600:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              num_leaves=70, random_state=123, reg_alpha=2, reg_lambda=3) result for MAE is 2.4987
2023-01-05 20:33:37,600:INFO:LGBMRegressor(random_state=123) is best model
2023-01-05 20:33:37,601:INFO:choose_better completed
2023-01-05 20:33:37,601:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-01-05 20:33:37,609:INFO:_master_model_container: 20
2023-01-05 20:33:37,609:INFO:_display_container: 3
2023-01-05 20:33:37,609:INFO:LGBMRegressor(random_state=123)
2023-01-05 20:33:37,610:INFO:tune_model() successfully completed......................................
2023-01-05 20:33:37,712:INFO:Initializing plot_model()
2023-01-05 20:33:37,712:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LGBMRegressor(random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A81F3E7220>, system=True)
2023-01-05 20:33:37,712:INFO:Checking exceptions
2023-01-05 20:33:37,718:INFO:Preloading libraries
2023-01-05 20:33:37,724:INFO:Copying training dataset
2023-01-05 20:33:37,725:INFO:Plot type: error
2023-01-05 20:33:37,886:INFO:Fitting Model
2023-01-05 20:33:37,886:INFO:Scoring test/hold-out set
2023-01-05 20:33:38,274:INFO:Visual Rendered Successfully
2023-01-05 20:33:38,389:INFO:plot_model() successfully completed......................................
2023-01-05 20:33:38,390:INFO:Initializing predict_model()
2023-01-05 20:33:38,390:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A81F3E7220>, estimator=LGBMRegressor(random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001A82BEDF280>)
2023-01-05 20:33:38,390:INFO:Checking exceptions
2023-01-05 20:33:38,390:INFO:Preloading libraries
2023-01-05 20:33:38,555:INFO:Initializing finalize_model()
2023-01-05 20:33:38,555:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A81F3E7220>, estimator=LGBMRegressor(random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-01-05 20:33:38,556:INFO:Finalizing LGBMRegressor(random_state=123)
2023-01-05 20:33:38,564:INFO:Initializing create_model()
2023-01-05 20:33:38,564:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A81F3E7220>, estimator=LGBMRegressor(random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-01-05 20:33:38,564:INFO:Checking exceptions
2023-01-05 20:33:38,565:INFO:Importing libraries
2023-01-05 20:33:38,565:INFO:Copying training dataset
2023-01-05 20:33:38,566:INFO:Defining folds
2023-01-05 20:33:38,566:INFO:Declaring metric variables
2023-01-05 20:33:38,566:INFO:Importing untrained model
2023-01-05 20:33:38,566:INFO:Declaring custom model
2023-01-05 20:33:38,567:INFO:Light Gradient Boosting Machine Imported successfully
2023-01-05 20:33:38,568:INFO:Cross validation set to False
2023-01-05 20:33:38,568:INFO:Fitting Model
2023-01-05 20:33:39,534:INFO:Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator', LGBMRegressor(random_state=123))])
2023-01-05 20:33:39,534:INFO:create_model() successfully completed......................................
2023-01-05 20:33:39,644:INFO:_master_model_container: 20
2023-01-05 20:33:39,644:INFO:_display_container: 4
2023-01-05 20:33:39,650:INFO:Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator', LGBMRegressor(random_state=123))])
2023-01-05 20:33:39,650:INFO:finalize_model() successfully completed......................................
2023-01-05 20:33:39,773:INFO:Initializing predict_model()
2023-01-05 20:33:39,774:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A81F3E7220>, estimator=Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator', LGBMRegressor(random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001A82BEDF940>)
2023-01-05 20:33:39,774:INFO:Checking exceptions
2023-01-05 20:33:39,774:INFO:Preloading libraries
2023-01-05 20:33:39,776:INFO:Set up data.
2023-01-05 20:33:39,790:INFO:Set up index.
2023-01-05 20:33:40,232:INFO:Initializing save_model()
2023-01-05 20:33:40,233:INFO:save_model(model=Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator', LGBMRegressor(random_state=123))]), model_name=c:\Users\Kodotautas\Desktop\Data_science\7_TIME_SERIES_FORECAST_AUTOML/models/final_model.pkl, prep_pipe_=Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-01-05 20:33:40,233:INFO:Adding model into prep_pipe
2023-01-05 20:33:40,242:WARNING:Only Model saved as it was a pipeline.
2023-01-05 20:33:40,250:INFO:c:\Users\Kodotautas\Desktop\Data_science\7_TIME_SERIES_FORECAST_AUTOML/models/final_model.pkl.pkl saved in current working directory
2023-01-05 20:33:40,257:INFO:Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator', LGBMRegressor(random_state=123))])
2023-01-05 20:33:40,257:INFO:save_model() successfully completed......................................
2023-01-05 20:37:33,696:INFO:PyCaret RegressionExperiment
2023-01-05 20:37:33,697:INFO:Logging name: reg-default-name
2023-01-05 20:37:33,697:INFO:ML Usecase: MLUsecase.REGRESSION
2023-01-05 20:37:33,697:INFO:version 3.0.0.rc6
2023-01-05 20:37:33,697:INFO:Initializing setup()
2023-01-05 20:37:33,697:INFO:self.USI: 6279
2023-01-05 20:37:33,697:INFO:self._variable_keys: {'y_train', 'data', 'gpu_n_jobs_param', 'fold_shuffle_param', 'n_jobs_param', 'exp_name_log', 'fold_generator', 'seed', 'gpu_param', 'USI', 'exp_id', 'logging_param', 'html_param', 'transform_target_param', 'y_test', 'target_param', 'X', 'X_test', 'log_plots_param', 'pipeline', '_available_plots', 'idx', 'fold_groups_param', 'X_train', '_ml_usecase', 'y', 'memory'}
2023-01-05 20:37:33,697:INFO:Checking environment
2023-01-05 20:37:33,697:INFO:python_version: 3.9.13
2023-01-05 20:37:33,697:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-01-05 20:37:33,697:INFO:machine: AMD64
2023-01-05 20:37:33,697:INFO:platform: Windows-10-10.0.19044-SP0
2023-01-05 20:37:33,697:INFO:Memory: svmem(total=17114804224, available=8737091584, percent=49.0, used=8377712640, free=8737091584)
2023-01-05 20:37:33,698:INFO:Physical Core: 4
2023-01-05 20:37:33,698:INFO:Logical Core: 4
2023-01-05 20:37:33,698:INFO:Checking libraries
2023-01-05 20:37:33,698:INFO:System:
2023-01-05 20:37:33,698:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-01-05 20:37:33,698:INFO:executable: c:\Users\Kodotautas\anaconda3\python.exe
2023-01-05 20:37:33,698:INFO:   machine: Windows-10-10.0.19044-SP0
2023-01-05 20:37:33,698:INFO:PyCaret required dependencies:
2023-01-05 20:37:33,698:INFO:                 pip: 22.2.2
2023-01-05 20:37:33,698:INFO:          setuptools: 63.4.1
2023-01-05 20:37:33,698:INFO:             pycaret: 3.0.0rc6
2023-01-05 20:37:33,698:INFO:             IPython: 7.31.1
2023-01-05 20:37:33,698:INFO:          ipywidgets: 7.6.5
2023-01-05 20:37:33,698:INFO:                tqdm: 4.64.1
2023-01-05 20:37:33,698:INFO:               numpy: 1.21.5
2023-01-05 20:37:33,698:INFO:              pandas: 1.4.4
2023-01-05 20:37:33,699:INFO:              jinja2: 2.11.3
2023-01-05 20:37:33,699:INFO:               scipy: 1.9.1
2023-01-05 20:37:33,699:INFO:              joblib: 1.2.0
2023-01-05 20:37:33,699:INFO:             sklearn: 1.0.2
2023-01-05 20:37:33,699:INFO:                pyod: 1.0.7
2023-01-05 20:37:33,699:INFO:            imblearn: 0.10.1
2023-01-05 20:37:33,699:INFO:   category_encoders: 2.5.1.post0
2023-01-05 20:37:33,699:INFO:            lightgbm: 3.3.3
2023-01-05 20:37:33,699:INFO:               numba: 0.55.1
2023-01-05 20:37:33,699:INFO:            requests: 2.28.1
2023-01-05 20:37:33,699:INFO:          matplotlib: 3.5.2
2023-01-05 20:37:33,699:INFO:          scikitplot: 0.3.7
2023-01-05 20:37:33,699:INFO:         yellowbrick: 1.5
2023-01-05 20:37:33,699:INFO:              plotly: 5.9.0
2023-01-05 20:37:33,699:INFO:             kaleido: 0.2.1
2023-01-05 20:37:33,699:INFO:         statsmodels: 0.13.2
2023-01-05 20:37:33,699:INFO:              sktime: 0.14.1
2023-01-05 20:37:33,699:INFO:               tbats: 1.1.2
2023-01-05 20:37:33,699:INFO:            pmdarima: 2.0.2
2023-01-05 20:37:33,700:INFO:              psutil: 5.9.0
2023-01-05 20:37:33,700:INFO:PyCaret optional dependencies:
2023-01-05 20:37:33,700:INFO:                shap: 0.41.0
2023-01-05 20:37:33,700:INFO:           interpret: Not installed
2023-01-05 20:37:33,700:INFO:                umap: Not installed
2023-01-05 20:37:33,700:INFO:    pandas_profiling: Not installed
2023-01-05 20:37:33,700:INFO:  explainerdashboard: Not installed
2023-01-05 20:37:33,700:INFO:             autoviz: Not installed
2023-01-05 20:37:33,700:INFO:           fairlearn: Not installed
2023-01-05 20:37:33,700:INFO:             xgboost: Not installed
2023-01-05 20:37:33,700:INFO:            catboost: Not installed
2023-01-05 20:37:33,700:INFO:              kmodes: Not installed
2023-01-05 20:37:33,700:INFO:             mlxtend: Not installed
2023-01-05 20:37:33,700:INFO:       statsforecast: Not installed
2023-01-05 20:37:33,700:INFO:        tune_sklearn: 0.4.3
2023-01-05 20:37:33,700:INFO:                 ray: 2.0.0
2023-01-05 20:37:33,700:INFO:            hyperopt: 0.2.7
2023-01-05 20:37:33,700:INFO:              optuna: 3.0.1
2023-01-05 20:37:33,700:INFO:               skopt: 0.9.0
2023-01-05 20:37:33,700:INFO:              mlflow: Not installed
2023-01-05 20:37:33,700:INFO:              gradio: Not installed
2023-01-05 20:37:33,700:INFO:             fastapi: 0.88.0
2023-01-05 20:37:33,701:INFO:             uvicorn: 0.20.0
2023-01-05 20:37:33,701:INFO:              m2cgen: Not installed
2023-01-05 20:37:33,701:INFO:           evidently: Not installed
2023-01-05 20:37:33,701:INFO:                nltk: 3.7
2023-01-05 20:37:33,701:INFO:            pyLDAvis: Not installed
2023-01-05 20:37:33,701:INFO:              gensim: 4.1.2
2023-01-05 20:37:33,701:INFO:               spacy: 3.4.2
2023-01-05 20:37:33,701:INFO:           wordcloud: Not installed
2023-01-05 20:37:33,701:INFO:            textblob: Not installed
2023-01-05 20:37:33,701:INFO:               fugue: Not installed
2023-01-05 20:37:33,701:INFO:           streamlit: Not installed
2023-01-05 20:37:33,701:INFO:             prophet: Not installed
2023-01-05 20:37:33,701:INFO:None
2023-01-05 20:37:33,701:INFO:Set up data.
2023-01-05 20:37:33,722:INFO:Set up train/test split.
2023-01-05 20:37:33,734:INFO:Set up index.
2023-01-05 20:37:33,736:INFO:Set up folding strategy.
2023-01-05 20:37:33,736:INFO:Assigning column types.
2023-01-05 20:37:33,747:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-01-05 20:37:33,747:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-01-05 20:37:33,752:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-05 20:37:33,757:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-05 20:37:33,824:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-05 20:37:33,873:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-05 20:37:33,873:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:37:33,874:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:37:33,874:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-01-05 20:37:33,880:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-05 20:37:33,885:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-05 20:37:33,951:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-05 20:37:33,997:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-05 20:37:33,997:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:37:33,998:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:37:33,998:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-01-05 20:37:34,003:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-05 20:37:34,008:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-05 20:37:34,074:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-05 20:37:34,125:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-05 20:37:34,125:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:37:34,126:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:37:34,131:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-05 20:37:34,136:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-05 20:37:34,203:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-05 20:37:34,253:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-05 20:37:34,254:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:37:34,254:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:37:34,254:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-01-05 20:37:34,264:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-05 20:37:34,335:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-05 20:37:34,383:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-05 20:37:34,384:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:37:34,384:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:37:34,394:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-05 20:37:34,460:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-05 20:37:34,509:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-05 20:37:34,510:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:37:34,510:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:37:34,510:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-01-05 20:37:34,591:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-05 20:37:34,638:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-05 20:37:34,639:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:37:34,639:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:37:34,720:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-05 20:37:34,772:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-05 20:37:34,772:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:37:34,772:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:37:34,773:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-01-05 20:37:34,851:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-05 20:37:34,900:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:37:34,900:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:37:34,985:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-05 20:37:35,035:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:37:35,035:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:37:35,035:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-01-05 20:37:35,162:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:37:35,163:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:37:35,291:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:37:35,292:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:37:35,293:INFO:Preparing preprocessing pipeline...
2023-01-05 20:37:35,295:INFO:Set up simple imputation.
2023-01-05 20:37:35,295:INFO:Set up column transformation.
2023-01-05 20:37:35,295:INFO:Set up feature normalization.
2023-01-05 20:37:35,333:INFO:Finished creating preprocessing pipeline.
2023-01-05 20:37:35,339:INFO:Pipeline: Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2023-01-05 20:37:35,339:INFO:Creating final display dataframe.
2023-01-05 20:37:35,578:INFO:Setup _display_container:                Description             Value
0               Session id               123
1                   Target        b2b+b2c+vt
2              Target type        Regression
3               Data shape        (9930, 48)
4         Train data shape        (6951, 48)
5          Test data shape        (2979, 48)
6         Numeric features                 8
7               Preprocess              True
8          Imputation type            simple
9       Numeric imputation              mean
10  Categorical imputation              mode
11          Transformation              True
12   Transformation method       yeo-johnson
13               Normalize              True
14        Normalize method            zscore
15          Fold Generator   TimeSeriesSplit
16             Fold Number                 5
17                CPU Jobs                -1
18                 Use GPU             False
19          Log Experiment             False
20         Experiment Name  reg-default-name
21                     USI              6279
2023-01-05 20:37:35,722:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:37:35,722:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:37:35,852:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:37:35,852:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:37:35,853:INFO:setup() successfully completed in 2.16s...............
2023-01-05 20:37:35,853:INFO:Initializing compare_models()
2023-01-05 20:37:35,853:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A82C270700>, include=None, fold=None, round=4, cross_validation=True, sort=MAE, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001A82C270700>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'MAE', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-01-05 20:37:35,853:INFO:Checking exceptions
2023-01-05 20:37:35,858:INFO:Preparing display monitor
2023-01-05 20:37:35,905:INFO:Initializing Linear Regression
2023-01-05 20:37:35,905:INFO:Total runtime is 0.0 minutes
2023-01-05 20:37:35,919:INFO:SubProcess create_model() called ==================================
2023-01-05 20:37:35,920:INFO:Initializing create_model()
2023-01-05 20:37:35,920:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A82C270700>, estimator=lr, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A82BA2BA60>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:37:35,920:INFO:Checking exceptions
2023-01-05 20:37:35,920:INFO:Importing libraries
2023-01-05 20:37:35,920:INFO:Copying training dataset
2023-01-05 20:37:35,939:INFO:Defining folds
2023-01-05 20:37:35,939:INFO:Declaring metric variables
2023-01-05 20:37:35,944:INFO:Importing untrained model
2023-01-05 20:37:35,948:INFO:Linear Regression Imported successfully
2023-01-05 20:37:35,959:INFO:Starting cross validation
2023-01-05 20:37:35,961:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:37:36,255:INFO:Calculating mean and std
2023-01-05 20:37:36,256:INFO:Creating metrics dataframe
2023-01-05 20:37:36,259:INFO:Uploading results into container
2023-01-05 20:37:36,259:INFO:Uploading model into container now
2023-01-05 20:37:36,260:INFO:_master_model_container: 1
2023-01-05 20:37:36,260:INFO:_display_container: 2
2023-01-05 20:37:36,260:INFO:LinearRegression(n_jobs=-1)
2023-01-05 20:37:36,260:INFO:create_model() successfully completed......................................
2023-01-05 20:37:36,374:INFO:SubProcess create_model() end ==================================
2023-01-05 20:37:36,374:INFO:Creating metrics dataframe
2023-01-05 20:37:36,384:INFO:Initializing Lasso Regression
2023-01-05 20:37:36,384:INFO:Total runtime is 0.007986128330230713 minutes
2023-01-05 20:37:36,389:INFO:SubProcess create_model() called ==================================
2023-01-05 20:37:36,389:INFO:Initializing create_model()
2023-01-05 20:37:36,390:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A82C270700>, estimator=lasso, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A82BA2BA60>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:37:36,390:INFO:Checking exceptions
2023-01-05 20:37:36,390:INFO:Importing libraries
2023-01-05 20:37:36,390:INFO:Copying training dataset
2023-01-05 20:37:36,398:INFO:Defining folds
2023-01-05 20:37:36,399:INFO:Declaring metric variables
2023-01-05 20:37:36,402:INFO:Importing untrained model
2023-01-05 20:37:36,407:INFO:Lasso Regression Imported successfully
2023-01-05 20:37:36,414:INFO:Starting cross validation
2023-01-05 20:37:36,416:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:37:36,679:INFO:Calculating mean and std
2023-01-05 20:37:36,680:INFO:Creating metrics dataframe
2023-01-05 20:37:36,684:INFO:Uploading results into container
2023-01-05 20:37:36,685:INFO:Uploading model into container now
2023-01-05 20:37:36,685:INFO:_master_model_container: 2
2023-01-05 20:37:36,686:INFO:_display_container: 2
2023-01-05 20:37:36,686:INFO:Lasso(random_state=123)
2023-01-05 20:37:36,686:INFO:create_model() successfully completed......................................
2023-01-05 20:37:36,787:INFO:SubProcess create_model() end ==================================
2023-01-05 20:37:36,787:INFO:Creating metrics dataframe
2023-01-05 20:37:36,795:INFO:Initializing Ridge Regression
2023-01-05 20:37:36,796:INFO:Total runtime is 0.014823567867279053 minutes
2023-01-05 20:37:36,799:INFO:SubProcess create_model() called ==================================
2023-01-05 20:37:36,800:INFO:Initializing create_model()
2023-01-05 20:37:36,800:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A82C270700>, estimator=ridge, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A82BA2BA60>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:37:36,800:INFO:Checking exceptions
2023-01-05 20:37:36,800:INFO:Importing libraries
2023-01-05 20:37:36,800:INFO:Copying training dataset
2023-01-05 20:37:36,808:INFO:Defining folds
2023-01-05 20:37:36,808:INFO:Declaring metric variables
2023-01-05 20:37:36,811:INFO:Importing untrained model
2023-01-05 20:37:36,815:INFO:Ridge Regression Imported successfully
2023-01-05 20:37:36,824:INFO:Starting cross validation
2023-01-05 20:37:36,825:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:37:37,086:INFO:Calculating mean and std
2023-01-05 20:37:37,088:INFO:Creating metrics dataframe
2023-01-05 20:37:37,091:INFO:Uploading results into container
2023-01-05 20:37:37,091:INFO:Uploading model into container now
2023-01-05 20:37:37,091:INFO:_master_model_container: 3
2023-01-05 20:37:37,092:INFO:_display_container: 2
2023-01-05 20:37:37,092:INFO:Ridge(random_state=123)
2023-01-05 20:37:37,092:INFO:create_model() successfully completed......................................
2023-01-05 20:37:37,194:INFO:SubProcess create_model() end ==================================
2023-01-05 20:37:37,194:INFO:Creating metrics dataframe
2023-01-05 20:37:37,206:INFO:Initializing Elastic Net
2023-01-05 20:37:37,206:INFO:Total runtime is 0.0216780424118042 minutes
2023-01-05 20:37:37,210:INFO:SubProcess create_model() called ==================================
2023-01-05 20:37:37,211:INFO:Initializing create_model()
2023-01-05 20:37:37,211:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A82C270700>, estimator=en, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A82BA2BA60>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:37:37,211:INFO:Checking exceptions
2023-01-05 20:37:37,211:INFO:Importing libraries
2023-01-05 20:37:37,211:INFO:Copying training dataset
2023-01-05 20:37:37,222:INFO:Defining folds
2023-01-05 20:37:37,222:INFO:Declaring metric variables
2023-01-05 20:37:37,226:INFO:Importing untrained model
2023-01-05 20:37:37,231:INFO:Elastic Net Imported successfully
2023-01-05 20:37:37,241:INFO:Starting cross validation
2023-01-05 20:37:37,242:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:37:37,497:INFO:Calculating mean and std
2023-01-05 20:37:37,499:INFO:Creating metrics dataframe
2023-01-05 20:37:37,502:INFO:Uploading results into container
2023-01-05 20:37:37,502:INFO:Uploading model into container now
2023-01-05 20:37:37,502:INFO:_master_model_container: 4
2023-01-05 20:37:37,503:INFO:_display_container: 2
2023-01-05 20:37:37,503:INFO:ElasticNet(random_state=123)
2023-01-05 20:37:37,503:INFO:create_model() successfully completed......................................
2023-01-05 20:37:37,606:INFO:SubProcess create_model() end ==================================
2023-01-05 20:37:37,607:INFO:Creating metrics dataframe
2023-01-05 20:37:37,618:INFO:Initializing Least Angle Regression
2023-01-05 20:37:37,619:INFO:Total runtime is 0.02855839729309082 minutes
2023-01-05 20:37:37,623:INFO:SubProcess create_model() called ==================================
2023-01-05 20:37:37,623:INFO:Initializing create_model()
2023-01-05 20:37:37,623:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A82C270700>, estimator=lar, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A82BA2BA60>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:37:37,623:INFO:Checking exceptions
2023-01-05 20:37:37,623:INFO:Importing libraries
2023-01-05 20:37:37,623:INFO:Copying training dataset
2023-01-05 20:37:37,633:INFO:Defining folds
2023-01-05 20:37:37,633:INFO:Declaring metric variables
2023-01-05 20:37:37,638:INFO:Importing untrained model
2023-01-05 20:37:37,642:INFO:Least Angle Regression Imported successfully
2023-01-05 20:37:37,655:INFO:Starting cross validation
2023-01-05 20:37:37,657:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:37:37,731:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-05 20:37:37,733:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-05 20:37:37,736:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-05 20:37:37,738:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-05 20:37:37,795:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-05 20:37:37,934:INFO:Calculating mean and std
2023-01-05 20:37:37,936:INFO:Creating metrics dataframe
2023-01-05 20:37:37,939:INFO:Uploading results into container
2023-01-05 20:37:37,939:INFO:Uploading model into container now
2023-01-05 20:37:37,939:INFO:_master_model_container: 5
2023-01-05 20:37:37,940:INFO:_display_container: 2
2023-01-05 20:37:37,940:INFO:Lars(random_state=123)
2023-01-05 20:37:37,940:INFO:create_model() successfully completed......................................
2023-01-05 20:37:38,041:INFO:SubProcess create_model() end ==================================
2023-01-05 20:37:38,041:INFO:Creating metrics dataframe
2023-01-05 20:37:38,051:INFO:Initializing Lasso Least Angle Regression
2023-01-05 20:37:38,051:INFO:Total runtime is 0.035763947168986 minutes
2023-01-05 20:37:38,054:INFO:SubProcess create_model() called ==================================
2023-01-05 20:37:38,055:INFO:Initializing create_model()
2023-01-05 20:37:38,055:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A82C270700>, estimator=llar, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A82BA2BA60>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:37:38,055:INFO:Checking exceptions
2023-01-05 20:37:38,055:INFO:Importing libraries
2023-01-05 20:37:38,055:INFO:Copying training dataset
2023-01-05 20:37:38,065:INFO:Defining folds
2023-01-05 20:37:38,065:INFO:Declaring metric variables
2023-01-05 20:37:38,070:INFO:Importing untrained model
2023-01-05 20:37:38,075:INFO:Lasso Least Angle Regression Imported successfully
2023-01-05 20:37:38,085:INFO:Starting cross validation
2023-01-05 20:37:38,087:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:37:38,161:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-05 20:37:38,164:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-05 20:37:38,168:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-05 20:37:38,170:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-05 20:37:38,220:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-05 20:37:38,347:INFO:Calculating mean and std
2023-01-05 20:37:38,349:INFO:Creating metrics dataframe
2023-01-05 20:37:38,352:INFO:Uploading results into container
2023-01-05 20:37:38,353:INFO:Uploading model into container now
2023-01-05 20:37:38,353:INFO:_master_model_container: 6
2023-01-05 20:37:38,354:INFO:_display_container: 2
2023-01-05 20:37:38,354:INFO:LassoLars(random_state=123)
2023-01-05 20:37:38,354:INFO:create_model() successfully completed......................................
2023-01-05 20:37:38,456:INFO:SubProcess create_model() end ==================================
2023-01-05 20:37:38,456:INFO:Creating metrics dataframe
2023-01-05 20:37:38,466:INFO:Initializing Orthogonal Matching Pursuit
2023-01-05 20:37:38,467:INFO:Total runtime is 0.042700608571370445 minutes
2023-01-05 20:37:38,470:INFO:SubProcess create_model() called ==================================
2023-01-05 20:37:38,470:INFO:Initializing create_model()
2023-01-05 20:37:38,471:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A82C270700>, estimator=omp, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A82BA2BA60>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:37:38,471:INFO:Checking exceptions
2023-01-05 20:37:38,471:INFO:Importing libraries
2023-01-05 20:37:38,471:INFO:Copying training dataset
2023-01-05 20:37:38,480:INFO:Defining folds
2023-01-05 20:37:38,480:INFO:Declaring metric variables
2023-01-05 20:37:38,485:INFO:Importing untrained model
2023-01-05 20:37:38,489:INFO:Orthogonal Matching Pursuit Imported successfully
2023-01-05 20:37:38,497:INFO:Starting cross validation
2023-01-05 20:37:38,499:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:37:38,587:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-05 20:37:38,591:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-05 20:37:38,595:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-05 20:37:38,609:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-05 20:37:38,650:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-05 20:37:38,788:INFO:Calculating mean and std
2023-01-05 20:37:38,790:INFO:Creating metrics dataframe
2023-01-05 20:37:38,793:INFO:Uploading results into container
2023-01-05 20:37:38,793:INFO:Uploading model into container now
2023-01-05 20:37:38,793:INFO:_master_model_container: 7
2023-01-05 20:37:38,793:INFO:_display_container: 2
2023-01-05 20:37:38,794:INFO:OrthogonalMatchingPursuit()
2023-01-05 20:37:38,794:INFO:create_model() successfully completed......................................
2023-01-05 20:37:38,893:INFO:SubProcess create_model() end ==================================
2023-01-05 20:37:38,893:INFO:Creating metrics dataframe
2023-01-05 20:37:38,907:INFO:Initializing Bayesian Ridge
2023-01-05 20:37:38,907:INFO:Total runtime is 0.05002799431482951 minutes
2023-01-05 20:37:38,911:INFO:SubProcess create_model() called ==================================
2023-01-05 20:37:38,911:INFO:Initializing create_model()
2023-01-05 20:37:38,911:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A82C270700>, estimator=br, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A82BA2BA60>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:37:38,911:INFO:Checking exceptions
2023-01-05 20:37:38,912:INFO:Importing libraries
2023-01-05 20:37:38,912:INFO:Copying training dataset
2023-01-05 20:37:38,921:INFO:Defining folds
2023-01-05 20:37:38,921:INFO:Declaring metric variables
2023-01-05 20:37:38,924:INFO:Importing untrained model
2023-01-05 20:37:38,929:INFO:Bayesian Ridge Imported successfully
2023-01-05 20:37:38,938:INFO:Starting cross validation
2023-01-05 20:37:38,939:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:37:39,214:INFO:Calculating mean and std
2023-01-05 20:37:39,216:INFO:Creating metrics dataframe
2023-01-05 20:37:39,219:INFO:Uploading results into container
2023-01-05 20:37:39,219:INFO:Uploading model into container now
2023-01-05 20:37:39,219:INFO:_master_model_container: 8
2023-01-05 20:37:39,220:INFO:_display_container: 2
2023-01-05 20:37:39,220:INFO:BayesianRidge()
2023-01-05 20:37:39,220:INFO:create_model() successfully completed......................................
2023-01-05 20:37:39,325:INFO:SubProcess create_model() end ==================================
2023-01-05 20:37:39,325:INFO:Creating metrics dataframe
2023-01-05 20:37:39,337:INFO:Initializing Passive Aggressive Regressor
2023-01-05 20:37:39,338:INFO:Total runtime is 0.057210508982340494 minutes
2023-01-05 20:37:39,342:INFO:SubProcess create_model() called ==================================
2023-01-05 20:37:39,343:INFO:Initializing create_model()
2023-01-05 20:37:39,343:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A82C270700>, estimator=par, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A82BA2BA60>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:37:39,343:INFO:Checking exceptions
2023-01-05 20:37:39,343:INFO:Importing libraries
2023-01-05 20:37:39,343:INFO:Copying training dataset
2023-01-05 20:37:39,354:INFO:Defining folds
2023-01-05 20:37:39,354:INFO:Declaring metric variables
2023-01-05 20:37:39,359:INFO:Importing untrained model
2023-01-05 20:37:39,364:INFO:Passive Aggressive Regressor Imported successfully
2023-01-05 20:37:39,373:INFO:Starting cross validation
2023-01-05 20:37:39,374:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:37:39,670:INFO:Calculating mean and std
2023-01-05 20:37:39,672:INFO:Creating metrics dataframe
2023-01-05 20:37:39,675:INFO:Uploading results into container
2023-01-05 20:37:39,675:INFO:Uploading model into container now
2023-01-05 20:37:39,676:INFO:_master_model_container: 9
2023-01-05 20:37:39,676:INFO:_display_container: 2
2023-01-05 20:37:39,676:INFO:PassiveAggressiveRegressor(random_state=123)
2023-01-05 20:37:39,676:INFO:create_model() successfully completed......................................
2023-01-05 20:37:39,786:INFO:SubProcess create_model() end ==================================
2023-01-05 20:37:39,786:INFO:Creating metrics dataframe
2023-01-05 20:37:39,799:INFO:Initializing Huber Regressor
2023-01-05 20:37:39,799:INFO:Total runtime is 0.06489679018656412 minutes
2023-01-05 20:37:39,804:INFO:SubProcess create_model() called ==================================
2023-01-05 20:37:39,804:INFO:Initializing create_model()
2023-01-05 20:37:39,804:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A82C270700>, estimator=huber, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A82BA2BA60>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:37:39,804:INFO:Checking exceptions
2023-01-05 20:37:39,804:INFO:Importing libraries
2023-01-05 20:37:39,804:INFO:Copying training dataset
2023-01-05 20:37:39,815:INFO:Defining folds
2023-01-05 20:37:39,815:INFO:Declaring metric variables
2023-01-05 20:37:39,820:INFO:Importing untrained model
2023-01-05 20:37:39,824:INFO:Huber Regressor Imported successfully
2023-01-05 20:37:39,833:INFO:Starting cross validation
2023-01-05 20:37:39,835:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:37:40,004:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-05 20:37:40,102:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-05 20:37:40,246:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-05 20:37:40,288:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-05 20:37:40,507:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-05 20:37:40,631:INFO:Calculating mean and std
2023-01-05 20:37:40,634:INFO:Creating metrics dataframe
2023-01-05 20:37:40,638:INFO:Uploading results into container
2023-01-05 20:37:40,638:INFO:Uploading model into container now
2023-01-05 20:37:40,638:INFO:_master_model_container: 10
2023-01-05 20:37:40,638:INFO:_display_container: 2
2023-01-05 20:37:40,639:INFO:HuberRegressor()
2023-01-05 20:37:40,639:INFO:create_model() successfully completed......................................
2023-01-05 20:37:40,766:INFO:SubProcess create_model() end ==================================
2023-01-05 20:37:40,766:INFO:Creating metrics dataframe
2023-01-05 20:37:40,787:INFO:Initializing K Neighbors Regressor
2023-01-05 20:37:40,788:INFO:Total runtime is 0.08138686021169025 minutes
2023-01-05 20:37:40,792:INFO:SubProcess create_model() called ==================================
2023-01-05 20:37:40,792:INFO:Initializing create_model()
2023-01-05 20:37:40,792:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A82C270700>, estimator=knn, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A82BA2BA60>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:37:40,792:INFO:Checking exceptions
2023-01-05 20:37:40,792:INFO:Importing libraries
2023-01-05 20:37:40,793:INFO:Copying training dataset
2023-01-05 20:37:40,803:INFO:Defining folds
2023-01-05 20:37:40,803:INFO:Declaring metric variables
2023-01-05 20:37:40,807:INFO:Importing untrained model
2023-01-05 20:37:40,811:INFO:K Neighbors Regressor Imported successfully
2023-01-05 20:37:40,825:INFO:Starting cross validation
2023-01-05 20:37:40,826:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:37:41,476:INFO:Calculating mean and std
2023-01-05 20:37:41,478:INFO:Creating metrics dataframe
2023-01-05 20:37:41,481:INFO:Uploading results into container
2023-01-05 20:37:41,482:INFO:Uploading model into container now
2023-01-05 20:37:41,482:INFO:_master_model_container: 11
2023-01-05 20:37:41,482:INFO:_display_container: 2
2023-01-05 20:37:41,482:INFO:KNeighborsRegressor(n_jobs=-1)
2023-01-05 20:37:41,482:INFO:create_model() successfully completed......................................
2023-01-05 20:37:41,595:INFO:SubProcess create_model() end ==================================
2023-01-05 20:37:41,595:INFO:Creating metrics dataframe
2023-01-05 20:37:41,610:INFO:Initializing Decision Tree Regressor
2023-01-05 20:37:41,611:INFO:Total runtime is 0.09510353406270344 minutes
2023-01-05 20:37:41,616:INFO:SubProcess create_model() called ==================================
2023-01-05 20:37:41,617:INFO:Initializing create_model()
2023-01-05 20:37:41,617:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A82C270700>, estimator=dt, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A82BA2BA60>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:37:41,617:INFO:Checking exceptions
2023-01-05 20:37:41,617:INFO:Importing libraries
2023-01-05 20:37:41,617:INFO:Copying training dataset
2023-01-05 20:37:41,626:INFO:Defining folds
2023-01-05 20:37:41,626:INFO:Declaring metric variables
2023-01-05 20:37:41,631:INFO:Importing untrained model
2023-01-05 20:37:41,636:INFO:Decision Tree Regressor Imported successfully
2023-01-05 20:37:41,645:INFO:Starting cross validation
2023-01-05 20:37:41,647:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:37:42,265:INFO:Calculating mean and std
2023-01-05 20:37:42,267:INFO:Creating metrics dataframe
2023-01-05 20:37:42,272:INFO:Uploading results into container
2023-01-05 20:37:42,273:INFO:Uploading model into container now
2023-01-05 20:37:42,273:INFO:_master_model_container: 12
2023-01-05 20:37:42,273:INFO:_display_container: 2
2023-01-05 20:37:42,274:INFO:DecisionTreeRegressor(random_state=123)
2023-01-05 20:37:42,274:INFO:create_model() successfully completed......................................
2023-01-05 20:37:42,394:INFO:SubProcess create_model() end ==================================
2023-01-05 20:37:42,395:INFO:Creating metrics dataframe
2023-01-05 20:37:42,411:INFO:Initializing Random Forest Regressor
2023-01-05 20:37:42,411:INFO:Total runtime is 0.1084368348121643 minutes
2023-01-05 20:37:42,416:INFO:SubProcess create_model() called ==================================
2023-01-05 20:37:42,417:INFO:Initializing create_model()
2023-01-05 20:37:42,417:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A82C270700>, estimator=rf, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A82BA2BA60>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:37:42,417:INFO:Checking exceptions
2023-01-05 20:37:42,417:INFO:Importing libraries
2023-01-05 20:37:42,417:INFO:Copying training dataset
2023-01-05 20:37:42,426:INFO:Defining folds
2023-01-05 20:37:42,426:INFO:Declaring metric variables
2023-01-05 20:37:42,431:INFO:Importing untrained model
2023-01-05 20:37:42,435:INFO:Random Forest Regressor Imported successfully
2023-01-05 20:37:42,443:INFO:Starting cross validation
2023-01-05 20:37:42,448:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:37:52,277:INFO:Calculating mean and std
2023-01-05 20:37:52,279:INFO:Creating metrics dataframe
2023-01-05 20:37:52,282:INFO:Uploading results into container
2023-01-05 20:37:52,283:INFO:Uploading model into container now
2023-01-05 20:37:52,284:INFO:_master_model_container: 13
2023-01-05 20:37:52,284:INFO:_display_container: 2
2023-01-05 20:37:52,284:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-01-05 20:37:52,285:INFO:create_model() successfully completed......................................
2023-01-05 20:37:52,389:INFO:SubProcess create_model() end ==================================
2023-01-05 20:37:52,389:INFO:Creating metrics dataframe
2023-01-05 20:37:52,402:INFO:Initializing Extra Trees Regressor
2023-01-05 20:37:52,402:INFO:Total runtime is 0.27495349645614625 minutes
2023-01-05 20:37:52,405:INFO:SubProcess create_model() called ==================================
2023-01-05 20:37:52,406:INFO:Initializing create_model()
2023-01-05 20:37:52,406:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A82C270700>, estimator=et, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A82BA2BA60>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:37:52,406:INFO:Checking exceptions
2023-01-05 20:37:52,406:INFO:Importing libraries
2023-01-05 20:37:52,406:INFO:Copying training dataset
2023-01-05 20:37:52,415:INFO:Defining folds
2023-01-05 20:37:52,416:INFO:Declaring metric variables
2023-01-05 20:37:52,420:INFO:Importing untrained model
2023-01-05 20:37:52,424:INFO:Extra Trees Regressor Imported successfully
2023-01-05 20:37:52,432:INFO:Starting cross validation
2023-01-05 20:37:52,434:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:37:56,698:INFO:Calculating mean and std
2023-01-05 20:37:56,699:INFO:Creating metrics dataframe
2023-01-05 20:37:56,703:INFO:Uploading results into container
2023-01-05 20:37:56,703:INFO:Uploading model into container now
2023-01-05 20:37:56,704:INFO:_master_model_container: 14
2023-01-05 20:37:56,704:INFO:_display_container: 2
2023-01-05 20:37:56,704:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-01-05 20:37:56,704:INFO:create_model() successfully completed......................................
2023-01-05 20:37:56,804:INFO:SubProcess create_model() end ==================================
2023-01-05 20:37:56,804:INFO:Creating metrics dataframe
2023-01-05 20:37:56,819:INFO:Initializing AdaBoost Regressor
2023-01-05 20:37:56,819:INFO:Total runtime is 0.34857022762298584 minutes
2023-01-05 20:37:56,823:INFO:SubProcess create_model() called ==================================
2023-01-05 20:37:56,824:INFO:Initializing create_model()
2023-01-05 20:37:56,824:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A82C270700>, estimator=ada, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A82BA2BA60>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:37:56,824:INFO:Checking exceptions
2023-01-05 20:37:56,824:INFO:Importing libraries
2023-01-05 20:37:56,824:INFO:Copying training dataset
2023-01-05 20:37:56,833:INFO:Defining folds
2023-01-05 20:37:56,834:INFO:Declaring metric variables
2023-01-05 20:37:56,839:INFO:Importing untrained model
2023-01-05 20:37:56,843:INFO:AdaBoost Regressor Imported successfully
2023-01-05 20:37:56,851:INFO:Starting cross validation
2023-01-05 20:37:56,853:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:37:58,719:INFO:Calculating mean and std
2023-01-05 20:37:58,721:INFO:Creating metrics dataframe
2023-01-05 20:37:58,724:INFO:Uploading results into container
2023-01-05 20:37:58,724:INFO:Uploading model into container now
2023-01-05 20:37:58,724:INFO:_master_model_container: 15
2023-01-05 20:37:58,725:INFO:_display_container: 2
2023-01-05 20:37:58,725:INFO:AdaBoostRegressor(random_state=123)
2023-01-05 20:37:58,725:INFO:create_model() successfully completed......................................
2023-01-05 20:37:58,823:INFO:SubProcess create_model() end ==================================
2023-01-05 20:37:58,823:INFO:Creating metrics dataframe
2023-01-05 20:37:58,838:INFO:Initializing Gradient Boosting Regressor
2023-01-05 20:37:58,838:INFO:Total runtime is 0.3822092612584432 minutes
2023-01-05 20:37:58,842:INFO:SubProcess create_model() called ==================================
2023-01-05 20:37:58,842:INFO:Initializing create_model()
2023-01-05 20:37:58,842:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A82C270700>, estimator=gbr, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A82BA2BA60>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:37:58,842:INFO:Checking exceptions
2023-01-05 20:37:58,842:INFO:Importing libraries
2023-01-05 20:37:58,842:INFO:Copying training dataset
2023-01-05 20:37:58,852:INFO:Defining folds
2023-01-05 20:37:58,853:INFO:Declaring metric variables
2023-01-05 20:37:58,856:INFO:Importing untrained model
2023-01-05 20:37:58,861:INFO:Gradient Boosting Regressor Imported successfully
2023-01-05 20:37:58,868:INFO:Starting cross validation
2023-01-05 20:37:58,871:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:38:03,459:INFO:Calculating mean and std
2023-01-05 20:38:03,461:INFO:Creating metrics dataframe
2023-01-05 20:38:03,464:INFO:Uploading results into container
2023-01-05 20:38:03,465:INFO:Uploading model into container now
2023-01-05 20:38:03,466:INFO:_master_model_container: 16
2023-01-05 20:38:03,466:INFO:_display_container: 2
2023-01-05 20:38:03,466:INFO:GradientBoostingRegressor(random_state=123)
2023-01-05 20:38:03,467:INFO:create_model() successfully completed......................................
2023-01-05 20:38:03,569:INFO:SubProcess create_model() end ==================================
2023-01-05 20:38:03,569:INFO:Creating metrics dataframe
2023-01-05 20:38:03,581:INFO:Initializing Light Gradient Boosting Machine
2023-01-05 20:38:03,581:INFO:Total runtime is 0.4612547198931376 minutes
2023-01-05 20:38:03,585:INFO:SubProcess create_model() called ==================================
2023-01-05 20:38:03,586:INFO:Initializing create_model()
2023-01-05 20:38:03,586:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A82C270700>, estimator=lightgbm, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A82BA2BA60>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:38:03,586:INFO:Checking exceptions
2023-01-05 20:38:03,586:INFO:Importing libraries
2023-01-05 20:38:03,586:INFO:Copying training dataset
2023-01-05 20:38:03,596:INFO:Defining folds
2023-01-05 20:38:03,596:INFO:Declaring metric variables
2023-01-05 20:38:03,601:INFO:Importing untrained model
2023-01-05 20:38:03,605:INFO:Light Gradient Boosting Machine Imported successfully
2023-01-05 20:38:03,614:INFO:Starting cross validation
2023-01-05 20:38:03,616:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:38:04,729:INFO:Calculating mean and std
2023-01-05 20:38:04,731:INFO:Creating metrics dataframe
2023-01-05 20:38:04,736:INFO:Uploading results into container
2023-01-05 20:38:04,736:INFO:Uploading model into container now
2023-01-05 20:38:04,737:INFO:_master_model_container: 17
2023-01-05 20:38:04,737:INFO:_display_container: 2
2023-01-05 20:38:04,737:INFO:LGBMRegressor(random_state=123)
2023-01-05 20:38:04,737:INFO:create_model() successfully completed......................................
2023-01-05 20:38:04,839:INFO:SubProcess create_model() end ==================================
2023-01-05 20:38:04,839:INFO:Creating metrics dataframe
2023-01-05 20:38:04,852:INFO:Initializing Dummy Regressor
2023-01-05 20:38:04,852:INFO:Total runtime is 0.4824413498242696 minutes
2023-01-05 20:38:04,856:INFO:SubProcess create_model() called ==================================
2023-01-05 20:38:04,857:INFO:Initializing create_model()
2023-01-05 20:38:04,857:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A82C270700>, estimator=dummy, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A82BA2BA60>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:38:04,857:INFO:Checking exceptions
2023-01-05 20:38:04,857:INFO:Importing libraries
2023-01-05 20:38:04,857:INFO:Copying training dataset
2023-01-05 20:38:04,867:INFO:Defining folds
2023-01-05 20:38:04,867:INFO:Declaring metric variables
2023-01-05 20:38:04,871:INFO:Importing untrained model
2023-01-05 20:38:04,875:INFO:Dummy Regressor Imported successfully
2023-01-05 20:38:04,885:INFO:Starting cross validation
2023-01-05 20:38:04,886:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:38:05,141:INFO:Calculating mean and std
2023-01-05 20:38:05,143:INFO:Creating metrics dataframe
2023-01-05 20:38:05,146:INFO:Uploading results into container
2023-01-05 20:38:05,146:INFO:Uploading model into container now
2023-01-05 20:38:05,147:INFO:_master_model_container: 18
2023-01-05 20:38:05,148:INFO:_display_container: 2
2023-01-05 20:38:05,148:INFO:DummyRegressor()
2023-01-05 20:38:05,148:INFO:create_model() successfully completed......................................
2023-01-05 20:38:05,251:INFO:SubProcess create_model() end ==================================
2023-01-05 20:38:05,251:INFO:Creating metrics dataframe
2023-01-05 20:38:05,276:INFO:Initializing create_model()
2023-01-05 20:38:05,276:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A82C270700>, estimator=LGBMRegressor(random_state=123), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:38:05,276:INFO:Checking exceptions
2023-01-05 20:38:05,279:INFO:Importing libraries
2023-01-05 20:38:05,279:INFO:Copying training dataset
2023-01-05 20:38:05,288:INFO:Defining folds
2023-01-05 20:38:05,288:INFO:Declaring metric variables
2023-01-05 20:38:05,288:INFO:Importing untrained model
2023-01-05 20:38:05,288:INFO:Declaring custom model
2023-01-05 20:38:05,289:INFO:Light Gradient Boosting Machine Imported successfully
2023-01-05 20:38:05,290:INFO:Cross validation set to False
2023-01-05 20:38:05,290:INFO:Fitting Model
2023-01-05 20:38:05,524:INFO:LGBMRegressor(random_state=123)
2023-01-05 20:38:05,524:INFO:create_model() successfully completed......................................
2023-01-05 20:38:05,669:INFO:_master_model_container: 18
2023-01-05 20:38:05,669:INFO:_display_container: 2
2023-01-05 20:38:05,669:INFO:LGBMRegressor(random_state=123)
2023-01-05 20:38:05,670:INFO:compare_models() successfully completed......................................
2023-01-05 20:38:05,670:INFO:Initializing tune_model()
2023-01-05 20:38:05,671:INFO:tune_model(estimator=LGBMRegressor(random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=MAE, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A82C270700>)
2023-01-05 20:38:05,671:INFO:Checking exceptions
2023-01-05 20:38:05,705:INFO:Copying training dataset
2023-01-05 20:38:05,715:INFO:Checking base model
2023-01-05 20:38:05,716:INFO:Base model : Light Gradient Boosting Machine
2023-01-05 20:38:05,720:INFO:Declaring metric variables
2023-01-05 20:38:05,727:INFO:Defining Hyperparameters
2023-01-05 20:38:05,843:INFO:Tuning with n_jobs=-1
2023-01-05 20:38:05,843:INFO:Initializing RandomizedSearchCV
2023-01-05 20:38:11,162:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2023-01-05 20:38:11,164:INFO:Hyperparameter search completed
2023-01-05 20:38:11,164:INFO:SubProcess create_model() called ==================================
2023-01-05 20:38:11,164:INFO:Initializing create_model()
2023-01-05 20:38:11,164:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A82C270700>, estimator=LGBMRegressor(random_state=123), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A821CD5130>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2023-01-05 20:38:11,164:INFO:Checking exceptions
2023-01-05 20:38:11,165:INFO:Importing libraries
2023-01-05 20:38:11,165:INFO:Copying training dataset
2023-01-05 20:38:11,175:INFO:Defining folds
2023-01-05 20:38:11,175:INFO:Declaring metric variables
2023-01-05 20:38:11,178:INFO:Importing untrained model
2023-01-05 20:38:11,178:INFO:Declaring custom model
2023-01-05 20:38:11,183:INFO:Light Gradient Boosting Machine Imported successfully
2023-01-05 20:38:11,192:INFO:Starting cross validation
2023-01-05 20:38:11,193:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:38:12,465:INFO:Calculating mean and std
2023-01-05 20:38:12,467:INFO:Creating metrics dataframe
2023-01-05 20:38:12,472:INFO:Finalizing model
2023-01-05 20:38:12,920:INFO:Uploading results into container
2023-01-05 20:38:12,921:INFO:Uploading model into container now
2023-01-05 20:38:12,922:INFO:_master_model_container: 19
2023-01-05 20:38:12,922:INFO:_display_container: 3
2023-01-05 20:38:12,923:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              num_leaves=70, random_state=123, reg_alpha=2, reg_lambda=3)
2023-01-05 20:38:12,923:INFO:create_model() successfully completed......................................
2023-01-05 20:38:13,034:INFO:SubProcess create_model() end ==================================
2023-01-05 20:38:13,034:INFO:choose_better activated
2023-01-05 20:38:13,037:INFO:SubProcess create_model() called ==================================
2023-01-05 20:38:13,038:INFO:Initializing create_model()
2023-01-05 20:38:13,038:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A82C270700>, estimator=LGBMRegressor(random_state=123), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:38:13,038:INFO:Checking exceptions
2023-01-05 20:38:13,040:INFO:Importing libraries
2023-01-05 20:38:13,040:INFO:Copying training dataset
2023-01-05 20:38:13,048:INFO:Defining folds
2023-01-05 20:38:13,048:INFO:Declaring metric variables
2023-01-05 20:38:13,048:INFO:Importing untrained model
2023-01-05 20:38:13,049:INFO:Declaring custom model
2023-01-05 20:38:13,049:INFO:Light Gradient Boosting Machine Imported successfully
2023-01-05 20:38:13,050:INFO:Starting cross validation
2023-01-05 20:38:13,051:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:38:14,124:INFO:Calculating mean and std
2023-01-05 20:38:14,125:INFO:Creating metrics dataframe
2023-01-05 20:38:14,127:INFO:Finalizing model
2023-01-05 20:38:14,375:INFO:Uploading results into container
2023-01-05 20:38:14,375:INFO:Uploading model into container now
2023-01-05 20:38:14,376:INFO:_master_model_container: 20
2023-01-05 20:38:14,376:INFO:_display_container: 4
2023-01-05 20:38:14,376:INFO:LGBMRegressor(random_state=123)
2023-01-05 20:38:14,376:INFO:create_model() successfully completed......................................
2023-01-05 20:38:14,487:INFO:SubProcess create_model() end ==================================
2023-01-05 20:38:14,488:INFO:LGBMRegressor(random_state=123) result for MAE is 2.201
2023-01-05 20:38:14,488:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              num_leaves=70, random_state=123, reg_alpha=2, reg_lambda=3) result for MAE is 2.4987
2023-01-05 20:38:14,489:INFO:LGBMRegressor(random_state=123) is best model
2023-01-05 20:38:14,489:INFO:choose_better completed
2023-01-05 20:38:14,489:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-01-05 20:38:14,497:INFO:_master_model_container: 20
2023-01-05 20:38:14,498:INFO:_display_container: 3
2023-01-05 20:38:14,498:INFO:LGBMRegressor(random_state=123)
2023-01-05 20:38:14,499:INFO:tune_model() successfully completed......................................
2023-01-05 20:38:14,613:INFO:Initializing plot_model()
2023-01-05 20:38:14,614:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LGBMRegressor(random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A82C270700>, system=True)
2023-01-05 20:38:14,614:INFO:Checking exceptions
2023-01-05 20:38:14,621:INFO:Preloading libraries
2023-01-05 20:38:14,627:INFO:Copying training dataset
2023-01-05 20:38:14,627:INFO:Plot type: error
2023-01-05 20:38:14,780:INFO:Fitting Model
2023-01-05 20:38:14,780:INFO:Scoring test/hold-out set
2023-01-05 20:38:15,019:INFO:Visual Rendered Successfully
2023-01-05 20:38:15,132:INFO:plot_model() successfully completed......................................
2023-01-05 20:38:15,133:INFO:Initializing predict_model()
2023-01-05 20:38:15,133:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A82C270700>, estimator=LGBMRegressor(random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001A82BB2D700>)
2023-01-05 20:38:15,133:INFO:Checking exceptions
2023-01-05 20:38:15,134:INFO:Preloading libraries
2023-01-05 20:38:15,296:INFO:Initializing finalize_model()
2023-01-05 20:38:15,296:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A82C270700>, estimator=LGBMRegressor(random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-01-05 20:38:15,297:INFO:Finalizing LGBMRegressor(random_state=123)
2023-01-05 20:38:15,305:INFO:Initializing create_model()
2023-01-05 20:38:15,305:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A82C270700>, estimator=LGBMRegressor(random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-01-05 20:38:15,305:INFO:Checking exceptions
2023-01-05 20:38:15,307:INFO:Importing libraries
2023-01-05 20:38:15,307:INFO:Copying training dataset
2023-01-05 20:38:15,307:INFO:Defining folds
2023-01-05 20:38:15,307:INFO:Declaring metric variables
2023-01-05 20:38:15,308:INFO:Importing untrained model
2023-01-05 20:38:15,308:INFO:Declaring custom model
2023-01-05 20:38:15,308:INFO:Light Gradient Boosting Machine Imported successfully
2023-01-05 20:38:15,309:INFO:Cross validation set to False
2023-01-05 20:38:15,309:INFO:Fitting Model
2023-01-05 20:38:15,720:INFO:Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator', LGBMRegressor(random_state=123))])
2023-01-05 20:38:15,720:INFO:create_model() successfully completed......................................
2023-01-05 20:38:15,824:INFO:_master_model_container: 20
2023-01-05 20:38:15,824:INFO:_display_container: 4
2023-01-05 20:38:15,830:INFO:Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator', LGBMRegressor(random_state=123))])
2023-01-05 20:38:15,830:INFO:finalize_model() successfully completed......................................
2023-01-05 20:38:15,936:INFO:Initializing predict_model()
2023-01-05 20:38:15,936:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A82C270700>, estimator=Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator', LGBMRegressor(random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001A82865DB80>)
2023-01-05 20:38:15,936:INFO:Checking exceptions
2023-01-05 20:38:15,936:INFO:Preloading libraries
2023-01-05 20:38:15,938:INFO:Set up data.
2023-01-05 20:38:15,953:INFO:Set up index.
2023-01-05 20:39:30,834:INFO:PyCaret RegressionExperiment
2023-01-05 20:39:30,834:INFO:Logging name: reg-default-name
2023-01-05 20:39:30,834:INFO:ML Usecase: MLUsecase.REGRESSION
2023-01-05 20:39:30,834:INFO:version 3.0.0.rc6
2023-01-05 20:39:30,834:INFO:Initializing setup()
2023-01-05 20:39:30,834:INFO:self.USI: f54c
2023-01-05 20:39:30,835:INFO:self._variable_keys: {'y_train', 'data', 'gpu_n_jobs_param', 'fold_shuffle_param', 'n_jobs_param', 'exp_name_log', 'fold_generator', 'seed', 'gpu_param', 'USI', 'exp_id', 'logging_param', 'html_param', 'transform_target_param', 'y_test', 'target_param', 'X', 'X_test', 'log_plots_param', 'pipeline', '_available_plots', 'idx', 'fold_groups_param', 'X_train', '_ml_usecase', 'y', 'memory'}
2023-01-05 20:39:30,835:INFO:Checking environment
2023-01-05 20:39:30,835:INFO:python_version: 3.9.13
2023-01-05 20:39:30,835:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-01-05 20:39:30,835:INFO:machine: AMD64
2023-01-05 20:39:30,835:INFO:platform: Windows-10-10.0.19044-SP0
2023-01-05 20:39:30,835:INFO:Memory: svmem(total=17114804224, available=8652627968, percent=49.4, used=8462176256, free=8652627968)
2023-01-05 20:39:30,835:INFO:Physical Core: 4
2023-01-05 20:39:30,835:INFO:Logical Core: 4
2023-01-05 20:39:30,835:INFO:Checking libraries
2023-01-05 20:39:30,835:INFO:System:
2023-01-05 20:39:30,835:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-01-05 20:39:30,835:INFO:executable: c:\Users\Kodotautas\anaconda3\python.exe
2023-01-05 20:39:30,835:INFO:   machine: Windows-10-10.0.19044-SP0
2023-01-05 20:39:30,835:INFO:PyCaret required dependencies:
2023-01-05 20:39:30,836:INFO:                 pip: 22.2.2
2023-01-05 20:39:30,836:INFO:          setuptools: 63.4.1
2023-01-05 20:39:30,836:INFO:             pycaret: 3.0.0rc6
2023-01-05 20:39:30,836:INFO:             IPython: 7.31.1
2023-01-05 20:39:30,836:INFO:          ipywidgets: 7.6.5
2023-01-05 20:39:30,836:INFO:                tqdm: 4.64.1
2023-01-05 20:39:30,836:INFO:               numpy: 1.21.5
2023-01-05 20:39:30,836:INFO:              pandas: 1.4.4
2023-01-05 20:39:30,836:INFO:              jinja2: 2.11.3
2023-01-05 20:39:30,836:INFO:               scipy: 1.9.1
2023-01-05 20:39:30,836:INFO:              joblib: 1.2.0
2023-01-05 20:39:30,836:INFO:             sklearn: 1.0.2
2023-01-05 20:39:30,836:INFO:                pyod: 1.0.7
2023-01-05 20:39:30,836:INFO:            imblearn: 0.10.1
2023-01-05 20:39:30,836:INFO:   category_encoders: 2.5.1.post0
2023-01-05 20:39:30,836:INFO:            lightgbm: 3.3.3
2023-01-05 20:39:30,836:INFO:               numba: 0.55.1
2023-01-05 20:39:30,836:INFO:            requests: 2.28.1
2023-01-05 20:39:30,837:INFO:          matplotlib: 3.5.2
2023-01-05 20:39:30,837:INFO:          scikitplot: 0.3.7
2023-01-05 20:39:30,837:INFO:         yellowbrick: 1.5
2023-01-05 20:39:30,837:INFO:              plotly: 5.9.0
2023-01-05 20:39:30,837:INFO:             kaleido: 0.2.1
2023-01-05 20:39:30,837:INFO:         statsmodels: 0.13.2
2023-01-05 20:39:30,837:INFO:              sktime: 0.14.1
2023-01-05 20:39:30,837:INFO:               tbats: 1.1.2
2023-01-05 20:39:30,837:INFO:            pmdarima: 2.0.2
2023-01-05 20:39:30,837:INFO:              psutil: 5.9.0
2023-01-05 20:39:30,837:INFO:PyCaret optional dependencies:
2023-01-05 20:39:30,837:INFO:                shap: 0.41.0
2023-01-05 20:39:30,837:INFO:           interpret: Not installed
2023-01-05 20:39:30,837:INFO:                umap: Not installed
2023-01-05 20:39:30,837:INFO:    pandas_profiling: Not installed
2023-01-05 20:39:30,837:INFO:  explainerdashboard: Not installed
2023-01-05 20:39:30,837:INFO:             autoviz: Not installed
2023-01-05 20:39:30,837:INFO:           fairlearn: Not installed
2023-01-05 20:39:30,837:INFO:             xgboost: Not installed
2023-01-05 20:39:30,837:INFO:            catboost: Not installed
2023-01-05 20:39:30,837:INFO:              kmodes: Not installed
2023-01-05 20:39:30,837:INFO:             mlxtend: Not installed
2023-01-05 20:39:30,838:INFO:       statsforecast: Not installed
2023-01-05 20:39:30,838:INFO:        tune_sklearn: 0.4.3
2023-01-05 20:39:30,838:INFO:                 ray: 2.0.0
2023-01-05 20:39:30,838:INFO:            hyperopt: 0.2.7
2023-01-05 20:39:30,838:INFO:              optuna: 3.0.1
2023-01-05 20:39:30,838:INFO:               skopt: 0.9.0
2023-01-05 20:39:30,838:INFO:              mlflow: Not installed
2023-01-05 20:39:30,838:INFO:              gradio: Not installed
2023-01-05 20:39:30,838:INFO:             fastapi: 0.88.0
2023-01-05 20:39:30,838:INFO:             uvicorn: 0.20.0
2023-01-05 20:39:30,838:INFO:              m2cgen: Not installed
2023-01-05 20:39:30,838:INFO:           evidently: Not installed
2023-01-05 20:39:30,838:INFO:                nltk: 3.7
2023-01-05 20:39:30,838:INFO:            pyLDAvis: Not installed
2023-01-05 20:39:30,838:INFO:              gensim: 4.1.2
2023-01-05 20:39:30,838:INFO:               spacy: 3.4.2
2023-01-05 20:39:30,838:INFO:           wordcloud: Not installed
2023-01-05 20:39:30,838:INFO:            textblob: Not installed
2023-01-05 20:39:30,838:INFO:               fugue: Not installed
2023-01-05 20:39:30,838:INFO:           streamlit: Not installed
2023-01-05 20:39:30,838:INFO:             prophet: Not installed
2023-01-05 20:39:30,838:INFO:None
2023-01-05 20:39:30,838:INFO:Set up data.
2023-01-05 20:39:30,857:INFO:Set up train/test split.
2023-01-05 20:39:30,869:INFO:Set up index.
2023-01-05 20:39:30,872:INFO:Set up folding strategy.
2023-01-05 20:39:30,872:INFO:Assigning column types.
2023-01-05 20:39:30,881:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-01-05 20:39:30,881:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-01-05 20:39:30,886:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-05 20:39:30,890:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-05 20:39:30,955:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-05 20:39:31,003:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-05 20:39:31,003:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:39:31,003:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:39:31,004:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-01-05 20:39:31,009:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-05 20:39:31,014:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-05 20:39:31,080:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-05 20:39:31,126:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-05 20:39:31,127:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:39:31,127:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:39:31,127:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-01-05 20:39:31,132:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-05 20:39:31,137:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-05 20:39:31,204:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-05 20:39:31,251:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-05 20:39:31,251:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:39:31,252:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:39:31,257:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-05 20:39:31,262:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-05 20:39:31,327:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-05 20:39:31,375:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-05 20:39:31,375:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:39:31,376:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:39:31,376:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-01-05 20:39:31,386:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-05 20:39:31,453:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-05 20:39:31,500:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-05 20:39:31,501:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:39:31,502:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:39:31,512:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-05 20:39:31,577:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-05 20:39:31,624:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-05 20:39:31,624:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:39:31,625:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:39:31,625:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-01-05 20:39:31,699:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-05 20:39:31,745:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-05 20:39:31,746:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:39:31,746:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:39:31,822:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-05 20:39:31,869:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-05 20:39:31,869:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:39:31,870:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:39:31,870:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-01-05 20:39:31,945:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-05 20:39:31,992:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:39:31,992:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:39:32,067:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-05 20:39:32,114:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:39:32,114:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:39:32,115:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-01-05 20:39:32,253:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:39:32,253:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:39:32,373:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:39:32,373:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:39:32,374:INFO:Preparing preprocessing pipeline...
2023-01-05 20:39:32,376:INFO:Set up simple imputation.
2023-01-05 20:39:32,376:INFO:Set up column transformation.
2023-01-05 20:39:32,376:INFO:Set up feature normalization.
2023-01-05 20:39:32,411:INFO:Finished creating preprocessing pipeline.
2023-01-05 20:39:32,417:INFO:Pipeline: Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2023-01-05 20:39:32,417:INFO:Creating final display dataframe.
2023-01-05 20:39:32,656:INFO:Setup _display_container:                Description             Value
0               Session id               123
1                   Target        b2b+b2c+vt
2              Target type        Regression
3               Data shape        (9930, 48)
4         Train data shape        (6951, 48)
5          Test data shape        (2979, 48)
6         Numeric features                 8
7               Preprocess              True
8          Imputation type            simple
9       Numeric imputation              mean
10  Categorical imputation              mode
11          Transformation              True
12   Transformation method       yeo-johnson
13               Normalize              True
14        Normalize method            zscore
15          Fold Generator   TimeSeriesSplit
16             Fold Number                 5
17                CPU Jobs                -1
18                 Use GPU             False
19          Log Experiment             False
20         Experiment Name  reg-default-name
21                     USI              f54c
2023-01-05 20:39:32,795:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:39:32,796:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:39:32,922:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:39:32,923:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:39:32,923:INFO:setup() successfully completed in 2.09s...............
2023-01-05 20:39:32,924:INFO:Initializing compare_models()
2023-01-05 20:39:32,924:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A82B8EBEB0>, include=None, fold=None, round=4, cross_validation=True, sort=MAE, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001A82B8EBEB0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'MAE', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-01-05 20:39:32,924:INFO:Checking exceptions
2023-01-05 20:39:32,929:INFO:Preparing display monitor
2023-01-05 20:39:32,971:INFO:Initializing Linear Regression
2023-01-05 20:39:32,971:INFO:Total runtime is 0.0 minutes
2023-01-05 20:39:32,975:INFO:SubProcess create_model() called ==================================
2023-01-05 20:39:32,975:INFO:Initializing create_model()
2023-01-05 20:39:32,976:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A82B8EBEB0>, estimator=lr, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A821CA7E20>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:39:32,976:INFO:Checking exceptions
2023-01-05 20:39:32,976:INFO:Importing libraries
2023-01-05 20:39:32,976:INFO:Copying training dataset
2023-01-05 20:39:32,987:INFO:Defining folds
2023-01-05 20:39:32,987:INFO:Declaring metric variables
2023-01-05 20:39:32,990:INFO:Importing untrained model
2023-01-05 20:39:32,994:INFO:Linear Regression Imported successfully
2023-01-05 20:39:33,003:INFO:Starting cross validation
2023-01-05 20:39:33,005:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:39:33,286:INFO:Calculating mean and std
2023-01-05 20:39:33,286:INFO:Creating metrics dataframe
2023-01-05 20:39:33,289:INFO:Uploading results into container
2023-01-05 20:39:33,290:INFO:Uploading model into container now
2023-01-05 20:39:33,290:INFO:_master_model_container: 1
2023-01-05 20:39:33,290:INFO:_display_container: 2
2023-01-05 20:39:33,290:INFO:LinearRegression(n_jobs=-1)
2023-01-05 20:39:33,290:INFO:create_model() successfully completed......................................
2023-01-05 20:39:33,476:INFO:SubProcess create_model() end ==================================
2023-01-05 20:39:33,476:INFO:Creating metrics dataframe
2023-01-05 20:39:33,484:INFO:Initializing Lasso Regression
2023-01-05 20:39:33,484:INFO:Total runtime is 0.008549928665161133 minutes
2023-01-05 20:39:33,489:INFO:SubProcess create_model() called ==================================
2023-01-05 20:39:33,489:INFO:Initializing create_model()
2023-01-05 20:39:33,490:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A82B8EBEB0>, estimator=lasso, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A821CA7E20>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:39:33,490:INFO:Checking exceptions
2023-01-05 20:39:33,490:INFO:Importing libraries
2023-01-05 20:39:33,490:INFO:Copying training dataset
2023-01-05 20:39:33,498:INFO:Defining folds
2023-01-05 20:39:33,498:INFO:Declaring metric variables
2023-01-05 20:39:33,502:INFO:Importing untrained model
2023-01-05 20:39:33,506:INFO:Lasso Regression Imported successfully
2023-01-05 20:39:33,514:INFO:Starting cross validation
2023-01-05 20:39:33,516:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:39:33,789:INFO:Calculating mean and std
2023-01-05 20:39:33,790:INFO:Creating metrics dataframe
2023-01-05 20:39:33,793:INFO:Uploading results into container
2023-01-05 20:39:33,793:INFO:Uploading model into container now
2023-01-05 20:39:33,794:INFO:_master_model_container: 2
2023-01-05 20:39:33,794:INFO:_display_container: 2
2023-01-05 20:39:33,794:INFO:Lasso(random_state=123)
2023-01-05 20:39:33,794:INFO:create_model() successfully completed......................................
2023-01-05 20:39:33,897:INFO:SubProcess create_model() end ==================================
2023-01-05 20:39:33,897:INFO:Creating metrics dataframe
2023-01-05 20:39:33,907:INFO:Initializing Ridge Regression
2023-01-05 20:39:33,907:INFO:Total runtime is 0.015599946180979412 minutes
2023-01-05 20:39:33,911:INFO:SubProcess create_model() called ==================================
2023-01-05 20:39:33,912:INFO:Initializing create_model()
2023-01-05 20:39:33,912:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A82B8EBEB0>, estimator=ridge, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A821CA7E20>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:39:33,912:INFO:Checking exceptions
2023-01-05 20:39:33,912:INFO:Importing libraries
2023-01-05 20:39:33,912:INFO:Copying training dataset
2023-01-05 20:39:33,920:INFO:Defining folds
2023-01-05 20:39:33,920:INFO:Declaring metric variables
2023-01-05 20:39:33,923:INFO:Importing untrained model
2023-01-05 20:39:33,927:INFO:Ridge Regression Imported successfully
2023-01-05 20:39:33,936:INFO:Starting cross validation
2023-01-05 20:39:33,937:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:39:34,197:INFO:Calculating mean and std
2023-01-05 20:39:34,199:INFO:Creating metrics dataframe
2023-01-05 20:39:34,203:INFO:Uploading results into container
2023-01-05 20:39:34,204:INFO:Uploading model into container now
2023-01-05 20:39:34,205:INFO:_master_model_container: 3
2023-01-05 20:39:34,205:INFO:_display_container: 2
2023-01-05 20:39:34,206:INFO:Ridge(random_state=123)
2023-01-05 20:39:34,206:INFO:create_model() successfully completed......................................
2023-01-05 20:39:34,317:INFO:SubProcess create_model() end ==================================
2023-01-05 20:39:34,317:INFO:Creating metrics dataframe
2023-01-05 20:39:34,328:INFO:Initializing Elastic Net
2023-01-05 20:39:34,328:INFO:Total runtime is 0.022620534896850588 minutes
2023-01-05 20:39:34,332:INFO:SubProcess create_model() called ==================================
2023-01-05 20:39:34,332:INFO:Initializing create_model()
2023-01-05 20:39:34,332:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A82B8EBEB0>, estimator=en, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A821CA7E20>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:39:34,332:INFO:Checking exceptions
2023-01-05 20:39:34,332:INFO:Importing libraries
2023-01-05 20:39:34,332:INFO:Copying training dataset
2023-01-05 20:39:34,344:INFO:Defining folds
2023-01-05 20:39:34,344:INFO:Declaring metric variables
2023-01-05 20:39:34,349:INFO:Importing untrained model
2023-01-05 20:39:34,354:INFO:Elastic Net Imported successfully
2023-01-05 20:39:34,362:INFO:Starting cross validation
2023-01-05 20:39:34,365:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:39:34,653:INFO:Calculating mean and std
2023-01-05 20:39:34,654:INFO:Creating metrics dataframe
2023-01-05 20:39:34,657:INFO:Uploading results into container
2023-01-05 20:39:34,658:INFO:Uploading model into container now
2023-01-05 20:39:34,658:INFO:_master_model_container: 4
2023-01-05 20:39:34,658:INFO:_display_container: 2
2023-01-05 20:39:34,659:INFO:ElasticNet(random_state=123)
2023-01-05 20:39:34,659:INFO:create_model() successfully completed......................................
2023-01-05 20:39:34,773:INFO:SubProcess create_model() end ==================================
2023-01-05 20:39:34,773:INFO:Creating metrics dataframe
2023-01-05 20:39:34,783:INFO:Initializing Least Angle Regression
2023-01-05 20:39:34,783:INFO:Total runtime is 0.03019040822982788 minutes
2023-01-05 20:39:34,787:INFO:SubProcess create_model() called ==================================
2023-01-05 20:39:34,787:INFO:Initializing create_model()
2023-01-05 20:39:34,788:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A82B8EBEB0>, estimator=lar, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A821CA7E20>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:39:34,788:INFO:Checking exceptions
2023-01-05 20:39:34,788:INFO:Importing libraries
2023-01-05 20:39:34,788:INFO:Copying training dataset
2023-01-05 20:39:34,797:INFO:Defining folds
2023-01-05 20:39:34,798:INFO:Declaring metric variables
2023-01-05 20:39:34,802:INFO:Importing untrained model
2023-01-05 20:39:34,807:INFO:Least Angle Regression Imported successfully
2023-01-05 20:39:34,815:INFO:Starting cross validation
2023-01-05 20:39:34,816:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:39:34,896:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-05 20:39:34,898:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-05 20:39:34,898:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-05 20:39:34,901:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-05 20:39:34,962:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-05 20:39:35,109:INFO:Calculating mean and std
2023-01-05 20:39:35,110:INFO:Creating metrics dataframe
2023-01-05 20:39:35,113:INFO:Uploading results into container
2023-01-05 20:39:35,114:INFO:Uploading model into container now
2023-01-05 20:39:35,114:INFO:_master_model_container: 5
2023-01-05 20:39:35,114:INFO:_display_container: 2
2023-01-05 20:39:35,114:INFO:Lars(random_state=123)
2023-01-05 20:39:35,114:INFO:create_model() successfully completed......................................
2023-01-05 20:39:35,224:INFO:SubProcess create_model() end ==================================
2023-01-05 20:39:35,225:INFO:Creating metrics dataframe
2023-01-05 20:39:35,237:INFO:Initializing Lasso Least Angle Regression
2023-01-05 20:39:35,237:INFO:Total runtime is 0.03775731325149536 minutes
2023-01-05 20:39:35,241:INFO:SubProcess create_model() called ==================================
2023-01-05 20:39:35,242:INFO:Initializing create_model()
2023-01-05 20:39:35,242:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A82B8EBEB0>, estimator=llar, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A821CA7E20>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:39:35,242:INFO:Checking exceptions
2023-01-05 20:39:35,242:INFO:Importing libraries
2023-01-05 20:39:35,243:INFO:Copying training dataset
2023-01-05 20:39:35,251:INFO:Defining folds
2023-01-05 20:39:35,252:INFO:Declaring metric variables
2023-01-05 20:39:35,257:INFO:Importing untrained model
2023-01-05 20:39:35,261:INFO:Lasso Least Angle Regression Imported successfully
2023-01-05 20:39:35,271:INFO:Starting cross validation
2023-01-05 20:39:35,273:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:39:35,348:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-05 20:39:35,353:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-05 20:39:35,356:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-05 20:39:35,362:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-05 20:39:35,408:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-05 20:39:35,534:INFO:Calculating mean and std
2023-01-05 20:39:35,537:INFO:Creating metrics dataframe
2023-01-05 20:39:35,543:INFO:Uploading results into container
2023-01-05 20:39:35,544:INFO:Uploading model into container now
2023-01-05 20:39:35,544:INFO:_master_model_container: 6
2023-01-05 20:39:35,544:INFO:_display_container: 2
2023-01-05 20:39:35,545:INFO:LassoLars(random_state=123)
2023-01-05 20:39:35,545:INFO:create_model() successfully completed......................................
2023-01-05 20:39:35,650:INFO:SubProcess create_model() end ==================================
2023-01-05 20:39:35,651:INFO:Creating metrics dataframe
2023-01-05 20:39:35,660:INFO:Initializing Orthogonal Matching Pursuit
2023-01-05 20:39:35,660:INFO:Total runtime is 0.04481390317281087 minutes
2023-01-05 20:39:35,664:INFO:SubProcess create_model() called ==================================
2023-01-05 20:39:35,665:INFO:Initializing create_model()
2023-01-05 20:39:35,665:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A82B8EBEB0>, estimator=omp, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A821CA7E20>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:39:35,665:INFO:Checking exceptions
2023-01-05 20:39:35,665:INFO:Importing libraries
2023-01-05 20:39:35,665:INFO:Copying training dataset
2023-01-05 20:39:35,675:INFO:Defining folds
2023-01-05 20:39:35,675:INFO:Declaring metric variables
2023-01-05 20:39:35,680:INFO:Importing untrained model
2023-01-05 20:39:35,684:INFO:Orthogonal Matching Pursuit Imported successfully
2023-01-05 20:39:35,693:INFO:Starting cross validation
2023-01-05 20:39:35,695:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:39:35,770:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-05 20:39:35,771:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-05 20:39:35,772:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-05 20:39:35,774:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-05 20:39:35,829:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-05 20:39:35,964:INFO:Calculating mean and std
2023-01-05 20:39:35,966:INFO:Creating metrics dataframe
2023-01-05 20:39:35,970:INFO:Uploading results into container
2023-01-05 20:39:35,971:INFO:Uploading model into container now
2023-01-05 20:39:35,972:INFO:_master_model_container: 7
2023-01-05 20:39:35,972:INFO:_display_container: 2
2023-01-05 20:39:35,973:INFO:OrthogonalMatchingPursuit()
2023-01-05 20:39:35,973:INFO:create_model() successfully completed......................................
2023-01-05 20:39:36,084:INFO:SubProcess create_model() end ==================================
2023-01-05 20:39:36,085:INFO:Creating metrics dataframe
2023-01-05 20:39:36,096:INFO:Initializing Bayesian Ridge
2023-01-05 20:39:36,096:INFO:Total runtime is 0.052075831095377605 minutes
2023-01-05 20:39:36,100:INFO:SubProcess create_model() called ==================================
2023-01-05 20:39:36,100:INFO:Initializing create_model()
2023-01-05 20:39:36,100:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A82B8EBEB0>, estimator=br, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A821CA7E20>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:39:36,101:INFO:Checking exceptions
2023-01-05 20:39:36,101:INFO:Importing libraries
2023-01-05 20:39:36,101:INFO:Copying training dataset
2023-01-05 20:39:36,110:INFO:Defining folds
2023-01-05 20:39:36,111:INFO:Declaring metric variables
2023-01-05 20:39:36,115:INFO:Importing untrained model
2023-01-05 20:39:36,119:INFO:Bayesian Ridge Imported successfully
2023-01-05 20:39:36,128:INFO:Starting cross validation
2023-01-05 20:39:36,130:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:39:36,404:INFO:Calculating mean and std
2023-01-05 20:39:36,406:INFO:Creating metrics dataframe
2023-01-05 20:39:36,409:INFO:Uploading results into container
2023-01-05 20:39:36,409:INFO:Uploading model into container now
2023-01-05 20:39:36,410:INFO:_master_model_container: 8
2023-01-05 20:39:36,410:INFO:_display_container: 2
2023-01-05 20:39:36,410:INFO:BayesianRidge()
2023-01-05 20:39:36,410:INFO:create_model() successfully completed......................................
2023-01-05 20:39:36,512:INFO:SubProcess create_model() end ==================================
2023-01-05 20:39:36,512:INFO:Creating metrics dataframe
2023-01-05 20:39:36,523:INFO:Initializing Passive Aggressive Regressor
2023-01-05 20:39:36,523:INFO:Total runtime is 0.05919800996780396 minutes
2023-01-05 20:39:36,527:INFO:SubProcess create_model() called ==================================
2023-01-05 20:39:36,528:INFO:Initializing create_model()
2023-01-05 20:39:36,528:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A82B8EBEB0>, estimator=par, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A821CA7E20>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:39:36,528:INFO:Checking exceptions
2023-01-05 20:39:36,528:INFO:Importing libraries
2023-01-05 20:39:36,528:INFO:Copying training dataset
2023-01-05 20:39:36,538:INFO:Defining folds
2023-01-05 20:39:36,539:INFO:Declaring metric variables
2023-01-05 20:39:36,543:INFO:Importing untrained model
2023-01-05 20:39:36,548:INFO:Passive Aggressive Regressor Imported successfully
2023-01-05 20:39:36,559:INFO:Starting cross validation
2023-01-05 20:39:36,561:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:39:36,841:INFO:Calculating mean and std
2023-01-05 20:39:36,843:INFO:Creating metrics dataframe
2023-01-05 20:39:36,846:INFO:Uploading results into container
2023-01-05 20:39:36,846:INFO:Uploading model into container now
2023-01-05 20:39:36,847:INFO:_master_model_container: 9
2023-01-05 20:39:36,847:INFO:_display_container: 2
2023-01-05 20:39:36,847:INFO:PassiveAggressiveRegressor(random_state=123)
2023-01-05 20:39:36,847:INFO:create_model() successfully completed......................................
2023-01-05 20:39:36,953:INFO:SubProcess create_model() end ==================================
2023-01-05 20:39:36,953:INFO:Creating metrics dataframe
2023-01-05 20:39:36,964:INFO:Initializing Huber Regressor
2023-01-05 20:39:36,964:INFO:Total runtime is 0.06654602686564128 minutes
2023-01-05 20:39:36,970:INFO:SubProcess create_model() called ==================================
2023-01-05 20:39:36,970:INFO:Initializing create_model()
2023-01-05 20:39:36,970:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A82B8EBEB0>, estimator=huber, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A821CA7E20>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:39:36,971:INFO:Checking exceptions
2023-01-05 20:39:36,971:INFO:Importing libraries
2023-01-05 20:39:36,971:INFO:Copying training dataset
2023-01-05 20:39:36,980:INFO:Defining folds
2023-01-05 20:39:36,980:INFO:Declaring metric variables
2023-01-05 20:39:36,985:INFO:Importing untrained model
2023-01-05 20:39:36,989:INFO:Huber Regressor Imported successfully
2023-01-05 20:39:36,998:INFO:Starting cross validation
2023-01-05 20:39:36,999:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:39:37,146:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-05 20:39:37,241:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-05 20:39:37,321:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-05 20:39:37,350:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-05 20:39:37,535:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-05 20:39:37,660:INFO:Calculating mean and std
2023-01-05 20:39:37,662:INFO:Creating metrics dataframe
2023-01-05 20:39:37,665:INFO:Uploading results into container
2023-01-05 20:39:37,665:INFO:Uploading model into container now
2023-01-05 20:39:37,665:INFO:_master_model_container: 10
2023-01-05 20:39:37,665:INFO:_display_container: 2
2023-01-05 20:39:37,666:INFO:HuberRegressor()
2023-01-05 20:39:37,666:INFO:create_model() successfully completed......................................
2023-01-05 20:39:37,767:INFO:SubProcess create_model() end ==================================
2023-01-05 20:39:37,768:INFO:Creating metrics dataframe
2023-01-05 20:39:37,781:INFO:Initializing K Neighbors Regressor
2023-01-05 20:39:37,781:INFO:Total runtime is 0.08016244173049927 minutes
2023-01-05 20:39:37,786:INFO:SubProcess create_model() called ==================================
2023-01-05 20:39:37,786:INFO:Initializing create_model()
2023-01-05 20:39:37,786:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A82B8EBEB0>, estimator=knn, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A821CA7E20>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:39:37,786:INFO:Checking exceptions
2023-01-05 20:39:37,786:INFO:Importing libraries
2023-01-05 20:39:37,787:INFO:Copying training dataset
2023-01-05 20:39:37,797:INFO:Defining folds
2023-01-05 20:39:37,797:INFO:Declaring metric variables
2023-01-05 20:39:37,802:INFO:Importing untrained model
2023-01-05 20:39:37,807:INFO:K Neighbors Regressor Imported successfully
2023-01-05 20:39:37,817:INFO:Starting cross validation
2023-01-05 20:39:37,819:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:39:38,487:INFO:Calculating mean and std
2023-01-05 20:39:38,489:INFO:Creating metrics dataframe
2023-01-05 20:39:38,492:INFO:Uploading results into container
2023-01-05 20:39:38,492:INFO:Uploading model into container now
2023-01-05 20:39:38,492:INFO:_master_model_container: 11
2023-01-05 20:39:38,493:INFO:_display_container: 2
2023-01-05 20:39:38,493:INFO:KNeighborsRegressor(n_jobs=-1)
2023-01-05 20:39:38,493:INFO:create_model() successfully completed......................................
2023-01-05 20:39:38,608:INFO:SubProcess create_model() end ==================================
2023-01-05 20:39:38,609:INFO:Creating metrics dataframe
2023-01-05 20:39:38,622:INFO:Initializing Decision Tree Regressor
2023-01-05 20:39:38,622:INFO:Total runtime is 0.09417602221171062 minutes
2023-01-05 20:39:38,626:INFO:SubProcess create_model() called ==================================
2023-01-05 20:39:38,627:INFO:Initializing create_model()
2023-01-05 20:39:38,627:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A82B8EBEB0>, estimator=dt, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A821CA7E20>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:39:38,627:INFO:Checking exceptions
2023-01-05 20:39:38,627:INFO:Importing libraries
2023-01-05 20:39:38,627:INFO:Copying training dataset
2023-01-05 20:39:38,637:INFO:Defining folds
2023-01-05 20:39:38,638:INFO:Declaring metric variables
2023-01-05 20:39:38,642:INFO:Importing untrained model
2023-01-05 20:39:38,646:INFO:Decision Tree Regressor Imported successfully
2023-01-05 20:39:38,654:INFO:Starting cross validation
2023-01-05 20:39:38,657:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:39:39,179:INFO:Calculating mean and std
2023-01-05 20:39:39,181:INFO:Creating metrics dataframe
2023-01-05 20:39:39,187:INFO:Uploading results into container
2023-01-05 20:39:39,189:INFO:Uploading model into container now
2023-01-05 20:39:39,189:INFO:_master_model_container: 12
2023-01-05 20:39:39,189:INFO:_display_container: 2
2023-01-05 20:39:39,190:INFO:DecisionTreeRegressor(random_state=123)
2023-01-05 20:39:39,190:INFO:create_model() successfully completed......................................
2023-01-05 20:39:39,308:INFO:SubProcess create_model() end ==================================
2023-01-05 20:39:39,308:INFO:Creating metrics dataframe
2023-01-05 20:39:39,321:INFO:Initializing Random Forest Regressor
2023-01-05 20:39:39,321:INFO:Total runtime is 0.1058259924252828 minutes
2023-01-05 20:39:39,326:INFO:SubProcess create_model() called ==================================
2023-01-05 20:39:39,326:INFO:Initializing create_model()
2023-01-05 20:39:39,326:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A82B8EBEB0>, estimator=rf, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A821CA7E20>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:39:39,326:INFO:Checking exceptions
2023-01-05 20:39:39,327:INFO:Importing libraries
2023-01-05 20:39:39,327:INFO:Copying training dataset
2023-01-05 20:39:39,337:INFO:Defining folds
2023-01-05 20:39:39,337:INFO:Declaring metric variables
2023-01-05 20:39:39,342:INFO:Importing untrained model
2023-01-05 20:39:39,347:INFO:Random Forest Regressor Imported successfully
2023-01-05 20:39:39,371:INFO:Starting cross validation
2023-01-05 20:39:39,374:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:39:51,720:INFO:Calculating mean and std
2023-01-05 20:39:51,722:INFO:Creating metrics dataframe
2023-01-05 20:39:51,726:INFO:Uploading results into container
2023-01-05 20:39:51,726:INFO:Uploading model into container now
2023-01-05 20:39:51,727:INFO:_master_model_container: 13
2023-01-05 20:39:51,727:INFO:_display_container: 2
2023-01-05 20:39:51,727:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-01-05 20:39:51,728:INFO:create_model() successfully completed......................................
2023-01-05 20:39:51,941:INFO:SubProcess create_model() end ==================================
2023-01-05 20:39:51,942:INFO:Creating metrics dataframe
2023-01-05 20:39:51,960:INFO:Initializing Extra Trees Regressor
2023-01-05 20:39:51,961:INFO:Total runtime is 0.3164926886558533 minutes
2023-01-05 20:39:51,965:INFO:SubProcess create_model() called ==================================
2023-01-05 20:39:51,965:INFO:Initializing create_model()
2023-01-05 20:39:51,966:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A82B8EBEB0>, estimator=et, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A821CA7E20>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:39:51,966:INFO:Checking exceptions
2023-01-05 20:39:51,966:INFO:Importing libraries
2023-01-05 20:39:51,966:INFO:Copying training dataset
2023-01-05 20:39:51,977:INFO:Defining folds
2023-01-05 20:39:51,977:INFO:Declaring metric variables
2023-01-05 20:39:51,982:INFO:Importing untrained model
2023-01-05 20:39:51,987:INFO:Extra Trees Regressor Imported successfully
2023-01-05 20:39:51,995:INFO:Starting cross validation
2023-01-05 20:39:51,998:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:39:57,405:INFO:Calculating mean and std
2023-01-05 20:39:57,407:INFO:Creating metrics dataframe
2023-01-05 20:39:57,410:INFO:Uploading results into container
2023-01-05 20:39:57,412:INFO:Uploading model into container now
2023-01-05 20:39:57,412:INFO:_master_model_container: 14
2023-01-05 20:39:57,412:INFO:_display_container: 2
2023-01-05 20:39:57,412:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-01-05 20:39:57,413:INFO:create_model() successfully completed......................................
2023-01-05 20:39:57,573:INFO:SubProcess create_model() end ==================================
2023-01-05 20:39:57,573:INFO:Creating metrics dataframe
2023-01-05 20:39:57,590:INFO:Initializing AdaBoost Regressor
2023-01-05 20:39:57,590:INFO:Total runtime is 0.41030933856964114 minutes
2023-01-05 20:39:57,594:INFO:SubProcess create_model() called ==================================
2023-01-05 20:39:57,595:INFO:Initializing create_model()
2023-01-05 20:39:57,595:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A82B8EBEB0>, estimator=ada, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A821CA7E20>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:39:57,595:INFO:Checking exceptions
2023-01-05 20:39:57,595:INFO:Importing libraries
2023-01-05 20:39:57,596:INFO:Copying training dataset
2023-01-05 20:39:57,615:INFO:Defining folds
2023-01-05 20:39:57,616:INFO:Declaring metric variables
2023-01-05 20:39:57,620:INFO:Importing untrained model
2023-01-05 20:39:57,625:INFO:AdaBoost Regressor Imported successfully
2023-01-05 20:39:57,633:INFO:Starting cross validation
2023-01-05 20:39:57,634:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:40:00,089:INFO:Calculating mean and std
2023-01-05 20:40:00,091:INFO:Creating metrics dataframe
2023-01-05 20:40:00,095:INFO:Uploading results into container
2023-01-05 20:40:00,096:INFO:Uploading model into container now
2023-01-05 20:40:00,096:INFO:_master_model_container: 15
2023-01-05 20:40:00,097:INFO:_display_container: 2
2023-01-05 20:40:00,097:INFO:AdaBoostRegressor(random_state=123)
2023-01-05 20:40:00,097:INFO:create_model() successfully completed......................................
2023-01-05 20:40:00,211:INFO:SubProcess create_model() end ==================================
2023-01-05 20:40:00,211:INFO:Creating metrics dataframe
2023-01-05 20:40:00,225:INFO:Initializing Gradient Boosting Regressor
2023-01-05 20:40:00,225:INFO:Total runtime is 0.454226032892863 minutes
2023-01-05 20:40:00,228:INFO:SubProcess create_model() called ==================================
2023-01-05 20:40:00,229:INFO:Initializing create_model()
2023-01-05 20:40:00,229:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A82B8EBEB0>, estimator=gbr, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A821CA7E20>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:40:00,229:INFO:Checking exceptions
2023-01-05 20:40:00,229:INFO:Importing libraries
2023-01-05 20:40:00,229:INFO:Copying training dataset
2023-01-05 20:40:00,239:INFO:Defining folds
2023-01-05 20:40:00,239:INFO:Declaring metric variables
2023-01-05 20:40:00,243:INFO:Importing untrained model
2023-01-05 20:40:00,247:INFO:Gradient Boosting Regressor Imported successfully
2023-01-05 20:40:00,256:INFO:Starting cross validation
2023-01-05 20:40:00,257:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:40:06,747:INFO:Calculating mean and std
2023-01-05 20:40:06,749:INFO:Creating metrics dataframe
2023-01-05 20:40:06,752:INFO:Uploading results into container
2023-01-05 20:40:06,753:INFO:Uploading model into container now
2023-01-05 20:40:06,754:INFO:_master_model_container: 16
2023-01-05 20:40:06,754:INFO:_display_container: 2
2023-01-05 20:40:06,755:INFO:GradientBoostingRegressor(random_state=123)
2023-01-05 20:40:06,755:INFO:create_model() successfully completed......................................
2023-01-05 20:40:06,883:INFO:SubProcess create_model() end ==================================
2023-01-05 20:40:06,883:INFO:Creating metrics dataframe
2023-01-05 20:40:06,899:INFO:Initializing Light Gradient Boosting Machine
2023-01-05 20:40:06,899:INFO:Total runtime is 0.5654593467712403 minutes
2023-01-05 20:40:06,903:INFO:SubProcess create_model() called ==================================
2023-01-05 20:40:06,903:INFO:Initializing create_model()
2023-01-05 20:40:06,904:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A82B8EBEB0>, estimator=lightgbm, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A821CA7E20>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:40:06,904:INFO:Checking exceptions
2023-01-05 20:40:06,904:INFO:Importing libraries
2023-01-05 20:40:06,904:INFO:Copying training dataset
2023-01-05 20:40:06,914:INFO:Defining folds
2023-01-05 20:40:06,915:INFO:Declaring metric variables
2023-01-05 20:40:06,919:INFO:Importing untrained model
2023-01-05 20:40:06,926:INFO:Light Gradient Boosting Machine Imported successfully
2023-01-05 20:40:06,935:INFO:Starting cross validation
2023-01-05 20:40:06,936:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:40:08,255:INFO:Calculating mean and std
2023-01-05 20:40:08,258:INFO:Creating metrics dataframe
2023-01-05 20:40:08,261:INFO:Uploading results into container
2023-01-05 20:40:08,262:INFO:Uploading model into container now
2023-01-05 20:40:08,262:INFO:_master_model_container: 17
2023-01-05 20:40:08,262:INFO:_display_container: 2
2023-01-05 20:40:08,263:INFO:LGBMRegressor(random_state=123)
2023-01-05 20:40:08,263:INFO:create_model() successfully completed......................................
2023-01-05 20:40:08,392:INFO:SubProcess create_model() end ==================================
2023-01-05 20:40:08,393:INFO:Creating metrics dataframe
2023-01-05 20:40:08,407:INFO:Initializing Dummy Regressor
2023-01-05 20:40:08,407:INFO:Total runtime is 0.590592674414317 minutes
2023-01-05 20:40:08,411:INFO:SubProcess create_model() called ==================================
2023-01-05 20:40:08,411:INFO:Initializing create_model()
2023-01-05 20:40:08,412:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A82B8EBEB0>, estimator=dummy, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A821CA7E20>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:40:08,412:INFO:Checking exceptions
2023-01-05 20:40:08,412:INFO:Importing libraries
2023-01-05 20:40:08,412:INFO:Copying training dataset
2023-01-05 20:40:08,422:INFO:Defining folds
2023-01-05 20:40:08,423:INFO:Declaring metric variables
2023-01-05 20:40:08,427:INFO:Importing untrained model
2023-01-05 20:40:08,431:INFO:Dummy Regressor Imported successfully
2023-01-05 20:40:08,440:INFO:Starting cross validation
2023-01-05 20:40:08,442:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:40:08,734:INFO:Calculating mean and std
2023-01-05 20:40:08,736:INFO:Creating metrics dataframe
2023-01-05 20:40:08,740:INFO:Uploading results into container
2023-01-05 20:40:08,741:INFO:Uploading model into container now
2023-01-05 20:40:08,742:INFO:_master_model_container: 18
2023-01-05 20:40:08,742:INFO:_display_container: 2
2023-01-05 20:40:08,742:INFO:DummyRegressor()
2023-01-05 20:40:08,742:INFO:create_model() successfully completed......................................
2023-01-05 20:40:08,864:INFO:SubProcess create_model() end ==================================
2023-01-05 20:40:08,864:INFO:Creating metrics dataframe
2023-01-05 20:40:08,897:INFO:Initializing create_model()
2023-01-05 20:40:08,897:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A82B8EBEB0>, estimator=LGBMRegressor(random_state=123), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:40:08,897:INFO:Checking exceptions
2023-01-05 20:40:08,900:INFO:Importing libraries
2023-01-05 20:40:08,900:INFO:Copying training dataset
2023-01-05 20:40:08,909:INFO:Defining folds
2023-01-05 20:40:08,910:INFO:Declaring metric variables
2023-01-05 20:40:08,910:INFO:Importing untrained model
2023-01-05 20:40:08,910:INFO:Declaring custom model
2023-01-05 20:40:08,911:INFO:Light Gradient Boosting Machine Imported successfully
2023-01-05 20:40:08,912:INFO:Cross validation set to False
2023-01-05 20:40:08,912:INFO:Fitting Model
2023-01-05 20:40:09,542:INFO:LGBMRegressor(random_state=123)
2023-01-05 20:40:09,542:INFO:create_model() successfully completed......................................
2023-01-05 20:40:09,780:INFO:_master_model_container: 18
2023-01-05 20:40:09,780:INFO:_display_container: 2
2023-01-05 20:40:09,781:INFO:LGBMRegressor(random_state=123)
2023-01-05 20:40:09,781:INFO:compare_models() successfully completed......................................
2023-01-05 20:40:09,783:INFO:Initializing tune_model()
2023-01-05 20:40:09,783:INFO:tune_model(estimator=LGBMRegressor(random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=MAE, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A82B8EBEB0>)
2023-01-05 20:40:09,783:INFO:Checking exceptions
2023-01-05 20:40:09,828:INFO:Copying training dataset
2023-01-05 20:40:09,836:INFO:Checking base model
2023-01-05 20:40:09,837:INFO:Base model : Light Gradient Boosting Machine
2023-01-05 20:40:09,841:INFO:Declaring metric variables
2023-01-05 20:40:09,845:INFO:Defining Hyperparameters
2023-01-05 20:40:10,000:INFO:Tuning with n_jobs=-1
2023-01-05 20:40:10,000:INFO:Initializing RandomizedSearchCV
2023-01-05 20:40:16,826:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2023-01-05 20:40:16,828:INFO:Hyperparameter search completed
2023-01-05 20:40:16,828:INFO:SubProcess create_model() called ==================================
2023-01-05 20:40:16,828:INFO:Initializing create_model()
2023-01-05 20:40:16,828:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A82B8EBEB0>, estimator=LGBMRegressor(random_state=123), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A821CA7E20>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2023-01-05 20:40:16,829:INFO:Checking exceptions
2023-01-05 20:40:16,829:INFO:Importing libraries
2023-01-05 20:40:16,829:INFO:Copying training dataset
2023-01-05 20:40:16,840:INFO:Defining folds
2023-01-05 20:40:16,840:INFO:Declaring metric variables
2023-01-05 20:40:16,843:INFO:Importing untrained model
2023-01-05 20:40:16,843:INFO:Declaring custom model
2023-01-05 20:40:16,848:INFO:Light Gradient Boosting Machine Imported successfully
2023-01-05 20:40:16,856:INFO:Starting cross validation
2023-01-05 20:40:16,858:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:40:18,357:INFO:Calculating mean and std
2023-01-05 20:40:18,359:INFO:Creating metrics dataframe
2023-01-05 20:40:18,364:INFO:Finalizing model
2023-01-05 20:40:19,132:INFO:Uploading results into container
2023-01-05 20:40:19,133:INFO:Uploading model into container now
2023-01-05 20:40:19,134:INFO:_master_model_container: 19
2023-01-05 20:40:19,134:INFO:_display_container: 3
2023-01-05 20:40:19,135:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              num_leaves=70, random_state=123, reg_alpha=2, reg_lambda=3)
2023-01-05 20:40:19,135:INFO:create_model() successfully completed......................................
2023-01-05 20:40:19,252:INFO:SubProcess create_model() end ==================================
2023-01-05 20:40:19,252:INFO:choose_better activated
2023-01-05 20:40:19,257:INFO:SubProcess create_model() called ==================================
2023-01-05 20:40:19,258:INFO:Initializing create_model()
2023-01-05 20:40:19,258:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A82B8EBEB0>, estimator=LGBMRegressor(random_state=123), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:40:19,258:INFO:Checking exceptions
2023-01-05 20:40:19,260:INFO:Importing libraries
2023-01-05 20:40:19,260:INFO:Copying training dataset
2023-01-05 20:40:19,268:INFO:Defining folds
2023-01-05 20:40:19,269:INFO:Declaring metric variables
2023-01-05 20:40:19,269:INFO:Importing untrained model
2023-01-05 20:40:19,269:INFO:Declaring custom model
2023-01-05 20:40:19,270:INFO:Light Gradient Boosting Machine Imported successfully
2023-01-05 20:40:19,270:INFO:Starting cross validation
2023-01-05 20:40:19,271:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:40:20,473:INFO:Calculating mean and std
2023-01-05 20:40:20,474:INFO:Creating metrics dataframe
2023-01-05 20:40:20,476:INFO:Finalizing model
2023-01-05 20:40:20,728:INFO:Uploading results into container
2023-01-05 20:40:20,728:INFO:Uploading model into container now
2023-01-05 20:40:20,729:INFO:_master_model_container: 20
2023-01-05 20:40:20,729:INFO:_display_container: 4
2023-01-05 20:40:20,729:INFO:LGBMRegressor(random_state=123)
2023-01-05 20:40:20,729:INFO:create_model() successfully completed......................................
2023-01-05 20:40:20,840:INFO:SubProcess create_model() end ==================================
2023-01-05 20:40:20,841:INFO:LGBMRegressor(random_state=123) result for MAE is 2.201
2023-01-05 20:40:20,842:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              num_leaves=70, random_state=123, reg_alpha=2, reg_lambda=3) result for MAE is 2.4987
2023-01-05 20:40:20,842:INFO:LGBMRegressor(random_state=123) is best model
2023-01-05 20:40:20,842:INFO:choose_better completed
2023-01-05 20:40:20,842:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-01-05 20:40:20,851:INFO:_master_model_container: 20
2023-01-05 20:40:20,851:INFO:_display_container: 3
2023-01-05 20:40:20,852:INFO:LGBMRegressor(random_state=123)
2023-01-05 20:40:20,852:INFO:tune_model() successfully completed......................................
2023-01-05 20:40:20,971:INFO:Initializing plot_model()
2023-01-05 20:40:20,971:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LGBMRegressor(random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A82B8EBEB0>, system=True)
2023-01-05 20:40:20,971:INFO:Checking exceptions
2023-01-05 20:40:20,978:INFO:Preloading libraries
2023-01-05 20:40:20,984:INFO:Copying training dataset
2023-01-05 20:40:20,984:INFO:Plot type: error
2023-01-05 20:40:21,102:INFO:Fitting Model
2023-01-05 20:40:21,102:INFO:Scoring test/hold-out set
2023-01-05 20:40:21,344:INFO:Visual Rendered Successfully
2023-01-05 20:40:21,456:INFO:plot_model() successfully completed......................................
2023-01-05 20:40:21,457:INFO:Initializing predict_model()
2023-01-05 20:40:21,457:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A82B8EBEB0>, estimator=LGBMRegressor(random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001A82C139DC0>)
2023-01-05 20:40:21,457:INFO:Checking exceptions
2023-01-05 20:40:21,458:INFO:Preloading libraries
2023-01-05 20:40:21,624:INFO:Initializing finalize_model()
2023-01-05 20:40:21,624:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A82B8EBEB0>, estimator=LGBMRegressor(random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-01-05 20:40:21,624:INFO:Finalizing LGBMRegressor(random_state=123)
2023-01-05 20:40:21,632:INFO:Initializing create_model()
2023-01-05 20:40:21,633:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A82B8EBEB0>, estimator=LGBMRegressor(random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-01-05 20:40:21,633:INFO:Checking exceptions
2023-01-05 20:40:21,634:INFO:Importing libraries
2023-01-05 20:40:21,634:INFO:Copying training dataset
2023-01-05 20:40:21,635:INFO:Defining folds
2023-01-05 20:40:21,635:INFO:Declaring metric variables
2023-01-05 20:40:21,635:INFO:Importing untrained model
2023-01-05 20:40:21,635:INFO:Declaring custom model
2023-01-05 20:40:21,636:INFO:Light Gradient Boosting Machine Imported successfully
2023-01-05 20:40:21,637:INFO:Cross validation set to False
2023-01-05 20:40:21,637:INFO:Fitting Model
2023-01-05 20:40:21,938:INFO:Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator', LGBMRegressor(random_state=123))])
2023-01-05 20:40:21,938:INFO:create_model() successfully completed......................................
2023-01-05 20:40:22,048:INFO:_master_model_container: 20
2023-01-05 20:40:22,049:INFO:_display_container: 4
2023-01-05 20:40:22,055:INFO:Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator', LGBMRegressor(random_state=123))])
2023-01-05 20:40:22,056:INFO:finalize_model() successfully completed......................................
2023-01-05 20:40:22,163:INFO:Initializing predict_model()
2023-01-05 20:40:22,164:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A82B8EBEB0>, estimator=Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator', LGBMRegressor(random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001A82C139550>)
2023-01-05 20:40:22,164:INFO:Checking exceptions
2023-01-05 20:40:22,164:INFO:Preloading libraries
2023-01-05 20:40:22,166:INFO:Set up data.
2023-01-05 20:40:22,182:INFO:Set up index.
2023-01-05 20:41:54,102:INFO:PyCaret RegressionExperiment
2023-01-05 20:41:54,102:INFO:Logging name: reg-default-name
2023-01-05 20:41:54,102:INFO:ML Usecase: MLUsecase.REGRESSION
2023-01-05 20:41:54,102:INFO:version 3.0.0.rc6
2023-01-05 20:41:54,103:INFO:Initializing setup()
2023-01-05 20:41:54,103:INFO:self.USI: 4f7e
2023-01-05 20:41:54,103:INFO:self._variable_keys: {'y_train', 'data', 'gpu_n_jobs_param', 'fold_shuffle_param', 'n_jobs_param', 'exp_name_log', 'fold_generator', 'seed', 'gpu_param', 'USI', 'exp_id', 'logging_param', 'html_param', 'transform_target_param', 'y_test', 'target_param', 'X', 'X_test', 'log_plots_param', 'pipeline', '_available_plots', 'idx', 'fold_groups_param', 'X_train', '_ml_usecase', 'y', 'memory'}
2023-01-05 20:41:54,103:INFO:Checking environment
2023-01-05 20:41:54,103:INFO:python_version: 3.9.13
2023-01-05 20:41:54,103:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-01-05 20:41:54,103:INFO:machine: AMD64
2023-01-05 20:41:54,103:INFO:platform: Windows-10-10.0.19044-SP0
2023-01-05 20:41:54,103:INFO:Memory: svmem(total=17114804224, available=8796635136, percent=48.6, used=8318169088, free=8796635136)
2023-01-05 20:41:54,103:INFO:Physical Core: 4
2023-01-05 20:41:54,103:INFO:Logical Core: 4
2023-01-05 20:41:54,103:INFO:Checking libraries
2023-01-05 20:41:54,103:INFO:System:
2023-01-05 20:41:54,103:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-01-05 20:41:54,103:INFO:executable: c:\Users\Kodotautas\anaconda3\python.exe
2023-01-05 20:41:54,103:INFO:   machine: Windows-10-10.0.19044-SP0
2023-01-05 20:41:54,103:INFO:PyCaret required dependencies:
2023-01-05 20:41:54,104:INFO:                 pip: 22.2.2
2023-01-05 20:41:54,104:INFO:          setuptools: 63.4.1
2023-01-05 20:41:54,104:INFO:             pycaret: 3.0.0rc6
2023-01-05 20:41:54,104:INFO:             IPython: 7.31.1
2023-01-05 20:41:54,104:INFO:          ipywidgets: 7.6.5
2023-01-05 20:41:54,104:INFO:                tqdm: 4.64.1
2023-01-05 20:41:54,104:INFO:               numpy: 1.21.5
2023-01-05 20:41:54,104:INFO:              pandas: 1.4.4
2023-01-05 20:41:54,104:INFO:              jinja2: 2.11.3
2023-01-05 20:41:54,104:INFO:               scipy: 1.9.1
2023-01-05 20:41:54,104:INFO:              joblib: 1.2.0
2023-01-05 20:41:54,104:INFO:             sklearn: 1.0.2
2023-01-05 20:41:54,104:INFO:                pyod: 1.0.7
2023-01-05 20:41:54,104:INFO:            imblearn: 0.10.1
2023-01-05 20:41:54,104:INFO:   category_encoders: 2.5.1.post0
2023-01-05 20:41:54,104:INFO:            lightgbm: 3.3.3
2023-01-05 20:41:54,104:INFO:               numba: 0.55.1
2023-01-05 20:41:54,104:INFO:            requests: 2.28.1
2023-01-05 20:41:54,104:INFO:          matplotlib: 3.5.2
2023-01-05 20:41:54,104:INFO:          scikitplot: 0.3.7
2023-01-05 20:41:54,104:INFO:         yellowbrick: 1.5
2023-01-05 20:41:54,104:INFO:              plotly: 5.9.0
2023-01-05 20:41:54,105:INFO:             kaleido: 0.2.1
2023-01-05 20:41:54,105:INFO:         statsmodels: 0.13.2
2023-01-05 20:41:54,105:INFO:              sktime: 0.14.1
2023-01-05 20:41:54,105:INFO:               tbats: 1.1.2
2023-01-05 20:41:54,105:INFO:            pmdarima: 2.0.2
2023-01-05 20:41:54,105:INFO:              psutil: 5.9.0
2023-01-05 20:41:54,105:INFO:PyCaret optional dependencies:
2023-01-05 20:41:54,105:INFO:                shap: 0.41.0
2023-01-05 20:41:54,105:INFO:           interpret: Not installed
2023-01-05 20:41:54,105:INFO:                umap: Not installed
2023-01-05 20:41:54,105:INFO:    pandas_profiling: Not installed
2023-01-05 20:41:54,105:INFO:  explainerdashboard: Not installed
2023-01-05 20:41:54,105:INFO:             autoviz: Not installed
2023-01-05 20:41:54,105:INFO:           fairlearn: Not installed
2023-01-05 20:41:54,105:INFO:             xgboost: Not installed
2023-01-05 20:41:54,105:INFO:            catboost: Not installed
2023-01-05 20:41:54,105:INFO:              kmodes: Not installed
2023-01-05 20:41:54,105:INFO:             mlxtend: Not installed
2023-01-05 20:41:54,105:INFO:       statsforecast: Not installed
2023-01-05 20:41:54,105:INFO:        tune_sklearn: 0.4.3
2023-01-05 20:41:54,105:INFO:                 ray: 2.0.0
2023-01-05 20:41:54,105:INFO:            hyperopt: 0.2.7
2023-01-05 20:41:54,105:INFO:              optuna: 3.0.1
2023-01-05 20:41:54,106:INFO:               skopt: 0.9.0
2023-01-05 20:41:54,106:INFO:              mlflow: Not installed
2023-01-05 20:41:54,106:INFO:              gradio: Not installed
2023-01-05 20:41:54,106:INFO:             fastapi: 0.88.0
2023-01-05 20:41:54,106:INFO:             uvicorn: 0.20.0
2023-01-05 20:41:54,106:INFO:              m2cgen: Not installed
2023-01-05 20:41:54,106:INFO:           evidently: Not installed
2023-01-05 20:41:54,106:INFO:                nltk: 3.7
2023-01-05 20:41:54,106:INFO:            pyLDAvis: Not installed
2023-01-05 20:41:54,106:INFO:              gensim: 4.1.2
2023-01-05 20:41:54,106:INFO:               spacy: 3.4.2
2023-01-05 20:41:54,106:INFO:           wordcloud: Not installed
2023-01-05 20:41:54,106:INFO:            textblob: Not installed
2023-01-05 20:41:54,106:INFO:               fugue: Not installed
2023-01-05 20:41:54,106:INFO:           streamlit: Not installed
2023-01-05 20:41:54,106:INFO:             prophet: Not installed
2023-01-05 20:41:54,106:INFO:None
2023-01-05 20:41:54,106:INFO:Set up data.
2023-01-05 20:41:54,127:INFO:Set up train/test split.
2023-01-05 20:41:54,139:INFO:Set up index.
2023-01-05 20:41:54,141:INFO:Set up folding strategy.
2023-01-05 20:41:54,141:INFO:Assigning column types.
2023-01-05 20:41:54,151:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-01-05 20:41:54,152:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-01-05 20:41:54,156:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-05 20:41:54,162:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-05 20:41:54,228:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-05 20:41:54,284:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-05 20:41:54,285:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:41:54,285:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:41:54,285:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-01-05 20:41:54,290:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-05 20:41:54,296:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-05 20:41:54,362:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-05 20:41:54,409:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-05 20:41:54,410:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:41:54,411:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:41:54,411:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-01-05 20:41:54,416:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-05 20:41:54,421:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-05 20:41:54,490:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-05 20:41:54,538:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-05 20:41:54,538:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:41:54,538:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:41:54,544:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-05 20:41:54,549:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-05 20:41:54,618:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-05 20:41:54,665:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-05 20:41:54,665:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:41:54,666:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:41:54,666:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-01-05 20:41:54,676:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-05 20:41:54,743:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-05 20:41:54,791:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-05 20:41:54,792:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:41:54,793:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:41:54,802:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-05 20:41:54,871:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-05 20:41:54,918:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-05 20:41:54,918:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:41:54,919:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:41:54,919:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-01-05 20:41:55,044:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-05 20:41:55,097:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-05 20:41:55,098:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:41:55,098:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:41:55,181:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-05 20:41:55,230:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-05 20:41:55,230:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:41:55,230:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:41:55,231:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-01-05 20:41:55,316:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-05 20:41:55,364:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:41:55,365:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:41:55,439:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-05 20:41:55,485:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:41:55,485:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:41:55,485:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-01-05 20:41:55,610:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:41:55,610:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:41:55,730:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:41:55,730:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:41:55,731:INFO:Preparing preprocessing pipeline...
2023-01-05 20:41:55,733:INFO:Set up simple imputation.
2023-01-05 20:41:55,733:INFO:Set up column transformation.
2023-01-05 20:41:55,733:INFO:Set up feature normalization.
2023-01-05 20:41:55,770:INFO:Finished creating preprocessing pipeline.
2023-01-05 20:41:55,776:INFO:Pipeline: Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2023-01-05 20:41:55,776:INFO:Creating final display dataframe.
2023-01-05 20:41:56,010:INFO:Setup _display_container:                Description             Value
0               Session id               123
1                   Target        b2b+b2c+vt
2              Target type        Regression
3               Data shape        (9930, 48)
4         Train data shape        (6951, 48)
5          Test data shape        (2979, 48)
6         Numeric features                 8
7               Preprocess              True
8          Imputation type            simple
9       Numeric imputation              mean
10  Categorical imputation              mode
11          Transformation              True
12   Transformation method       yeo-johnson
13               Normalize              True
14        Normalize method            zscore
15          Fold Generator   TimeSeriesSplit
16             Fold Number                 5
17                CPU Jobs                -1
18                 Use GPU             False
19          Log Experiment             False
20         Experiment Name  reg-default-name
21                     USI              4f7e
2023-01-05 20:41:56,136:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:41:56,136:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:41:56,258:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:41:56,258:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:41:56,259:INFO:setup() successfully completed in 2.16s...............
2023-01-05 20:41:56,260:INFO:Initializing compare_models()
2023-01-05 20:41:56,260:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A82BFEE400>, include=None, fold=None, round=4, cross_validation=True, sort=MAE, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001A82BFEE400>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'MAE', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-01-05 20:41:56,260:INFO:Checking exceptions
2023-01-05 20:41:56,265:INFO:Preparing display monitor
2023-01-05 20:41:56,302:INFO:Initializing Linear Regression
2023-01-05 20:41:56,302:INFO:Total runtime is 0.0 minutes
2023-01-05 20:41:56,306:INFO:SubProcess create_model() called ==================================
2023-01-05 20:41:56,307:INFO:Initializing create_model()
2023-01-05 20:41:56,307:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A82BFEE400>, estimator=lr, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A82BB37100>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:41:56,307:INFO:Checking exceptions
2023-01-05 20:41:56,307:INFO:Importing libraries
2023-01-05 20:41:56,307:INFO:Copying training dataset
2023-01-05 20:41:56,316:INFO:Defining folds
2023-01-05 20:41:56,316:INFO:Declaring metric variables
2023-01-05 20:41:56,320:INFO:Importing untrained model
2023-01-05 20:41:56,324:INFO:Linear Regression Imported successfully
2023-01-05 20:41:56,333:INFO:Starting cross validation
2023-01-05 20:41:56,334:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:41:56,609:INFO:Calculating mean and std
2023-01-05 20:41:56,610:INFO:Creating metrics dataframe
2023-01-05 20:41:56,612:INFO:Uploading results into container
2023-01-05 20:41:56,613:INFO:Uploading model into container now
2023-01-05 20:41:56,613:INFO:_master_model_container: 1
2023-01-05 20:41:56,613:INFO:_display_container: 2
2023-01-05 20:41:56,613:INFO:LinearRegression(n_jobs=-1)
2023-01-05 20:41:56,613:INFO:create_model() successfully completed......................................
2023-01-05 20:41:56,722:INFO:SubProcess create_model() end ==================================
2023-01-05 20:41:56,723:INFO:Creating metrics dataframe
2023-01-05 20:41:56,731:INFO:Initializing Lasso Regression
2023-01-05 20:41:56,731:INFO:Total runtime is 0.007152338822682698 minutes
2023-01-05 20:41:56,734:INFO:SubProcess create_model() called ==================================
2023-01-05 20:41:56,735:INFO:Initializing create_model()
2023-01-05 20:41:56,735:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A82BFEE400>, estimator=lasso, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A82BB37100>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:41:56,735:INFO:Checking exceptions
2023-01-05 20:41:56,735:INFO:Importing libraries
2023-01-05 20:41:56,735:INFO:Copying training dataset
2023-01-05 20:41:56,743:INFO:Defining folds
2023-01-05 20:41:56,743:INFO:Declaring metric variables
2023-01-05 20:41:56,746:INFO:Importing untrained model
2023-01-05 20:41:56,750:INFO:Lasso Regression Imported successfully
2023-01-05 20:41:56,757:INFO:Starting cross validation
2023-01-05 20:41:56,759:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:41:57,017:INFO:Calculating mean and std
2023-01-05 20:41:57,017:INFO:Creating metrics dataframe
2023-01-05 20:41:57,020:INFO:Uploading results into container
2023-01-05 20:41:57,021:INFO:Uploading model into container now
2023-01-05 20:41:57,021:INFO:_master_model_container: 2
2023-01-05 20:41:57,021:INFO:_display_container: 2
2023-01-05 20:41:57,021:INFO:Lasso(random_state=123)
2023-01-05 20:41:57,021:INFO:create_model() successfully completed......................................
2023-01-05 20:41:57,119:INFO:SubProcess create_model() end ==================================
2023-01-05 20:41:57,119:INFO:Creating metrics dataframe
2023-01-05 20:41:57,128:INFO:Initializing Ridge Regression
2023-01-05 20:41:57,128:INFO:Total runtime is 0.013770035902659098 minutes
2023-01-05 20:41:57,132:INFO:SubProcess create_model() called ==================================
2023-01-05 20:41:57,132:INFO:Initializing create_model()
2023-01-05 20:41:57,133:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A82BFEE400>, estimator=ridge, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A82BB37100>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:41:57,133:INFO:Checking exceptions
2023-01-05 20:41:57,133:INFO:Importing libraries
2023-01-05 20:41:57,133:INFO:Copying training dataset
2023-01-05 20:41:57,140:INFO:Defining folds
2023-01-05 20:41:57,140:INFO:Declaring metric variables
2023-01-05 20:41:57,144:INFO:Importing untrained model
2023-01-05 20:41:57,148:INFO:Ridge Regression Imported successfully
2023-01-05 20:41:57,156:INFO:Starting cross validation
2023-01-05 20:41:57,157:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:41:57,411:INFO:Calculating mean and std
2023-01-05 20:41:57,413:INFO:Creating metrics dataframe
2023-01-05 20:41:57,416:INFO:Uploading results into container
2023-01-05 20:41:57,416:INFO:Uploading model into container now
2023-01-05 20:41:57,417:INFO:_master_model_container: 3
2023-01-05 20:41:57,417:INFO:_display_container: 2
2023-01-05 20:41:57,417:INFO:Ridge(random_state=123)
2023-01-05 20:41:57,417:INFO:create_model() successfully completed......................................
2023-01-05 20:41:57,515:INFO:SubProcess create_model() end ==================================
2023-01-05 20:41:57,516:INFO:Creating metrics dataframe
2023-01-05 20:41:57,526:INFO:Initializing Elastic Net
2023-01-05 20:41:57,526:INFO:Total runtime is 0.020393176873524984 minutes
2023-01-05 20:41:57,530:INFO:SubProcess create_model() called ==================================
2023-01-05 20:41:57,530:INFO:Initializing create_model()
2023-01-05 20:41:57,530:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A82BFEE400>, estimator=en, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A82BB37100>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:41:57,530:INFO:Checking exceptions
2023-01-05 20:41:57,531:INFO:Importing libraries
2023-01-05 20:41:57,531:INFO:Copying training dataset
2023-01-05 20:41:57,540:INFO:Defining folds
2023-01-05 20:41:57,540:INFO:Declaring metric variables
2023-01-05 20:41:57,544:INFO:Importing untrained model
2023-01-05 20:41:57,548:INFO:Elastic Net Imported successfully
2023-01-05 20:41:57,556:INFO:Starting cross validation
2023-01-05 20:41:57,557:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:41:57,805:INFO:Calculating mean and std
2023-01-05 20:41:57,807:INFO:Creating metrics dataframe
2023-01-05 20:41:57,810:INFO:Uploading results into container
2023-01-05 20:41:57,810:INFO:Uploading model into container now
2023-01-05 20:41:57,810:INFO:_master_model_container: 4
2023-01-05 20:41:57,811:INFO:_display_container: 2
2023-01-05 20:41:57,811:INFO:ElasticNet(random_state=123)
2023-01-05 20:41:57,811:INFO:create_model() successfully completed......................................
2023-01-05 20:41:57,909:INFO:SubProcess create_model() end ==================================
2023-01-05 20:41:57,909:INFO:Creating metrics dataframe
2023-01-05 20:41:57,919:INFO:Initializing Least Angle Regression
2023-01-05 20:41:57,919:INFO:Total runtime is 0.026950716972351074 minutes
2023-01-05 20:41:57,923:INFO:SubProcess create_model() called ==================================
2023-01-05 20:41:57,923:INFO:Initializing create_model()
2023-01-05 20:41:57,924:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A82BFEE400>, estimator=lar, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A82BB37100>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:41:57,924:INFO:Checking exceptions
2023-01-05 20:41:57,924:INFO:Importing libraries
2023-01-05 20:41:57,924:INFO:Copying training dataset
2023-01-05 20:41:57,933:INFO:Defining folds
2023-01-05 20:41:57,933:INFO:Declaring metric variables
2023-01-05 20:41:57,937:INFO:Importing untrained model
2023-01-05 20:41:57,941:INFO:Least Angle Regression Imported successfully
2023-01-05 20:41:57,950:INFO:Starting cross validation
2023-01-05 20:41:57,951:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:41:58,018:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-05 20:41:58,021:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-05 20:41:58,025:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-05 20:41:58,027:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-05 20:41:58,081:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-05 20:41:58,211:INFO:Calculating mean and std
2023-01-05 20:41:58,213:INFO:Creating metrics dataframe
2023-01-05 20:41:58,216:INFO:Uploading results into container
2023-01-05 20:41:58,216:INFO:Uploading model into container now
2023-01-05 20:41:58,216:INFO:_master_model_container: 5
2023-01-05 20:41:58,216:INFO:_display_container: 2
2023-01-05 20:41:58,217:INFO:Lars(random_state=123)
2023-01-05 20:41:58,217:INFO:create_model() successfully completed......................................
2023-01-05 20:41:58,316:INFO:SubProcess create_model() end ==================================
2023-01-05 20:41:58,316:INFO:Creating metrics dataframe
2023-01-05 20:41:58,327:INFO:Initializing Lasso Least Angle Regression
2023-01-05 20:41:58,327:INFO:Total runtime is 0.03375608523686727 minutes
2023-01-05 20:41:58,331:INFO:SubProcess create_model() called ==================================
2023-01-05 20:41:58,331:INFO:Initializing create_model()
2023-01-05 20:41:58,331:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A82BFEE400>, estimator=llar, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A82BB37100>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:41:58,331:INFO:Checking exceptions
2023-01-05 20:41:58,332:INFO:Importing libraries
2023-01-05 20:41:58,332:INFO:Copying training dataset
2023-01-05 20:41:58,341:INFO:Defining folds
2023-01-05 20:41:58,341:INFO:Declaring metric variables
2023-01-05 20:41:58,345:INFO:Importing untrained model
2023-01-05 20:41:58,350:INFO:Lasso Least Angle Regression Imported successfully
2023-01-05 20:41:58,358:INFO:Starting cross validation
2023-01-05 20:41:58,359:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:41:58,425:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-05 20:41:58,428:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-05 20:41:58,432:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-05 20:41:58,434:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-05 20:41:58,479:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-05 20:41:58,604:INFO:Calculating mean and std
2023-01-05 20:41:58,606:INFO:Creating metrics dataframe
2023-01-05 20:41:58,609:INFO:Uploading results into container
2023-01-05 20:41:58,609:INFO:Uploading model into container now
2023-01-05 20:41:58,609:INFO:_master_model_container: 6
2023-01-05 20:41:58,609:INFO:_display_container: 2
2023-01-05 20:41:58,610:INFO:LassoLars(random_state=123)
2023-01-05 20:41:58,610:INFO:create_model() successfully completed......................................
2023-01-05 20:41:58,708:INFO:SubProcess create_model() end ==================================
2023-01-05 20:41:58,708:INFO:Creating metrics dataframe
2023-01-05 20:41:58,718:INFO:Initializing Orthogonal Matching Pursuit
2023-01-05 20:41:58,718:INFO:Total runtime is 0.04026217460632324 minutes
2023-01-05 20:41:58,722:INFO:SubProcess create_model() called ==================================
2023-01-05 20:41:58,722:INFO:Initializing create_model()
2023-01-05 20:41:58,722:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A82BFEE400>, estimator=omp, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A82BB37100>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:41:58,723:INFO:Checking exceptions
2023-01-05 20:41:58,723:INFO:Importing libraries
2023-01-05 20:41:58,723:INFO:Copying training dataset
2023-01-05 20:41:58,731:INFO:Defining folds
2023-01-05 20:41:58,732:INFO:Declaring metric variables
2023-01-05 20:41:58,736:INFO:Importing untrained model
2023-01-05 20:41:58,740:INFO:Orthogonal Matching Pursuit Imported successfully
2023-01-05 20:41:58,748:INFO:Starting cross validation
2023-01-05 20:41:58,749:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:41:58,814:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-05 20:41:58,817:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-05 20:41:58,820:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-05 20:41:58,822:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-05 20:41:58,867:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-05 20:41:58,998:INFO:Calculating mean and std
2023-01-05 20:41:59,000:INFO:Creating metrics dataframe
2023-01-05 20:41:59,003:INFO:Uploading results into container
2023-01-05 20:41:59,003:INFO:Uploading model into container now
2023-01-05 20:41:59,003:INFO:_master_model_container: 7
2023-01-05 20:41:59,003:INFO:_display_container: 2
2023-01-05 20:41:59,004:INFO:OrthogonalMatchingPursuit()
2023-01-05 20:41:59,004:INFO:create_model() successfully completed......................................
2023-01-05 20:41:59,102:INFO:SubProcess create_model() end ==================================
2023-01-05 20:41:59,102:INFO:Creating metrics dataframe
2023-01-05 20:41:59,113:INFO:Initializing Bayesian Ridge
2023-01-05 20:41:59,113:INFO:Total runtime is 0.04685095945994059 minutes
2023-01-05 20:41:59,117:INFO:SubProcess create_model() called ==================================
2023-01-05 20:41:59,118:INFO:Initializing create_model()
2023-01-05 20:41:59,118:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A82BFEE400>, estimator=br, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A82BB37100>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:41:59,118:INFO:Checking exceptions
2023-01-05 20:41:59,118:INFO:Importing libraries
2023-01-05 20:41:59,118:INFO:Copying training dataset
2023-01-05 20:41:59,127:INFO:Defining folds
2023-01-05 20:41:59,127:INFO:Declaring metric variables
2023-01-05 20:41:59,132:INFO:Importing untrained model
2023-01-05 20:41:59,136:INFO:Bayesian Ridge Imported successfully
2023-01-05 20:41:59,143:INFO:Starting cross validation
2023-01-05 20:41:59,145:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:41:59,424:INFO:Calculating mean and std
2023-01-05 20:41:59,426:INFO:Creating metrics dataframe
2023-01-05 20:41:59,429:INFO:Uploading results into container
2023-01-05 20:41:59,429:INFO:Uploading model into container now
2023-01-05 20:41:59,429:INFO:_master_model_container: 8
2023-01-05 20:41:59,429:INFO:_display_container: 2
2023-01-05 20:41:59,430:INFO:BayesianRidge()
2023-01-05 20:41:59,430:INFO:create_model() successfully completed......................................
2023-01-05 20:41:59,529:INFO:SubProcess create_model() end ==================================
2023-01-05 20:41:59,529:INFO:Creating metrics dataframe
2023-01-05 20:41:59,540:INFO:Initializing Passive Aggressive Regressor
2023-01-05 20:41:59,540:INFO:Total runtime is 0.05395952860514323 minutes
2023-01-05 20:41:59,544:INFO:SubProcess create_model() called ==================================
2023-01-05 20:41:59,544:INFO:Initializing create_model()
2023-01-05 20:41:59,545:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A82BFEE400>, estimator=par, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A82BB37100>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:41:59,545:INFO:Checking exceptions
2023-01-05 20:41:59,545:INFO:Importing libraries
2023-01-05 20:41:59,545:INFO:Copying training dataset
2023-01-05 20:41:59,554:INFO:Defining folds
2023-01-05 20:41:59,554:INFO:Declaring metric variables
2023-01-05 20:41:59,558:INFO:Importing untrained model
2023-01-05 20:41:59,562:INFO:Passive Aggressive Regressor Imported successfully
2023-01-05 20:41:59,570:INFO:Starting cross validation
2023-01-05 20:41:59,571:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:41:59,835:INFO:Calculating mean and std
2023-01-05 20:41:59,837:INFO:Creating metrics dataframe
2023-01-05 20:41:59,840:INFO:Uploading results into container
2023-01-05 20:41:59,840:INFO:Uploading model into container now
2023-01-05 20:41:59,841:INFO:_master_model_container: 9
2023-01-05 20:41:59,841:INFO:_display_container: 2
2023-01-05 20:41:59,841:INFO:PassiveAggressiveRegressor(random_state=123)
2023-01-05 20:41:59,841:INFO:create_model() successfully completed......................................
2023-01-05 20:41:59,939:INFO:SubProcess create_model() end ==================================
2023-01-05 20:41:59,940:INFO:Creating metrics dataframe
2023-01-05 20:41:59,951:INFO:Initializing Huber Regressor
2023-01-05 20:41:59,952:INFO:Total runtime is 0.06083106597264608 minutes
2023-01-05 20:41:59,955:INFO:SubProcess create_model() called ==================================
2023-01-05 20:41:59,956:INFO:Initializing create_model()
2023-01-05 20:41:59,956:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A82BFEE400>, estimator=huber, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A82BB37100>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:41:59,956:INFO:Checking exceptions
2023-01-05 20:41:59,956:INFO:Importing libraries
2023-01-05 20:41:59,956:INFO:Copying training dataset
2023-01-05 20:41:59,965:INFO:Defining folds
2023-01-05 20:41:59,965:INFO:Declaring metric variables
2023-01-05 20:41:59,970:INFO:Importing untrained model
2023-01-05 20:41:59,973:INFO:Huber Regressor Imported successfully
2023-01-05 20:41:59,981:INFO:Starting cross validation
2023-01-05 20:41:59,982:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:42:00,122:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-05 20:42:00,202:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-05 20:42:00,260:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-05 20:42:00,306:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-05 20:42:00,505:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-05 20:42:00,625:INFO:Calculating mean and std
2023-01-05 20:42:00,627:INFO:Creating metrics dataframe
2023-01-05 20:42:00,630:INFO:Uploading results into container
2023-01-05 20:42:00,630:INFO:Uploading model into container now
2023-01-05 20:42:00,630:INFO:_master_model_container: 10
2023-01-05 20:42:00,630:INFO:_display_container: 2
2023-01-05 20:42:00,631:INFO:HuberRegressor()
2023-01-05 20:42:00,631:INFO:create_model() successfully completed......................................
2023-01-05 20:42:00,730:INFO:SubProcess create_model() end ==================================
2023-01-05 20:42:00,730:INFO:Creating metrics dataframe
2023-01-05 20:42:00,742:INFO:Initializing K Neighbors Regressor
2023-01-05 20:42:00,742:INFO:Total runtime is 0.0740027149518331 minutes
2023-01-05 20:42:00,746:INFO:SubProcess create_model() called ==================================
2023-01-05 20:42:00,747:INFO:Initializing create_model()
2023-01-05 20:42:00,747:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A82BFEE400>, estimator=knn, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A82BB37100>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:42:00,747:INFO:Checking exceptions
2023-01-05 20:42:00,747:INFO:Importing libraries
2023-01-05 20:42:00,747:INFO:Copying training dataset
2023-01-05 20:42:00,756:INFO:Defining folds
2023-01-05 20:42:00,757:INFO:Declaring metric variables
2023-01-05 20:42:00,760:INFO:Importing untrained model
2023-01-05 20:42:00,765:INFO:K Neighbors Regressor Imported successfully
2023-01-05 20:42:00,772:INFO:Starting cross validation
2023-01-05 20:42:00,774:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:42:01,366:INFO:Calculating mean and std
2023-01-05 20:42:01,368:INFO:Creating metrics dataframe
2023-01-05 20:42:01,370:INFO:Uploading results into container
2023-01-05 20:42:01,371:INFO:Uploading model into container now
2023-01-05 20:42:01,371:INFO:_master_model_container: 11
2023-01-05 20:42:01,371:INFO:_display_container: 2
2023-01-05 20:42:01,372:INFO:KNeighborsRegressor(n_jobs=-1)
2023-01-05 20:42:01,372:INFO:create_model() successfully completed......................................
2023-01-05 20:42:01,471:INFO:SubProcess create_model() end ==================================
2023-01-05 20:42:01,472:INFO:Creating metrics dataframe
2023-01-05 20:42:01,484:INFO:Initializing Decision Tree Regressor
2023-01-05 20:42:01,485:INFO:Total runtime is 0.08638846476872762 minutes
2023-01-05 20:42:01,489:INFO:SubProcess create_model() called ==================================
2023-01-05 20:42:01,489:INFO:Initializing create_model()
2023-01-05 20:42:01,489:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A82BFEE400>, estimator=dt, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A82BB37100>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:42:01,490:INFO:Checking exceptions
2023-01-05 20:42:01,490:INFO:Importing libraries
2023-01-05 20:42:01,490:INFO:Copying training dataset
2023-01-05 20:42:01,499:INFO:Defining folds
2023-01-05 20:42:01,499:INFO:Declaring metric variables
2023-01-05 20:42:01,503:INFO:Importing untrained model
2023-01-05 20:42:01,507:INFO:Decision Tree Regressor Imported successfully
2023-01-05 20:42:01,514:INFO:Starting cross validation
2023-01-05 20:42:01,516:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:42:01,993:INFO:Calculating mean and std
2023-01-05 20:42:01,995:INFO:Creating metrics dataframe
2023-01-05 20:42:01,998:INFO:Uploading results into container
2023-01-05 20:42:01,998:INFO:Uploading model into container now
2023-01-05 20:42:01,999:INFO:_master_model_container: 12
2023-01-05 20:42:01,999:INFO:_display_container: 2
2023-01-05 20:42:01,999:INFO:DecisionTreeRegressor(random_state=123)
2023-01-05 20:42:01,999:INFO:create_model() successfully completed......................................
2023-01-05 20:42:02,097:INFO:SubProcess create_model() end ==================================
2023-01-05 20:42:02,098:INFO:Creating metrics dataframe
2023-01-05 20:42:02,109:INFO:Initializing Random Forest Regressor
2023-01-05 20:42:02,109:INFO:Total runtime is 0.09678889513015747 minutes
2023-01-05 20:42:02,113:INFO:SubProcess create_model() called ==================================
2023-01-05 20:42:02,114:INFO:Initializing create_model()
2023-01-05 20:42:02,114:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A82BFEE400>, estimator=rf, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A82BB37100>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:42:02,114:INFO:Checking exceptions
2023-01-05 20:42:02,114:INFO:Importing libraries
2023-01-05 20:42:02,114:INFO:Copying training dataset
2023-01-05 20:42:02,123:INFO:Defining folds
2023-01-05 20:42:02,123:INFO:Declaring metric variables
2023-01-05 20:42:02,128:INFO:Importing untrained model
2023-01-05 20:42:02,132:INFO:Random Forest Regressor Imported successfully
2023-01-05 20:42:02,140:INFO:Starting cross validation
2023-01-05 20:42:02,141:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:42:11,310:INFO:Calculating mean and std
2023-01-05 20:42:11,312:INFO:Creating metrics dataframe
2023-01-05 20:42:11,315:INFO:Uploading results into container
2023-01-05 20:42:11,316:INFO:Uploading model into container now
2023-01-05 20:42:11,316:INFO:_master_model_container: 13
2023-01-05 20:42:11,316:INFO:_display_container: 2
2023-01-05 20:42:11,317:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-01-05 20:42:11,317:INFO:create_model() successfully completed......................................
2023-01-05 20:42:11,420:INFO:SubProcess create_model() end ==================================
2023-01-05 20:42:11,420:INFO:Creating metrics dataframe
2023-01-05 20:42:11,433:INFO:Initializing Extra Trees Regressor
2023-01-05 20:42:11,434:INFO:Total runtime is 0.25220116376876833 minutes
2023-01-05 20:42:11,438:INFO:SubProcess create_model() called ==================================
2023-01-05 20:42:11,438:INFO:Initializing create_model()
2023-01-05 20:42:11,438:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A82BFEE400>, estimator=et, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A82BB37100>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:42:11,438:INFO:Checking exceptions
2023-01-05 20:42:11,438:INFO:Importing libraries
2023-01-05 20:42:11,439:INFO:Copying training dataset
2023-01-05 20:42:11,448:INFO:Defining folds
2023-01-05 20:42:11,448:INFO:Declaring metric variables
2023-01-05 20:42:11,452:INFO:Importing untrained model
2023-01-05 20:42:11,456:INFO:Extra Trees Regressor Imported successfully
2023-01-05 20:42:11,464:INFO:Starting cross validation
2023-01-05 20:42:11,465:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:42:15,901:INFO:Calculating mean and std
2023-01-05 20:42:15,903:INFO:Creating metrics dataframe
2023-01-05 20:42:15,906:INFO:Uploading results into container
2023-01-05 20:42:15,907:INFO:Uploading model into container now
2023-01-05 20:42:15,907:INFO:_master_model_container: 14
2023-01-05 20:42:15,907:INFO:_display_container: 2
2023-01-05 20:42:15,907:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-01-05 20:42:15,908:INFO:create_model() successfully completed......................................
2023-01-05 20:42:16,026:INFO:SubProcess create_model() end ==================================
2023-01-05 20:42:16,027:INFO:Creating metrics dataframe
2023-01-05 20:42:16,041:INFO:Initializing AdaBoost Regressor
2023-01-05 20:42:16,041:INFO:Total runtime is 0.3289844234784444 minutes
2023-01-05 20:42:16,046:INFO:SubProcess create_model() called ==================================
2023-01-05 20:42:16,047:INFO:Initializing create_model()
2023-01-05 20:42:16,047:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A82BFEE400>, estimator=ada, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A82BB37100>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:42:16,047:INFO:Checking exceptions
2023-01-05 20:42:16,047:INFO:Importing libraries
2023-01-05 20:42:16,047:INFO:Copying training dataset
2023-01-05 20:42:16,058:INFO:Defining folds
2023-01-05 20:42:16,058:INFO:Declaring metric variables
2023-01-05 20:42:16,063:INFO:Importing untrained model
2023-01-05 20:42:16,068:INFO:AdaBoost Regressor Imported successfully
2023-01-05 20:42:16,076:INFO:Starting cross validation
2023-01-05 20:42:16,078:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:42:18,028:INFO:Calculating mean and std
2023-01-05 20:42:18,030:INFO:Creating metrics dataframe
2023-01-05 20:42:18,032:INFO:Uploading results into container
2023-01-05 20:42:18,033:INFO:Uploading model into container now
2023-01-05 20:42:18,033:INFO:_master_model_container: 15
2023-01-05 20:42:18,033:INFO:_display_container: 2
2023-01-05 20:42:18,033:INFO:AdaBoostRegressor(random_state=123)
2023-01-05 20:42:18,034:INFO:create_model() successfully completed......................................
2023-01-05 20:42:18,140:INFO:SubProcess create_model() end ==================================
2023-01-05 20:42:18,140:INFO:Creating metrics dataframe
2023-01-05 20:42:18,152:INFO:Initializing Gradient Boosting Regressor
2023-01-05 20:42:18,152:INFO:Total runtime is 0.36416322787602745 minutes
2023-01-05 20:42:18,156:INFO:SubProcess create_model() called ==================================
2023-01-05 20:42:18,157:INFO:Initializing create_model()
2023-01-05 20:42:18,157:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A82BFEE400>, estimator=gbr, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A82BB37100>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:42:18,157:INFO:Checking exceptions
2023-01-05 20:42:18,157:INFO:Importing libraries
2023-01-05 20:42:18,157:INFO:Copying training dataset
2023-01-05 20:42:18,166:INFO:Defining folds
2023-01-05 20:42:18,166:INFO:Declaring metric variables
2023-01-05 20:42:18,169:INFO:Importing untrained model
2023-01-05 20:42:18,174:INFO:Gradient Boosting Regressor Imported successfully
2023-01-05 20:42:18,181:INFO:Starting cross validation
2023-01-05 20:42:18,182:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:42:22,945:INFO:Calculating mean and std
2023-01-05 20:42:22,947:INFO:Creating metrics dataframe
2023-01-05 20:42:22,950:INFO:Uploading results into container
2023-01-05 20:42:22,950:INFO:Uploading model into container now
2023-01-05 20:42:22,950:INFO:_master_model_container: 16
2023-01-05 20:42:22,951:INFO:_display_container: 2
2023-01-05 20:42:22,951:INFO:GradientBoostingRegressor(random_state=123)
2023-01-05 20:42:22,951:INFO:create_model() successfully completed......................................
2023-01-05 20:42:23,050:INFO:SubProcess create_model() end ==================================
2023-01-05 20:42:23,050:INFO:Creating metrics dataframe
2023-01-05 20:42:23,062:INFO:Initializing Light Gradient Boosting Machine
2023-01-05 20:42:23,063:INFO:Total runtime is 0.44601084391276047 minutes
2023-01-05 20:42:23,067:INFO:SubProcess create_model() called ==================================
2023-01-05 20:42:23,067:INFO:Initializing create_model()
2023-01-05 20:42:23,068:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A82BFEE400>, estimator=lightgbm, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A82BB37100>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:42:23,068:INFO:Checking exceptions
2023-01-05 20:42:23,068:INFO:Importing libraries
2023-01-05 20:42:23,068:INFO:Copying training dataset
2023-01-05 20:42:23,077:INFO:Defining folds
2023-01-05 20:42:23,077:INFO:Declaring metric variables
2023-01-05 20:42:23,081:INFO:Importing untrained model
2023-01-05 20:42:23,085:INFO:Light Gradient Boosting Machine Imported successfully
2023-01-05 20:42:23,093:INFO:Starting cross validation
2023-01-05 20:42:23,094:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:42:24,167:INFO:Calculating mean and std
2023-01-05 20:42:24,169:INFO:Creating metrics dataframe
2023-01-05 20:42:24,172:INFO:Uploading results into container
2023-01-05 20:42:24,172:INFO:Uploading model into container now
2023-01-05 20:42:24,173:INFO:_master_model_container: 17
2023-01-05 20:42:24,173:INFO:_display_container: 2
2023-01-05 20:42:24,173:INFO:LGBMRegressor(random_state=123)
2023-01-05 20:42:24,173:INFO:create_model() successfully completed......................................
2023-01-05 20:42:24,296:INFO:SubProcess create_model() end ==================================
2023-01-05 20:42:24,297:INFO:Creating metrics dataframe
2023-01-05 20:42:24,313:INFO:Initializing Dummy Regressor
2023-01-05 20:42:24,314:INFO:Total runtime is 0.46686000029246016 minutes
2023-01-05 20:42:24,318:INFO:SubProcess create_model() called ==================================
2023-01-05 20:42:24,319:INFO:Initializing create_model()
2023-01-05 20:42:24,319:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A82BFEE400>, estimator=dummy, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A82BB37100>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:42:24,319:INFO:Checking exceptions
2023-01-05 20:42:24,319:INFO:Importing libraries
2023-01-05 20:42:24,319:INFO:Copying training dataset
2023-01-05 20:42:24,332:INFO:Defining folds
2023-01-05 20:42:24,332:INFO:Declaring metric variables
2023-01-05 20:42:24,336:INFO:Importing untrained model
2023-01-05 20:42:24,340:INFO:Dummy Regressor Imported successfully
2023-01-05 20:42:24,348:INFO:Starting cross validation
2023-01-05 20:42:24,349:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:42:24,605:INFO:Calculating mean and std
2023-01-05 20:42:24,607:INFO:Creating metrics dataframe
2023-01-05 20:42:24,610:INFO:Uploading results into container
2023-01-05 20:42:24,610:INFO:Uploading model into container now
2023-01-05 20:42:24,610:INFO:_master_model_container: 18
2023-01-05 20:42:24,612:INFO:_display_container: 2
2023-01-05 20:42:24,612:INFO:DummyRegressor()
2023-01-05 20:42:24,612:INFO:create_model() successfully completed......................................
2023-01-05 20:42:24,710:INFO:SubProcess create_model() end ==================================
2023-01-05 20:42:24,710:INFO:Creating metrics dataframe
2023-01-05 20:42:24,734:INFO:Initializing create_model()
2023-01-05 20:42:24,734:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A82BFEE400>, estimator=LGBMRegressor(random_state=123), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:42:24,735:INFO:Checking exceptions
2023-01-05 20:42:24,737:INFO:Importing libraries
2023-01-05 20:42:24,737:INFO:Copying training dataset
2023-01-05 20:42:24,744:INFO:Defining folds
2023-01-05 20:42:24,744:INFO:Declaring metric variables
2023-01-05 20:42:24,744:INFO:Importing untrained model
2023-01-05 20:42:24,745:INFO:Declaring custom model
2023-01-05 20:42:24,745:INFO:Light Gradient Boosting Machine Imported successfully
2023-01-05 20:42:24,746:INFO:Cross validation set to False
2023-01-05 20:42:24,746:INFO:Fitting Model
2023-01-05 20:42:24,958:INFO:LGBMRegressor(random_state=123)
2023-01-05 20:42:24,958:INFO:create_model() successfully completed......................................
2023-01-05 20:42:25,097:INFO:_master_model_container: 18
2023-01-05 20:42:25,097:INFO:_display_container: 2
2023-01-05 20:42:25,097:INFO:LGBMRegressor(random_state=123)
2023-01-05 20:42:25,097:INFO:compare_models() successfully completed......................................
2023-01-05 20:42:25,098:INFO:Initializing tune_model()
2023-01-05 20:42:25,099:INFO:tune_model(estimator=LGBMRegressor(random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=MAE, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A82BFEE400>)
2023-01-05 20:42:25,099:INFO:Checking exceptions
2023-01-05 20:42:25,129:INFO:Copying training dataset
2023-01-05 20:42:25,138:INFO:Checking base model
2023-01-05 20:42:25,138:INFO:Base model : Light Gradient Boosting Machine
2023-01-05 20:42:25,142:INFO:Declaring metric variables
2023-01-05 20:42:25,146:INFO:Defining Hyperparameters
2023-01-05 20:42:25,252:INFO:Tuning with n_jobs=-1
2023-01-05 20:42:25,252:INFO:Initializing RandomizedSearchCV
2023-01-05 20:42:30,482:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2023-01-05 20:42:30,483:INFO:Hyperparameter search completed
2023-01-05 20:42:30,484:INFO:SubProcess create_model() called ==================================
2023-01-05 20:42:30,484:INFO:Initializing create_model()
2023-01-05 20:42:30,485:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A82BFEE400>, estimator=LGBMRegressor(random_state=123), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A82BD78640>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2023-01-05 20:42:30,485:INFO:Checking exceptions
2023-01-05 20:42:30,485:INFO:Importing libraries
2023-01-05 20:42:30,485:INFO:Copying training dataset
2023-01-05 20:42:30,493:INFO:Defining folds
2023-01-05 20:42:30,493:INFO:Declaring metric variables
2023-01-05 20:42:30,496:INFO:Importing untrained model
2023-01-05 20:42:30,497:INFO:Declaring custom model
2023-01-05 20:42:30,501:INFO:Light Gradient Boosting Machine Imported successfully
2023-01-05 20:42:30,508:INFO:Starting cross validation
2023-01-05 20:42:30,509:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:42:31,774:INFO:Calculating mean and std
2023-01-05 20:42:31,776:INFO:Creating metrics dataframe
2023-01-05 20:42:31,782:INFO:Finalizing model
2023-01-05 20:42:32,229:INFO:Uploading results into container
2023-01-05 20:42:32,230:INFO:Uploading model into container now
2023-01-05 20:42:32,230:INFO:_master_model_container: 19
2023-01-05 20:42:32,230:INFO:_display_container: 3
2023-01-05 20:42:32,231:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              num_leaves=70, random_state=123, reg_alpha=2, reg_lambda=3)
2023-01-05 20:42:32,231:INFO:create_model() successfully completed......................................
2023-01-05 20:42:32,337:INFO:SubProcess create_model() end ==================================
2023-01-05 20:42:32,338:INFO:choose_better activated
2023-01-05 20:42:32,341:INFO:SubProcess create_model() called ==================================
2023-01-05 20:42:32,341:INFO:Initializing create_model()
2023-01-05 20:42:32,342:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A82BFEE400>, estimator=LGBMRegressor(random_state=123), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:42:32,342:INFO:Checking exceptions
2023-01-05 20:42:32,344:INFO:Importing libraries
2023-01-05 20:42:32,344:INFO:Copying training dataset
2023-01-05 20:42:32,352:INFO:Defining folds
2023-01-05 20:42:32,352:INFO:Declaring metric variables
2023-01-05 20:42:32,352:INFO:Importing untrained model
2023-01-05 20:42:32,352:INFO:Declaring custom model
2023-01-05 20:42:32,353:INFO:Light Gradient Boosting Machine Imported successfully
2023-01-05 20:42:32,353:INFO:Starting cross validation
2023-01-05 20:42:32,354:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:42:33,420:INFO:Calculating mean and std
2023-01-05 20:42:33,421:INFO:Creating metrics dataframe
2023-01-05 20:42:33,423:INFO:Finalizing model
2023-01-05 20:42:33,640:INFO:Uploading results into container
2023-01-05 20:42:33,641:INFO:Uploading model into container now
2023-01-05 20:42:33,641:INFO:_master_model_container: 20
2023-01-05 20:42:33,641:INFO:_display_container: 4
2023-01-05 20:42:33,642:INFO:LGBMRegressor(random_state=123)
2023-01-05 20:42:33,642:INFO:create_model() successfully completed......................................
2023-01-05 20:42:33,750:INFO:SubProcess create_model() end ==================================
2023-01-05 20:42:33,751:INFO:LGBMRegressor(random_state=123) result for MAE is 2.201
2023-01-05 20:42:33,751:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              num_leaves=70, random_state=123, reg_alpha=2, reg_lambda=3) result for MAE is 2.4987
2023-01-05 20:42:33,752:INFO:LGBMRegressor(random_state=123) is best model
2023-01-05 20:42:33,752:INFO:choose_better completed
2023-01-05 20:42:33,752:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-01-05 20:42:33,760:INFO:_master_model_container: 20
2023-01-05 20:42:33,761:INFO:_display_container: 3
2023-01-05 20:42:33,761:INFO:LGBMRegressor(random_state=123)
2023-01-05 20:42:33,761:INFO:tune_model() successfully completed......................................
2023-01-05 20:42:33,868:INFO:Initializing plot_model()
2023-01-05 20:42:33,868:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LGBMRegressor(random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A82BFEE400>, system=True)
2023-01-05 20:42:33,868:INFO:Checking exceptions
2023-01-05 20:42:33,874:INFO:Preloading libraries
2023-01-05 20:42:33,881:INFO:Copying training dataset
2023-01-05 20:42:33,881:INFO:Plot type: error
2023-01-05 20:42:33,991:INFO:Fitting Model
2023-01-05 20:42:33,991:INFO:Scoring test/hold-out set
2023-01-05 20:42:34,232:INFO:Visual Rendered Successfully
2023-01-05 20:42:34,339:INFO:plot_model() successfully completed......................................
2023-01-05 20:42:34,340:INFO:Initializing predict_model()
2023-01-05 20:42:34,340:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A82BFEE400>, estimator=LGBMRegressor(random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001A82CBA3940>)
2023-01-05 20:42:34,340:INFO:Checking exceptions
2023-01-05 20:42:34,340:INFO:Preloading libraries
2023-01-05 20:42:34,496:INFO:Initializing finalize_model()
2023-01-05 20:42:34,496:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A82BFEE400>, estimator=LGBMRegressor(random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-01-05 20:42:34,496:INFO:Finalizing LGBMRegressor(random_state=123)
2023-01-05 20:42:34,504:INFO:Initializing create_model()
2023-01-05 20:42:34,504:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A82BFEE400>, estimator=LGBMRegressor(random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-01-05 20:42:34,505:INFO:Checking exceptions
2023-01-05 20:42:34,506:INFO:Importing libraries
2023-01-05 20:42:34,506:INFO:Copying training dataset
2023-01-05 20:42:34,507:INFO:Defining folds
2023-01-05 20:42:34,507:INFO:Declaring metric variables
2023-01-05 20:42:34,507:INFO:Importing untrained model
2023-01-05 20:42:34,507:INFO:Declaring custom model
2023-01-05 20:42:34,508:INFO:Light Gradient Boosting Machine Imported successfully
2023-01-05 20:42:34,509:INFO:Cross validation set to False
2023-01-05 20:42:34,509:INFO:Fitting Model
2023-01-05 20:42:34,789:INFO:Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator', LGBMRegressor(random_state=123))])
2023-01-05 20:42:34,789:INFO:create_model() successfully completed......................................
2023-01-05 20:42:34,900:INFO:_master_model_container: 20
2023-01-05 20:42:34,900:INFO:_display_container: 4
2023-01-05 20:42:34,906:INFO:Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator', LGBMRegressor(random_state=123))])
2023-01-05 20:42:34,907:INFO:finalize_model() successfully completed......................................
2023-01-05 20:42:35,014:INFO:Initializing predict_model()
2023-01-05 20:42:35,015:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A82BFEE400>, estimator=Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator', LGBMRegressor(random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001A82CBA3550>)
2023-01-05 20:42:35,015:INFO:Checking exceptions
2023-01-05 20:42:35,015:INFO:Preloading libraries
2023-01-05 20:42:35,017:INFO:Set up data.
2023-01-05 20:42:35,031:INFO:Set up index.
2023-01-05 20:42:35,745:INFO:Initializing evaluate_model()
2023-01-05 20:42:35,746:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A82BFEE400>, estimator=Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator', LGBMRegressor(random_state=123))]), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None, use_train_data=False)
2023-01-05 20:42:35,780:INFO:Initializing plot_model()
2023-01-05 20:42:35,780:INFO:plot_model(plot=pipeline, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), use_train_data=False, verbose=False, display=None, display_format=None, estimator=Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator', LGBMRegressor(random_state=123))]), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A82BFEE400>, system=True)
2023-01-05 20:42:35,780:INFO:Checking exceptions
2023-01-05 20:42:35,785:INFO:Preloading libraries
2023-01-05 20:42:35,792:INFO:Copying training dataset
2023-01-05 20:42:35,792:INFO:Plot type: pipeline
2023-01-05 20:42:35,923:INFO:Visual Rendered Successfully
2023-01-05 20:42:36,030:INFO:plot_model() successfully completed......................................
2023-01-05 20:42:36,043:INFO:Initializing save_model()
2023-01-05 20:42:36,044:INFO:save_model(model=Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator', LGBMRegressor(random_state=123))]), model_name=c:\Users\Kodotautas\Desktop\Data_science\7_TIME_SERIES_FORECAST_AUTOML/models/final_model.pkl, prep_pipe_=Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-01-05 20:42:36,044:INFO:Adding model into prep_pipe
2023-01-05 20:42:36,050:WARNING:Only Model saved as it was a pipeline.
2023-01-05 20:42:36,059:INFO:c:\Users\Kodotautas\Desktop\Data_science\7_TIME_SERIES_FORECAST_AUTOML/models/final_model.pkl.pkl saved in current working directory
2023-01-05 20:42:36,065:INFO:Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator', LGBMRegressor(random_state=123))])
2023-01-05 20:42:36,065:INFO:save_model() successfully completed......................................
2023-01-05 20:44:00,792:INFO:Initializing plot_model()
2023-01-05 20:44:00,792:INFO:plot_model(plot=residuals, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), use_train_data=False, verbose=False, display=None, display_format=None, estimator=Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator', LGBMRegressor(random_state=123))]), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A82BFEE400>, system=True)
2023-01-05 20:44:00,793:INFO:Checking exceptions
2023-01-05 20:44:00,799:INFO:Preloading libraries
2023-01-05 20:44:00,807:INFO:Copying training dataset
2023-01-05 20:44:00,808:INFO:Plot type: residuals
2023-01-05 20:44:00,964:INFO:Fitting Model
2023-01-05 20:44:01,050:INFO:Scoring test/hold-out set
2023-01-05 20:44:01,502:INFO:Visual Rendered Successfully
2023-01-05 20:44:01,646:INFO:plot_model() successfully completed......................................
2023-01-05 20:44:06,159:INFO:Initializing plot_model()
2023-01-05 20:44:06,159:INFO:plot_model(plot=error, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), use_train_data=False, verbose=False, display=None, display_format=None, estimator=Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator', LGBMRegressor(random_state=123))]), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A82BFEE400>, system=True)
2023-01-05 20:44:06,159:INFO:Checking exceptions
2023-01-05 20:44:06,165:INFO:Preloading libraries
2023-01-05 20:44:06,170:INFO:Copying training dataset
2023-01-05 20:44:06,170:INFO:Plot type: error
2023-01-05 20:44:06,282:INFO:Fitting Model
2023-01-05 20:44:06,282:INFO:Scoring test/hold-out set
2023-01-05 20:44:06,535:INFO:Visual Rendered Successfully
2023-01-05 20:44:06,648:INFO:plot_model() successfully completed......................................
2023-01-05 20:44:10,557:INFO:Initializing plot_model()
2023-01-05 20:44:10,558:INFO:plot_model(plot=rfe, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), use_train_data=False, verbose=False, display=None, display_format=None, estimator=Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator', LGBMRegressor(random_state=123))]), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A82BFEE400>, system=True)
2023-01-05 20:44:10,558:INFO:Checking exceptions
2023-01-05 20:44:10,563:INFO:Preloading libraries
2023-01-05 20:44:10,569:INFO:Copying training dataset
2023-01-05 20:44:10,570:INFO:Plot type: rfe
2023-01-05 20:44:10,692:INFO:Fitting Model
2023-01-05 20:45:59,669:INFO:Initializing plot_model()
2023-01-05 20:45:59,669:INFO:plot_model(plot=feature, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), use_train_data=False, verbose=False, display=None, display_format=None, estimator=Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator', LGBMRegressor(random_state=123))]), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A82BFEE400>, system=True)
2023-01-05 20:45:59,670:INFO:Checking exceptions
2023-01-05 20:45:59,676:INFO:Preloading libraries
2023-01-05 20:45:59,683:INFO:Copying training dataset
2023-01-05 20:45:59,683:INFO:Plot type: feature
2023-01-05 20:45:59,683:WARNING:No coef_ found. Trying feature_importances_
2023-01-05 20:45:59,931:INFO:Visual Rendered Successfully
2023-01-05 20:46:00,047:INFO:plot_model() successfully completed......................................
2023-01-05 20:46:55,234:INFO:Initializing plot_model()
2023-01-05 20:46:55,234:INFO:plot_model(plot=rfe, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), use_train_data=False, verbose=False, display=None, display_format=None, estimator=Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator', LGBMRegressor(random_state=123))]), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A82BFEE400>, system=True)
2023-01-05 20:46:55,234:INFO:Checking exceptions
2023-01-05 20:46:55,240:INFO:Preloading libraries
2023-01-05 20:46:55,249:INFO:Copying training dataset
2023-01-05 20:46:55,249:INFO:Plot type: rfe
2023-01-05 20:46:55,381:INFO:Fitting Model
2023-01-05 20:53:47,989:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-01-05 20:53:47,989:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-01-05 20:53:47,989:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-01-05 20:53:47,989:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-01-05 20:53:48,593:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-01-05 20:53:48,932:INFO:PyCaret RegressionExperiment
2023-01-05 20:53:48,932:INFO:Logging name: reg-default-name
2023-01-05 20:53:48,932:INFO:ML Usecase: MLUsecase.REGRESSION
2023-01-05 20:53:48,932:INFO:version 3.0.0.rc6
2023-01-05 20:53:48,932:INFO:Initializing setup()
2023-01-05 20:53:48,932:INFO:self.USI: 82ff
2023-01-05 20:53:48,932:INFO:self._variable_keys: {'USI', 'gpu_param', 'target_param', 'X', 'pipeline', 'fold_groups_param', 'gpu_n_jobs_param', 'data', 'log_plots_param', 'idx', 'n_jobs_param', '_available_plots', 'seed', '_ml_usecase', 'y', 'exp_name_log', 'fold_generator', 'fold_shuffle_param', 'y_train', 'exp_id', 'X_test', 'y_test', 'transform_target_param', 'logging_param', 'X_train', 'html_param', 'memory'}
2023-01-05 20:53:48,933:INFO:Checking environment
2023-01-05 20:53:48,933:INFO:python_version: 3.9.13
2023-01-05 20:53:48,933:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-01-05 20:53:48,933:INFO:machine: AMD64
2023-01-05 20:53:48,933:INFO:platform: Windows-10-10.0.19044-SP0
2023-01-05 20:53:48,933:INFO:Memory: svmem(total=17114804224, available=9085698048, percent=46.9, used=8029106176, free=9085698048)
2023-01-05 20:53:48,933:INFO:Physical Core: 4
2023-01-05 20:53:48,933:INFO:Logical Core: 4
2023-01-05 20:53:48,933:INFO:Checking libraries
2023-01-05 20:53:48,933:INFO:System:
2023-01-05 20:53:48,933:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-01-05 20:53:48,933:INFO:executable: c:\Users\Kodotautas\anaconda3\python.exe
2023-01-05 20:53:48,933:INFO:   machine: Windows-10-10.0.19044-SP0
2023-01-05 20:53:48,933:INFO:PyCaret required dependencies:
2023-01-05 20:53:48,933:INFO:                 pip: 22.2.2
2023-01-05 20:53:48,933:INFO:          setuptools: 63.4.1
2023-01-05 20:53:48,933:INFO:             pycaret: 3.0.0rc6
2023-01-05 20:53:48,933:INFO:             IPython: 7.31.1
2023-01-05 20:53:48,933:INFO:          ipywidgets: 7.6.5
2023-01-05 20:53:48,933:INFO:                tqdm: 4.64.1
2023-01-05 20:53:48,933:INFO:               numpy: 1.21.5
2023-01-05 20:53:48,934:INFO:              pandas: 1.4.4
2023-01-05 20:53:48,934:INFO:              jinja2: 2.11.3
2023-01-05 20:53:48,934:INFO:               scipy: 1.9.1
2023-01-05 20:53:48,934:INFO:              joblib: 1.2.0
2023-01-05 20:53:48,934:INFO:             sklearn: 1.0.2
2023-01-05 20:53:48,934:INFO:                pyod: 1.0.7
2023-01-05 20:53:48,934:INFO:            imblearn: 0.10.1
2023-01-05 20:53:48,934:INFO:   category_encoders: 2.5.1.post0
2023-01-05 20:53:48,934:INFO:            lightgbm: 3.3.3
2023-01-05 20:53:48,934:INFO:               numba: 0.55.1
2023-01-05 20:53:48,934:INFO:            requests: 2.28.1
2023-01-05 20:53:48,934:INFO:          matplotlib: 3.5.2
2023-01-05 20:53:48,934:INFO:          scikitplot: 0.3.7
2023-01-05 20:53:48,934:INFO:         yellowbrick: 1.5
2023-01-05 20:53:48,934:INFO:              plotly: 5.9.0
2023-01-05 20:53:48,934:INFO:             kaleido: 0.2.1
2023-01-05 20:53:48,934:INFO:         statsmodels: 0.13.2
2023-01-05 20:53:48,934:INFO:              sktime: 0.14.1
2023-01-05 20:53:48,934:INFO:               tbats: 1.1.2
2023-01-05 20:53:48,934:INFO:            pmdarima: 2.0.2
2023-01-05 20:53:48,934:INFO:              psutil: 5.9.0
2023-01-05 20:53:48,934:INFO:PyCaret optional dependencies:
2023-01-05 20:53:49,279:INFO:                shap: 0.41.0
2023-01-05 20:53:49,279:INFO:           interpret: Not installed
2023-01-05 20:53:49,279:INFO:                umap: Not installed
2023-01-05 20:53:49,279:INFO:    pandas_profiling: Not installed
2023-01-05 20:53:49,280:INFO:  explainerdashboard: Not installed
2023-01-05 20:53:49,280:INFO:             autoviz: Not installed
2023-01-05 20:53:49,280:INFO:           fairlearn: Not installed
2023-01-05 20:53:49,280:INFO:             xgboost: Not installed
2023-01-05 20:53:49,280:INFO:            catboost: Not installed
2023-01-05 20:53:49,280:INFO:              kmodes: Not installed
2023-01-05 20:53:49,280:INFO:             mlxtend: Not installed
2023-01-05 20:53:49,280:INFO:       statsforecast: Not installed
2023-01-05 20:53:49,280:INFO:        tune_sklearn: 0.4.3
2023-01-05 20:53:49,280:INFO:                 ray: 2.0.0
2023-01-05 20:53:49,280:INFO:            hyperopt: 0.2.7
2023-01-05 20:53:49,280:INFO:              optuna: 3.0.1
2023-01-05 20:53:49,280:INFO:               skopt: 0.9.0
2023-01-05 20:53:49,280:INFO:              mlflow: Not installed
2023-01-05 20:53:49,280:INFO:              gradio: Not installed
2023-01-05 20:53:49,280:INFO:             fastapi: 0.88.0
2023-01-05 20:53:49,280:INFO:             uvicorn: 0.20.0
2023-01-05 20:53:49,280:INFO:              m2cgen: Not installed
2023-01-05 20:53:49,280:INFO:           evidently: Not installed
2023-01-05 20:53:49,280:INFO:                nltk: 3.7
2023-01-05 20:53:49,280:INFO:            pyLDAvis: Not installed
2023-01-05 20:53:49,280:INFO:              gensim: 4.1.2
2023-01-05 20:53:49,280:INFO:               spacy: 3.4.2
2023-01-05 20:53:49,281:INFO:           wordcloud: Not installed
2023-01-05 20:53:49,281:INFO:            textblob: Not installed
2023-01-05 20:53:49,281:INFO:               fugue: Not installed
2023-01-05 20:53:49,281:INFO:           streamlit: Not installed
2023-01-05 20:53:49,281:INFO:             prophet: Not installed
2023-01-05 20:53:49,281:INFO:None
2023-01-05 20:53:49,281:INFO:Set up data.
2023-01-05 20:53:49,301:INFO:Set up train/test split.
2023-01-05 20:53:49,313:INFO:Set up index.
2023-01-05 20:53:49,315:INFO:Set up folding strategy.
2023-01-05 20:53:49,316:INFO:Assigning column types.
2023-01-05 20:53:49,325:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-01-05 20:53:49,326:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-01-05 20:53:49,330:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-05 20:53:49,335:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-05 20:53:49,402:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-05 20:53:49,447:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-05 20:53:49,448:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:53:49,577:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:53:49,577:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-01-05 20:53:49,582:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-05 20:53:49,586:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-05 20:53:49,654:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-05 20:53:49,700:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-05 20:53:49,701:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:53:49,701:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:53:49,701:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-01-05 20:53:49,706:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-05 20:53:49,711:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-05 20:53:49,776:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-05 20:53:49,821:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-05 20:53:49,822:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:53:49,822:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:53:49,827:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-05 20:53:49,832:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-05 20:53:49,897:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-05 20:53:49,942:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-05 20:53:49,943:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:53:49,943:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:53:49,944:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-01-05 20:53:49,953:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-05 20:53:50,017:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-05 20:53:50,062:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-05 20:53:50,063:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:53:50,063:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:53:50,072:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-05 20:53:50,137:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-05 20:53:50,182:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-05 20:53:50,183:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:53:50,183:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:53:50,184:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-01-05 20:53:50,258:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-05 20:53:50,303:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-05 20:53:50,303:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:53:50,303:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:53:50,377:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-05 20:53:50,421:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-05 20:53:50,422:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:53:50,422:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:53:50,422:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-01-05 20:53:50,496:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-05 20:53:50,541:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:53:50,541:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:53:50,615:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-05 20:53:50,661:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:53:50,661:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:53:50,661:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-01-05 20:53:50,784:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:53:50,784:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:53:50,903:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:53:50,903:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:53:50,904:INFO:Preparing preprocessing pipeline...
2023-01-05 20:53:50,906:INFO:Set up simple imputation.
2023-01-05 20:53:50,906:INFO:Set up column transformation.
2023-01-05 20:53:50,906:INFO:Set up feature normalization.
2023-01-05 20:53:50,943:INFO:Finished creating preprocessing pipeline.
2023-01-05 20:53:50,950:INFO:Pipeline: Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2023-01-05 20:53:50,950:INFO:Creating final display dataframe.
2023-01-05 20:53:51,182:INFO:Setup _display_container:                Description             Value
0               Session id               123
1                   Target        b2b+b2c+vt
2              Target type        Regression
3               Data shape        (9930, 48)
4         Train data shape        (6951, 48)
5          Test data shape        (2979, 48)
6         Numeric features                 8
7               Preprocess              True
8          Imputation type            simple
9       Numeric imputation              mean
10  Categorical imputation              mode
11          Transformation              True
12   Transformation method       yeo-johnson
13               Normalize              True
14        Normalize method            zscore
15          Fold Generator   TimeSeriesSplit
16             Fold Number                 5
17                CPU Jobs                -1
18                 Use GPU             False
19          Log Experiment             False
20         Experiment Name  reg-default-name
21                     USI              82ff
2023-01-05 20:53:51,318:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:53:51,318:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:53:51,437:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:53:51,438:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:53:51,438:INFO:setup() successfully completed in 2.51s...............
2023-01-05 20:53:51,438:INFO:Initializing compare_models()
2023-01-05 20:53:51,438:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A5A013BA90>, include=None, fold=None, round=4, cross_validation=True, sort=MAE, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000002A5A013BA90>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'MAE', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-01-05 20:53:51,439:INFO:Checking exceptions
2023-01-05 20:53:51,444:INFO:Preparing display monitor
2023-01-05 20:53:51,486:INFO:Initializing Linear Regression
2023-01-05 20:53:51,486:INFO:Total runtime is 1.6709168752034504e-05 minutes
2023-01-05 20:53:51,489:INFO:SubProcess create_model() called ==================================
2023-01-05 20:53:51,490:INFO:Initializing create_model()
2023-01-05 20:53:51,490:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A5A013BA90>, estimator=lr, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A5AC098640>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:53:51,490:INFO:Checking exceptions
2023-01-05 20:53:51,490:INFO:Importing libraries
2023-01-05 20:53:51,490:INFO:Copying training dataset
2023-01-05 20:53:51,500:INFO:Defining folds
2023-01-05 20:53:51,501:INFO:Declaring metric variables
2023-01-05 20:53:51,505:INFO:Importing untrained model
2023-01-05 20:53:51,511:INFO:Linear Regression Imported successfully
2023-01-05 20:53:51,519:INFO:Starting cross validation
2023-01-05 20:53:51,530:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:53:57,220:INFO:Calculating mean and std
2023-01-05 20:53:57,222:INFO:Creating metrics dataframe
2023-01-05 20:53:57,225:INFO:Uploading results into container
2023-01-05 20:53:57,226:INFO:Uploading model into container now
2023-01-05 20:53:57,226:INFO:_master_model_container: 1
2023-01-05 20:53:57,226:INFO:_display_container: 2
2023-01-05 20:53:57,227:INFO:LinearRegression(n_jobs=-1)
2023-01-05 20:53:57,227:INFO:create_model() successfully completed......................................
2023-01-05 20:53:57,320:INFO:SubProcess create_model() end ==================================
2023-01-05 20:53:57,320:INFO:Creating metrics dataframe
2023-01-05 20:53:57,331:INFO:Initializing Lasso Regression
2023-01-05 20:53:57,331:INFO:Total runtime is 0.09744061628977457 minutes
2023-01-05 20:53:57,336:INFO:SubProcess create_model() called ==================================
2023-01-05 20:53:57,337:INFO:Initializing create_model()
2023-01-05 20:53:57,337:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A5A013BA90>, estimator=lasso, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A5AC098640>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:53:57,337:INFO:Checking exceptions
2023-01-05 20:53:57,337:INFO:Importing libraries
2023-01-05 20:53:57,337:INFO:Copying training dataset
2023-01-05 20:53:57,348:INFO:Defining folds
2023-01-05 20:53:57,348:INFO:Declaring metric variables
2023-01-05 20:53:57,352:INFO:Importing untrained model
2023-01-05 20:53:57,356:INFO:Lasso Regression Imported successfully
2023-01-05 20:53:57,367:INFO:Starting cross validation
2023-01-05 20:53:57,368:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:53:57,634:INFO:Calculating mean and std
2023-01-05 20:53:57,636:INFO:Creating metrics dataframe
2023-01-05 20:53:57,639:INFO:Uploading results into container
2023-01-05 20:53:57,639:INFO:Uploading model into container now
2023-01-05 20:53:57,640:INFO:_master_model_container: 2
2023-01-05 20:53:57,641:INFO:_display_container: 2
2023-01-05 20:53:57,641:INFO:Lasso(random_state=123)
2023-01-05 20:53:57,641:INFO:create_model() successfully completed......................................
2023-01-05 20:53:57,740:INFO:SubProcess create_model() end ==================================
2023-01-05 20:53:57,740:INFO:Creating metrics dataframe
2023-01-05 20:53:57,751:INFO:Initializing Ridge Regression
2023-01-05 20:53:57,751:INFO:Total runtime is 0.10444548527399698 minutes
2023-01-05 20:53:57,755:INFO:SubProcess create_model() called ==================================
2023-01-05 20:53:57,756:INFO:Initializing create_model()
2023-01-05 20:53:57,756:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A5A013BA90>, estimator=ridge, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A5AC098640>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:53:57,756:INFO:Checking exceptions
2023-01-05 20:53:57,757:INFO:Importing libraries
2023-01-05 20:53:57,757:INFO:Copying training dataset
2023-01-05 20:53:57,767:INFO:Defining folds
2023-01-05 20:53:57,767:INFO:Declaring metric variables
2023-01-05 20:53:57,772:INFO:Importing untrained model
2023-01-05 20:53:57,778:INFO:Ridge Regression Imported successfully
2023-01-05 20:53:57,786:INFO:Starting cross validation
2023-01-05 20:53:57,788:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:53:58,045:INFO:Calculating mean and std
2023-01-05 20:53:58,047:INFO:Creating metrics dataframe
2023-01-05 20:53:58,050:INFO:Uploading results into container
2023-01-05 20:53:58,050:INFO:Uploading model into container now
2023-01-05 20:53:58,051:INFO:_master_model_container: 3
2023-01-05 20:53:58,051:INFO:_display_container: 2
2023-01-05 20:53:58,051:INFO:Ridge(random_state=123)
2023-01-05 20:53:58,051:INFO:create_model() successfully completed......................................
2023-01-05 20:53:58,146:INFO:SubProcess create_model() end ==================================
2023-01-05 20:53:58,146:INFO:Creating metrics dataframe
2023-01-05 20:53:58,158:INFO:Initializing Elastic Net
2023-01-05 20:53:58,158:INFO:Total runtime is 0.1112280011177063 minutes
2023-01-05 20:53:58,163:INFO:SubProcess create_model() called ==================================
2023-01-05 20:53:58,163:INFO:Initializing create_model()
2023-01-05 20:53:58,163:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A5A013BA90>, estimator=en, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A5AC098640>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:53:58,163:INFO:Checking exceptions
2023-01-05 20:53:58,163:INFO:Importing libraries
2023-01-05 20:53:58,163:INFO:Copying training dataset
2023-01-05 20:53:58,172:INFO:Defining folds
2023-01-05 20:53:58,173:INFO:Declaring metric variables
2023-01-05 20:53:58,178:INFO:Importing untrained model
2023-01-05 20:53:58,182:INFO:Elastic Net Imported successfully
2023-01-05 20:53:58,189:INFO:Starting cross validation
2023-01-05 20:53:58,192:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:53:58,458:INFO:Calculating mean and std
2023-01-05 20:53:58,460:INFO:Creating metrics dataframe
2023-01-05 20:53:58,465:INFO:Uploading results into container
2023-01-05 20:53:58,466:INFO:Uploading model into container now
2023-01-05 20:53:58,466:INFO:_master_model_container: 4
2023-01-05 20:53:58,466:INFO:_display_container: 2
2023-01-05 20:53:58,466:INFO:ElasticNet(random_state=123)
2023-01-05 20:53:58,466:INFO:create_model() successfully completed......................................
2023-01-05 20:53:58,563:INFO:SubProcess create_model() end ==================================
2023-01-05 20:53:58,563:INFO:Creating metrics dataframe
2023-01-05 20:53:58,573:INFO:Initializing Least Angle Regression
2023-01-05 20:53:58,573:INFO:Total runtime is 0.11813509464263916 minutes
2023-01-05 20:53:58,577:INFO:SubProcess create_model() called ==================================
2023-01-05 20:53:58,578:INFO:Initializing create_model()
2023-01-05 20:53:58,578:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A5A013BA90>, estimator=lar, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A5AC098640>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:53:58,578:INFO:Checking exceptions
2023-01-05 20:53:58,578:INFO:Importing libraries
2023-01-05 20:53:58,578:INFO:Copying training dataset
2023-01-05 20:53:58,587:INFO:Defining folds
2023-01-05 20:53:58,587:INFO:Declaring metric variables
2023-01-05 20:53:58,592:INFO:Importing untrained model
2023-01-05 20:53:58,598:INFO:Least Angle Regression Imported successfully
2023-01-05 20:53:58,605:INFO:Starting cross validation
2023-01-05 20:53:58,607:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:53:58,682:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-05 20:53:58,684:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-05 20:53:58,689:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-05 20:53:58,694:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-05 20:53:58,773:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-05 20:53:58,919:INFO:Calculating mean and std
2023-01-05 20:53:58,921:INFO:Creating metrics dataframe
2023-01-05 20:53:58,923:INFO:Uploading results into container
2023-01-05 20:53:58,925:INFO:Uploading model into container now
2023-01-05 20:53:58,926:INFO:_master_model_container: 5
2023-01-05 20:53:58,926:INFO:_display_container: 2
2023-01-05 20:53:58,927:INFO:Lars(random_state=123)
2023-01-05 20:53:58,927:INFO:create_model() successfully completed......................................
2023-01-05 20:53:59,029:INFO:SubProcess create_model() end ==================================
2023-01-05 20:53:59,029:INFO:Creating metrics dataframe
2023-01-05 20:53:59,040:INFO:Initializing Lasso Least Angle Regression
2023-01-05 20:53:59,040:INFO:Total runtime is 0.1259170413017273 minutes
2023-01-05 20:53:59,044:INFO:SubProcess create_model() called ==================================
2023-01-05 20:53:59,045:INFO:Initializing create_model()
2023-01-05 20:53:59,045:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A5A013BA90>, estimator=llar, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A5AC098640>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:53:59,045:INFO:Checking exceptions
2023-01-05 20:53:59,045:INFO:Importing libraries
2023-01-05 20:53:59,045:INFO:Copying training dataset
2023-01-05 20:53:59,054:INFO:Defining folds
2023-01-05 20:53:59,055:INFO:Declaring metric variables
2023-01-05 20:53:59,059:INFO:Importing untrained model
2023-01-05 20:53:59,064:INFO:Lasso Least Angle Regression Imported successfully
2023-01-05 20:53:59,072:INFO:Starting cross validation
2023-01-05 20:53:59,073:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:53:59,140:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-05 20:53:59,144:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-05 20:53:59,147:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-05 20:53:59,150:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-05 20:53:59,195:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-05 20:53:59,319:INFO:Calculating mean and std
2023-01-05 20:53:59,321:INFO:Creating metrics dataframe
2023-01-05 20:53:59,325:INFO:Uploading results into container
2023-01-05 20:53:59,326:INFO:Uploading model into container now
2023-01-05 20:53:59,326:INFO:_master_model_container: 6
2023-01-05 20:53:59,326:INFO:_display_container: 2
2023-01-05 20:53:59,327:INFO:LassoLars(random_state=123)
2023-01-05 20:53:59,327:INFO:create_model() successfully completed......................................
2023-01-05 20:53:59,435:INFO:SubProcess create_model() end ==================================
2023-01-05 20:53:59,435:INFO:Creating metrics dataframe
2023-01-05 20:53:59,446:INFO:Initializing Orthogonal Matching Pursuit
2023-01-05 20:53:59,446:INFO:Total runtime is 0.13268338044484457 minutes
2023-01-05 20:53:59,450:INFO:SubProcess create_model() called ==================================
2023-01-05 20:53:59,451:INFO:Initializing create_model()
2023-01-05 20:53:59,451:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A5A013BA90>, estimator=omp, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A5AC098640>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:53:59,451:INFO:Checking exceptions
2023-01-05 20:53:59,451:INFO:Importing libraries
2023-01-05 20:53:59,451:INFO:Copying training dataset
2023-01-05 20:53:59,461:INFO:Defining folds
2023-01-05 20:53:59,462:INFO:Declaring metric variables
2023-01-05 20:53:59,466:INFO:Importing untrained model
2023-01-05 20:53:59,469:INFO:Orthogonal Matching Pursuit Imported successfully
2023-01-05 20:53:59,477:INFO:Starting cross validation
2023-01-05 20:53:59,479:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:53:59,547:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-05 20:53:59,551:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-05 20:53:59,555:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-05 20:53:59,569:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-05 20:53:59,630:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-05 20:53:59,759:INFO:Calculating mean and std
2023-01-05 20:53:59,761:INFO:Creating metrics dataframe
2023-01-05 20:53:59,765:INFO:Uploading results into container
2023-01-05 20:53:59,765:INFO:Uploading model into container now
2023-01-05 20:53:59,766:INFO:_master_model_container: 7
2023-01-05 20:53:59,766:INFO:_display_container: 2
2023-01-05 20:53:59,766:INFO:OrthogonalMatchingPursuit()
2023-01-05 20:53:59,766:INFO:create_model() successfully completed......................................
2023-01-05 20:53:59,884:INFO:SubProcess create_model() end ==================================
2023-01-05 20:53:59,885:INFO:Creating metrics dataframe
2023-01-05 20:53:59,897:INFO:Initializing Bayesian Ridge
2023-01-05 20:53:59,898:INFO:Total runtime is 0.1402167280515035 minutes
2023-01-05 20:53:59,901:INFO:SubProcess create_model() called ==================================
2023-01-05 20:53:59,902:INFO:Initializing create_model()
2023-01-05 20:53:59,902:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A5A013BA90>, estimator=br, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A5AC098640>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:53:59,902:INFO:Checking exceptions
2023-01-05 20:53:59,903:INFO:Importing libraries
2023-01-05 20:53:59,903:INFO:Copying training dataset
2023-01-05 20:53:59,916:INFO:Defining folds
2023-01-05 20:53:59,916:INFO:Declaring metric variables
2023-01-05 20:53:59,921:INFO:Importing untrained model
2023-01-05 20:53:59,925:INFO:Bayesian Ridge Imported successfully
2023-01-05 20:53:59,933:INFO:Starting cross validation
2023-01-05 20:53:59,935:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:54:00,219:INFO:Calculating mean and std
2023-01-05 20:54:00,221:INFO:Creating metrics dataframe
2023-01-05 20:54:00,224:INFO:Uploading results into container
2023-01-05 20:54:00,225:INFO:Uploading model into container now
2023-01-05 20:54:00,225:INFO:_master_model_container: 8
2023-01-05 20:54:00,225:INFO:_display_container: 2
2023-01-05 20:54:00,226:INFO:BayesianRidge()
2023-01-05 20:54:00,226:INFO:create_model() successfully completed......................................
2023-01-05 20:54:00,332:INFO:SubProcess create_model() end ==================================
2023-01-05 20:54:00,332:INFO:Creating metrics dataframe
2023-01-05 20:54:00,342:INFO:Initializing Passive Aggressive Regressor
2023-01-05 20:54:00,343:INFO:Total runtime is 0.14763437906901042 minutes
2023-01-05 20:54:00,346:INFO:SubProcess create_model() called ==================================
2023-01-05 20:54:00,347:INFO:Initializing create_model()
2023-01-05 20:54:00,347:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A5A013BA90>, estimator=par, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A5AC098640>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:54:00,347:INFO:Checking exceptions
2023-01-05 20:54:00,347:INFO:Importing libraries
2023-01-05 20:54:00,347:INFO:Copying training dataset
2023-01-05 20:54:00,357:INFO:Defining folds
2023-01-05 20:54:00,357:INFO:Declaring metric variables
2023-01-05 20:54:00,361:INFO:Importing untrained model
2023-01-05 20:54:00,365:INFO:Passive Aggressive Regressor Imported successfully
2023-01-05 20:54:00,373:INFO:Starting cross validation
2023-01-05 20:54:00,374:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:54:00,687:INFO:Calculating mean and std
2023-01-05 20:54:00,689:INFO:Creating metrics dataframe
2023-01-05 20:54:00,692:INFO:Uploading results into container
2023-01-05 20:54:00,692:INFO:Uploading model into container now
2023-01-05 20:54:00,693:INFO:_master_model_container: 9
2023-01-05 20:54:00,693:INFO:_display_container: 2
2023-01-05 20:54:00,693:INFO:PassiveAggressiveRegressor(random_state=123)
2023-01-05 20:54:00,693:INFO:create_model() successfully completed......................................
2023-01-05 20:54:00,802:INFO:SubProcess create_model() end ==================================
2023-01-05 20:54:00,802:INFO:Creating metrics dataframe
2023-01-05 20:54:00,814:INFO:Initializing Huber Regressor
2023-01-05 20:54:00,814:INFO:Total runtime is 0.1554931402206421 minutes
2023-01-05 20:54:00,818:INFO:SubProcess create_model() called ==================================
2023-01-05 20:54:00,819:INFO:Initializing create_model()
2023-01-05 20:54:00,819:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A5A013BA90>, estimator=huber, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A5AC098640>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:54:00,819:INFO:Checking exceptions
2023-01-05 20:54:00,819:INFO:Importing libraries
2023-01-05 20:54:00,819:INFO:Copying training dataset
2023-01-05 20:54:00,828:INFO:Defining folds
2023-01-05 20:54:00,828:INFO:Declaring metric variables
2023-01-05 20:54:00,832:INFO:Importing untrained model
2023-01-05 20:54:00,836:INFO:Huber Regressor Imported successfully
2023-01-05 20:54:00,844:INFO:Starting cross validation
2023-01-05 20:54:00,846:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:54:01,016:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-05 20:54:01,083:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-05 20:54:01,194:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-05 20:54:01,290:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-05 20:54:01,468:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-05 20:54:01,600:INFO:Calculating mean and std
2023-01-05 20:54:01,604:INFO:Creating metrics dataframe
2023-01-05 20:54:01,609:INFO:Uploading results into container
2023-01-05 20:54:01,609:INFO:Uploading model into container now
2023-01-05 20:54:01,610:INFO:_master_model_container: 10
2023-01-05 20:54:01,610:INFO:_display_container: 2
2023-01-05 20:54:01,610:INFO:HuberRegressor()
2023-01-05 20:54:01,610:INFO:create_model() successfully completed......................................
2023-01-05 20:54:01,716:INFO:SubProcess create_model() end ==================================
2023-01-05 20:54:01,716:INFO:Creating metrics dataframe
2023-01-05 20:54:01,728:INFO:Initializing K Neighbors Regressor
2023-01-05 20:54:01,728:INFO:Total runtime is 0.17072649796803793 minutes
2023-01-05 20:54:01,732:INFO:SubProcess create_model() called ==================================
2023-01-05 20:54:01,732:INFO:Initializing create_model()
2023-01-05 20:54:01,732:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A5A013BA90>, estimator=knn, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A5AC098640>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:54:01,732:INFO:Checking exceptions
2023-01-05 20:54:01,733:INFO:Importing libraries
2023-01-05 20:54:01,733:INFO:Copying training dataset
2023-01-05 20:54:01,743:INFO:Defining folds
2023-01-05 20:54:01,743:INFO:Declaring metric variables
2023-01-05 20:54:01,747:INFO:Importing untrained model
2023-01-05 20:54:01,751:INFO:K Neighbors Regressor Imported successfully
2023-01-05 20:54:01,758:INFO:Starting cross validation
2023-01-05 20:54:01,759:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:54:02,391:INFO:Calculating mean and std
2023-01-05 20:54:02,393:INFO:Creating metrics dataframe
2023-01-05 20:54:02,396:INFO:Uploading results into container
2023-01-05 20:54:02,396:INFO:Uploading model into container now
2023-01-05 20:54:02,397:INFO:_master_model_container: 11
2023-01-05 20:54:02,397:INFO:_display_container: 2
2023-01-05 20:54:02,397:INFO:KNeighborsRegressor(n_jobs=-1)
2023-01-05 20:54:02,397:INFO:create_model() successfully completed......................................
2023-01-05 20:54:02,493:INFO:SubProcess create_model() end ==================================
2023-01-05 20:54:02,493:INFO:Creating metrics dataframe
2023-01-05 20:54:02,505:INFO:Initializing Decision Tree Regressor
2023-01-05 20:54:02,505:INFO:Total runtime is 0.18368171453475954 minutes
2023-01-05 20:54:02,509:INFO:SubProcess create_model() called ==================================
2023-01-05 20:54:02,510:INFO:Initializing create_model()
2023-01-05 20:54:02,510:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A5A013BA90>, estimator=dt, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A5AC098640>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:54:02,510:INFO:Checking exceptions
2023-01-05 20:54:02,510:INFO:Importing libraries
2023-01-05 20:54:02,510:INFO:Copying training dataset
2023-01-05 20:54:02,520:INFO:Defining folds
2023-01-05 20:54:02,520:INFO:Declaring metric variables
2023-01-05 20:54:02,525:INFO:Importing untrained model
2023-01-05 20:54:02,529:INFO:Decision Tree Regressor Imported successfully
2023-01-05 20:54:02,537:INFO:Starting cross validation
2023-01-05 20:54:02,538:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:54:03,018:INFO:Calculating mean and std
2023-01-05 20:54:03,020:INFO:Creating metrics dataframe
2023-01-05 20:54:03,023:INFO:Uploading results into container
2023-01-05 20:54:03,024:INFO:Uploading model into container now
2023-01-05 20:54:03,024:INFO:_master_model_container: 12
2023-01-05 20:54:03,024:INFO:_display_container: 2
2023-01-05 20:54:03,024:INFO:DecisionTreeRegressor(random_state=123)
2023-01-05 20:54:03,024:INFO:create_model() successfully completed......................................
2023-01-05 20:54:03,116:INFO:SubProcess create_model() end ==================================
2023-01-05 20:54:03,116:INFO:Creating metrics dataframe
2023-01-05 20:54:03,129:INFO:Initializing Random Forest Regressor
2023-01-05 20:54:03,129:INFO:Total runtime is 0.19407700300216676 minutes
2023-01-05 20:54:03,133:INFO:SubProcess create_model() called ==================================
2023-01-05 20:54:03,133:INFO:Initializing create_model()
2023-01-05 20:54:03,134:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A5A013BA90>, estimator=rf, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A5AC098640>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:54:03,134:INFO:Checking exceptions
2023-01-05 20:54:03,134:INFO:Importing libraries
2023-01-05 20:54:03,134:INFO:Copying training dataset
2023-01-05 20:54:03,143:INFO:Defining folds
2023-01-05 20:54:03,143:INFO:Declaring metric variables
2023-01-05 20:54:03,148:INFO:Importing untrained model
2023-01-05 20:54:03,152:INFO:Random Forest Regressor Imported successfully
2023-01-05 20:54:03,159:INFO:Starting cross validation
2023-01-05 20:54:03,161:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:54:13,550:INFO:Calculating mean and std
2023-01-05 20:54:13,552:INFO:Creating metrics dataframe
2023-01-05 20:54:13,556:INFO:Uploading results into container
2023-01-05 20:54:13,556:INFO:Uploading model into container now
2023-01-05 20:54:13,557:INFO:_master_model_container: 13
2023-01-05 20:54:13,557:INFO:_display_container: 2
2023-01-05 20:54:13,557:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-01-05 20:54:13,558:INFO:create_model() successfully completed......................................
2023-01-05 20:54:13,655:INFO:SubProcess create_model() end ==================================
2023-01-05 20:54:13,655:INFO:Creating metrics dataframe
2023-01-05 20:54:13,668:INFO:Initializing Extra Trees Regressor
2023-01-05 20:54:13,668:INFO:Total runtime is 0.3697269956270854 minutes
2023-01-05 20:54:13,672:INFO:SubProcess create_model() called ==================================
2023-01-05 20:54:13,672:INFO:Initializing create_model()
2023-01-05 20:54:13,672:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A5A013BA90>, estimator=et, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A5AC098640>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:54:13,672:INFO:Checking exceptions
2023-01-05 20:54:13,673:INFO:Importing libraries
2023-01-05 20:54:13,673:INFO:Copying training dataset
2023-01-05 20:54:13,682:INFO:Defining folds
2023-01-05 20:54:13,683:INFO:Declaring metric variables
2023-01-05 20:54:13,687:INFO:Importing untrained model
2023-01-05 20:54:13,692:INFO:Extra Trees Regressor Imported successfully
2023-01-05 20:54:13,700:INFO:Starting cross validation
2023-01-05 20:54:13,701:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:54:19,511:INFO:Calculating mean and std
2023-01-05 20:54:19,513:INFO:Creating metrics dataframe
2023-01-05 20:54:19,518:INFO:Uploading results into container
2023-01-05 20:54:19,518:INFO:Uploading model into container now
2023-01-05 20:54:19,519:INFO:_master_model_container: 14
2023-01-05 20:54:19,519:INFO:_display_container: 2
2023-01-05 20:54:19,519:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-01-05 20:54:19,519:INFO:create_model() successfully completed......................................
2023-01-05 20:54:19,630:INFO:SubProcess create_model() end ==================================
2023-01-05 20:54:19,630:INFO:Creating metrics dataframe
2023-01-05 20:54:19,643:INFO:Initializing AdaBoost Regressor
2023-01-05 20:54:19,643:INFO:Total runtime is 0.46931033134460454 minutes
2023-01-05 20:54:19,647:INFO:SubProcess create_model() called ==================================
2023-01-05 20:54:19,647:INFO:Initializing create_model()
2023-01-05 20:54:19,647:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A5A013BA90>, estimator=ada, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A5AC098640>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:54:19,647:INFO:Checking exceptions
2023-01-05 20:54:19,647:INFO:Importing libraries
2023-01-05 20:54:19,648:INFO:Copying training dataset
2023-01-05 20:54:19,657:INFO:Defining folds
2023-01-05 20:54:19,657:INFO:Declaring metric variables
2023-01-05 20:54:19,661:INFO:Importing untrained model
2023-01-05 20:54:19,666:INFO:AdaBoost Regressor Imported successfully
2023-01-05 20:54:19,672:INFO:Starting cross validation
2023-01-05 20:54:19,674:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:54:22,004:INFO:Calculating mean and std
2023-01-05 20:54:22,006:INFO:Creating metrics dataframe
2023-01-05 20:54:22,010:INFO:Uploading results into container
2023-01-05 20:54:22,011:INFO:Uploading model into container now
2023-01-05 20:54:22,011:INFO:_master_model_container: 15
2023-01-05 20:54:22,011:INFO:_display_container: 2
2023-01-05 20:54:22,012:INFO:AdaBoostRegressor(random_state=123)
2023-01-05 20:54:22,012:INFO:create_model() successfully completed......................................
2023-01-05 20:54:22,116:INFO:SubProcess create_model() end ==================================
2023-01-05 20:54:22,117:INFO:Creating metrics dataframe
2023-01-05 20:54:22,129:INFO:Initializing Gradient Boosting Regressor
2023-01-05 20:54:22,129:INFO:Total runtime is 0.5107436617215475 minutes
2023-01-05 20:54:22,133:INFO:SubProcess create_model() called ==================================
2023-01-05 20:54:22,133:INFO:Initializing create_model()
2023-01-05 20:54:22,133:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A5A013BA90>, estimator=gbr, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A5AC098640>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:54:22,133:INFO:Checking exceptions
2023-01-05 20:54:22,133:INFO:Importing libraries
2023-01-05 20:54:22,134:INFO:Copying training dataset
2023-01-05 20:54:22,143:INFO:Defining folds
2023-01-05 20:54:22,143:INFO:Declaring metric variables
2023-01-05 20:54:22,147:INFO:Importing untrained model
2023-01-05 20:54:22,151:INFO:Gradient Boosting Regressor Imported successfully
2023-01-05 20:54:22,159:INFO:Starting cross validation
2023-01-05 20:54:22,160:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:54:27,928:INFO:Calculating mean and std
2023-01-05 20:54:27,930:INFO:Creating metrics dataframe
2023-01-05 20:54:27,933:INFO:Uploading results into container
2023-01-05 20:54:27,934:INFO:Uploading model into container now
2023-01-05 20:54:27,934:INFO:_master_model_container: 16
2023-01-05 20:54:27,934:INFO:_display_container: 2
2023-01-05 20:54:27,935:INFO:GradientBoostingRegressor(random_state=123)
2023-01-05 20:54:27,935:INFO:create_model() successfully completed......................................
2023-01-05 20:54:28,042:INFO:SubProcess create_model() end ==================================
2023-01-05 20:54:28,042:INFO:Creating metrics dataframe
2023-01-05 20:54:28,056:INFO:Initializing Light Gradient Boosting Machine
2023-01-05 20:54:28,056:INFO:Total runtime is 0.6095270236333212 minutes
2023-01-05 20:54:28,060:INFO:SubProcess create_model() called ==================================
2023-01-05 20:54:28,060:INFO:Initializing create_model()
2023-01-05 20:54:28,061:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A5A013BA90>, estimator=lightgbm, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A5AC098640>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:54:28,061:INFO:Checking exceptions
2023-01-05 20:54:28,061:INFO:Importing libraries
2023-01-05 20:54:28,061:INFO:Copying training dataset
2023-01-05 20:54:28,071:INFO:Defining folds
2023-01-05 20:54:28,071:INFO:Declaring metric variables
2023-01-05 20:54:28,076:INFO:Importing untrained model
2023-01-05 20:54:28,080:INFO:Light Gradient Boosting Machine Imported successfully
2023-01-05 20:54:28,088:INFO:Starting cross validation
2023-01-05 20:54:28,089:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:54:30,649:INFO:Calculating mean and std
2023-01-05 20:54:30,651:INFO:Creating metrics dataframe
2023-01-05 20:54:30,655:INFO:Uploading results into container
2023-01-05 20:54:30,656:INFO:Uploading model into container now
2023-01-05 20:54:30,656:INFO:_master_model_container: 17
2023-01-05 20:54:30,657:INFO:_display_container: 2
2023-01-05 20:54:30,657:INFO:LGBMRegressor(random_state=123)
2023-01-05 20:54:30,657:INFO:create_model() successfully completed......................................
2023-01-05 20:54:30,765:INFO:SubProcess create_model() end ==================================
2023-01-05 20:54:30,766:INFO:Creating metrics dataframe
2023-01-05 20:54:30,779:INFO:Initializing Dummy Regressor
2023-01-05 20:54:30,779:INFO:Total runtime is 0.6549103260040284 minutes
2023-01-05 20:54:30,782:INFO:SubProcess create_model() called ==================================
2023-01-05 20:54:30,782:INFO:Initializing create_model()
2023-01-05 20:54:30,782:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A5A013BA90>, estimator=dummy, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A5AC098640>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:54:30,783:INFO:Checking exceptions
2023-01-05 20:54:30,783:INFO:Importing libraries
2023-01-05 20:54:30,783:INFO:Copying training dataset
2023-01-05 20:54:30,792:INFO:Defining folds
2023-01-05 20:54:30,792:INFO:Declaring metric variables
2023-01-05 20:54:30,796:INFO:Importing untrained model
2023-01-05 20:54:30,800:INFO:Dummy Regressor Imported successfully
2023-01-05 20:54:30,807:INFO:Starting cross validation
2023-01-05 20:54:30,808:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:54:31,059:INFO:Calculating mean and std
2023-01-05 20:54:31,061:INFO:Creating metrics dataframe
2023-01-05 20:54:31,064:INFO:Uploading results into container
2023-01-05 20:54:31,064:INFO:Uploading model into container now
2023-01-05 20:54:31,065:INFO:_master_model_container: 18
2023-01-05 20:54:31,065:INFO:_display_container: 2
2023-01-05 20:54:31,065:INFO:DummyRegressor()
2023-01-05 20:54:31,065:INFO:create_model() successfully completed......................................
2023-01-05 20:54:31,159:INFO:SubProcess create_model() end ==================================
2023-01-05 20:54:31,159:INFO:Creating metrics dataframe
2023-01-05 20:54:31,183:INFO:Initializing create_model()
2023-01-05 20:54:31,183:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A5A013BA90>, estimator=LGBMRegressor(random_state=123), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:54:31,184:INFO:Checking exceptions
2023-01-05 20:54:31,186:INFO:Importing libraries
2023-01-05 20:54:31,186:INFO:Copying training dataset
2023-01-05 20:54:31,194:INFO:Defining folds
2023-01-05 20:54:31,194:INFO:Declaring metric variables
2023-01-05 20:54:31,195:INFO:Importing untrained model
2023-01-05 20:54:31,195:INFO:Declaring custom model
2023-01-05 20:54:31,195:INFO:Light Gradient Boosting Machine Imported successfully
2023-01-05 20:54:31,196:INFO:Cross validation set to False
2023-01-05 20:54:31,196:INFO:Fitting Model
2023-01-05 20:54:31,451:INFO:LGBMRegressor(random_state=123)
2023-01-05 20:54:31,451:INFO:create_model() successfully completed......................................
2023-01-05 20:54:31,585:INFO:_master_model_container: 18
2023-01-05 20:54:31,585:INFO:_display_container: 2
2023-01-05 20:54:31,586:INFO:LGBMRegressor(random_state=123)
2023-01-05 20:54:31,586:INFO:compare_models() successfully completed......................................
2023-01-05 20:54:31,587:INFO:Initializing tune_model()
2023-01-05 20:54:31,587:INFO:tune_model(estimator=LGBMRegressor(random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=MAE, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A5A013BA90>)
2023-01-05 20:54:31,587:INFO:Checking exceptions
2023-01-05 20:54:31,618:INFO:Copying training dataset
2023-01-05 20:54:31,627:INFO:Checking base model
2023-01-05 20:54:31,627:INFO:Base model : Light Gradient Boosting Machine
2023-01-05 20:54:31,631:INFO:Declaring metric variables
2023-01-05 20:54:31,634:INFO:Defining Hyperparameters
2023-01-05 20:54:31,733:INFO:Tuning with n_jobs=-1
2023-01-05 20:54:31,733:INFO:Initializing RandomizedSearchCV
2023-01-05 20:54:38,888:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2023-01-05 20:54:38,890:INFO:Hyperparameter search completed
2023-01-05 20:54:38,890:INFO:SubProcess create_model() called ==================================
2023-01-05 20:54:38,891:INFO:Initializing create_model()
2023-01-05 20:54:38,891:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A5A013BA90>, estimator=LGBMRegressor(random_state=123), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A5A0024430>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2023-01-05 20:54:38,891:INFO:Checking exceptions
2023-01-05 20:54:38,891:INFO:Importing libraries
2023-01-05 20:54:38,891:INFO:Copying training dataset
2023-01-05 20:54:38,900:INFO:Defining folds
2023-01-05 20:54:38,900:INFO:Declaring metric variables
2023-01-05 20:54:38,904:INFO:Importing untrained model
2023-01-05 20:54:38,904:INFO:Declaring custom model
2023-01-05 20:54:38,909:INFO:Light Gradient Boosting Machine Imported successfully
2023-01-05 20:54:38,916:INFO:Starting cross validation
2023-01-05 20:54:38,918:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:54:40,694:INFO:Calculating mean and std
2023-01-05 20:54:40,696:INFO:Creating metrics dataframe
2023-01-05 20:54:40,702:INFO:Finalizing model
2023-01-05 20:54:41,800:INFO:Uploading results into container
2023-01-05 20:54:41,801:INFO:Uploading model into container now
2023-01-05 20:54:41,802:INFO:_master_model_container: 19
2023-01-05 20:54:41,802:INFO:_display_container: 3
2023-01-05 20:54:41,802:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              num_leaves=70, random_state=123, reg_alpha=2, reg_lambda=3)
2023-01-05 20:54:41,803:INFO:create_model() successfully completed......................................
2023-01-05 20:54:41,900:INFO:SubProcess create_model() end ==================================
2023-01-05 20:54:41,900:INFO:choose_better activated
2023-01-05 20:54:41,903:INFO:SubProcess create_model() called ==================================
2023-01-05 20:54:41,904:INFO:Initializing create_model()
2023-01-05 20:54:41,904:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A5A013BA90>, estimator=LGBMRegressor(random_state=123), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:54:41,904:INFO:Checking exceptions
2023-01-05 20:54:41,906:INFO:Importing libraries
2023-01-05 20:54:41,906:INFO:Copying training dataset
2023-01-05 20:54:41,914:INFO:Defining folds
2023-01-05 20:54:41,914:INFO:Declaring metric variables
2023-01-05 20:54:41,914:INFO:Importing untrained model
2023-01-05 20:54:41,914:INFO:Declaring custom model
2023-01-05 20:54:41,915:INFO:Light Gradient Boosting Machine Imported successfully
2023-01-05 20:54:41,915:INFO:Starting cross validation
2023-01-05 20:54:41,916:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:54:43,203:INFO:Calculating mean and std
2023-01-05 20:54:43,204:INFO:Creating metrics dataframe
2023-01-05 20:54:43,206:INFO:Finalizing model
2023-01-05 20:54:43,588:INFO:Uploading results into container
2023-01-05 20:54:43,589:INFO:Uploading model into container now
2023-01-05 20:54:43,589:INFO:_master_model_container: 20
2023-01-05 20:54:43,589:INFO:_display_container: 4
2023-01-05 20:54:43,589:INFO:LGBMRegressor(random_state=123)
2023-01-05 20:54:43,589:INFO:create_model() successfully completed......................................
2023-01-05 20:54:43,686:INFO:SubProcess create_model() end ==================================
2023-01-05 20:54:43,686:INFO:LGBMRegressor(random_state=123) result for MAE is 2.201
2023-01-05 20:54:43,687:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              num_leaves=70, random_state=123, reg_alpha=2, reg_lambda=3) result for MAE is 2.4987
2023-01-05 20:54:43,687:INFO:LGBMRegressor(random_state=123) is best model
2023-01-05 20:54:43,688:INFO:choose_better completed
2023-01-05 20:54:43,688:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-01-05 20:54:43,695:INFO:_master_model_container: 20
2023-01-05 20:54:43,696:INFO:_display_container: 3
2023-01-05 20:54:43,696:INFO:LGBMRegressor(random_state=123)
2023-01-05 20:54:43,696:INFO:tune_model() successfully completed......................................
2023-01-05 20:54:43,793:INFO:Initializing plot_model()
2023-01-05 20:54:43,793:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LGBMRegressor(random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A5A013BA90>, system=True)
2023-01-05 20:54:43,794:INFO:Checking exceptions
2023-01-05 20:54:43,800:INFO:Preloading libraries
2023-01-05 20:54:43,808:INFO:Copying training dataset
2023-01-05 20:54:43,808:INFO:Plot type: error
2023-01-05 20:54:43,978:INFO:Fitting Model
2023-01-05 20:54:43,979:INFO:Scoring test/hold-out set
2023-01-05 20:54:44,413:INFO:Visual Rendered Successfully
2023-01-05 20:54:44,523:INFO:plot_model() successfully completed......................................
2023-01-05 20:54:44,523:INFO:Initializing predict_model()
2023-01-05 20:54:44,524:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A5A013BA90>, estimator=LGBMRegressor(random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000002A5ABDF2DC0>)
2023-01-05 20:54:44,524:INFO:Checking exceptions
2023-01-05 20:54:44,524:INFO:Preloading libraries
2023-01-05 20:54:44,679:INFO:Initializing finalize_model()
2023-01-05 20:54:44,679:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A5A013BA90>, estimator=LGBMRegressor(random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-01-05 20:54:44,679:INFO:Finalizing LGBMRegressor(random_state=123)
2023-01-05 20:54:44,687:INFO:Initializing create_model()
2023-01-05 20:54:44,687:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A5A013BA90>, estimator=LGBMRegressor(random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-01-05 20:54:44,687:INFO:Checking exceptions
2023-01-05 20:54:44,689:INFO:Importing libraries
2023-01-05 20:54:44,689:INFO:Copying training dataset
2023-01-05 20:54:44,689:INFO:Defining folds
2023-01-05 20:54:44,690:INFO:Declaring metric variables
2023-01-05 20:54:44,690:INFO:Importing untrained model
2023-01-05 20:54:44,690:INFO:Declaring custom model
2023-01-05 20:54:44,691:INFO:Light Gradient Boosting Machine Imported successfully
2023-01-05 20:54:44,691:INFO:Cross validation set to False
2023-01-05 20:54:44,691:INFO:Fitting Model
2023-01-05 20:54:45,057:INFO:Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator', LGBMRegressor(random_state=123))])
2023-01-05 20:54:45,057:INFO:create_model() successfully completed......................................
2023-01-05 20:54:45,157:INFO:_master_model_container: 20
2023-01-05 20:54:45,157:INFO:_display_container: 4
2023-01-05 20:54:45,164:INFO:Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator', LGBMRegressor(random_state=123))])
2023-01-05 20:54:45,164:INFO:finalize_model() successfully completed......................................
2023-01-05 20:54:45,271:INFO:Initializing predict_model()
2023-01-05 20:54:45,272:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A5A013BA90>, estimator=Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator', LGBMRegressor(random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000002A5ABDF2DC0>)
2023-01-05 20:54:45,272:INFO:Checking exceptions
2023-01-05 20:54:45,272:INFO:Preloading libraries
2023-01-05 20:54:45,274:INFO:Set up data.
2023-01-05 20:54:45,288:INFO:Set up index.
2023-01-05 20:54:46,017:INFO:Initializing evaluate_model()
2023-01-05 20:54:46,018:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A5A013BA90>, estimator=Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator', LGBMRegressor(random_state=123))]), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None, use_train_data=False)
2023-01-05 20:54:46,050:INFO:Initializing plot_model()
2023-01-05 20:54:46,050:INFO:plot_model(plot=pipeline, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), use_train_data=False, verbose=False, display=None, display_format=None, estimator=Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator', LGBMRegressor(random_state=123))]), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A5A013BA90>, system=True)
2023-01-05 20:54:46,050:INFO:Checking exceptions
2023-01-05 20:54:46,056:INFO:Preloading libraries
2023-01-05 20:54:46,063:INFO:Copying training dataset
2023-01-05 20:54:46,063:INFO:Plot type: pipeline
2023-01-05 20:54:46,182:INFO:Visual Rendered Successfully
2023-01-05 20:54:46,291:INFO:plot_model() successfully completed......................................
2023-01-05 20:54:46,305:INFO:Initializing save_model()
2023-01-05 20:54:46,305:INFO:save_model(model=Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator', LGBMRegressor(random_state=123))]), model_name=c:\Users\Kodotautas\Desktop\Data_science\7_TIME_SERIES_FORECAST_AUTOML/models/final_model.pkl, prep_pipe_=Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-01-05 20:54:46,305:INFO:Adding model into prep_pipe
2023-01-05 20:54:46,312:WARNING:Only Model saved as it was a pipeline.
2023-01-05 20:54:46,320:INFO:c:\Users\Kodotautas\Desktop\Data_science\7_TIME_SERIES_FORECAST_AUTOML/models/final_model.pkl.pkl saved in current working directory
2023-01-05 20:54:46,327:INFO:Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator', LGBMRegressor(random_state=123))])
2023-01-05 20:54:46,327:INFO:save_model() successfully completed......................................
2023-01-05 20:56:48,006:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-01-05 20:56:48,006:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-01-05 20:56:48,007:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-01-05 20:56:48,007:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-01-05 20:56:48,636:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-01-05 20:56:49,029:INFO:PyCaret RegressionExperiment
2023-01-05 20:56:49,029:INFO:Logging name: reg-default-name
2023-01-05 20:56:49,029:INFO:ML Usecase: MLUsecase.REGRESSION
2023-01-05 20:56:49,029:INFO:version 3.0.0.rc6
2023-01-05 20:56:49,029:INFO:Initializing setup()
2023-01-05 20:56:49,029:INFO:self.USI: 8c51
2023-01-05 20:56:49,029:INFO:self._variable_keys: {'n_jobs_param', '_ml_usecase', 'memory', 'seed', 'fold_shuffle_param', 'X_test', 'html_param', 'y_test', 'y', '_available_plots', 'USI', 'exp_id', 'target_param', 'gpu_n_jobs_param', 'X', 'exp_name_log', 'gpu_param', 'fold_groups_param', 'transform_target_param', 'y_train', 'log_plots_param', 'data', 'X_train', 'pipeline', 'logging_param', 'idx', 'fold_generator'}
2023-01-05 20:56:49,030:INFO:Checking environment
2023-01-05 20:56:49,030:INFO:python_version: 3.9.13
2023-01-05 20:56:49,030:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-01-05 20:56:49,030:INFO:machine: AMD64
2023-01-05 20:56:49,030:INFO:platform: Windows-10-10.0.19044-SP0
2023-01-05 20:56:49,030:INFO:Memory: svmem(total=17114804224, available=9107587072, percent=46.8, used=8007217152, free=9107587072)
2023-01-05 20:56:49,030:INFO:Physical Core: 4
2023-01-05 20:56:49,030:INFO:Logical Core: 4
2023-01-05 20:56:49,030:INFO:Checking libraries
2023-01-05 20:56:49,030:INFO:System:
2023-01-05 20:56:49,030:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-01-05 20:56:49,030:INFO:executable: c:\Users\Kodotautas\anaconda3\python.exe
2023-01-05 20:56:49,030:INFO:   machine: Windows-10-10.0.19044-SP0
2023-01-05 20:56:49,030:INFO:PyCaret required dependencies:
2023-01-05 20:56:49,030:INFO:                 pip: 22.2.2
2023-01-05 20:56:49,031:INFO:          setuptools: 63.4.1
2023-01-05 20:56:49,032:INFO:             pycaret: 3.0.0rc6
2023-01-05 20:56:49,032:INFO:             IPython: 7.31.1
2023-01-05 20:56:49,032:INFO:          ipywidgets: 7.6.5
2023-01-05 20:56:49,032:INFO:                tqdm: 4.64.1
2023-01-05 20:56:49,032:INFO:               numpy: 1.21.5
2023-01-05 20:56:49,032:INFO:              pandas: 1.4.4
2023-01-05 20:56:49,032:INFO:              jinja2: 2.11.3
2023-01-05 20:56:49,032:INFO:               scipy: 1.9.1
2023-01-05 20:56:49,032:INFO:              joblib: 1.2.0
2023-01-05 20:56:49,032:INFO:             sklearn: 1.0.2
2023-01-05 20:56:49,032:INFO:                pyod: 1.0.7
2023-01-05 20:56:49,033:INFO:            imblearn: 0.10.1
2023-01-05 20:56:49,033:INFO:   category_encoders: 2.5.1.post0
2023-01-05 20:56:49,033:INFO:            lightgbm: 3.3.3
2023-01-05 20:56:49,033:INFO:               numba: 0.55.1
2023-01-05 20:56:49,033:INFO:            requests: 2.28.1
2023-01-05 20:56:49,033:INFO:          matplotlib: 3.5.2
2023-01-05 20:56:49,033:INFO:          scikitplot: 0.3.7
2023-01-05 20:56:49,033:INFO:         yellowbrick: 1.5
2023-01-05 20:56:49,033:INFO:              plotly: 5.9.0
2023-01-05 20:56:49,033:INFO:             kaleido: 0.2.1
2023-01-05 20:56:49,033:INFO:         statsmodels: 0.13.2
2023-01-05 20:56:49,033:INFO:              sktime: 0.14.1
2023-01-05 20:56:49,033:INFO:               tbats: 1.1.2
2023-01-05 20:56:49,033:INFO:            pmdarima: 2.0.2
2023-01-05 20:56:49,033:INFO:              psutil: 5.9.0
2023-01-05 20:56:49,033:INFO:PyCaret optional dependencies:
2023-01-05 20:56:49,387:INFO:                shap: 0.41.0
2023-01-05 20:56:49,387:INFO:           interpret: Not installed
2023-01-05 20:56:49,387:INFO:                umap: Not installed
2023-01-05 20:56:49,388:INFO:    pandas_profiling: Not installed
2023-01-05 20:56:49,388:INFO:  explainerdashboard: Not installed
2023-01-05 20:56:49,388:INFO:             autoviz: Not installed
2023-01-05 20:56:49,388:INFO:           fairlearn: Not installed
2023-01-05 20:56:49,388:INFO:             xgboost: Not installed
2023-01-05 20:56:49,388:INFO:            catboost: Not installed
2023-01-05 20:56:49,388:INFO:              kmodes: Not installed
2023-01-05 20:56:49,388:INFO:             mlxtend: Not installed
2023-01-05 20:56:49,388:INFO:       statsforecast: Not installed
2023-01-05 20:56:49,388:INFO:        tune_sklearn: 0.4.3
2023-01-05 20:56:49,388:INFO:                 ray: 2.0.0
2023-01-05 20:56:49,388:INFO:            hyperopt: 0.2.7
2023-01-05 20:56:49,388:INFO:              optuna: 3.0.1
2023-01-05 20:56:49,388:INFO:               skopt: 0.9.0
2023-01-05 20:56:49,388:INFO:              mlflow: Not installed
2023-01-05 20:56:49,388:INFO:              gradio: Not installed
2023-01-05 20:56:49,388:INFO:             fastapi: 0.88.0
2023-01-05 20:56:49,388:INFO:             uvicorn: 0.20.0
2023-01-05 20:56:49,388:INFO:              m2cgen: Not installed
2023-01-05 20:56:49,388:INFO:           evidently: Not installed
2023-01-05 20:56:49,388:INFO:                nltk: 3.7
2023-01-05 20:56:49,388:INFO:            pyLDAvis: Not installed
2023-01-05 20:56:49,388:INFO:              gensim: 4.1.2
2023-01-05 20:56:49,388:INFO:               spacy: 3.4.2
2023-01-05 20:56:49,389:INFO:           wordcloud: Not installed
2023-01-05 20:56:49,389:INFO:            textblob: Not installed
2023-01-05 20:56:49,389:INFO:               fugue: Not installed
2023-01-05 20:56:49,389:INFO:           streamlit: Not installed
2023-01-05 20:56:49,389:INFO:             prophet: Not installed
2023-01-05 20:56:49,389:INFO:None
2023-01-05 20:56:49,389:INFO:Set up data.
2023-01-05 20:56:49,409:INFO:Set up train/test split.
2023-01-05 20:56:49,421:INFO:Set up index.
2023-01-05 20:56:49,424:INFO:Set up folding strategy.
2023-01-05 20:56:49,424:INFO:Assigning column types.
2023-01-05 20:56:49,434:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-01-05 20:56:49,434:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-01-05 20:56:49,439:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-05 20:56:49,444:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-05 20:56:49,511:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-05 20:56:49,560:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-05 20:56:49,561:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:56:49,695:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:56:49,695:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-01-05 20:56:49,701:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-05 20:56:49,705:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-05 20:56:49,776:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-05 20:56:49,824:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-05 20:56:49,824:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:56:49,825:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:56:49,825:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-01-05 20:56:49,830:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-05 20:56:49,835:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-05 20:56:49,901:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-05 20:56:49,947:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-05 20:56:49,949:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:56:49,949:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:56:49,954:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-05 20:56:49,959:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-05 20:56:50,029:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-05 20:56:50,091:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-05 20:56:50,091:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:56:50,092:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:56:50,092:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-01-05 20:56:50,102:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-05 20:56:50,168:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-05 20:56:50,215:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-05 20:56:50,216:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:56:50,216:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:56:50,226:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-05 20:56:50,291:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-05 20:56:50,338:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-05 20:56:50,339:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:56:50,339:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:56:50,339:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-01-05 20:56:50,416:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-05 20:56:50,461:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-05 20:56:50,462:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:56:50,462:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:56:50,538:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-05 20:56:50,584:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-05 20:56:50,585:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:56:50,585:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:56:50,585:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-01-05 20:56:50,659:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-05 20:56:50,707:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:56:50,707:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:56:50,784:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-05 20:56:50,831:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:56:50,831:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:56:50,832:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-01-05 20:56:50,959:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:56:50,960:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:56:51,086:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:56:51,087:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:56:51,088:INFO:Preparing preprocessing pipeline...
2023-01-05 20:56:51,090:INFO:Set up simple imputation.
2023-01-05 20:56:51,090:INFO:Set up column transformation.
2023-01-05 20:56:51,090:INFO:Set up feature normalization.
2023-01-05 20:56:51,126:INFO:Finished creating preprocessing pipeline.
2023-01-05 20:56:51,133:INFO:Pipeline: Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2023-01-05 20:56:51,133:INFO:Creating final display dataframe.
2023-01-05 20:56:51,369:INFO:Setup _display_container:                Description             Value
0               Session id               123
1                   Target        b2b+b2c+vt
2              Target type        Regression
3               Data shape        (9930, 48)
4         Train data shape        (6951, 48)
5          Test data shape        (2979, 48)
6         Numeric features                 8
7               Preprocess              True
8          Imputation type            simple
9       Numeric imputation              mean
10  Categorical imputation              mode
11          Transformation              True
12   Transformation method       yeo-johnson
13               Normalize              True
14        Normalize method            zscore
15          Fold Generator   TimeSeriesSplit
16             Fold Number                 5
17                CPU Jobs                -1
18                 Use GPU             False
19          Log Experiment             False
20         Experiment Name  reg-default-name
21                     USI              8c51
2023-01-05 20:56:51,511:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:56:51,512:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:56:51,637:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:56:51,637:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 20:56:51,638:INFO:setup() successfully completed in 2.61s...............
2023-01-05 20:56:51,638:INFO:Initializing compare_models()
2023-01-05 20:56:51,638:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000027828EAF250>, include=None, fold=None, round=4, cross_validation=True, sort=MAE, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x0000027828EAF250>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'MAE', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-01-05 20:56:51,638:INFO:Checking exceptions
2023-01-05 20:56:51,643:INFO:Preparing display monitor
2023-01-05 20:56:51,684:INFO:Initializing Linear Regression
2023-01-05 20:56:51,684:INFO:Total runtime is 0.0 minutes
2023-01-05 20:56:51,688:INFO:SubProcess create_model() called ==================================
2023-01-05 20:56:51,689:INFO:Initializing create_model()
2023-01-05 20:56:51,689:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000027828EAF250>, estimator=lr, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027833BA9730>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:56:51,689:INFO:Checking exceptions
2023-01-05 20:56:51,689:INFO:Importing libraries
2023-01-05 20:56:51,689:INFO:Copying training dataset
2023-01-05 20:56:51,701:INFO:Defining folds
2023-01-05 20:56:51,701:INFO:Declaring metric variables
2023-01-05 20:56:51,708:INFO:Importing untrained model
2023-01-05 20:56:51,712:INFO:Linear Regression Imported successfully
2023-01-05 20:56:51,722:INFO:Starting cross validation
2023-01-05 20:56:51,729:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:56:57,255:INFO:Calculating mean and std
2023-01-05 20:56:57,258:INFO:Creating metrics dataframe
2023-01-05 20:56:57,264:INFO:Uploading results into container
2023-01-05 20:56:57,264:INFO:Uploading model into container now
2023-01-05 20:56:57,265:INFO:_master_model_container: 1
2023-01-05 20:56:57,265:INFO:_display_container: 2
2023-01-05 20:56:57,265:INFO:LinearRegression(n_jobs=-1)
2023-01-05 20:56:57,265:INFO:create_model() successfully completed......................................
2023-01-05 20:56:57,386:INFO:SubProcess create_model() end ==================================
2023-01-05 20:56:57,386:INFO:Creating metrics dataframe
2023-01-05 20:56:57,396:INFO:Initializing Lasso Regression
2023-01-05 20:56:57,396:INFO:Total runtime is 0.09519994258880615 minutes
2023-01-05 20:56:57,400:INFO:SubProcess create_model() called ==================================
2023-01-05 20:56:57,400:INFO:Initializing create_model()
2023-01-05 20:56:57,401:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000027828EAF250>, estimator=lasso, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027833BA9730>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:56:57,401:INFO:Checking exceptions
2023-01-05 20:56:57,401:INFO:Importing libraries
2023-01-05 20:56:57,401:INFO:Copying training dataset
2023-01-05 20:56:57,411:INFO:Defining folds
2023-01-05 20:56:57,411:INFO:Declaring metric variables
2023-01-05 20:56:57,418:INFO:Importing untrained model
2023-01-05 20:56:57,423:INFO:Lasso Regression Imported successfully
2023-01-05 20:56:57,431:INFO:Starting cross validation
2023-01-05 20:56:57,433:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:56:57,713:INFO:Calculating mean and std
2023-01-05 20:56:57,715:INFO:Creating metrics dataframe
2023-01-05 20:56:57,720:INFO:Uploading results into container
2023-01-05 20:56:57,721:INFO:Uploading model into container now
2023-01-05 20:56:57,721:INFO:_master_model_container: 2
2023-01-05 20:56:57,721:INFO:_display_container: 2
2023-01-05 20:56:57,721:INFO:Lasso(random_state=123)
2023-01-05 20:56:57,721:INFO:create_model() successfully completed......................................
2023-01-05 20:56:57,819:INFO:SubProcess create_model() end ==================================
2023-01-05 20:56:57,819:INFO:Creating metrics dataframe
2023-01-05 20:56:57,828:INFO:Initializing Ridge Regression
2023-01-05 20:56:57,828:INFO:Total runtime is 0.10239996115366617 minutes
2023-01-05 20:56:57,831:INFO:SubProcess create_model() called ==================================
2023-01-05 20:56:57,832:INFO:Initializing create_model()
2023-01-05 20:56:57,832:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000027828EAF250>, estimator=ridge, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027833BA9730>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:56:57,832:INFO:Checking exceptions
2023-01-05 20:56:57,832:INFO:Importing libraries
2023-01-05 20:56:57,832:INFO:Copying training dataset
2023-01-05 20:56:57,841:INFO:Defining folds
2023-01-05 20:56:57,841:INFO:Declaring metric variables
2023-01-05 20:56:57,846:INFO:Importing untrained model
2023-01-05 20:56:57,852:INFO:Ridge Regression Imported successfully
2023-01-05 20:56:57,860:INFO:Starting cross validation
2023-01-05 20:56:57,861:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:56:58,121:INFO:Calculating mean and std
2023-01-05 20:56:58,123:INFO:Creating metrics dataframe
2023-01-05 20:56:58,126:INFO:Uploading results into container
2023-01-05 20:56:58,126:INFO:Uploading model into container now
2023-01-05 20:56:58,127:INFO:_master_model_container: 3
2023-01-05 20:56:58,127:INFO:_display_container: 2
2023-01-05 20:56:58,127:INFO:Ridge(random_state=123)
2023-01-05 20:56:58,127:INFO:create_model() successfully completed......................................
2023-01-05 20:56:58,225:INFO:SubProcess create_model() end ==================================
2023-01-05 20:56:58,226:INFO:Creating metrics dataframe
2023-01-05 20:56:58,236:INFO:Initializing Elastic Net
2023-01-05 20:56:58,236:INFO:Total runtime is 0.10920518239339193 minutes
2023-01-05 20:56:58,239:INFO:SubProcess create_model() called ==================================
2023-01-05 20:56:58,240:INFO:Initializing create_model()
2023-01-05 20:56:58,240:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000027828EAF250>, estimator=en, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027833BA9730>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:56:58,240:INFO:Checking exceptions
2023-01-05 20:56:58,240:INFO:Importing libraries
2023-01-05 20:56:58,240:INFO:Copying training dataset
2023-01-05 20:56:58,249:INFO:Defining folds
2023-01-05 20:56:58,249:INFO:Declaring metric variables
2023-01-05 20:56:58,253:INFO:Importing untrained model
2023-01-05 20:56:58,257:INFO:Elastic Net Imported successfully
2023-01-05 20:56:58,266:INFO:Starting cross validation
2023-01-05 20:56:58,268:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:56:58,547:INFO:Calculating mean and std
2023-01-05 20:56:58,550:INFO:Creating metrics dataframe
2023-01-05 20:56:58,553:INFO:Uploading results into container
2023-01-05 20:56:58,554:INFO:Uploading model into container now
2023-01-05 20:56:58,554:INFO:_master_model_container: 4
2023-01-05 20:56:58,555:INFO:_display_container: 2
2023-01-05 20:56:58,555:INFO:ElasticNet(random_state=123)
2023-01-05 20:56:58,555:INFO:create_model() successfully completed......................................
2023-01-05 20:56:58,656:INFO:SubProcess create_model() end ==================================
2023-01-05 20:56:58,656:INFO:Creating metrics dataframe
2023-01-05 20:56:58,665:INFO:Initializing Least Angle Regression
2023-01-05 20:56:58,666:INFO:Total runtime is 0.11637477080027263 minutes
2023-01-05 20:56:58,669:INFO:SubProcess create_model() called ==================================
2023-01-05 20:56:58,670:INFO:Initializing create_model()
2023-01-05 20:56:58,670:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000027828EAF250>, estimator=lar, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027833BA9730>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:56:58,670:INFO:Checking exceptions
2023-01-05 20:56:58,670:INFO:Importing libraries
2023-01-05 20:56:58,670:INFO:Copying training dataset
2023-01-05 20:56:58,679:INFO:Defining folds
2023-01-05 20:56:58,679:INFO:Declaring metric variables
2023-01-05 20:56:58,683:INFO:Importing untrained model
2023-01-05 20:56:58,688:INFO:Least Angle Regression Imported successfully
2023-01-05 20:56:58,696:INFO:Starting cross validation
2023-01-05 20:56:58,697:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:56:58,771:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-05 20:56:58,773:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-05 20:56:58,776:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-05 20:56:58,782:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-05 20:56:58,839:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-05 20:56:58,968:INFO:Calculating mean and std
2023-01-05 20:56:58,970:INFO:Creating metrics dataframe
2023-01-05 20:56:58,973:INFO:Uploading results into container
2023-01-05 20:56:58,973:INFO:Uploading model into container now
2023-01-05 20:56:58,974:INFO:_master_model_container: 5
2023-01-05 20:56:58,974:INFO:_display_container: 2
2023-01-05 20:56:58,974:INFO:Lars(random_state=123)
2023-01-05 20:56:58,974:INFO:create_model() successfully completed......................................
2023-01-05 20:56:59,067:INFO:SubProcess create_model() end ==================================
2023-01-05 20:56:59,067:INFO:Creating metrics dataframe
2023-01-05 20:56:59,078:INFO:Initializing Lasso Least Angle Regression
2023-01-05 20:56:59,078:INFO:Total runtime is 0.1232455849647522 minutes
2023-01-05 20:56:59,082:INFO:SubProcess create_model() called ==================================
2023-01-05 20:56:59,082:INFO:Initializing create_model()
2023-01-05 20:56:59,083:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000027828EAF250>, estimator=llar, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027833BA9730>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:56:59,083:INFO:Checking exceptions
2023-01-05 20:56:59,083:INFO:Importing libraries
2023-01-05 20:56:59,083:INFO:Copying training dataset
2023-01-05 20:56:59,091:INFO:Defining folds
2023-01-05 20:56:59,092:INFO:Declaring metric variables
2023-01-05 20:56:59,097:INFO:Importing untrained model
2023-01-05 20:56:59,102:INFO:Lasso Least Angle Regression Imported successfully
2023-01-05 20:56:59,111:INFO:Starting cross validation
2023-01-05 20:56:59,112:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:56:59,183:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-05 20:56:59,187:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-05 20:56:59,190:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-05 20:56:59,193:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-05 20:56:59,238:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-05 20:56:59,373:INFO:Calculating mean and std
2023-01-05 20:56:59,375:INFO:Creating metrics dataframe
2023-01-05 20:56:59,378:INFO:Uploading results into container
2023-01-05 20:56:59,378:INFO:Uploading model into container now
2023-01-05 20:56:59,379:INFO:_master_model_container: 6
2023-01-05 20:56:59,379:INFO:_display_container: 2
2023-01-05 20:56:59,379:INFO:LassoLars(random_state=123)
2023-01-05 20:56:59,379:INFO:create_model() successfully completed......................................
2023-01-05 20:56:59,471:INFO:SubProcess create_model() end ==================================
2023-01-05 20:56:59,471:INFO:Creating metrics dataframe
2023-01-05 20:56:59,485:INFO:Initializing Orthogonal Matching Pursuit
2023-01-05 20:56:59,485:INFO:Total runtime is 0.1300188144048055 minutes
2023-01-05 20:56:59,489:INFO:SubProcess create_model() called ==================================
2023-01-05 20:56:59,489:INFO:Initializing create_model()
2023-01-05 20:56:59,489:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000027828EAF250>, estimator=omp, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027833BA9730>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:56:59,490:INFO:Checking exceptions
2023-01-05 20:56:59,490:INFO:Importing libraries
2023-01-05 20:56:59,490:INFO:Copying training dataset
2023-01-05 20:56:59,499:INFO:Defining folds
2023-01-05 20:56:59,499:INFO:Declaring metric variables
2023-01-05 20:56:59,504:INFO:Importing untrained model
2023-01-05 20:56:59,508:INFO:Orthogonal Matching Pursuit Imported successfully
2023-01-05 20:56:59,519:INFO:Starting cross validation
2023-01-05 20:56:59,521:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:56:59,596:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-05 20:56:59,599:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-05 20:56:59,603:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-05 20:56:59,604:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-05 20:56:59,653:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-05 20:56:59,784:INFO:Calculating mean and std
2023-01-05 20:56:59,787:INFO:Creating metrics dataframe
2023-01-05 20:56:59,791:INFO:Uploading results into container
2023-01-05 20:56:59,792:INFO:Uploading model into container now
2023-01-05 20:56:59,792:INFO:_master_model_container: 7
2023-01-05 20:56:59,793:INFO:_display_container: 2
2023-01-05 20:56:59,793:INFO:OrthogonalMatchingPursuit()
2023-01-05 20:56:59,793:INFO:create_model() successfully completed......................................
2023-01-05 20:56:59,891:INFO:SubProcess create_model() end ==================================
2023-01-05 20:56:59,891:INFO:Creating metrics dataframe
2023-01-05 20:56:59,902:INFO:Initializing Bayesian Ridge
2023-01-05 20:56:59,902:INFO:Total runtime is 0.13697164456049601 minutes
2023-01-05 20:56:59,906:INFO:SubProcess create_model() called ==================================
2023-01-05 20:56:59,907:INFO:Initializing create_model()
2023-01-05 20:56:59,907:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000027828EAF250>, estimator=br, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027833BA9730>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:56:59,907:INFO:Checking exceptions
2023-01-05 20:56:59,907:INFO:Importing libraries
2023-01-05 20:56:59,907:INFO:Copying training dataset
2023-01-05 20:56:59,917:INFO:Defining folds
2023-01-05 20:56:59,918:INFO:Declaring metric variables
2023-01-05 20:56:59,922:INFO:Importing untrained model
2023-01-05 20:56:59,926:INFO:Bayesian Ridge Imported successfully
2023-01-05 20:56:59,936:INFO:Starting cross validation
2023-01-05 20:56:59,938:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:57:00,211:INFO:Calculating mean and std
2023-01-05 20:57:00,213:INFO:Creating metrics dataframe
2023-01-05 20:57:00,216:INFO:Uploading results into container
2023-01-05 20:57:00,217:INFO:Uploading model into container now
2023-01-05 20:57:00,218:INFO:_master_model_container: 8
2023-01-05 20:57:00,218:INFO:_display_container: 2
2023-01-05 20:57:00,218:INFO:BayesianRidge()
2023-01-05 20:57:00,219:INFO:create_model() successfully completed......................................
2023-01-05 20:57:00,312:INFO:SubProcess create_model() end ==================================
2023-01-05 20:57:00,312:INFO:Creating metrics dataframe
2023-01-05 20:57:00,323:INFO:Initializing Passive Aggressive Regressor
2023-01-05 20:57:00,323:INFO:Total runtime is 0.14398303429285686 minutes
2023-01-05 20:57:00,326:INFO:SubProcess create_model() called ==================================
2023-01-05 20:57:00,327:INFO:Initializing create_model()
2023-01-05 20:57:00,327:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000027828EAF250>, estimator=par, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027833BA9730>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:57:00,327:INFO:Checking exceptions
2023-01-05 20:57:00,327:INFO:Importing libraries
2023-01-05 20:57:00,327:INFO:Copying training dataset
2023-01-05 20:57:00,337:INFO:Defining folds
2023-01-05 20:57:00,337:INFO:Declaring metric variables
2023-01-05 20:57:00,340:INFO:Importing untrained model
2023-01-05 20:57:00,346:INFO:Passive Aggressive Regressor Imported successfully
2023-01-05 20:57:00,354:INFO:Starting cross validation
2023-01-05 20:57:00,355:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:57:00,643:INFO:Calculating mean and std
2023-01-05 20:57:00,645:INFO:Creating metrics dataframe
2023-01-05 20:57:00,648:INFO:Uploading results into container
2023-01-05 20:57:00,648:INFO:Uploading model into container now
2023-01-05 20:57:00,649:INFO:_master_model_container: 9
2023-01-05 20:57:00,649:INFO:_display_container: 2
2023-01-05 20:57:00,650:INFO:PassiveAggressiveRegressor(random_state=123)
2023-01-05 20:57:00,650:INFO:create_model() successfully completed......................................
2023-01-05 20:57:00,745:INFO:SubProcess create_model() end ==================================
2023-01-05 20:57:00,745:INFO:Creating metrics dataframe
2023-01-05 20:57:00,756:INFO:Initializing Huber Regressor
2023-01-05 20:57:00,756:INFO:Total runtime is 0.15120451450347902 minutes
2023-01-05 20:57:00,760:INFO:SubProcess create_model() called ==================================
2023-01-05 20:57:00,760:INFO:Initializing create_model()
2023-01-05 20:57:00,761:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000027828EAF250>, estimator=huber, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027833BA9730>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:57:00,761:INFO:Checking exceptions
2023-01-05 20:57:00,761:INFO:Importing libraries
2023-01-05 20:57:00,761:INFO:Copying training dataset
2023-01-05 20:57:00,770:INFO:Defining folds
2023-01-05 20:57:00,770:INFO:Declaring metric variables
2023-01-05 20:57:00,774:INFO:Importing untrained model
2023-01-05 20:57:00,779:INFO:Huber Regressor Imported successfully
2023-01-05 20:57:00,789:INFO:Starting cross validation
2023-01-05 20:57:00,791:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:57:00,930:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-05 20:57:01,023:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-05 20:57:01,103:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-05 20:57:01,139:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-05 20:57:01,330:WARNING:c:\Users\Kodotautas\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-05 20:57:01,463:INFO:Calculating mean and std
2023-01-05 20:57:01,465:INFO:Creating metrics dataframe
2023-01-05 20:57:01,469:INFO:Uploading results into container
2023-01-05 20:57:01,470:INFO:Uploading model into container now
2023-01-05 20:57:01,471:INFO:_master_model_container: 10
2023-01-05 20:57:01,471:INFO:_display_container: 2
2023-01-05 20:57:01,471:INFO:HuberRegressor()
2023-01-05 20:57:01,471:INFO:create_model() successfully completed......................................
2023-01-05 20:57:01,578:INFO:SubProcess create_model() end ==================================
2023-01-05 20:57:01,578:INFO:Creating metrics dataframe
2023-01-05 20:57:01,593:INFO:Initializing K Neighbors Regressor
2023-01-05 20:57:01,593:INFO:Total runtime is 0.1651525894800822 minutes
2023-01-05 20:57:01,597:INFO:SubProcess create_model() called ==================================
2023-01-05 20:57:01,597:INFO:Initializing create_model()
2023-01-05 20:57:01,597:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000027828EAF250>, estimator=knn, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027833BA9730>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:57:01,597:INFO:Checking exceptions
2023-01-05 20:57:01,598:INFO:Importing libraries
2023-01-05 20:57:01,598:INFO:Copying training dataset
2023-01-05 20:57:01,610:INFO:Defining folds
2023-01-05 20:57:01,611:INFO:Declaring metric variables
2023-01-05 20:57:01,617:INFO:Importing untrained model
2023-01-05 20:57:01,621:INFO:K Neighbors Regressor Imported successfully
2023-01-05 20:57:01,629:INFO:Starting cross validation
2023-01-05 20:57:01,630:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:57:02,262:INFO:Calculating mean and std
2023-01-05 20:57:02,264:INFO:Creating metrics dataframe
2023-01-05 20:57:02,267:INFO:Uploading results into container
2023-01-05 20:57:02,267:INFO:Uploading model into container now
2023-01-05 20:57:02,268:INFO:_master_model_container: 11
2023-01-05 20:57:02,268:INFO:_display_container: 2
2023-01-05 20:57:02,268:INFO:KNeighborsRegressor(n_jobs=-1)
2023-01-05 20:57:02,268:INFO:create_model() successfully completed......................................
2023-01-05 20:57:02,362:INFO:SubProcess create_model() end ==================================
2023-01-05 20:57:02,363:INFO:Creating metrics dataframe
2023-01-05 20:57:02,376:INFO:Initializing Decision Tree Regressor
2023-01-05 20:57:02,376:INFO:Total runtime is 0.17821192344029746 minutes
2023-01-05 20:57:02,380:INFO:SubProcess create_model() called ==================================
2023-01-05 20:57:02,381:INFO:Initializing create_model()
2023-01-05 20:57:02,381:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000027828EAF250>, estimator=dt, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027833BA9730>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:57:02,381:INFO:Checking exceptions
2023-01-05 20:57:02,381:INFO:Importing libraries
2023-01-05 20:57:02,381:INFO:Copying training dataset
2023-01-05 20:57:02,391:INFO:Defining folds
2023-01-05 20:57:02,391:INFO:Declaring metric variables
2023-01-05 20:57:02,396:INFO:Importing untrained model
2023-01-05 20:57:02,401:INFO:Decision Tree Regressor Imported successfully
2023-01-05 20:57:02,411:INFO:Starting cross validation
2023-01-05 20:57:02,413:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:57:02,950:INFO:Calculating mean and std
2023-01-05 20:57:02,952:INFO:Creating metrics dataframe
2023-01-05 20:57:02,955:INFO:Uploading results into container
2023-01-05 20:57:02,955:INFO:Uploading model into container now
2023-01-05 20:57:02,955:INFO:_master_model_container: 12
2023-01-05 20:57:02,955:INFO:_display_container: 2
2023-01-05 20:57:02,956:INFO:DecisionTreeRegressor(random_state=123)
2023-01-05 20:57:02,956:INFO:create_model() successfully completed......................................
2023-01-05 20:57:03,045:INFO:SubProcess create_model() end ==================================
2023-01-05 20:57:03,045:INFO:Creating metrics dataframe
2023-01-05 20:57:03,060:INFO:Initializing Random Forest Regressor
2023-01-05 20:57:03,060:INFO:Total runtime is 0.18960148890813194 minutes
2023-01-05 20:57:03,064:INFO:SubProcess create_model() called ==================================
2023-01-05 20:57:03,065:INFO:Initializing create_model()
2023-01-05 20:57:03,065:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000027828EAF250>, estimator=rf, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027833BA9730>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:57:03,065:INFO:Checking exceptions
2023-01-05 20:57:03,065:INFO:Importing libraries
2023-01-05 20:57:03,065:INFO:Copying training dataset
2023-01-05 20:57:03,074:INFO:Defining folds
2023-01-05 20:57:03,075:INFO:Declaring metric variables
2023-01-05 20:57:03,079:INFO:Importing untrained model
2023-01-05 20:57:03,084:INFO:Random Forest Regressor Imported successfully
2023-01-05 20:57:03,092:INFO:Starting cross validation
2023-01-05 20:57:03,093:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:57:12,416:INFO:Calculating mean and std
2023-01-05 20:57:12,418:INFO:Creating metrics dataframe
2023-01-05 20:57:12,421:INFO:Uploading results into container
2023-01-05 20:57:12,421:INFO:Uploading model into container now
2023-01-05 20:57:12,422:INFO:_master_model_container: 13
2023-01-05 20:57:12,422:INFO:_display_container: 2
2023-01-05 20:57:12,422:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-01-05 20:57:12,423:INFO:create_model() successfully completed......................................
2023-01-05 20:57:12,521:INFO:SubProcess create_model() end ==================================
2023-01-05 20:57:12,521:INFO:Creating metrics dataframe
2023-01-05 20:57:12,534:INFO:Initializing Extra Trees Regressor
2023-01-05 20:57:12,534:INFO:Total runtime is 0.3475027163823446 minutes
2023-01-05 20:57:12,538:INFO:SubProcess create_model() called ==================================
2023-01-05 20:57:12,539:INFO:Initializing create_model()
2023-01-05 20:57:12,539:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000027828EAF250>, estimator=et, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027833BA9730>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:57:12,539:INFO:Checking exceptions
2023-01-05 20:57:12,539:INFO:Importing libraries
2023-01-05 20:57:12,539:INFO:Copying training dataset
2023-01-05 20:57:12,550:INFO:Defining folds
2023-01-05 20:57:12,550:INFO:Declaring metric variables
2023-01-05 20:57:12,555:INFO:Importing untrained model
2023-01-05 20:57:12,560:INFO:Extra Trees Regressor Imported successfully
2023-01-05 20:57:12,569:INFO:Starting cross validation
2023-01-05 20:57:12,570:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:57:17,405:INFO:Calculating mean and std
2023-01-05 20:57:17,407:INFO:Creating metrics dataframe
2023-01-05 20:57:17,410:INFO:Uploading results into container
2023-01-05 20:57:17,410:INFO:Uploading model into container now
2023-01-05 20:57:17,410:INFO:_master_model_container: 14
2023-01-05 20:57:17,410:INFO:_display_container: 2
2023-01-05 20:57:17,411:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-01-05 20:57:17,411:INFO:create_model() successfully completed......................................
2023-01-05 20:57:17,504:INFO:SubProcess create_model() end ==================================
2023-01-05 20:57:17,505:INFO:Creating metrics dataframe
2023-01-05 20:57:17,521:INFO:Initializing AdaBoost Regressor
2023-01-05 20:57:17,521:INFO:Total runtime is 0.43061554431915283 minutes
2023-01-05 20:57:17,525:INFO:SubProcess create_model() called ==================================
2023-01-05 20:57:17,526:INFO:Initializing create_model()
2023-01-05 20:57:17,526:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000027828EAF250>, estimator=ada, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027833BA9730>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:57:17,526:INFO:Checking exceptions
2023-01-05 20:57:17,526:INFO:Importing libraries
2023-01-05 20:57:17,526:INFO:Copying training dataset
2023-01-05 20:57:17,536:INFO:Defining folds
2023-01-05 20:57:17,537:INFO:Declaring metric variables
2023-01-05 20:57:17,541:INFO:Importing untrained model
2023-01-05 20:57:17,545:INFO:AdaBoost Regressor Imported successfully
2023-01-05 20:57:17,553:INFO:Starting cross validation
2023-01-05 20:57:17,554:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:57:19,828:INFO:Calculating mean and std
2023-01-05 20:57:19,830:INFO:Creating metrics dataframe
2023-01-05 20:57:19,835:INFO:Uploading results into container
2023-01-05 20:57:19,836:INFO:Uploading model into container now
2023-01-05 20:57:19,836:INFO:_master_model_container: 15
2023-01-05 20:57:19,837:INFO:_display_container: 2
2023-01-05 20:57:19,837:INFO:AdaBoostRegressor(random_state=123)
2023-01-05 20:57:19,837:INFO:create_model() successfully completed......................................
2023-01-05 20:57:19,952:INFO:SubProcess create_model() end ==================================
2023-01-05 20:57:19,952:INFO:Creating metrics dataframe
2023-01-05 20:57:19,967:INFO:Initializing Gradient Boosting Regressor
2023-01-05 20:57:19,967:INFO:Total runtime is 0.47138225634892783 minutes
2023-01-05 20:57:19,972:INFO:SubProcess create_model() called ==================================
2023-01-05 20:57:19,972:INFO:Initializing create_model()
2023-01-05 20:57:19,973:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000027828EAF250>, estimator=gbr, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027833BA9730>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:57:19,973:INFO:Checking exceptions
2023-01-05 20:57:19,973:INFO:Importing libraries
2023-01-05 20:57:19,973:INFO:Copying training dataset
2023-01-05 20:57:19,983:INFO:Defining folds
2023-01-05 20:57:19,984:INFO:Declaring metric variables
2023-01-05 20:57:19,988:INFO:Importing untrained model
2023-01-05 20:57:19,992:INFO:Gradient Boosting Regressor Imported successfully
2023-01-05 20:57:20,002:INFO:Starting cross validation
2023-01-05 20:57:20,004:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:57:26,067:INFO:Calculating mean and std
2023-01-05 20:57:26,069:INFO:Creating metrics dataframe
2023-01-05 20:57:26,080:INFO:Uploading results into container
2023-01-05 20:57:26,081:INFO:Uploading model into container now
2023-01-05 20:57:26,081:INFO:_master_model_container: 16
2023-01-05 20:57:26,082:INFO:_display_container: 2
2023-01-05 20:57:26,082:INFO:GradientBoostingRegressor(random_state=123)
2023-01-05 20:57:26,082:INFO:create_model() successfully completed......................................
2023-01-05 20:57:26,187:INFO:SubProcess create_model() end ==================================
2023-01-05 20:57:26,187:INFO:Creating metrics dataframe
2023-01-05 20:57:26,202:INFO:Initializing Light Gradient Boosting Machine
2023-01-05 20:57:26,203:INFO:Total runtime is 0.5753155191739401 minutes
2023-01-05 20:57:26,206:INFO:SubProcess create_model() called ==================================
2023-01-05 20:57:26,206:INFO:Initializing create_model()
2023-01-05 20:57:26,206:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000027828EAF250>, estimator=lightgbm, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027833BA9730>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:57:26,206:INFO:Checking exceptions
2023-01-05 20:57:26,207:INFO:Importing libraries
2023-01-05 20:57:26,207:INFO:Copying training dataset
2023-01-05 20:57:26,220:INFO:Defining folds
2023-01-05 20:57:26,220:INFO:Declaring metric variables
2023-01-05 20:57:26,224:INFO:Importing untrained model
2023-01-05 20:57:26,230:INFO:Light Gradient Boosting Machine Imported successfully
2023-01-05 20:57:26,238:INFO:Starting cross validation
2023-01-05 20:57:26,240:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:57:29,494:INFO:Calculating mean and std
2023-01-05 20:57:29,496:INFO:Creating metrics dataframe
2023-01-05 20:57:29,499:INFO:Uploading results into container
2023-01-05 20:57:29,500:INFO:Uploading model into container now
2023-01-05 20:57:29,500:INFO:_master_model_container: 17
2023-01-05 20:57:29,500:INFO:_display_container: 2
2023-01-05 20:57:29,500:INFO:LGBMRegressor(random_state=123)
2023-01-05 20:57:29,500:INFO:create_model() successfully completed......................................
2023-01-05 20:57:29,595:INFO:SubProcess create_model() end ==================================
2023-01-05 20:57:29,595:INFO:Creating metrics dataframe
2023-01-05 20:57:29,611:INFO:Initializing Dummy Regressor
2023-01-05 20:57:29,612:INFO:Total runtime is 0.6321388800938925 minutes
2023-01-05 20:57:29,616:INFO:SubProcess create_model() called ==================================
2023-01-05 20:57:29,616:INFO:Initializing create_model()
2023-01-05 20:57:29,617:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000027828EAF250>, estimator=dummy, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027833BA9730>, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:57:29,617:INFO:Checking exceptions
2023-01-05 20:57:29,617:INFO:Importing libraries
2023-01-05 20:57:29,617:INFO:Copying training dataset
2023-01-05 20:57:29,626:INFO:Defining folds
2023-01-05 20:57:29,627:INFO:Declaring metric variables
2023-01-05 20:57:29,630:INFO:Importing untrained model
2023-01-05 20:57:29,635:INFO:Dummy Regressor Imported successfully
2023-01-05 20:57:29,642:INFO:Starting cross validation
2023-01-05 20:57:29,644:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:57:29,936:INFO:Calculating mean and std
2023-01-05 20:57:29,938:INFO:Creating metrics dataframe
2023-01-05 20:57:29,942:INFO:Uploading results into container
2023-01-05 20:57:29,942:INFO:Uploading model into container now
2023-01-05 20:57:29,943:INFO:_master_model_container: 18
2023-01-05 20:57:29,943:INFO:_display_container: 2
2023-01-05 20:57:29,943:INFO:DummyRegressor()
2023-01-05 20:57:29,943:INFO:create_model() successfully completed......................................
2023-01-05 20:57:30,086:INFO:SubProcess create_model() end ==================================
2023-01-05 20:57:30,086:INFO:Creating metrics dataframe
2023-01-05 20:57:30,126:INFO:Initializing create_model()
2023-01-05 20:57:30,126:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000027828EAF250>, estimator=LGBMRegressor(random_state=123), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:57:30,126:INFO:Checking exceptions
2023-01-05 20:57:30,129:INFO:Importing libraries
2023-01-05 20:57:30,129:INFO:Copying training dataset
2023-01-05 20:57:30,138:INFO:Defining folds
2023-01-05 20:57:30,138:INFO:Declaring metric variables
2023-01-05 20:57:30,138:INFO:Importing untrained model
2023-01-05 20:57:30,139:INFO:Declaring custom model
2023-01-05 20:57:30,139:INFO:Light Gradient Boosting Machine Imported successfully
2023-01-05 20:57:30,144:INFO:Cross validation set to False
2023-01-05 20:57:30,144:INFO:Fitting Model
2023-01-05 20:57:30,742:INFO:LGBMRegressor(random_state=123)
2023-01-05 20:57:30,743:INFO:create_model() successfully completed......................................
2023-01-05 20:57:30,915:INFO:_master_model_container: 18
2023-01-05 20:57:30,916:INFO:_display_container: 2
2023-01-05 20:57:30,916:INFO:LGBMRegressor(random_state=123)
2023-01-05 20:57:30,917:INFO:compare_models() successfully completed......................................
2023-01-05 20:57:30,918:INFO:Initializing tune_model()
2023-01-05 20:57:30,918:INFO:tune_model(estimator=LGBMRegressor(random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=MAE, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000027828EAF250>)
2023-01-05 20:57:30,918:INFO:Checking exceptions
2023-01-05 20:57:30,950:INFO:Copying training dataset
2023-01-05 20:57:30,961:INFO:Checking base model
2023-01-05 20:57:30,961:INFO:Base model : Light Gradient Boosting Machine
2023-01-05 20:57:30,967:INFO:Declaring metric variables
2023-01-05 20:57:30,978:INFO:Defining Hyperparameters
2023-01-05 20:57:31,098:INFO:Tuning with n_jobs=-1
2023-01-05 20:57:31,099:INFO:Initializing RandomizedSearchCV
2023-01-05 20:57:37,846:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2023-01-05 20:57:37,848:INFO:Hyperparameter search completed
2023-01-05 20:57:37,848:INFO:SubProcess create_model() called ==================================
2023-01-05 20:57:37,848:INFO:Initializing create_model()
2023-01-05 20:57:37,848:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000027828EAF250>, estimator=LGBMRegressor(random_state=123), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002783254AF70>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2023-01-05 20:57:37,848:INFO:Checking exceptions
2023-01-05 20:57:37,848:INFO:Importing libraries
2023-01-05 20:57:37,848:INFO:Copying training dataset
2023-01-05 20:57:37,860:INFO:Defining folds
2023-01-05 20:57:37,860:INFO:Declaring metric variables
2023-01-05 20:57:37,864:INFO:Importing untrained model
2023-01-05 20:57:37,864:INFO:Declaring custom model
2023-01-05 20:57:37,870:INFO:Light Gradient Boosting Machine Imported successfully
2023-01-05 20:57:37,877:INFO:Starting cross validation
2023-01-05 20:57:37,879:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:57:39,275:INFO:Calculating mean and std
2023-01-05 20:57:39,276:INFO:Creating metrics dataframe
2023-01-05 20:57:39,282:INFO:Finalizing model
2023-01-05 20:57:39,806:INFO:Uploading results into container
2023-01-05 20:57:39,807:INFO:Uploading model into container now
2023-01-05 20:57:39,808:INFO:_master_model_container: 19
2023-01-05 20:57:39,808:INFO:_display_container: 3
2023-01-05 20:57:39,808:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              num_leaves=70, random_state=123, reg_alpha=2, reg_lambda=3)
2023-01-05 20:57:39,809:INFO:create_model() successfully completed......................................
2023-01-05 20:57:39,913:INFO:SubProcess create_model() end ==================================
2023-01-05 20:57:39,914:INFO:choose_better activated
2023-01-05 20:57:39,919:INFO:SubProcess create_model() called ==================================
2023-01-05 20:57:39,920:INFO:Initializing create_model()
2023-01-05 20:57:39,920:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000027828EAF250>, estimator=LGBMRegressor(random_state=123), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-01-05 20:57:39,920:INFO:Checking exceptions
2023-01-05 20:57:39,922:INFO:Importing libraries
2023-01-05 20:57:39,922:INFO:Copying training dataset
2023-01-05 20:57:39,930:INFO:Defining folds
2023-01-05 20:57:39,930:INFO:Declaring metric variables
2023-01-05 20:57:39,931:INFO:Importing untrained model
2023-01-05 20:57:39,931:INFO:Declaring custom model
2023-01-05 20:57:39,931:INFO:Light Gradient Boosting Machine Imported successfully
2023-01-05 20:57:39,932:INFO:Starting cross validation
2023-01-05 20:57:39,934:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), n_jobs=-1
2023-01-05 20:57:41,125:INFO:Calculating mean and std
2023-01-05 20:57:41,126:INFO:Creating metrics dataframe
2023-01-05 20:57:41,128:INFO:Finalizing model
2023-01-05 20:57:41,380:INFO:Uploading results into container
2023-01-05 20:57:41,380:INFO:Uploading model into container now
2023-01-05 20:57:41,381:INFO:_master_model_container: 20
2023-01-05 20:57:41,381:INFO:_display_container: 4
2023-01-05 20:57:41,381:INFO:LGBMRegressor(random_state=123)
2023-01-05 20:57:41,381:INFO:create_model() successfully completed......................................
2023-01-05 20:57:41,483:INFO:SubProcess create_model() end ==================================
2023-01-05 20:57:41,483:INFO:LGBMRegressor(random_state=123) result for MAE is 2.201
2023-01-05 20:57:41,484:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              num_leaves=70, random_state=123, reg_alpha=2, reg_lambda=3) result for MAE is 2.4987
2023-01-05 20:57:41,484:INFO:LGBMRegressor(random_state=123) is best model
2023-01-05 20:57:41,485:INFO:choose_better completed
2023-01-05 20:57:41,485:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-01-05 20:57:41,494:INFO:_master_model_container: 20
2023-01-05 20:57:41,494:INFO:_display_container: 3
2023-01-05 20:57:41,494:INFO:LGBMRegressor(random_state=123)
2023-01-05 20:57:41,494:INFO:tune_model() successfully completed......................................
2023-01-05 20:57:41,607:INFO:Initializing plot_model()
2023-01-05 20:57:41,607:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LGBMRegressor(random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000027828EAF250>, system=True)
2023-01-05 20:57:41,607:INFO:Checking exceptions
2023-01-05 20:57:41,613:INFO:Preloading libraries
2023-01-05 20:57:41,621:INFO:Copying training dataset
2023-01-05 20:57:41,621:INFO:Plot type: error
2023-01-05 20:57:41,794:INFO:Fitting Model
2023-01-05 20:57:41,794:INFO:Scoring test/hold-out set
2023-01-05 20:57:42,207:INFO:Visual Rendered Successfully
2023-01-05 20:57:42,304:INFO:plot_model() successfully completed......................................
2023-01-05 20:57:42,305:INFO:Initializing predict_model()
2023-01-05 20:57:42,305:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000027828EAF250>, estimator=LGBMRegressor(random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x0000027833820B80>)
2023-01-05 20:57:42,305:INFO:Checking exceptions
2023-01-05 20:57:42,305:INFO:Preloading libraries
2023-01-05 20:57:42,479:INFO:Initializing finalize_model()
2023-01-05 20:57:42,480:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000027828EAF250>, estimator=LGBMRegressor(random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-01-05 20:57:42,480:INFO:Finalizing LGBMRegressor(random_state=123)
2023-01-05 20:57:42,489:INFO:Initializing create_model()
2023-01-05 20:57:42,489:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000027828EAF250>, estimator=LGBMRegressor(random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-01-05 20:57:42,489:INFO:Checking exceptions
2023-01-05 20:57:42,491:INFO:Importing libraries
2023-01-05 20:57:42,491:INFO:Copying training dataset
2023-01-05 20:57:42,491:INFO:Defining folds
2023-01-05 20:57:42,491:INFO:Declaring metric variables
2023-01-05 20:57:42,492:INFO:Importing untrained model
2023-01-05 20:57:42,492:INFO:Declaring custom model
2023-01-05 20:57:42,492:INFO:Light Gradient Boosting Machine Imported successfully
2023-01-05 20:57:42,493:INFO:Cross validation set to False
2023-01-05 20:57:42,493:INFO:Fitting Model
2023-01-05 20:57:42,861:INFO:Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator', LGBMRegressor(random_state=123))])
2023-01-05 20:57:42,861:INFO:create_model() successfully completed......................................
2023-01-05 20:57:42,962:INFO:_master_model_container: 20
2023-01-05 20:57:42,962:INFO:_display_container: 4
2023-01-05 20:57:42,970:INFO:Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator', LGBMRegressor(random_state=123))])
2023-01-05 20:57:42,970:INFO:finalize_model() successfully completed......................................
2023-01-05 20:57:43,074:INFO:Initializing predict_model()
2023-01-05 20:57:43,074:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000027828EAF250>, estimator=Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator', LGBMRegressor(random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x0000027833820B80>)
2023-01-05 20:57:43,074:INFO:Checking exceptions
2023-01-05 20:57:43,074:INFO:Preloading libraries
2023-01-05 20:57:43,076:INFO:Set up data.
2023-01-05 20:57:43,092:INFO:Set up index.
2023-01-05 20:57:43,852:INFO:Initializing evaluate_model()
2023-01-05 20:57:43,852:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000027828EAF250>, estimator=Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator', LGBMRegressor(random_state=123))]), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None, use_train_data=False)
2023-01-05 20:57:43,887:INFO:Initializing plot_model()
2023-01-05 20:57:43,888:INFO:plot_model(plot=pipeline, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), use_train_data=False, verbose=False, display=None, display_format=None, estimator=Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator', LGBMRegressor(random_state=123))]), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000027828EAF250>, system=True)
2023-01-05 20:57:43,888:INFO:Checking exceptions
2023-01-05 20:57:43,893:INFO:Preloading libraries
2023-01-05 20:57:43,901:INFO:Copying training dataset
2023-01-05 20:57:43,901:INFO:Plot type: pipeline
2023-01-05 20:57:44,035:INFO:Visual Rendered Successfully
2023-01-05 20:57:44,140:INFO:plot_model() successfully completed......................................
2023-01-05 20:57:44,160:INFO:Initializing save_model()
2023-01-05 20:57:44,160:INFO:save_model(model=Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator', LGBMRegressor(random_state=123))]), model_name=c:\Users\Kodotautas\Desktop\Data_science\7_TIME_SERIES_FORECAST_AUTOML/models/final_model.pkl, prep_pipe_=Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-01-05 20:57:44,160:INFO:Adding model into prep_pipe
2023-01-05 20:57:44,166:WARNING:Only Model saved as it was a pipeline.
2023-01-05 20:57:44,179:INFO:c:\Users\Kodotautas\Desktop\Data_science\7_TIME_SERIES_FORECAST_AUTOML/models/final_model.pkl.pkl saved in current working directory
2023-01-05 20:57:44,186:INFO:Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator', LGBMRegressor(random_state=123))])
2023-01-05 20:57:44,187:INFO:save_model() successfully completed......................................
2023-01-05 20:58:33,093:INFO:Initializing plot_model()
2023-01-05 20:58:33,094:INFO:plot_model(plot=feature, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), use_train_data=False, verbose=False, display=None, display_format=None, estimator=Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator', LGBMRegressor(random_state=123))]), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000027828EAF250>, system=True)
2023-01-05 20:58:33,094:INFO:Checking exceptions
2023-01-05 20:58:33,099:INFO:Preloading libraries
2023-01-05 20:58:33,105:INFO:Copying training dataset
2023-01-05 20:58:33,105:INFO:Plot type: feature
2023-01-05 20:58:33,105:WARNING:No coef_ found. Trying feature_importances_
2023-01-05 20:58:33,280:INFO:Visual Rendered Successfully
2023-01-05 20:58:33,381:INFO:plot_model() successfully completed......................................
2023-01-05 20:58:48,604:INFO:Initializing plot_model()
2023-01-05 20:58:48,604:INFO:plot_model(plot=rfe, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None), use_train_data=False, verbose=False, display=None, display_format=None, estimator=Pipeline(memory=Memory(location=C:\Users\KODOTA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['month', 'day', 'hour',
                                             'day_of_week', 'week_of_year',
                                             'quarter', 'day_of_year',
                                             'is_weekend'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator', LGBMRegressor(random_state=123))]), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000027828EAF250>, system=True)
2023-01-05 20:58:48,604:INFO:Checking exceptions
2023-01-05 20:58:48,610:INFO:Preloading libraries
2023-01-05 20:58:48,615:INFO:Copying training dataset
2023-01-05 20:58:48,615:INFO:Plot type: rfe
2023-01-05 20:58:48,731:INFO:Fitting Model
2023-01-05 21:06:17,768:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-01-05 21:06:17,768:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-01-05 21:06:17,768:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-01-05 21:06:17,768:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-01-05 21:06:18,495:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-01-05 21:06:18,845:INFO:PyCaret RegressionExperiment
2023-01-05 21:06:18,846:INFO:Logging name: reg-default-name
2023-01-05 21:06:18,846:INFO:ML Usecase: MLUsecase.REGRESSION
2023-01-05 21:06:18,846:INFO:version 3.0.0.rc6
2023-01-05 21:06:18,846:INFO:Initializing setup()
2023-01-05 21:06:18,846:INFO:self.USI: 6929
2023-01-05 21:06:18,846:INFO:self._variable_keys: {'X_train', '_ml_usecase', 'gpu_n_jobs_param', 'gpu_param', 'pipeline', 'X_test', 'data', 'log_plots_param', 'html_param', 'y_train', 'transform_target_param', 'X', 'n_jobs_param', 'exp_id', 'y', 'memory', 'USI', 'idx', 'fold_shuffle_param', 'fold_groups_param', 'y_test', 'fold_generator', 'exp_name_log', 'target_param', '_available_plots', 'logging_param', 'seed'}
2023-01-05 21:06:18,846:INFO:Checking environment
2023-01-05 21:06:18,846:INFO:python_version: 3.9.13
2023-01-05 21:06:18,846:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-01-05 21:06:18,846:INFO:machine: AMD64
2023-01-05 21:06:18,846:INFO:platform: Windows-10-10.0.19044-SP0
2023-01-05 21:06:18,846:INFO:Memory: svmem(total=17114804224, available=9787138048, percent=42.8, used=7327666176, free=9787138048)
2023-01-05 21:06:18,846:INFO:Physical Core: 4
2023-01-05 21:06:18,846:INFO:Logical Core: 4
2023-01-05 21:06:18,846:INFO:Checking libraries
2023-01-05 21:06:18,846:INFO:System:
2023-01-05 21:06:18,846:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-01-05 21:06:18,846:INFO:executable: c:\Users\Kodotautas\anaconda3\python.exe
2023-01-05 21:06:18,847:INFO:   machine: Windows-10-10.0.19044-SP0
2023-01-05 21:06:18,847:INFO:PyCaret required dependencies:
2023-01-05 21:06:18,847:INFO:                 pip: 22.2.2
2023-01-05 21:06:18,847:INFO:          setuptools: 63.4.1
2023-01-05 21:06:18,847:INFO:             pycaret: 3.0.0rc6
2023-01-05 21:06:18,847:INFO:             IPython: 7.31.1
2023-01-05 21:06:18,847:INFO:          ipywidgets: 7.6.5
2023-01-05 21:06:18,847:INFO:                tqdm: 4.64.1
2023-01-05 21:06:18,847:INFO:               numpy: 1.21.5
2023-01-05 21:06:18,847:INFO:              pandas: 1.4.4
2023-01-05 21:06:18,847:INFO:              jinja2: 2.11.3
2023-01-05 21:06:18,847:INFO:               scipy: 1.9.1
2023-01-05 21:06:18,847:INFO:              joblib: 1.2.0
2023-01-05 21:06:18,847:INFO:             sklearn: 1.0.2
2023-01-05 21:06:18,847:INFO:                pyod: 1.0.7
2023-01-05 21:06:18,847:INFO:            imblearn: 0.10.1
2023-01-05 21:06:18,847:INFO:   category_encoders: 2.5.1.post0
2023-01-05 21:06:18,847:INFO:            lightgbm: 3.3.3
2023-01-05 21:06:18,847:INFO:               numba: 0.55.1
2023-01-05 21:06:18,848:INFO:            requests: 2.28.1
2023-01-05 21:06:18,848:INFO:          matplotlib: 3.5.2
2023-01-05 21:06:18,848:INFO:          scikitplot: 0.3.7
2023-01-05 21:06:18,848:INFO:         yellowbrick: 1.5
2023-01-05 21:06:18,848:INFO:              plotly: 5.9.0
2023-01-05 21:06:18,848:INFO:             kaleido: 0.2.1
2023-01-05 21:06:18,848:INFO:         statsmodels: 0.13.2
2023-01-05 21:06:18,848:INFO:              sktime: 0.14.1
2023-01-05 21:06:18,848:INFO:               tbats: 1.1.2
2023-01-05 21:06:18,848:INFO:            pmdarima: 2.0.2
2023-01-05 21:06:18,848:INFO:              psutil: 5.9.0
2023-01-05 21:06:18,848:INFO:PyCaret optional dependencies:
2023-01-05 21:06:19,097:INFO:                shap: 0.41.0
2023-01-05 21:06:19,098:INFO:           interpret: Not installed
2023-01-05 21:06:19,098:INFO:                umap: Not installed
2023-01-05 21:06:19,098:INFO:    pandas_profiling: Not installed
2023-01-05 21:06:19,098:INFO:  explainerdashboard: Not installed
2023-01-05 21:06:19,098:INFO:             autoviz: Not installed
2023-01-05 21:06:19,098:INFO:           fairlearn: Not installed
2023-01-05 21:06:19,098:INFO:             xgboost: Not installed
2023-01-05 21:06:19,098:INFO:            catboost: Not installed
2023-01-05 21:06:19,098:INFO:              kmodes: Not installed
2023-01-05 21:06:19,098:INFO:             mlxtend: Not installed
2023-01-05 21:06:19,098:INFO:       statsforecast: Not installed
2023-01-05 21:06:19,098:INFO:        tune_sklearn: 0.4.3
2023-01-05 21:06:19,098:INFO:                 ray: 2.0.0
2023-01-05 21:06:19,098:INFO:            hyperopt: 0.2.7
2023-01-05 21:06:19,098:INFO:              optuna: 3.0.1
2023-01-05 21:06:19,098:INFO:               skopt: 0.9.0
2023-01-05 21:06:19,098:INFO:              mlflow: Not installed
2023-01-05 21:06:19,098:INFO:              gradio: Not installed
2023-01-05 21:06:19,099:INFO:             fastapi: 0.88.0
2023-01-05 21:06:19,099:INFO:             uvicorn: 0.20.0
2023-01-05 21:06:19,099:INFO:              m2cgen: Not installed
2023-01-05 21:06:19,099:INFO:           evidently: Not installed
2023-01-05 21:06:19,099:INFO:                nltk: 3.7
2023-01-05 21:06:19,099:INFO:            pyLDAvis: Not installed
2023-01-05 21:06:19,099:INFO:              gensim: 4.1.2
2023-01-05 21:06:19,099:INFO:               spacy: 3.4.2
2023-01-05 21:06:19,099:INFO:           wordcloud: Not installed
2023-01-05 21:06:19,099:INFO:            textblob: Not installed
2023-01-05 21:06:19,099:INFO:               fugue: Not installed
2023-01-05 21:06:19,099:INFO:           streamlit: Not installed
2023-01-05 21:06:19,099:INFO:             prophet: Not installed
2023-01-05 21:06:19,099:INFO:None
2023-01-05 21:06:19,099:INFO:Set up data.
2023-01-05 21:06:19,119:INFO:Set up train/test split.
2023-01-05 21:06:19,131:INFO:Set up index.
2023-01-05 21:06:19,133:INFO:Set up folding strategy.
2023-01-05 21:06:19,133:INFO:Assigning column types.
2023-01-05 21:13:43,997:INFO:PyCaret RegressionExperiment
2023-01-05 21:13:43,997:INFO:Logging name: reg-default-name
2023-01-05 21:13:43,997:INFO:ML Usecase: MLUsecase.REGRESSION
2023-01-05 21:13:43,997:INFO:version 3.0.0.rc6
2023-01-05 21:13:43,997:INFO:Initializing setup()
2023-01-05 21:13:43,997:INFO:self.USI: 9632
2023-01-05 21:13:43,997:INFO:self._variable_keys: {'X_train', '_ml_usecase', 'gpu_n_jobs_param', 'gpu_param', 'pipeline', 'X_test', 'data', 'log_plots_param', 'html_param', 'y_train', 'transform_target_param', 'X', 'n_jobs_param', 'exp_id', 'y', 'memory', 'USI', 'idx', 'fold_shuffle_param', 'fold_groups_param', 'y_test', 'fold_generator', 'exp_name_log', 'target_param', '_available_plots', 'logging_param', 'seed'}
2023-01-05 21:13:43,997:INFO:Checking environment
2023-01-05 21:13:43,997:INFO:python_version: 3.9.13
2023-01-05 21:13:43,998:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-01-05 21:13:43,998:INFO:machine: AMD64
2023-01-05 21:13:43,998:INFO:platform: Windows-10-10.0.19044-SP0
2023-01-05 21:13:43,998:INFO:Memory: svmem(total=17114804224, available=10075549696, percent=41.1, used=7039254528, free=10075549696)
2023-01-05 21:13:43,998:INFO:Physical Core: 4
2023-01-05 21:13:43,998:INFO:Logical Core: 4
2023-01-05 21:13:43,998:INFO:Checking libraries
2023-01-05 21:13:43,998:INFO:System:
2023-01-05 21:13:43,998:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-01-05 21:13:43,998:INFO:executable: c:\Users\Kodotautas\anaconda3\python.exe
2023-01-05 21:13:43,998:INFO:   machine: Windows-10-10.0.19044-SP0
2023-01-05 21:13:43,998:INFO:PyCaret required dependencies:
2023-01-05 21:13:43,998:INFO:                 pip: 22.2.2
2023-01-05 21:13:43,998:INFO:          setuptools: 63.4.1
2023-01-05 21:13:43,998:INFO:             pycaret: 3.0.0rc6
2023-01-05 21:13:43,998:INFO:             IPython: 7.31.1
2023-01-05 21:13:43,998:INFO:          ipywidgets: 7.6.5
2023-01-05 21:13:43,998:INFO:                tqdm: 4.64.1
2023-01-05 21:13:43,999:INFO:               numpy: 1.21.5
2023-01-05 21:13:43,999:INFO:              pandas: 1.4.4
2023-01-05 21:13:43,999:INFO:              jinja2: 2.11.3
2023-01-05 21:13:43,999:INFO:               scipy: 1.9.1
2023-01-05 21:13:43,999:INFO:              joblib: 1.2.0
2023-01-05 21:13:43,999:INFO:             sklearn: 1.0.2
2023-01-05 21:13:43,999:INFO:                pyod: 1.0.7
2023-01-05 21:13:43,999:INFO:            imblearn: 0.10.1
2023-01-05 21:13:43,999:INFO:   category_encoders: 2.5.1.post0
2023-01-05 21:13:43,999:INFO:            lightgbm: 3.3.3
2023-01-05 21:13:43,999:INFO:               numba: 0.55.1
2023-01-05 21:13:43,999:INFO:            requests: 2.28.1
2023-01-05 21:13:43,999:INFO:          matplotlib: 3.5.2
2023-01-05 21:13:43,999:INFO:          scikitplot: 0.3.7
2023-01-05 21:13:43,999:INFO:         yellowbrick: 1.5
2023-01-05 21:13:43,999:INFO:              plotly: 5.9.0
2023-01-05 21:13:43,999:INFO:             kaleido: 0.2.1
2023-01-05 21:13:43,999:INFO:         statsmodels: 0.13.2
2023-01-05 21:13:43,999:INFO:              sktime: 0.14.1
2023-01-05 21:13:43,999:INFO:               tbats: 1.1.2
2023-01-05 21:13:43,999:INFO:            pmdarima: 2.0.2
2023-01-05 21:13:44,000:INFO:              psutil: 5.9.0
2023-01-05 21:13:44,000:INFO:PyCaret optional dependencies:
2023-01-05 21:13:44,000:INFO:                shap: 0.41.0
2023-01-05 21:13:44,000:INFO:           interpret: Not installed
2023-01-05 21:13:44,000:INFO:                umap: Not installed
2023-01-05 21:13:44,000:INFO:    pandas_profiling: Not installed
2023-01-05 21:13:44,000:INFO:  explainerdashboard: Not installed
2023-01-05 21:13:44,000:INFO:             autoviz: Not installed
2023-01-05 21:13:44,000:INFO:           fairlearn: Not installed
2023-01-05 21:13:44,000:INFO:             xgboost: Not installed
2023-01-05 21:13:44,000:INFO:            catboost: Not installed
2023-01-05 21:13:44,000:INFO:              kmodes: Not installed
2023-01-05 21:13:44,000:INFO:             mlxtend: Not installed
2023-01-05 21:13:44,000:INFO:       statsforecast: Not installed
2023-01-05 21:13:44,000:INFO:        tune_sklearn: 0.4.3
2023-01-05 21:13:44,000:INFO:                 ray: 2.0.0
2023-01-05 21:13:44,000:INFO:            hyperopt: 0.2.7
2023-01-05 21:13:44,000:INFO:              optuna: 3.0.1
2023-01-05 21:13:44,000:INFO:               skopt: 0.9.0
2023-01-05 21:13:44,001:INFO:              mlflow: Not installed
2023-01-05 21:13:44,001:INFO:              gradio: Not installed
2023-01-05 21:13:44,001:INFO:             fastapi: 0.88.0
2023-01-05 21:13:44,001:INFO:             uvicorn: 0.20.0
2023-01-05 21:13:44,001:INFO:              m2cgen: Not installed
2023-01-05 21:13:44,001:INFO:           evidently: Not installed
2023-01-05 21:13:44,001:INFO:                nltk: 3.7
2023-01-05 21:13:44,001:INFO:            pyLDAvis: Not installed
2023-01-05 21:13:44,001:INFO:              gensim: 4.1.2
2023-01-05 21:13:44,001:INFO:               spacy: 3.4.2
2023-01-05 21:13:44,001:INFO:           wordcloud: Not installed
2023-01-05 21:13:44,001:INFO:            textblob: Not installed
2023-01-05 21:13:44,001:INFO:               fugue: Not installed
2023-01-05 21:13:44,001:INFO:           streamlit: Not installed
2023-01-05 21:13:44,001:INFO:             prophet: Not installed
2023-01-05 21:13:44,001:INFO:None
2023-01-05 21:13:44,001:INFO:Set up data.
2023-01-05 21:13:44,020:INFO:Set up train/test split.
2023-01-05 21:13:44,031:INFO:Set up index.
2023-01-05 21:13:44,033:INFO:Set up folding strategy.
2023-01-05 21:13:44,033:INFO:Assigning column types.
2023-01-05 21:13:44,042:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-01-05 21:13:44,043:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-01-05 21:13:44,048:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-05 21:13:44,053:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-05 21:13:44,195:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-05 21:13:44,258:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-05 21:13:44,266:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 21:13:44,448:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 21:13:44,448:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-01-05 21:13:44,453:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-05 21:13:44,458:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-05 21:13:44,524:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-05 21:13:44,570:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-05 21:13:44,571:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 21:13:44,571:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 21:13:44,572:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-01-05 21:13:44,577:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-05 21:13:44,582:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-05 21:13:44,648:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-05 21:13:44,694:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-05 21:13:44,695:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 21:13:44,695:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 21:13:44,700:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-05 21:13:44,705:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-05 21:13:44,777:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-05 21:13:44,826:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-05 21:13:44,826:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 21:13:44,827:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 21:13:44,827:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-01-05 21:13:44,837:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-05 21:13:44,904:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-05 21:13:44,951:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-05 21:13:44,951:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 21:13:44,952:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 21:13:44,962:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-05 21:13:45,028:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-05 21:13:45,074:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-05 21:13:45,074:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 21:13:45,074:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 21:13:45,075:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-01-05 21:13:45,152:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-05 21:13:45,198:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-05 21:13:45,198:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 21:13:45,198:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 21:13:45,273:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-05 21:13:45,319:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-05 21:13:45,320:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 21:13:45,320:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 21:13:45,320:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-01-05 21:13:45,396:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-05 21:13:45,446:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 21:13:45,447:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 21:13:45,521:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-05 21:13:45,568:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 21:13:45,568:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 21:13:45,568:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-01-05 21:13:45,690:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 21:13:45,690:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 21:13:45,815:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 21:13:45,815:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-01-05 21:13:45,816:INFO:Preparing preprocessing pipeline...
2023-01-05 21:13:45,818:INFO:Set up simple imputation.
2023-01-05 21:13:45,818:INFO:Set up column transformation.
2023-01-05 21:13:45,818:INFO:Set up feature normalization.
